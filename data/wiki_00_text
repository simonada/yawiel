Anarchism

Anarchism is an anti-authoritarian political philosophy that advocates self-governed societies based on voluntary, cooperative institutions and the rejection of coercive hierarchies those societies view as unjust. These institutions are often described as stateless societies, although several authors have defined them more specifically as distinct institutions based on non-hierarchical or free associations. Anarchism holds the state to be undesirable, unnecessary, and harmful. Any philosophy consistent with statelessness, that is, principled opposition to the State, is anarchist, thus anarchist schools of thought range from anarcho-communism to anarcho-capitalism.

While opposition to the state is central, many forms of anarchism specifically entail opposing authority or hierarchical organisation based on authority in the conduct of all human relations. Anarchism is often considered a far-left ideology, and much of anarchist economics and anarchist legal philosophy reflect anti-authoritarian interpretations of communism, collectivism, syndicalism, mutualism, or participatory economics.

Anarchism does not offer a fixed body of doctrine from a single particular world view, instead fluxing and flowing as a philosophy. Many types and traditions of anarchism exist, not all of which are mutually exclusive. Anarchist schools of thought can differ fundamentally, supporting anything from extreme individualism to complete collectivism. Strains of anarchism have often been divided into the categories of social and individualist anarchism or similar dual classifications.

The etymological origin of anarchism derives from ancient Greek word "anarkhia". "Anarkhia " meant "without a ruler" as it was composed by the prefix "a" (i.e "without") and the word "arkhos" (i.e leader or ruler). The suffix -ism is used to denote the ideological current that favours anarchism. The first known use of this word was in 1642. Various factions within the French Revolution labelled opponents as anarchists (as Maximilien Robespierre did the Hébertists) although few shared many views of later anarchists. There would be many revolutionaries of the early nineteenth century who contributed to the anarchist doctrines of the next generation, such as William Godwin and Wilhelm Weitling, but they did not use the word "anarchist" or "anarchism" in describing themselves or their beliefs.

The first political philosopher to call himself an anarchist was Pierre-Joseph Proudhon, marking the formal birth of anarchism in the mid-nineteenth century. Since the 1890s and beginning in France, the term "libertarianism" has often been used as a synonym for anarchism and its use as a synonym is still common outside the United States. On the other hand, some use libertarianism to refer to individualistic free market philosophy only, referring to free market anarchism as libertarian anarchism.

Defining anarchism is not an easy task. There is a lot of talk among scholars and anarchists on the matter and various currents perceive anarchism slightly differently. Hence, it might be true to say that anarchism is a cluster of political philosophies rejecting hierarchies (including the state and all associated institutions), in favour of a society based on voluntary association, freedom and decentralization. This definition though has its own shortcomings, as the definition based on etymology (which is simply a negation of a ruler), or based on anti-statism (anarchism is much more than that) or even the anti-authoritarian (which is an "a posteriori" concussion) Major elements of the definition of anarchism include a)the will for a non coercive society b)the rejection of State apparatus, c)belief in human nature, even though it is even harder to define it than anarchism d)a suggestion on how to act to pursue the ideal of anarchy.

The earliest anarchist themes can be found in the 6th century BC among the works of Taoist philosopher Laozi and in later centuries by Zhuangzi becomes a ruler of a Nation". Diogenes of Sinope and the Cynics as well as their contemporary Zeno of Citium, the founder of Stoicism, also introduced similar topics. Jesus is sometimes considered the first anarchist in the Christian anarchist tradition. Georges Lechartier wrote: "The true founder of anarchy was Jesus Christ and [...] the first anarchist society was that of the apostles". In early Islamic history, some manifestations of anarchic thought are found during the Islamic civil war over the Caliphate, where the Kharijites insisted that the imamate
The French Renaissance political philosopher Étienne de La Boétie wrote in his most famous work the "Discourse on Voluntary Servitude" what some historians consider an important anarchist precedent. The radical Protestant Christian Gerrard Winstanley and his group the Diggers are cited by various authors as proposing anarchist social measures in the 17th century in England. The term "anarchist" first entered the English language in 1642 during the English Civil War as a term of abuse, used by Royalists against their Roundhead opponents. By the time of the French Revolution, some such as the Enraged Ones began to use the term positively in opposition to Jacobin centralisation of power, seeing "revolutionary government" as oxymoronic. By the turn of the 19th century, the English word "anarchism" had lost its initial negative connotation.

Modern anarchism emerged from the secular or religious thought of the Enlightenment, particularly Jean-Jacques Rousseau
As part of the political turmoil of the 1790s in the wake of the French Revolution, William Godwin developed the first expression of modern anarchist thought. According to Peter Kropotkin, Godwin was "the first to formulate the political and economical conceptions of anarchism, even though he did not give that name to the ideas developed in his work" while Godwin attached his anarchist ideas to an early Edmund Burke.

Godwin is generally regarded as the founder of the school of thought known as philosophical anarchism. He argued in "Political Justice" (1793) that government has an inherently malevolent influence on society and that it perpetuates dependency and ignorance. He thought that the spread of the use of reason to the masses would eventually cause government to wither away as an unnecessary force. Although he did not accord the state with moral legitimacy, he was against the use of revolutionary tactics for removing the government from power. Rather, he advocated for its replacement through a process of peaceful evolution.

His aversion to the imposition of a rules-based society led him to denounce as a manifestation of the people's "mental enslavement" the foundations of law, property rights and even the institution of marriage. He considered the basic foundations of society as constraining the natural development of individuals to use their powers of reasoning to arrive at a mutually beneficial method of social organisation. In each case, government and its institutions are shown to constrain the development of our capacity to live wholly in accordance with the full and free exercise of private judgement.

The French Pierre-Joseph Proudhon is regarded as the first self-proclaimed anarchist, a label he adopted in his groundbreaking work "What is Property?", published in 1840. It is for this reason that some claim Proudhon as the founder of modern anarchist theory. He developed the theory of spontaneous order in society, where organisation emerges without a central coordinator imposing its own idea of order against the wills of individuals acting in their own interests. His famous quote on the matter is "Liberty is the mother, not the daughter, of order". In "What is Property?", Proudhon answers with the famous accusation "Property is theft". In this work, he opposed the institution of decreed "property" ("propriété"), where owners have complete rights to "use and abuse" their property as they wish. He contrasted this with what he called "possession", or limited ownership of resources and goods only while in more or less continuous use. However, Proudhon later added that "Property is Liberty" and argued that it was a bulwark against state power. His opposition to the state, organised religion and certain capitalist practices inspired subsequent anarchists and made him one of the leading social thinkers of his time.

The anarcho-communist Joseph Déjacque was the first person to describe himself as "libertarian". Unlike Proudhon, he argued that "it is not the product of his or her labour that the worker has a right to, but to the satisfaction of his or her needs, whatever may be their nature". In 1844, the post-Hegelian philosopher Max Stirner published in Germany the book, "The Ego and Its Own", which would later be considered an influential early text of individualist anarchism. French anarchists active in the 1848 Revolution included Anselme Bellegarrigue
In Europe, harsh reaction followed the revolutions of 1848, during which ten countries had experienced brief or long-term social upheaval as groups carried out nationalist uprisings. After most of these attempts at systematic change ended in failure, conservative elements took advantage of the divided groups of socialists, liberals and nationalists along with anarchists to prevent further revolt. In Spain, Ramón de la Sagra established the anarchist journal "El Porvenir" in La Coruña in 1845 which was inspired by Proudhon's ideas. The Catalan politician Francesc Pi i Margall became the principal translator of Proudhon's works into Spanish and later briefly became President of Spain in 1873 while being the leader of the Federal Democratic Republican Party. According to George Woodcock: "These translations were to have a profound and lasting effect on the development of Spanish anarchism after 1870, but before that time Proudhonian ideas, as interpreted by Pi, already provided much of the inspiration for the federalist movement which sprang up in the early 1860s". According to the "Encyclopædia Britannica": "During the Spanish revolution of 1873, Pi y Margall attempted to establish a decentralised, or "cantonalist," political system on Proudhonian lines".

In 1864, the International Workingmen's Association (sometimes called the First International) united diverse revolutionary currents including French followers of Proudhon, Blanquists, Philadelphes, English trade unionists, socialists and social democrats. Due to its links to active workers' movements, the International became a significant organisation. Karl Marx became a leading figure in the International and a member of its General Council. Proudhon's followers, the mutualists, opposed Marx's state socialism, advocating political abstentionism and small property holdings. Woodcock also reports that the American individualist anarchists Lysander Spooner and William Batchelder Greene had been members of the First International. In 1868, following their unsuccessful participation in the League of Peace and Freedom (LPF) Russian revolutionary Mikhail Bakunin and his collectivist anarchist associates joined the First International, which had decided not to get involved with the LPF. They allied themselves with the federalist socialist sections of the International, who advocated the revolutionary overthrow of the state and the collectivisation of property. At first, the collectivists worked with the Marxists to push the First International in a more revolutionary socialist direction. Subsequently, the International became polarised into two camps, with Marx and Bakunin as their respective figureheads. Bakunin characterised Marx's ideas as centralist and predicted that if a Marxist party came to power, its leaders would simply take the place of the ruling class they had fought against.

Anarchist historian George Woodcock reports: "The annual Congress of the International had not taken place in 1870 owing to the outbreak of the Paris Commune, and in 1871 the General Council called only a special conference in London. One delegate was able to attend from Spain and none from Italy, while a technical excuse—that they had split away from the Fédération Romande—was used to avoid inviting Bakunin's Swiss supporters. Thus only a tiny minority of anarchists was present, and the General Council's resolutions passed almost unanimously. Most of them were clearly directed against Bakunin and his followers". In 1872, the conflict climaxed with a final split between the two groups at the Hague Congress, where Bakunin and James Guillaume were expelled from the International and its headquarters were transferred to New York. In response, the federalist sections formed their own International at the St. Imier Congress, adopting a revolutionary anarchist programme.

The Paris Commune was a government that briefly ruled Paris from 18 March (more formally, from 28 March) to 28 May 1871. The Commune was the result of an uprising in Paris after France was defeated in the Franco-Prussian War. Anarchists participated actively in the establishment of the Paris Commune. They included Louise Michel, the Reclus brothers (Élie Reclus and Élisée Reclus) and Eugene Varlin (the latter murdered in the repression afterwards). As for the reforms initiated by the Commune, such as the re-opening of workplaces as co-operatives, anarchists can see their ideas of associated labour beginning to be realised. Moreover, the Commune's ideas on federation obviously reflected the influence of Proudhon on French radical ideas. The Commune's vision of a communal France based on a federation of delegates bound by imperative mandates issued by their electors and subject to recall at any moment echoes Bakunin's and Proudhon's ideas (Proudhon, like Bakunin, had argued in favour of the "implementation of the binding mandate" in 1848 and for federation of communes), thus both economically and politically the Paris Commune was heavily influenced by anarchist ideas. George Woodcock states that "a notable contribution to the activities of the Commune and particularly to the organization of public services was made by members of various anarchist factions, including the mutualists Courbet, Longuet, and Vermorel, the libertarian collectivists Varlin, Malon, and Lefrangais, and the bakuninists Elie and Elisée Reclus and Louise Michel".

The anti-authoritarian sections of the First International were the precursors of the anarcho-syndicalists, seeking to "replace the privilege and authority of the State" with the "free and spontaneous organization of labour". In 1886, the Federation of Organized Trades and Labor Unions of the United States and Canada unanimously set 1 May 1886 as the date by which the eight-hour work day
In response, unions across the United States prepared a general strike in support of the event. On 3 May, a fight broke out in Chicago when strikebreakers attempted to cross the picket line and two workers died when police opened fire upon the crowd. The next day on 4 May, anarchists staged a rally at Chicago's Haymarket Square. A bomb was thrown by an unknown party near the conclusion of the rally, killing an officer. In the ensuing panic, police opened fire on the crowd and each other. Seven police officers and at least four workers were killed. Eight anarchists directly and indirectly related to the organisers of the rally were arrested and charged with the murder of the deceased officer. The men became international political celebrities among the labour movement. Four of the men were executed and a fifth committed suicide prior to his own execution. The incident became known as the Haymarket affair and was a setback for the labour movement and the struggle for the eight-hour day. In 1890, a second attempt—this time international in scope—to organise for the eight-hour day was made. The event also had the secondary purpose of memorialising workers killed as a result of the Haymarket affair. Although it had initially been conceived as a once-off event, by the following year the celebration of International Workers' Day on May Day had become firmly established as an international worker's holiday.

In 1907, the International Anarchist Congress of Amsterdam gathered delegates from 14 different countries, among which were important figures of the anarchist movement, including Errico Malatesta, Pierre Monatte, Luigi Fabbri, Benoît Broutchoux, Emma Goldman, Rudolf Rocker and Christiaan Cornelissen. Various themes were treated during the Congress, in particular concerning the organisation of the anarchist movement, popular education issues, the general strike or antimilitarism. A central debate concerned the relation between anarchism and syndicalism (or trade unionism). Malatesta and Monatte were in particular disagreement themselves on this issue as the latter thought that syndicalism was revolutionary and would create the conditions of a social revolution while Malatesta did not consider syndicalism by itself sufficient. He thought that the trade union movement was reformist and even conservative, citing as essentially bourgeois and anti-worker the phenomenon of professional union officials. Malatesta warned that the syndicalists aims were in perpetuating syndicalism itself, whereas anarchists must always have anarchy as their end and consequently refrain from committing to any particular method of achieving it.

In 1881, the Spanish Workers Federation was the first major anarcho-syndicalist movement—anarchist trade union federations were of special importance in Spain. The most successful was the Confederación Nacional del Trabajo (National Confederation of Labour, CNT), founded in 1910. Before the 1940s, the CNT was the major force in Spanish working class politics, attracting 1.58 million members at one point and playing a major role in the Spanish Civil War. The CNT was affiliated with the International Workers Association, a federation of anarcho-syndicalist trade unions founded in 1922, with delegates representing two million workers from 15 countries in Europe and Latin America. In Latin America in particular, "[t]he anarchists quickly became active in organising craft and industrial workers throughout South and Central America, and until the early 1920s most of the trade unions in Mexico, Brazil, Peru, Chile, and Argentina were anarcho-syndicalist in general outlook; the prestige of the Spanish C.N.T. as a revolutionary organisation was undoubtedly to a great extent responsible for this situation. The largest and most militant of these organisations was the Federación Obrera Regional Argentina
Some anarchists, such as Johann Most, advocated publicising violent acts of retaliation against counter-revolutionaries because "we preach not only action in and for itself, but also action as propaganda". Scholars such as Beverly Gage contend that this was not advocacy of mass murder, but targeted killings of members of the ruling class at times when such actions might garner sympathy from the population, such as during periods of heightened government repression or labor conflicts where workers were killed. However, Most himself once boasted that "the existing system will be quickest and most radically overthrown by the annihilation of its exponents. Therefore, massacres of the enemies of the people must be set in motion". Most is best known for a pamphlet published in 1885, "The Science of Revolutionary Warfare", a how-to manual on the subject of making explosives based on knowledge he acquired while working at an explosives plant in New Jersey.

By the 1880s, people inside and outside the anarchist movement began to use the slogan, "propaganda of the deed" to refer to individual bombings, regicides and tyrannicides. From 1905 onwards, the Russian counterparts of these anti-syndicalist anarchist-communists become partisans of economic terrorism and illegal "expropriations". Illegalism as a practice emerged and within it "[t]he acts of the anarchist bombers and assassins ("propaganda by the deed") and the anarchist burglars ("individual reappropriation") expressed their desperation and their personal, violent rejection of an intolerable society. Moreover, they were clearly meant to be exemplary invitations to revolt". France's Bonnot Gang was the most famous group to embrace illegalism.

However, important figures in the anarchist movement distanced themselves from such individual acts as soon as 1887. Peter Kropotkin thus wrote that year in "Le Révolté" that "a structure based on centuries of history cannot be destroyed with a few kilos of dynamite". A variety of anarchists advocated the abandonment of these sorts of tactics in favour of collective revolutionary action, for example through the trade union movement. The anarcho-syndicalist Fernand Pelloutier argued in 1895 for renewed anarchist involvement in the labour movement on the basis that anarchism could do very well without "the individual dynamiter".

State repression (including the infamous 1894 French "lois scélérates") of the anarchist and labour movements following the few successful bombings and assassinations may have contributed in the first place to the abandonment of these kinds of tactics, although reciprocally state repression may have played a role in these isolated acts. The dismemberment of the French socialist movement into many groups and—following the suppression of the 1871—Paris Commune the execution and exile of many "communards" to penal colonies favoured individualist political expression and acts.

Numerous heads of state were assassinated between 1881 and 1914 by members of the anarchist movement, including Tsar Alexander II of Russia, President Sadi Carnot of France, Prime Minister Antonio Cánovas del Castillo of Spain, Empress Elisabeth of Austria, King Umberto I of Italy, President William McKinley of the United States, King Carlos I of Portugal and King George I of Greece. McKinley's assassin Leon Czolgosz claimed to have been influenced by anarchist and feminist
Anarchists participated alongside the Bolsheviks in both February and October revolutions and were initially enthusiastic about the Bolshevik revolution. However, following a political falling out with the Bolsheviks by the anarchists and other left-wing opposition the conflict culminated in the 1921 Kronstadt rebellion, which the new government repressed. Anarchists in central Russia were either imprisoned, driven underground or joined the victorious Bolsheviks; the anarchists from Petrograd and Moscow fled to Ukraine. In the Free Territory, they fought in the civil war against the Whites (a grouping of monarchists and other opponents of the October Revolution) and then the Bolsheviks as part of the Revolutionary Insurrectionary Army of Ukraine led by Nestor Makhno, who established an anarchist society in the region for a number of months.

Expelled American anarchists Emma Goldman and Alexander Berkman were among those agitating in response to Bolshevik policy and the suppression of the Kronstadt uprising, before they left Russia. Both wrote accounts of their experiences in Russia, criticising the amount of control the Bolsheviks exercised. For them, Bakunin's predictions about the consequences of Marxist rule that the rulers of the new "socialist" Marxist state would become a new elite had proved all too true.

The victory of the Bolsheviks in the October Revolution and the resulting Russian Civil War did serious damage to anarchist movements internationally. Many workers and activists saw Bolshevik success as setting an example and communist parties grew at the expense of anarchism and other socialist movements. In France and the United States, for example, members of the major syndicalist movements of the General Confederation of Labour and Industrial Workers of the World (IWW) left the organisations and joined the Communist International.

The revolutionary wave of 1917–1923 saw the active participation of anarchists in varying degrees of protagonism. In the German uprising known as the German Revolution of 1918–19 which established the Bavarian Soviet Republic, the anarchists Gustav Landauer, Silvio Gesell and Erich Mühsam had important leadership positions within the revolutionary councilist structures. In the Italian events known as the "biennio rosso", the anarcho-syndicalist trade union Unione Sindacale Italiana "grew to 800,000 members and the influence of the Italian Anarchist Union (20,000 members plus "Umanita Nova", its daily paper) grew accordingly [...] Anarchists were the first to suggest occupying workplaces." In the Mexican Revolution, the Mexican Liberal Party was established and during the early 1910s it led a series of military offensives leading to the conquest and occupation of certain towns and districts in Baja California with the leadership of anarcho-communist Ricardo Flores Magón.

In Paris, the Dielo Truda group of Russian anarchist exiles, which included Nestor Makhno, concluded that anarchists needed to develop new forms of organisation in response to the structures of Bolshevism. Their 1926 manifesto, called the "Organisational Platform of the General Union of Anarchists (Draft)", was supported. Platformist groups active today include the Workers Solidarity Movement in Ireland and the North Eastern Federation of Anarchist Communists of North America. Synthesis anarchism emerged as an organisational alternative to platformism that tries to join anarchists of different tendencies under the principles of anarchism without adjectives. In the 1920s, this form found as its main proponents Volin and Sebastien Faure. It is the main principle behind the anarchist federations grouped around the contemporary global International of Anarchist Federations.

In the 1920s and 1930s, the rise of fascism in Europe transformed anarchism's conflict with the state. Italy saw the first struggles between anarchists and Benito Mussolini's fascists. Italian anarchists played a key role in the anti-fascist organisation "Arditi del Popolo", which was strongest in areas with anarchist traditions and achieved some success in their activism, such as repelling Blackshirts in the anarchist stronghold of Parma in August 1922. The veteran Italian anarchist Luigi Fabbri was one of the first critical theorists of fascism, describing it as "the preventive counter-revolution". In France, where the far-right leagues came close to insurrection in the February 1934 riots, anarchists divided over a united front policy.

Anarchists in France and Italy were active in the Resistance during World War II. In Germany, the anarchist Erich Mühsam was arrested on charges unknown in the early morning hours of 28 February 1933, within a few hours after the Reichstag fire in Berlin. Joseph Goebbels, the Nazi propaganda minister, labelled him as one of "those Jewish subversives". Over the next seventeen months, he would be imprisoned in the concentration camps at Sonnenburg, Brandenburg and finally, Oranienburg. On 2 February 1934, Mühsam was transferred to the concentration camp at Oranienburg when finally on the night of 9 July 1934, Mühsam was tortured and murdered by the guards, his battered corpse found hanging in a latrine the next morning.

In Spain, the national anarcho-syndicalist trade union CNT initially refused to join a popular front electoral alliance and abstention by CNT supporters led to a right-wing election victory. In 1936, the CNT changed its policy and anarchist votes helped bring the popular front back to power. Months later, conservative members of the military, with the support of minority extreme-right parties, responded with an attempted coup, causing the Spanish Civil War (1936–1939). In response to the army rebellion, an anarchist-inspired movement of peasants and workers, supported by armed militias, took control of Barcelona and of large areas of rural Spain where they collectivised the land. However, the anarchists were losing ground even before the fascist victory in 1939 in a bitter struggle with the Stalinists, who controlled much of the distribution of military aid to the Republicans cause from the Soviet Union. According to Noam Chomsky, "the communists were mainly responsible for the destruction of the Spanish anarchists. Not just in Catalonia—the communist armies mainly destroyed the collectives elsewhere. The communists basically acted as the police force of the security system of the Republic and were very much opposed to the anarchists, partially because Stalin still hoped at that time to have some kind of pact with Western countries against Adolf Hitler. That failed and Stalin withdrew the support to the Republic. They even withdrew the Spanish gold reserves". The events known as the Spanish Revolution was a workers' social revolution that began during the outbreak of the Spanish Civil War in 1936 and resulted in the widespread implementation of anarchist and more broadly libertarian socialist organisational principles throughout various portions of the country for two to three years, primarily Catalonia, Aragon, Andalusia and parts of Levante. Much of Spain's economy was put under worker control and in anarchist strongholds like Catalonia the figure was as high as 75%, but lower in areas with heavy Communist Party of Spain influence as the Soviet-allied party actively resisted attempts at collectivisation enactment. Factories were run through worker committees, agrarian areas became collectivised and run as libertarian communes. Anarchist historian Sam Dolgoff estimated that about eight million people participated directly or at least indirectly in the Spanish Revolution, which he claimed "came closer to realising the ideal of the free stateless society on a vast scale than any other revolution in history". Spanish Communist Party-led troops suppressed the collectives and persecuted both dissident Marxists and anarchists. The prominent Italian anarchist Camillo Berneri, who volunteered to fight against Francisco Franco was killed instead in Spain by gunmen associated with the Spanish Communist Party. The city of Madrid was turned over to the Francoist forces by the last non-francoist mayor of the city, the anarchist Melchor Rodríguez García.

Anarchism sought to reorganise itself after the war and in this context the organisational debate between synthesis anarchism and platformism took importance once again especially in the anarchist movements of Italy and France. The Mexican Anarchist Federation was established in 1945 after the Anarchist Federation of the Centre united with the Anarchist Federation of the Federal District. In the early 1940s, the Antifascist International Solidarity and the Federation of Anarchist Groups of Cuba merged into the large national organisation Asociación Libertaria de Cuba (Cuban Libertarian Association). From 1944 to 1947, the Bulgarian Anarchist Communist Federation reemerged as part of a factory and workplace committee movement, but was repressed by the new Communist regime. In 1945 in France the Fédération Anarchiste and the anarchosyndicalist trade union Confédération nationale du travail was established in the next year while the also synthesist Federazione Anarchica Italiana was founded in Italy. Korean anarchists formed the League of Free Social Constructors in September 1945 and in 1946 the Japanese Anarchist Federation was founded. An International Anarchist Congress with delegates from across Europe was held in Paris in May 1948. After World War II, an appeal in the "Fraye Arbeter Shtime" detailing the plight of German anarchists and called for Americans to support them. By February 1946, the sending of aid parcels to anarchists in Germany was a large-scale operation. The Federation of Libertarian Socialists was founded in Germany in 1947 and Rudolf Rocker wrote for its organ, "Die Freie Gesellschaft", which survived until 1953. In 1956, the Uruguayan Anarchist Federation was founded. In 1955, the Anarcho-Communist Federation of Argentina renamed itself as the Argentine Libertarian Federation. The Syndicalist Workers' Federation (SWF) was a syndicalist group in active in post-war Britain, and one of Solidarity Federation's earliest predecessors. It was formed in 1950 by members of the dissolved Anarchist Federation of Britain (AFB). Unlike the AFB, which was influenced by anarcho-syndicalist ideas but ultimately not syndicalist itself, the SWF decided to pursue a more definitely syndicalist, worker-centred strategy from the outset.

Anarchism continued to influence important literary and intellectual personalities of the time, such as Albert Camus, Herbert Read, Paul Goodman, Dwight Macdonald, Allen Ginsberg, George Woodcock, Leopold Kohr, Julian Beck, John Cage and the French Surrealist group led by André Breton, which now openly embraced anarchism and collaborated in the Fédération Anarchiste.

Anarcho-pacifism became influential in the Anti-nuclear movement and anti war movements of the time as can be seen in the activism and writings of the English anarchist member of Campaign for Nuclear Disarmament Alex Comfort or the similar activism of the American catholic anarcho-pacifists Ammon Hennacy and Dorothy Day. Anarcho-pacifism became a "basis for a critique of militarism on both sides of the Cold War". The resurgence of anarchist ideas during this period is well documented in Robert Graham's Anarchism: A Documentary History of Libertarian Ideas
A surge of popular interest in anarchism occurred in western nations during the 1960s and 1970s. Anarchism was influential in the Counterculture of the 1960s and anarchists actively participated in the late sixties students and workers revolts. In 1968, in Carrara, Italy the International of Anarchist Federations was founded during an international anarchist conference held there in 1968 by the three existing European federations of France (the Fédération Anarchiste), the Federazione Anarchica Italiana of Italy and the Iberian Anarchist Federation as well as the Bulgarian federation in French exile.

In the United Kingdom in the 1970s, this was associated with the punk rock movement as exemplified by bands such as Crass and the Sex Pistols. The housing and employment crisis in most of Western Europe led to the formation of communes and squatter movements like that of Barcelona, Spain. In Denmark, squatters occupied a disused military base and declared the Freetown Christiania, an autonomous haven in central Copenhagen. Since the revival of anarchism in the mid-20th century, a number of new movements and schools of thought emerged. Although feminist tendencies have always been a part of the anarchist movement in the form of anarcha-feminism, they returned with vigour during the second wave of feminism in the 1960s. Anarchist anthropologist David Graeber and anarchist historian Andrej Grubacic have posited a rupture between generations of anarchism, with those "who often still have not shaken the sectarian habits" of the 19th century contrasted with the younger activists who are "much more informed, among other elements, by indigenous, feminist, ecological and cultural-critical ideas" and who by the turn of the 21st century formed "by far the majority" of anarchists.

Since the 1980s, anarchism has grown into a strong political force in Latin America, with the development of Fejuve (1979), CIPO-RFM (1980s), Zapatistas (1994), Horizontilidad (2001) and the Oaxaca Uprising (2006). Around the turn of the 21st century, anarchism grew in popularity and influence as part of the anti-war, anti-capitalist, and anti-globalisation movements. Anarchists became known for their involvement in protests against the meetings of the World Trade Organization (WTO), Group of Eight (G8) and the World Economic Forum (WEF). Some anarchist factions at these protests engaged in rioting, property destruction, and violent confrontations with police. These actions were precipitated by ad hoc, leaderless, anonymous cadres known as black blocs—other organisational tactics pioneered in this time include security culture, affinity groups and the use of decentralised technologies such as the internet. A significant event of this period was the confrontations at WTO conference in Seattle in 1999. According to anarchist scholar Simon Critchley, "contemporary anarchism can be seen as a powerful critique of the pseudo-libertarianism of contemporary neo-liberalism
International anarchist federations in existence include the International of Anarchist Federations, the International Workers' Association and International Libertarian Solidarity. The largest organised anarchist movement today is in Spain in the form of the Confederación General del Trabajo (CGT) and the CNT. CGT membership was estimated at around 100,000 for 2003.

Anarchist ideas have been influential in the development of the Democratic Federation of Northern Syria (DFNS), more commonly known as Rojava, a "de facto" autonomous region in northern Syria. Abdullah Öcalan—a founding member of the Kurdistan Workers' Party (PKK) who is currently imprisoned in Turkey—is an iconic and popular figure in the DFNS whose ideas shaped the region's society and politics. While in prison, Öcalan corresponded with (and was influenced by) Murray Bookchin, an anarcho-communist theorist and philosopher who developed Communalism and libertarian municipalism. Modelled after Bookchin's ideas, Öcalan developed the theory of democratic confederalism. In March 2005, he issued his "Declaration of Democratic Confederalism in Kurdistan", calling upon citizens "to stop attacking the government and instead create municipal assemblies, which he called 'democracy without the state
Anarchist schools of thought had been generally grouped in two main historical traditions, individualist anarchism and social anarchism, which have some different origins, values and evolution. The individualist wing of anarchism emphasises negative liberty, i.e. opposition to state or social control over the individual, while those in the social wing emphasise positive liberty to achieve one's potential and argue that humans have needs that society ought to fulfil, "recognising equality of entitlement". In a chronological and theoretical sense, there are classical—those created throughout the 19th century—and post-classical anarchist schools—those created since the mid-20th century and after.

Beyond the specific factions of anarchist thought is philosophical anarchism, which embodies the theoretical stance that the state lacks moral legitimacy without accepting the imperative of revolution to eliminate it. A component especially of individualist anarchism philosophical anarchism may accept the existence of a minimal state as unfortunate, and usually temporary, "necessary evil" but argue that citizens do not have a moral obligation to obey the state when its laws conflict with individual autonomy. One reaction against sectarianism within the anarchist milieu was "anarchism without adjectives", a call for toleration first adopted by Fernando Tarrida del Mármol in 1889 in response to the "bitter debates" of anarchist theory at the time. In abandoning the hyphenated anarchisms (i.e. collectivist-, communist-, mutualist- and individualist-anarchism), it sought to emphasise the anti-authoritarian beliefs common to all anarchist schools of thought.

Mutualism began in 18th-century English and French labour movements before taking an anarchist form associated with Pierre-Joseph Proudhon in France and others in the United States. Proudhon proposed spontaneous order, whereby organisation emerges without central authority, a "positive anarchy" where order arises when everybody does "what he wishes and only what he wishes" and where "business transactions alone produce the social order." Proudhon distinguished between ideal political possibilities and practical governance. For this reason, much in contrast to some of his theoretical statements concerning ultimate spontaneous self-governance, Proudhon was heavily involved in French parliamentary politics and allied himself not with anarchist but socialist factions of workers' movements and, in addition to advocating state-protected charters for worker-owned cooperatives, promoted certain nationalisation schemes during his life of public service.

Mutualist anarchism is concerned with reciprocity, free association, voluntary contract, federation, and credit and currency reform. According to the American mutualist William Batchelder Greene, each worker in the mutualist system would receive "just and exact pay for his work; services equivalent in cost being exchangeable for services equivalent in cost, without profit or discount". Mutualism has been retrospectively characterised as ideologically situated between individualist and collectivist forms of anarchism. Proudhon first characterised his goal as a "third form of society, the synthesis of communism and property".

Social anarchism calls for a system with common ownership of means of production and democratic control of all organisations, without any government authority or coercion. It is the largest school of thought in anarchism. Social anarchism rejects private property, seeing it as a source of social inequality (while retaining respect for personal property) and emphasises cooperation and mutual aid.

Collectivist anarchism, also referred to as revolutionary socialism or a form of such, is a revolutionary form of anarchism, commonly associated with Mikhail Bakunin and Johann Most. Collectivist anarchists oppose all private ownership of the means of production, instead advocating that ownership be collectivised. This was to be achieved through violent revolution, first starting with a small cohesive group through acts of violence, or propaganda by the deed, which would inspire the workers as a whole to revolt and forcibly collectivise the means of production.

However, collectivisation was not to be extended to the distribution of income as workers would be paid according to time worked, rather than receiving goods being distributed "according to need" as in anarcho-communism. This position was criticised by anarchist communists as effectively "uphold[ing] the wages system". Collectivist anarchism arose contemporaneously with Marxism, but opposed the Marxist dictatorship of the proletariat despite the stated Marxist goal of a collectivist stateless society. Anarchist, communist and collectivist ideas are not mutually exclusive
Anarcho-communism (also known as anarchist-communism, libertarian communism and occasionally as free communism) is a theory of anarchism that advocates abolition of the state, markets, money, private property (while retaining respect for personal property) and capitalism in favour of common ownership of the means of production, direct democracy and a horizontal network of voluntary associations and workers' councils with production and consumption based on the guiding principle: "From each according to his ability, to each according to his need".

Some forms of anarchist communism such as insurrectionary anarchism are strongly influenced by egoism and radical individualism, believing anarcho-communism is the best social system for the realisation of individual freedom. Most anarcho-communists view anarcho-communism as a way of reconciling the opposition between the individual and society.

Anarcho-communism developed out of radical socialist currents after the French Revolution but was first formulated as such in the Italian section of the First International. The theoretical work of Peter Kropotkin took importance later as it expanded and developed pro-organisationalist and insurrectionary anti-organisationalist sections. To date, the best known examples of an anarchist communist society (i.e. established around the ideas as they exist today and achieving worldwide attention and knowledge in the historical canon), are the anarchist territories during the Spanish Revolution and the Free Territory during the Russian Revolution. Through the efforts and influence of the Spanish anarchists during the Spanish Revolution within the Spanish Civil War, starting in 1936 anarchist communism existed in most of Aragon, parts of the Levante and Andalusia as well as in the stronghold of anarchist Catalonia before being crushed by the combined forces of the regime that won the war
Anarcho-syndicalism, direct action and workers' self-management. Anarcho-syndicalists believe that only direct action—that is, action concentrated on directly attaining a goal as opposed to indirect action, such as electing a representative to a government position—will allow workers to liberate themselves. Moreover, anarcho-syndicalists believe that workers' organisations (the organisations that struggle against the wage system, which in anarcho-syndicalist theory will eventually form the basis of a new society) should be self-managing. They should not have bosses or "business agents"—rather, the workers should be able to make all the decisions that affect them themselves. Rudolf Rocker was one of the most popular voices in the anarcho-syndicalist movement. He outlined a view of the origins of the movement, what it sought and why it was important to the future of labour in his 1938 pamphlet "Anarcho-Syndicalism". The International Workers Association is an international anarcho-syndicalist federation of various labour unions from different countries. The Spanish CNT played and still plays a major role in the Spanish labour movement. It was also an important force in the Spanish Civil War.

Individualist anarchism refers to several traditions of thought within the anarchist movement that emphasise the individual and their will over any kinds of external determinants such as groups, society, traditions and ideological systems. Individualist anarchism is not a single philosophy, but it instead refers to a group of individualistic philosophies that sometimes are in conflict.

In 1793, William Godwin, who has often been cited as the first anarchist, wrote "Political Justice", which some consider the first expression of anarchism. Godwin was a philosophical anarchist and from a rationalist and utilitarian basis opposed revolutionary action and saw a minimal state
An influential form of individualist anarchism, called "egoism", or egoist anarchism, was expounded by one of the earliest and best-known proponents of individualist anarchism, the German Max Stirner. Stirner's "The Ego and Its Own", published in 1844, is a founding text of the philosophy. According to Stirner, the only limitation on the rights of individuals is their power to obtain what they desire, without regard for God, state, or morality. To Stirner, rights were "spooks" in the mind and he held that society does not exist, but "the individuals are its reality". Stirner advocated self-assertion and foresaw unions of egoists, non-systematic associations continually renewed by all parties' support through an act of will, which Stirner proposed as a form of organisation in place of the state. Egoist anarchists argue that egoism will foster genuine and spontaneous union between individuals. "Egoism" has inspired many interpretations of Stirner's philosophy. It was re-discovered and promoted by German philosophical anarchist and homosexual activist John Henry Mackay.

Josiah Warren is widely regarded as the first American anarchist, and the four-page weekly paper he edited during 1833, "The Peaceful Revolutionist", was the first anarchist periodical published. For American anarchist historian Eunice Minette Schuster, "[i]t is apparent [...] that Proudhonian Anarchism was to be found in the United States at least as early as 1848 and that it was not conscious of its affinity to the Individualist Anarchism of Josiah Warren and Stephen Pearl Andrews [...] William B. Greene presented this Proudhonian Mutualism in its purest and most systematic form". Henry David Thoreau (1817–1862) was an important early influence in individualist anarchist thought in the United States and Europe. Thoreau was an American author, poet, naturalist, tax resister, development critic, surveyor, historian, philosopher and leading transcendentalist. He is best known for his books "Walden", a reflection upon simple living in natural surroundings, as well as his essay, "Civil Disobedience", an argument for individual resistance to civil government in moral opposition to an unjust state. Benjamin Tucker later fused Stirner's egoism with the economics of Warren and Proudhon in his eclectic influential publication "Liberty".

From these early influences, individualist anarchism in different countries attracted a small yet diverse following of Bohemian artists and intellectuals, free love and birth control advocates (see anarchism and issues related to love and sex), individualist naturists and nudists (see anarcho-naturism), freethought and anti-clerical activists as well as young anarchist outlaws in what became known as illegalism and individual reclamation (see European individualist anarchism and individualist anarchism in France). These authors and activists included Oscar Wilde, Emile Armand, Han Ryner, Henri Zisly, Renzo Novatore, Miguel Gimenez Igualada, Adolf Brand and Lev Chernyi
Anarchism continues to generate many philosophies and movements, at times eclectic, drawing upon various sources and syncretic, combining disparate concepts to create new philosophical approaches.

Insurrectionary anarchism is a revolutionary theory, practice, and tendency within the anarchist movement which emphasises insurrection within anarchist practice. It is critical of formal organisations such as labour unions and federations that are based on a political programme and periodic congresses. Instead, insurrectionary anarchists advocate informal organisation and small affinity group based organisation. Insurrectionary anarchists put value in attack, permanent class conflict and a refusal to negotiate or compromise with class enemies.

Green anarchism (or eco-anarchism) is a school of thought within anarchism that emphasises environmental issues, with an important precedent in anarcho-naturism and whose main contemporary currents are anarcho-primitivism and social ecology. Writing from a green anarchist perspective, John Zerzan attributes the ills of today's social degradation to technology and the birth of agricultural civilization. While Layla AbdelRahim argues that "the shift in human consciousness was also a shift in human subsistence strategies, whereby some human animals reinvented their narrative to center murder and predation and thereby institutionalize violence". Thus, according to her, civilization was the result of the human development of technologies and grammar for predatory economics. Language and literacy, she claims, are some of these technologies.

Anarcha-feminism (also called anarchist feminism and anarcho-feminism) combines anarchism with feminism. It generally views patriarchy as a manifestation of involuntary coercive hierarchy that should be replaced by decentralised free association. Anarcha-feminists believe that the struggle against patriarchy is an essential part of class struggle, and the anarchist struggle against the state. In essence, the philosophy sees anarchist struggle as a necessary component of feminist struggle and vice versa. L. Susan Brown claims that "as anarchism is a political philosophy that opposes all relationships of power, it is inherently feminist". Anarcha-feminism began with the late 19th-century writings of early feminist anarchists such as Emma Goldman and Voltairine de Cleyre.

Anarcho-pacifism is a tendency that rejects violence in the struggle for social change (see non-violence). It developed mostly in the Netherlands, Britain and the United States before and during the Second World War. Christian anarchism is a movement in political theology that combines anarchism and Christianity. Its main proponents included Leo Tolstoy, Dorothy Day, Ammon Hennacy and Jacques Ellul.

Religious anarchism refers to a set of related anarchist ideologies that are inspired by the teachings of (organized) religions, but many anarchists have traditionally been skeptical of and opposed to organized religion. Many different religions have served as inspiration for religious forms of anarchism, most notably Christianity as Christian anarchists believe that biblical teachings give credence to anarchist philosophy. Non-Christian forms of religious anarchism include Buddhist anarchism, Jewish anarchism and most recently Neopaganism.

Synthesis anarchism is a form of anarchism that tries to join anarchists of different tendencies under the principles of anarchism without adjectives. In the 1920s, this form found as its main proponents the anarcho-communists Voline and Sébastien Faure. It is the main principle behind the anarchist federations grouped around the contemporary global International of Anarchist Federations.

Platformism is a tendency within the wider anarchist movement based on the organisational theories in the tradition of Dielo Truda's "Organisational Platform of the General Union of Anarchists (Draft)". The document was based on the experiences of Russian anarchists in the 1917 October Revolution, which led eventually to the victory of the Bolsheviks over the anarchists and other groups. The "Platform" attempted to address and explain the anarchist movement's failures during the Russian Revolution.

Post-left anarchy is a recent current in anarchist thought that promotes a critique of anarchism's relationship to traditional left-wing politics. Some post-leftists seek to escape the confines of ideology in general also presenting a critique of organisations and morality. Influenced by the work of Max Stirner and by the Marxist Situationist International, post-left anarchy is marked by a focus on social insurrection and a rejection of leftist social organisation.

Post-anarchism is a theoretical move towards a synthesis of classical anarchist theory and poststructuralist thought, drawing from diverse ideas including post-left anarchy, postmodernism, autonomism, postcolonialism and the Situationist International.

Queer anarchism is a form of socialism which suggests anarchism as a solution to the issues faced by the LGBT community, mainly heteronormativity, homophobia, transphobia and biphobia. Anarcho-queer arose during the late 20th century based on the work of Michel Foucault "The History of Sexuality".

Left-wing market anarchism strongly affirm the classical liberal ideas of self-ownership and free markets while maintaining that taken to their logical conclusions, these ideas support strongly anti-corporatist, anti-hierarchical, pro-labour positions and anti-capitalism in economics and anti-imperialism in foreign policy.

Anarcho-capitalism advocates the elimination of the state in favour of self-ownership in a free market. Anarcho-capitalism developed from radical anti-state libertarianism and individualist anarchism, drawing from Austrian School economics, study of law and economics and public choice theory. There is a strong current within anarchism which believes that anarcho-capitalism cannot be considered a part of the anarchist movement due to the fact that anarchism has historically been an anti-capitalist movement and for definitional reasons which see anarchism as incompatible with capitalist forms.

Anarcho-transhumanism is a recently new branch of anarchism that takes traditional and modern anarchism, typically drawing from anarcho-syndicalism, left-libertarianism or libertarian socialism and combines it with transhumanism and post-humanism. It can be described as a "liberal democratic revolution, at its core the idea that people are happiest when they have rational control over their lives. Reason, science, and technology provide one kind of control, slowly freeing us from ignorance, toil, pain, disease and limited lifespans (aging)". Some anarcho-transhumanists might also follow technogaianism

Anarchism is a philosophy that embodies many diverse attitudes, tendencies and schools of thought and as such disagreement over questions of values, ideology and tactics is common. The compatibility of capitalism, nationalism and religion with anarchism is widely disputed. Similarly, anarchism enjoys complex relationships with ideologies such as Marxism, communism, collectivism, syndicalism/trade unionism and capitalism. Anarchists may be motivated by humanism, divine authority, enlightened self-interest, veganism or any number of alternative ethical doctrines.

Phenomena such as civilisation, technology (e.g. within anarcho-primitivism) and the democratic process may be sharply criticised within some anarchist tendencies and simultaneously lauded in others.

On a tactical level, while propaganda of the deed was a tactic used by anarchists in the 19th century (e.g. the nihilist movement), some contemporary anarchists espouse alternative direct action methods such as nonviolence, counter-economics and anti-state cryptography to bring about an anarchist society. About the scope of an anarchist society, some anarchists advocate a global one, while others do so by local ones. The diversity in anarchism has led to widely different use of identical terms among different anarchist traditions, which has led to many definitional concerns in anarchist theory
An important current within anarchism is free love. Free love advocates sometimes traced their roots back to Josiah Warren and to experimental communities, viewed sexual freedom as a clear, direct expression of an individual's sovereignty. Free love particularly stressed women's rights since most sexual laws discriminated against women, see for example marriage laws and anti-birth control measures. The most important American free love journal was "Lucifer the Lightbearer" (1883–1907), edited by Moses Harman and Lois Waisbrooker, but also there existed Ezra Heywood and Angela Heywood's "The Word" (1872–1890, 1892–1893). "Free Society" (1895–1897 as "The Firebrand"; 1897–1904 as "Free Society") was a major anarchist newspaper in the United States at the end of the 19th and beginning of the 20th centuries. The publication advocated free love and women's rights and critiqued "Comstockery"—i.e. censorship of sexual information. Also M. E. Lazarus was an important American individualist anarchist who promoted free love.

In New York City's Greenwich Village, bohemian feminists and socialists advocated self-realisation and pleasure for women (and also men) in the here and now. They encouraged playing with sexual roles and sexuality and the openly bisexual radical Edna St. Vincent Millay and the lesbian anarchist Margaret Anderson were prominent among them. Discussion groups organised by the Villagers were frequented by Emma Goldman, among others. Magnus Hirschfeld noted in 1923 that Goldman "has campaigned boldly and steadfastly for individual rights, and especially for those deprived of their rights. Thus it came about that she was the first and only woman, indeed the first and only American, to take up the defence of homosexual love before the general public". Before Goldman, heterosexual anarchist Robert Reitzel (1849–1898) spoke positively of homosexuality from the beginning of the 1890s in his Detroit-based German language journal "Der arme Teufel" (English: The Poor Devil). In Argentina, anarcha-feminist Virginia Bolten published the newspaper called "" (English: "The Woman's Voice"), which was published nine times in Rosario between 8 January 1896 and 1 January 1897 and was revived briefly in 1901.

In Europe, the main propagandist of free love within individualist anarchism was Emile Armand. He proposed the concept of "la camaraderie amoureuse" to speak of free love as the possibility of voluntary sexual encounter between consenting adults. He was also a consistent proponent of polyamory. In Germany, the Stirnerists Adolf Brand and John Henry Mackay were pioneering campaigners for the acceptance of male bisexuality and homosexuality. Mujeres Libres was an anarchist women's organisation in Spain that aimed to empower working class women. It was founded in 1936 by Lucía Sánchez Saornil, Mercedes Comaposada and Amparo Poch y Gascón and had approximately 30,000 members. The organisation was based on the idea of a "double struggle" for women's liberation and social revolution and argued that the two objectives were equally important and should be pursued in parallel. In order to gain mutual support, they created networks of women anarchists. Lucía Sánchez Saornil was a main founder of the Spanish anarcha-feminist federation Mujeres Libres who was open about her lesbianism. She was published in a variety of literary journals while working under a male pen name, she was able to explore lesbian themes at a time when homosexuality was criminalised and subject to censorship and punishment.

More recently, the British anarcho-pacifist Alex Comfort gained notoriety during the sexual revolution for writing the bestseller sex manual "The Joy of Sex". The issue of free love has a dedicated treatment in the work of French anarcho-hedonist philosopher Michel Onfray
For English anarchist William Godwin, education was "the main means by which change would be achieved". Godwin saw that the main goal of education should be the promotion of happiness. For Godwin, education had to have a "respect for the child's autonomy which precluded any form of coercion", a "pedagogy that respected this and sought to build on the child's own motivation and initiatives" and a "concern about the child's capacity to resist an ideology transmitted through the school". In his "Political Justice", he criticises state sponsored schooling "on account of its obvious alliance with national government". Early American anarchist Josiah Warren advanced alternative education experiences in the libertarian communities he established. Max Stirner wrote in 1842 a long essay on education called "The False Principle of our Education" in which Stirner names his educational principle "personalist", explaining that self-understanding consists in hourly self-creation. Education for him is to create "free men, sovereign characters", by which he means "eternal characters [...] who are therefore eternal because they form themselves each moment".

In the United States, freethought was a basically anti-Christian, anti-clerical movement, whose purpose was to make the individual politically and spiritually free to decide for himself on religious matters. A number of contributors to "Liberty" (anarchist publication) were prominent figures in both freethought and anarchism. The individualist anarchist George MacDonald was a co-editor of "Freethought" and, for a time, "The Truth Seeker". E.C. Walker was co-editor of "Lucifer, the Light-Bearer" and many anarchists were "ardent freethinkers; reprints from freethought papers such as "Lucifer, the Light-Bearer", "Freethought" and "The Truth Seeker" appeared in "Liberty"... The church was viewed as a common ally of the state and as a repressive force in and of itself".

In 1901, Catalan anarchist and free thinker Francesc Ferrer i Guàrdia established "modern" or progressive schools in Barcelona in defiance of an educational system controlled by the Catholic Church. The schools' stated goal was to "educate the working class in a rational, secular and non-coercive setting". Fiercely anti-clerical, Ferrer believed in "freedom in education", education free from the authority of church and state. Murray Bookchin wrote: "This period [1890s] was the heyday of libertarian schools and pedagogical projects in all areas of the country where Anarchists exercised some degree of influence. Perhaps the best-known effort in this field was Francisco Ferrer's Modern School (Escuela Moderna), a project which exercised a considerable influence on Catalan education and on experimental techniques of teaching generally". La Escuela Moderna and Ferrer's ideas generally formed the inspiration for a series of "Modern Schools" in the United States, Cuba, South America and London. The first of these was started in New York City in 1911. It also inspired the Italian newspaper "Università popolare", founded in 1901. Russian christian anarchist Leo Tolstoy established a school for peasant children on his estate. Tolstoy's educational experiments were short-lived due to harassment by the Tsarist secret police. Tolstoy established a conceptual difference between education and culture. He thought that "[e]ducation is the tendency of one man to make another just like himself [...] Education is culture under restraint, culture is free. [Education is] when the teaching is forced upon the pupil, and when then instruction is exclusive, that is when only those subjects are taught which the educator regards as necessary". For him, "without compulsion, education was transformed into culture".

A more recent libertarian tradition on education is that of unschooling and the free school in which child-led activity replaces pedagogic approaches. Experiments in Germany led to A. S. Neill founding what became Summerhill School in 1921. Summerhill is often cited as an example of anarchism in practice. However, although Summerhill and other free schools are radically libertarian, they differ in principle from those of Ferrer by not advocating an overtly political class struggle-approach. In addition to organising schools according to libertarian principles, anarchists have also questioned the concept of schooling per se. The term deschooling was popularised by Ivan Illich, who argued that the school as an institution is dysfunctional for self-determined learning and serves the creation of a consumer society instead.


Moral and pragmatic criticism of anarchism includes allegations of utopianism, tacit authoritarianism and vandalism towards feats of civilization.

Anarchism is evaluated as unfeasible or utopian by its critics, often in general and formal debate. European history professor Carl Landauer argued that social anarchism is unrealistic and that government is a "lesser evil" than a society without "repressive force". He also argued that "ill intentions will cease if repressive force disappears" is an "absurdity". However, "An Anarchist FAQ" states the following: "Anarchy is not a utopia, [and] anarchists make no such claims about human perfection. [...] Remaining disputes would be solved by reasonable methods, for example, the use of juries, mutual third parties, or community and workplace assemblies [as well as] some sort of "court" system would still be necessary to deal with the remaining crimes and to adjudicate disputes between citizens".

The anarchist tendency known as platformism has been criticized by Situationists, insurrectionaries, synthesis anarchists and others of preserving tacitly statist, authoritarian or bureaucratic tendencies.

In his essay "On Authority", Friedrich Engels claimed that radical decentralization promoted by anarchists would destroy modern industrial civilization, citing an example of railways
Category:Anti-capitalism
Category:Anti-fascism
Category:Far-left politics
Category:Libertarian socialism
Category:Political culture
Category:Political ideologies
Category:Social theoriesAutism

Autism is a developmental disorder characterized by difficulties with social interaction and communication and by restricted and repetitive behavior. Parents usually notice signs during the first three years of their child's life. These signs often develop gradually, though some children with autism reach their developmental milestones at a normal pace before worsening.
Autism is associated with a combination of genetic and environmental factors. Risk factors during pregnancy include certain infections, such as rubella, and toxins including valproic acid, alcohol, cocaine, pesticides and air pollution. Controversies surround other proposed environmental causes; for example, the vaccine hypothesis, which has been disproven. Autism affects information processing in the brain by altering connections and organization of nerve cells and their synapses. How this occurs is not well understood. In the DSM-5, autism and less severe forms of the condition, including Asperger syndrome and pervasive developmental disorder not otherwise specified (PDD-NOS), have been combined into the diagnosis of autism spectrum disorder (ASD).
Early speech therapy or behavioral interventions can help children with autism gain self-care, social, and communication skills. Although there is no known cure, there have been cases of children who recovered. Not many children with autism live independently after reaching adulthood, though some are successful. An autistic culture has developed, with some individuals seeking a cure and others believing autism should be accepted as a difference and not treated as a disorder.
Globally, autism is estimated to affect 24.8 million people . In the 2000s, the number of people affected was estimated at 1–2 per 1,000 people worldwide. In the developed countries, about 1.5% of children are diagnosed with ASD , a more than doubling from 0.7% in 2000 in the United States. It occurs four-to-five times more often in boys than girls. The number of people diagnosed has increased dramatically since the 1960s, partly due to changes in diagnostic practice. The question of whether actual rates have increased is unresolved.

Autism is a highly variable neurodevelopmental disorder that first appears during infancy or childhood, and generally follows a steady course without remission. People with autism may be severely impaired in some respects but normal, or even superior, in others. Overt symptoms gradually begin after the age of six months, become established by age two or three years and tend to continue through adulthood, although often in more muted form. It is distinguished not by a single symptom but by a characteristic triad of symptoms: impairments in social interaction; impairments in communication; and restricted interests and repetitive behavior. Other aspects, such as atypical eating, are also common but are not essential for diagnosis. Individual symptoms of autism occur in the general population and appear not to associate highly, without a sharp line separating pathologically severe from common traits.

Social deficits distinguish autism and the related autism spectrum disorders (ASD; see Classification) from other developmental disorders. People with autism have social impairments and often lack the intuition about others that many people take for granted. Noted autistic Temple Grandin described her inability to understand the social communication of neurotypicals, or people with normal neural development, as leaving her feeling "like an anthropologist on Mars".

Unusual social development becomes apparent early in childhood. Autistic infants show less attention to social stimuli, smile and look at others less often, and respond less to their own name. Autistic toddlers differ more strikingly from social norms; for example, they have less eye contact and turn-taking, and do not have the ability to use simple movements to express themselves, such as pointing at things. Three- to five-year-old children with autism are less likely to exhibit social understanding, approach others spontaneously, imitate and respond to emotions, communicate nonverbally, and take turns with others. However, they do form attachments to their primary caregivers. Most children with autism display moderately less attachment security than neurotypical children, although this difference disappears in children with higher mental development or less severe ASD. Older children and adults with ASD perform worse on tests of face and emotion recognition although this may be partly due to a lower ability to define a person's own emotions.

Children with high-functioning autism suffer from more intense and frequent loneliness compared to non-autistic peers, despite the common belief that children with autism prefer to be alone. Making and maintaining friendships often proves to be difficult for those with autism. For them, the quality of friendships, not the number of friends, predicts how lonely they feel. Functional friendships, such as those resulting in invitations to parties, may affect the quality of life more deeply.

There are many anecdotal reports, but few systematic studies, of aggression and violence in individuals with ASD. The limited data suggest that, in children with intellectual disability, autism is associated with aggression, destruction of property, and meltdowns.

About a third to a half of individuals with autism do not develop enough natural speech to meet their daily communication needs. Differences in communication may be present from the first year of life, and may include delayed onset of babbling, unusual gestures, diminished responsiveness, and vocal patterns that are not synchronized with the caregiver. In the second and third years, children with autism have less frequent and less diverse babbling, consonants, words, and word combinations; their gestures are less often integrated with words. Children with autism are less likely to make requests or share experiences, and are more likely to simply repeat others' words (echolalia) or reverse pronouns. Joint attention
Autistic individuals can display many forms of repetitive or restricted behavior, which the Repetitive Behavior Scale-Revised (RBS-R) categorizes as follows.


No single repetitive or self-injurious behavior seems to be specific to autism, but autism appears to have an elevated pattern of occurrence and severity of these behaviors.

Autistic individuals may have symptoms that are independent of the diagnosis, but that can affect the individual or the family.
An estimated 0.5% to 10% of individuals with ASD show unusual abilities, ranging from splinter skills such as the memorization of trivia to the extraordinarily rare talents of prodigious autistic savants. Many individuals with ASD show superior skills in perception and attention, relative to the general population. Sensory abnormalities are found in over 90% of those with autism, and are considered core features by some, although there is no good evidence that sensory symptoms differentiate autism from other developmental disorders. Differences are greater for under-responsivity (for example, walking into things) than for over-responsivity (for example, distress from loud noises) or for sensation seeking (for example, rhythmic movements). An estimated 60–80% of autistic people have motor signs that include poor muscle tone, poor motor planning, and toe walking; deficits in motor coordination are pervasive across ASD and are greater in autism proper. Unusual eating behavior occurs in about three-quarters of children with ASD, to the extent that it was formerly a diagnostic indicator. Selectivity is the most common problem, although eating rituals and food refusal also occur.

Parents of children with ASD have higher levels of stress. Siblings of children with ASD report greater admiration of and less conflict with the affected sibling than siblings of unaffected children and were similar to siblings of children with Down syndrome in these aspects of the sibling relationship. However, they reported lower levels of closeness and intimacy than siblings of children with Down syndrome; siblings of individuals with ASD have greater risk of negative well-being and poorer sibling relationships as adults. There is tentative evidence that autism occurs more frequently in people with gender dysphoria.

Gastrointestinal problems are one of the most commonly associated medical disorders
Autism has a strong genetic basis, although the genetics of autism are complex and it is unclear whether ASD is explained more by rare mutations with major effects, or by rare multigene interactions of common genetic variants. Complexity arises due to interactions among multiple genes, the environment, and epigenetic factors which do not change DNA sequencing but are heritable and influence gene expression. Many genes have been associated with autism through sequencing the genomes of affected individuals and their parents. Studies of twins suggest that heritability is 0.7 for autism and as high as 0.9 for ASD, and siblings of those with autism are about 25 times more likely to be autistic than the general population. However, most of the mutations that increase autism risk have not been identified. Typically, autism cannot be traced to a Mendelian (single-gene) mutation or to a single chromosome abnormality, and none of the genetic syndromes associated with ASDs have been shown to selectively cause ASD. Numerous candidate genes have been located, with only small effects attributable to any particular gene. Most loci individually explain less than 1% of cases of autism. The large number of autistic individuals with unaffected family members may result from spontaneous structural variation — such as deletions, duplications or inversions in genetic material during meiosis. Hence, a substantial fraction of autism cases may be traceable to genetic causes that are highly heritable but not inherited: that is, the mutation that causes the autism is not present in the parental genome. Autism may be underdiagnosed in women and girls due to an assumption that it is primarily a male condition.

Maternal nutrition and inflammation during preconception and pregnancy influences fetal neurodevelopment. Intrauterine growth restriction is associated with ASD, in both term and preterm infants.

Exposure to air pollution during pregnancy, especially heavy metals and particulates, may increase the risk of autism. Environmental factors that have been claimed without evidence to contribute to or exacerbate autism include certain foods, infectious diseases, solvents, PCBs, phthalates and phenols used in plastic products, pesticides, brominated flame retardants, alcohol, smoking, illicit drugs, vaccines, and prenatal stress. Some such as the MMR vaccine have been completely disproven.

Parents may first become aware of autistic symptoms in their child around the time of a routine vaccination. This has led to unsupported theories blaming vaccine "overload", a vaccine preservative, or the MMR vaccine for causing autism. The latter theory was supported by a litigation-funded study that has since been shown to have been "an elaborate fraud". Although these theories lack convincing scientific evidence and are biologically implausible, parental concern about a potential vaccine link with autism has led to lower rates of childhood immunizations, outbreaks of previously controlled childhood diseases in some countries, and the preventable deaths of several children.

Autism's symptoms result from maturation-related changes in various systems of the brain. How autism occurs is not well understood. Its mechanism can be divided into two areas: the pathophysiology of brain structures and processes associated with autism, and the neuropsychological linkages between brain structures and behaviors. The behaviors appear to have multiple pathophysiologies.

There is evidence that gut–brain axis abnormalities may be involved. A 2015 review proposed that immune dysregulation, gastrointestinal inflammation, malfunction of the autonomic nervous system, gut flora alterations, and food metabolites may cause brain neuroinflammation and dysfunction. A 2016 review concludes that enteric nervous system abnormalities might play a role in neurological disorders such as autism. Neural connections and the immune system are a pathway that may allow diseases originated in the intestine to spread to the brain.

Several lines of evidence point to synaptic dysfunction as a cause of autism. Some rare mutations may lead to autism by disrupting some synaptic pathways, such as those involved with cell adhesion. Gene replacement studies in mice suggest that autistic symptoms are closely related to later developmental steps that depend on activity in synapses and on activity-dependent changes. All known teratogens (agents that cause birth defects) related to the risk of autism appear to act during the first eight weeks from conception, and though this does not exclude the possibility that autism can be initiated or affected later, there is strong evidence that autism arises very early in development.

Diagnosis is based on behavior, not cause or mechanism. Under the DSM-5, autism is characterized by persistent deficits in social communication and interaction across multiple contexts, as well as restricted, repetitive patterns of behavior, interests, or activities. These deficits are present in early childhood, typically before age three, and lead to clinically significant functional impairment. Sample symptoms include lack of social or emotional reciprocity, stereotyped and repetitive use of language or idiosyncratic language, and persistent preoccupation with unusual objects. The disturbance must not be better accounted for by Rett syndrome, intellectual disability or global developmental delay. ICD-10 uses essentially the same definition.

Several diagnostic instruments are available. Two are commonly used in autism research: the Autism Diagnostic Interview-Revised (ADI-R) is a semistructured parent interview, and the Autism Diagnostic Observation Schedule (ADOS) uses observation and interaction with the child. The Childhood Autism Rating Scale (CARS) is used widely in clinical environments to assess severity of autism based on observation of children. The Diagnostic interview for social and communication disorders (DISCO) may also be used.

A pediatrician commonly performs a preliminary investigation by taking developmental history and physically examining the child. If warranted, diagnosis and evaluations are conducted with help from ASD specialists, observing and assessing cognitive, communication, family, and other factors using standardized tools, and taking into account any associated medical conditions. A pediatric neuropsychologist is often asked to assess behavior and cognitive skills, both to aid diagnosis and to help recommend educational interventions. A differential diagnosis for ASD at this stage might also consider intellectual disability, hearing impairment, and a specific language impairment such as Landau–Kleffner syndrome. The presence of autism can make it harder to diagnose coexisting psychiatric disorders such as depression.

Clinical genetics evaluations are often done once ASD is diagnosed, particularly when other symptoms already suggest a genetic cause. Although genetic technology allows clinical geneticists to link an estimated 40% of cases to genetic causes, consensus guidelines in the US and UK are limited to high-resolution chromosome and fragile X testing. A genotype-first model of diagnosis has been proposed, which would routinely assess the genome's copy number variations. As new genetic tests are developed several ethical, legal, and social issues will emerge. Commercial availability of tests may precede adequate understanding of how to use test results, given the complexity of autism's genetics. Metabolic and neuroimaging tests are sometimes helpful, but are not routine.

ASD can sometimes be diagnosed by age 14 months, although diagnosis becomes increasingly stable over the first three years of life: for example, a one-year-old who meets diagnostic criteria for ASD is less likely than a three-year-old to continue to do so a few years later. In the UK the National Autism Plan for Children recommends at most 30 weeks from first concern to completed diagnosis and assessment, though few cases are handled that quickly in practice. Although the symptoms of autism and ASD begin early in childhood, they are sometimes missed; years later, adults may seek diagnoses to help them or their friends and family understand themselves, to help their employers make adjustments, or in some locations to claim disability living allowances or other benefits. Girls are often diagnosed later than boys.

Underdiagnosis and overdiagnosis are problems in marginal cases, and much of the recent increase in the number of reported ASD cases is likely due to changes in diagnostic practices. The increasing popularity of drug treatment options and the expansion of benefits has given providers incentives to diagnose ASD, resulting in some overdiagnosis of children with uncertain symptoms. Conversely, the cost of screening and diagnosis and the challenge of obtaining payment can inhibit or delay diagnosis. It is particularly hard to diagnose autism among the visually impaired, partly because some of its diagnostic criteria depend on vision, and partly because autistic symptoms overlap with those of common blindness syndromes or blindisms.

Autism is one of the five pervasive developmental disorders (PDD), which are characterized by widespread abnormalities of social interactions and communication, and severely restricted interests and highly repetitive behavior. These symptoms do not imply sickness, fragility, or emotional disturbance.

Of the five PDD forms, Asperger syndrome is closest to autism in signs and likely causes; Rett syndrome and childhood disintegrative disorder share several signs with autism, but may have unrelated causes; PDD not otherwise specified (PDD-NOS; also called "atypical autism") is diagnosed when the criteria are not met for a more specific disorder. Unlike with autism, people with Asperger syndrome have no substantial delay in language development. The terminology of autism can be bewildering, with autism, Asperger syndrome and PDD-NOS often called the "autism spectrum disorders" (ASD) or sometimes the "autistic disorders", whereas autism itself is often called "autistic disorder", "childhood autism", or "infantile autism". In this article, "autism" refers to the classic autistic disorder; in clinical practice, though, "autism", "ASD", and "PDD" are often used interchangeably. ASD, in turn, is a subset of the broader autism phenotype, which describes individuals who may not have ASD but do have autistic-like traits, such as avoiding eye contact.

The manifestations of autism cover a wide spectrum, ranging from individuals with severe impairments—who may be silent, developmentally disabled, and locked into hand flapping and rocking—to high functioning individuals who may have active but distinctly odd social approaches, narrowly focused interests, and verbose, pedantic communication. Because the behavior spectrum is continuous, boundaries between diagnostic categories are necessarily somewhat arbitrary. Sometimes the syndrome is divided into low-, medium- or high-functioning autism (LFA, MFA, and HFA), based on IQ thresholds, or on how much support the individual requires in daily life; these subdivisions are not standardized and are controversial. Autism can also be divided into syndromal and non-syndromal autism; the syndromal autism is associated with severe or profound intellectual disability or a congenital syndrome with physical symptoms, such as tuberous sclerosis. Although individuals with Asperger syndrome tend to perform better cognitively than those with autism, the extent of the overlap between Asperger syndrome, HFA, and non-syndromal autism is unclear.

Some studies have reported diagnoses of autism in children due to a loss of language or social skills, as opposed to a failure to make progress, typically from 15 to 30 months of age. The validity of this distinction remains controversial; it is possible that regressive autism is a specific subtype, or that there is a continuum of behaviors between autism with and without regression.

Research into causes has been hampered by the inability to identify biologically meaningful subgroups within the autistic population and by the traditional boundaries between the disciplines of psychiatry, psychology, neurology and pediatrics. Newer technologies such as fMRI and diffusion tensor imaging can help identify biologically relevant phenotypes (observable traits) that can be viewed on brain scans, to help further neurogenetic studies of autism; one example is lowered activity in the fusiform face area of the brain, which is associated with impaired perception of people versus objects. It has been proposed to classify autism using genetics as well as behavior.

About half of parents of children with ASD notice their child's unusual behaviors by age 18 months, and about four-fifths notice by age 24 months. According to an article, failure to meet any of the following milestones "is an absolute indication to proceed with further evaluations. Delay in referral for such testing may delay early diagnosis and treatment and affect the long-term outcome".

The United States Preventive Services Task Force in 2016 found it was unclear if screening was beneficial or harmful among children in whom there is no concerns. The Japanese practice is to screen all children for ASD at 18 and 24 months, using autism-specific formal screening tests. In contrast, in the UK, children whose families or doctors recognize possible signs of autism are screened. It is not known which approach is more effective. Screening tools include the Modified Checklist for Autism in Toddlers (M-CHAT), the Early Screening of Autistic Traits Questionnaire, and the First Year Inventory; initial data on M-CHAT and its predecessor, the Checklist for Autism in Toddlers (CHAT), on children aged 18–30 months suggests that it is best used in a clinical setting and that it has low sensitivity (many false-negatives) but good specificity (few false-positives). It may be more accurate to precede these tests with a broadband screener that does not distinguish ASD from other developmental disorders. Screening tools designed for one culture's norms for behaviors like eye contact may be inappropriate for a different culture. Although genetic screening for autism is generally still impractical, it can be considered in some cases, such as children with neurological symptoms and dysmorphic features.

While infection with rubella during pregnancy causes fewer than 1% of cases of autism, vaccination against rubella
The main goals when treating children with autism are to lessen associated deficits and family distress, and to increase quality of life and functional independence. In general, higher IQs are correlated with greater responsiveness to treatment and improved treatment outcomes. No single treatment is best and treatment is typically tailored to the child's needs. Families and the educational system are the main resources for treatment. Services should be carried out by behavior analysts, special education teachers, speech pathologists, and licensed psychologists. Studies of interventions have methodological problems that prevent definitive conclusions about efficacy. However, the development of evidence-based interventions has advanced in recent years. Although many psychosocial interventions have some positive evidence, suggesting that some form of treatment is preferable to no treatment, the methodological quality of systematic reviews of these studies has generally been poor, their clinical results are mostly tentative, and there is little evidence for the relative effectiveness of treatment options. Intensive, sustained special education programs and behavior therapy early in life can help children acquire self-care, communication, and job skills, and often improve functioning and decrease symptom severity and maladaptive behaviors; claims that intervention by around age three years is crucial are not substantiated. While medications have not been found to help with core symptoms, they may be used for associated symptoms, such as irritability, inattention, or repetitive behavior patterns.

Educational interventions often used include applied behavior analysis (ABA), developmental models, structured teaching, speech and language therapy, social skills therapy, and occupational therapy. Among these approaches, interventions either treat autistic features comprehensively, or focalize treatment on a specific area of deficit. The quality of research for early intensive behavioral intervention (EIBI)—a treatment procedure encompassing over thirty hours per week of the structured type of ABA that is carried out with very young children—is currently low, and more vigorous research designs with larger sample sizes are needed. Two theoretical frameworks outlined for early childhood intervention include structured and naturalistic ABA interventions, and developmental social pragmatic models (DSP). One interventional strategy utilizes a parent training model, which teaches parents how to implement various ABA and DSP techniques, allowing for parents to disseminate interventions themselves. Various DSP programs have been developed to explicitly deliver intervention systems through at-home parent implementation. Despite the recent development of parent training models, these interventions have demonstrated effectiveness in numerous studies, being evaluated as a probable efficacious mode of treatment.

Early, intensive ABA therapy has demonstrated effectiveness in enhancing global functioning in preschool children, and is well-established for improving the intellectual performance of that age group. Similarly, a teacher-implemented intervention that utilizes a more naturalistic form of ABA combined with a developmental social pragmatic approach has been found to be beneficial in improving social-communication skills in young children, although there is less evidence in its treatment of global symptoms. Neuropsychological reports are often poorly communicated to educators, resulting in a gap between what a report recommends and what education is provided. It is not known whether treatment programs for children lead to significant improvements after the children grow up, and the limited research on the effectiveness of adult residential programs shows mixed results. The appropriateness of including children with varying severity of autism spectrum disorders in the general education population is a subject of current debate among educators and researchers.

Medications may be used to treat ASD symptoms that interfere with integrating a child into home or school when behavioral treatment fails. They may also be used for associated health problems, such as ADHD or anxiety. More than half of US children diagnosed with ASD are prescribed psychoactive drugs or anticonvulsants, with the most common drug classes being antidepressants, stimulants, and antipsychotics. The atypical antipsychotic drugs risperidone and aripiprazole are FDA-approved for treating associated aggressive and self-injurious behaviors. However, their side effects must be weighed against their potential benefits, and people with autism may respond atypically. Side effects, for example, may include weight gain, tiredness, drooling, and aggression. SSRI antidepressants, such as fluoxetine and fluvoxamine, have been shown to be effective in reducing repetitive and ritualistic behaviors, while the stimulant medication methylphenidate is beneficial for some children with co-morbid inattentiveness or hyperactivity. There is scant reliable research about the effectiveness or safety of drug treatments for adolescents and adults with ASD. No known medication relieves autism's core symptoms of social and communication impairments. Experiments in mice have reversed or reduced some symptoms related to autism by replacing or modulating gene function, suggesting the possibility of targeting therapies to specific rare mutations known to cause autism.

Although many alternative therapies and interventions are available, few are supported by scientific studies. Treatment approaches have little empirical support in quality-of-life contexts, and many programs focus on success measures that lack predictive validity and real-world relevance. Some alternative treatments may place the child at risk. A 2008 study found that compared to their peers, autistic boys have significantly thinner bones if on casein-free diets; in 2005, botched chelation therapy killed a five-year-old child with autism. Another alternative medicine practice with no evidence is CEASE therapy, a mixture of homeopathy, supplements, and 'vaccine detoxing'.

Although popularly used as an alternative treatment for people with autism, there is no good evidence that a gluten-free diet is of benefit. In the subset of people who have gluten sensitivity there is limited evidence that suggests that a gluten free diet may improve some autistic behaviors. There is tentative evidence that music therapy may improve social interactions, verbal communication, and non-verbal communication skills. There has been early research looking at hyperbaric treatments in children with autism.

The emergence of the autism rights movement has served as an attempt to encourage people to be more tolerant of those with autism. Through this movement, people hope to cause others to think of autism as a difference instead of a disease. Proponents of this movement wish to seek "acceptance, not cures." There have also been many worldwide events promoting autism awareness such as World Autism Awareness Day, Light It Up Blue, Autism Sunday, Autistic Pride Day, Autreat, and others. There have also been many organizations dedicated to increasing the awareness of autism and the effects that autism has on someone's life. These organizations include Autism Speaks, Autism National Committee, Autism Society of America, and many others. Social-science scholars have had an increased focused on studying those with autism in hopes to learn more about "autism as a culture, transcultural comparisons... and research on social movements." Media has had an influence on how the public perceives those with autism. "Rain Man", a film that won 4 Oscars including Best Picture, depicts a character with autism who has incredible talents and abilities. While many autistic individuals do not have these special abilities, some have been successful in their fields.

Treatment is expensive; indirect costs are more so. For someone born in 2000, a US study estimated an average lifetime cost of $ (net present value in dollars, inflation-adjusted from 2003 estimate), with about 10% medical care, 30% extra education and other care, and 60% lost economic productivity. Publicly supported programs are often inadequate or inappropriate for a given child, and unreimbursed out-of-pocket medical or therapy expenses are associated with likelihood of family financial problems; one 2008 US study found a 14% average loss of annual income in families of children with ASD, and a related study found that ASD is associated with higher probability that child care problems will greatly affect parental employment. US states increasingly require private health insurance to cover autism services, shifting costs from publicly funded education programs to privately funded health insurance. After childhood, key treatment issues include residential care, job training and placement, sexuality, social skills, and estate planning.

There is no known cure. Children recover occasionally, so that they lose their diagnosis of ASD; this occurs sometimes after intensive treatment and sometimes not. It is not known how often recovery happens; reported rates in unselected samples have ranged from 3% to 25%. Most children with autism acquire language by age five or younger, though a few have developed communication skills in later years. Most children with autism lack social support, meaningful relationships, future employment opportunities or self-determination. Although core difficulties tend to persist, symptoms often become less severe with age.

Few high-quality studies address long-term prognosis. Some adults show modest improvement in communication skills, but a few decline; no study has focused on autism after midlife. Acquiring language before age six, having an IQ above 50, and having a marketable skill all predict better outcomes; independent living

Most recent reviews tend to estimate a prevalence of 1–2 per 1,000 for autism and close to 6 per 1,000 for ASD, and 11 per 1,000 children in the United States for ASD as of 2008; because of inadequate data, these numbers may underestimate ASD's true rate. Globally, autism affects an estimated 24.8 million people , while Asperger syndrome affects a further 37.2 million. In 2012, the NHS estimated that the overall prevalence of autism among adults aged 18 years and over in the UK was 1.1%. Rates of PDD-NOS's has been estimated at 3.7 per 1,000, Asperger syndrome at roughly 0.6 per 1,000, and childhood disintegrative disorder

A few examples of autistic symptoms and treatments were described long before autism was named. The "Table Talk" of Martin Luther, compiled by his notetaker, Mathesius, contains the story of a 12-year-old boy who may have been severely autistic. Luther reportedly thought the boy was a soulless mass of flesh possessed by the devil, and suggested that he be suffocated, although a later critic has cast doubt on the veracity of this report. The earliest well-documented case of autism is that of Hugh Blair of Borgue, as detailed in a 1747 court case in which his brother successfully petitioned to annul Blair's marriage to gain Blair's inheritance. The Wild Boy of Aveyron, a feral child caught in 1798, showed several signs of autism; the medical student Jean Itard treated him with a behavioral program designed to help him form social attachments and to induce speech via imitation.

The New Latin word "autismus" (English translation "autism") was coined by the Swiss psychiatrist Eugen Bleuler in 1910 as he was defining symptoms of schizophrenia. He derived it from the Greek word "autós" (αὐτός, meaning "self"), and used it to mean morbid self-admiration, referring to "autistic withdrawal of the patient to his fantasies, against which any influence from outside becomes an intolerable disturbance". A Soviet child psychiatrist, Grunya Sukhareva

The word "autism" first took its modern sense in 1938 when Hans Asperger of the Vienna University Hospital adopted Bleuler's terminology "autistic psychopaths" in a lecture in German about child psychology. Asperger was investigating an ASD now known as Asperger syndrome, though for various reasons it was not widely recognized as a separate diagnosis until 1981. Leo Kanner of the Johns Hopkins Hospital first used "autism" in its modern sense in English when he introduced the label "early infantile autism" in a 1943 report of 11 children with striking behavioral similarities. Almost all the characteristics described in Kanner's first paper on the subject, notably "autistic aloneness" and "insistence on sameness", are still regarded as typical of the autistic spectrum of disorders. It is not known whether Kanner derived the term independently of Asperger.

Donald Triplett was the first person diagnosed with autism. He was diagnosed by Kanner after being first examined in 1938, and was labeled as "case 1". Triplett was noted for his savant abilities, particularly being able to name musical notes played on a piano and to mentally multiply numbers. His father, Oliver, described him as socially withdrawn but interested in number patterns, music notes, letters of the alphabet, and U.S. president pictures. By the age of 2, he had the ability to recite the 23rd Psalm and memorized 25 questions and answers from the Presbyterian catechism. He was also interested in creating musical chords.

Kanner's reuse of "autism" led to decades of confused terminology like "infantile schizophrenia", and child psychiatry's focus on maternal deprivation led to misconceptions of autism as an infant's response to "refrigerator mothers". Starting in the late 1960s autism was established as a separate syndrome.

As late as the mid-1970s there was little evidence of a genetic role in autism; while in 2007 it was believed to be one of the most heritable psychiatric conditions. Although the rise of parent organizations and the destigmatization of childhood ASD have affected how ASD is viewed, parents continue to feel social stigma in situations where their child's autistic behavior is perceived negatively, and many primary care physicians and medical specialists express some beliefs consistent with outdated autism research.

It took until 1980 for the DSM-III to differentiate autism from childhood schizophrenia. In 1987, the DSM-III-R provided a checklist for diagnosing autism. In May 2013, the DSM-5 was released, updating the classification for pervasive developmental disorders. The grouping of disorders, including PDD-NOS, autism, Asperger syndrome, Rett syndrome, and CDD, has been removed and replaced with the general term of Autism Spectrum Disorders. The two categories that exist are impaired social communication and/or interaction, and restricted and/or repetitive behaviors.

The Internet has helped autistic individuals bypass nonverbal cues and emotional sharing that they find difficult to deal with, and has given them a way to form online communities and work remotely. Societal and cultural aspects of autism have developed: some in the community seek a cure, while others believe that autism is simply another way of being
Category:Articles containing video clips
Category:Communication disorders
Category:Mental and behavioural disorders
Category:Neurological disorders
Category:Neurological disorders in children
Category:Pervasive developmental disorders
Category:Psychiatric diagnosis
Category:RTT

Albedo () (, meaning 'whiteness') is the measure of the diffuse reflection of solar radiation out of the total solar radiation received by an astronomical body (e.g. a planet like Earth). It is dimensionless and measured on a scale from 0 (corresponding to a black body that absorbs all incident radiation) to 1 (corresponding to a body that reflects all incident radiation).

Surface albedo is defined as the ratio of radiosity to the irradiance (flux per unit area) received by a surface. The proportion reflected is not only determined by properties of the surface itself, but also by the spectral and angular distribution of solar radiation reaching the Earth's surface. These factors vary with atmospheric composition, geographic location and time (see position of the Sun). While bi-hemispherical reflectance is calculated for a single angle of incidence (i.e., for a given position of the Sun), albedo is the directional integration of reflectance over all solar angles in a given period. The temporal resolution may range from seconds (as obtained from flux measurements) to daily, monthly, or annual averages.

Unless given for a specific wavelength (spectral albedo), albedo refers to the entire spectrum of solar radiation. Due to measurement constraints, it is often given for the spectrum in which most solar energy reaches the surface (between 0.3 and 3 μm). This spectrum includes visible light (0.39–0.7 μm), which explains why surfaces with a low albedo appear dark (e.g., trees absorb most radiation), whereas surfaces with a high albedo appear bright (e.g., snow reflects most radiation).

Albedo is an important concept in climatology, astronomy, and environmental management (e.g., as part of the Leadership in Energy and Environmental Design (LEED) program for sustainable rating of buildings). The average albedo of the Earth from the upper atmosphere, its "planetary albedo", is 30–35% because of cloud cover, but widely varies locally across the surface because of different geological and environmental features.

The term albedo was introduced into optics by Johann Heinrich Lambert in his 1760 work "Photometria".

Any albedo in visible light falls within a range of about 0.9 for fresh snow to about 0.04 for charcoal, one of the darkest substances. Deeply shadowed cavities can achieve an effective albedo approaching the zero of a black body. When seen from a distance, the ocean surface has a low albedo, as do most forests, whereas desert areas have some of the highest albedos among landforms. Most land areas are in an albedo range of 0.1 to 0.4. The average albedo of Earth
Earth's surface albedo is regularly estimated via Earth observation satellite sensors such as NASA's MODIS instruments on board the Terra and Aqua satellites, and the CERES instrument on the Suomi NPP and JPSS. As the amount of reflected radiation is only measured for a single direction by satellite, not all directions, a mathematical model is used to translate a sample set of satellite reflectance measurements into estimates of directional-hemispherical reflectance and bi-hemispherical reflectance (e.g.,). These calculations are based on the bidirectional reflectance distribution function (BRDF), which describes how the reflectance of a given surface depends on the view angle of the observer and the solar angle. BDRF can facilitate translations of observations of reflectance into albedo.

Earth's average surface temperature due to its albedo and the greenhouse effect is currently about 15 °C. If Earth were frozen entirely (and hence be more reflective), the average temperature of the planet would drop below −40 °C. If only the continental land masses became covered by glaciers, the mean temperature of the planet would drop to about 0 °C. In contrast, if the entire Earth was covered by water — a so-called aquaplanet — the average temperature on the planet would rise to almost 27 °C.

For land surfaces, it has been shown that the albedo at a particular solar zenith angle "θ" can be approximated by the proportionate sum of two terms: the directional-hemispherical reflectance at that solar zenith angle, formula_1, and the bi-hemispherical reflectance, formula_2, with formula_3 being the proportion of direct radiation from a given solar angle, and formula_4 being the proportion of diffuse illumination.

Hence, the actual albedo formula_5 (also called blue-sky albedo) can then be given as:

Directional-hemispherical reflectance is sometimes referred to as black-sky albedo and bi-hemispherical reflectance as white-sky albedo. These terms are important because they allow the albedo to be calculated for any given illumination conditions from a knowledge of the intrinsic properties of the surface.

The albedos of planets, satellites and minor planets such as asteroids can be used to infer much about their properties. The study of albedos, their dependence on wavelength, lighting angle ("phase angle"), and variation in time comprises a major part of the astronomical field of photometry. For small and far objects that cannot be resolved by telescopes, much of what we know comes from the study of their albedos. For example, the absolute albedo can indicate the surface ice content of outer Solar System objects, the variation of albedo with phase angle gives information about regolith properties, whereas unusually high radar albedo is indicative of high metal content in asteroids.

Enceladus, a moon of Saturn, has one of the highest known albedos of any body in the Solar System, with 99% of EM radiation reflected. Another notable high-albedo body is Eris, with an albedo of 0.96. Many small objects in the outer Solar System and asteroid belt have low albedos down to about 0.05. A typical comet nucleus has an albedo of 0.04. Such a dark surface is thought to be indicative of a primitive and heavily space weathered surface containing some organic compounds.

The overall albedo of the Moon is measured to be around 0.136, but it is strongly directional and non-Lambertian, displaying also a strong opposition effect. Although such reflectance properties are different from those of any terrestrial terrains, they are typical of the regolith surfaces of airless Solar System bodies.

Two common albedos that are used in astronomy are the (V-band) geometric albedo (measuring brightness when illumination comes from directly behind the observer) and the Bond albedo (measuring total proportion of electromagnetic energy reflected). Their values can differ significantly, which is a common source of confusion.

In detailed studies, the directional reflectance properties of astronomical bodies are often expressed in terms of the five Hapke parameters which semi-empirically describe the variation of albedo with phase angle, including a characterization of the opposition effect of regolith surfaces.

The correlation between astronomical (geometric) albedo, absolute magnitude and diameter is:
formula_7,

where formula_8 is the astronomical albedo, formula_9 is the diameter in kilometers, and formula_10 is the absolute magnitude.

Albedo is not directly dependent on illumination because changing the amount of incoming light proportionally changes the amount of reflected light, except in circumstances where a change in illumination induces a change in the Earth's surface at that location (e.g. through albedo-temperature feedback). That said, albedo and illumination both vary by latitude. Albedo is highest near the poles and lowest in the subtropics, with a local maximum in the tropics.

The intensity of albedo temperature effects depend on the amount of albedo and the level of local insolation (solar irradiance); high albedo areas in the arctic and antarctic regions are cold due to low insolation, where areas such as the Sahara Desert, which also have a relatively high albedo, will be hotter due to high insolation. Tropical and sub-tropical rainforest areas have low albedo, and are much hotter than their temperate forest counterparts, which have lower insolation. Because insolation plays such a big role in the heating and cooling effects of albedo, high insolation areas like the tropics will tend to show a more pronounced fluctuation in local temperature when local albedo changes.

Arctic regions notably release more heat back into space than what they absorb, effectively cooling the Earth. This has been a concern since arctic ice and snow has been melting at higher rates due to higher temperatures, creating regions in the arctic that are notably darker (being water or ground which is darker color) and reflects less heat back into space. This feedback loop results in a reduced albedo effect.

Albedo affects climate by determining how much radiation a planet absorbs. The uneven heating of Earth from albedo variations between land, ice, or ocean surfaces can drive weather.

When an area's albedo changes due to snowfall, a snow–temperature feedback results. A layer of snowfall increases local albedo, reflecting away sunlight, leading to local cooling. In principle, if no outside temperature change affects this area (e.g., a warm air mass), the raised albedo and lower temperature would maintain the current snow and invite further snowfall, deepening the snow–temperature feedback. However, because local weather is dynamic due to the change of seasons, eventually warm air masses and a more direct angle of sunlight (higher insolation) cause melting. When the melted area reveals surfaces with lower albedo, such as grass or soil, the effect is reversed: the darkening surface lowers albedo, increasing local temperatures, which induces more melting and thus reducing the albedo further, resulting in still more heating.

Snow albedo is highly variable, ranging from as high as 0.9 for freshly fallen snow, to about 0.4 for melting snow, and as low as 0.2 for dirty snow. Over Antarctica snow albedo averages a little more than 0.8. If a marginally snow-covered area warms, snow tends to melt, lowering the albedo, and hence leading to more snowmelt because more radiation is being absorbed by the snowpack (the ice–albedo positive feedback).

Just as fresh snow has a higher albedo than does dirty snow, the albedo of snow-covered sea ice is far higher than that of sea water. Sea water absorbs more solar radiation than would the same surface covered with reflective snow. When sea ice melts, either due to a rise in sea temperature or in response to increased solar radiation from above, the snow-covered surface is reduced, and more surface of sea water is exposed, so the rate of energy absorption increases. The extra absorbed energy heats the sea water, which in turn increases the rate at which sea ice melts. As with the preceding example of snowmelt, the process of melting of sea ice is thus another example of a positive feedback. Both positive feedback loops have long been recognized as important to the modern theory of Global warming.

Cryoconite, powdery windblown dust containing soot, sometimes reduces albedo on glaciers and ice sheets.

The dynamical nature of albedo in response to positive feedback, together with the effects of small errors in the measurement of albedo, can lead to large errors in energy estimates. Because of this, in order to reduce the error of energy estimates, it is important to measure the albedo of snow-covered areas through remote sensing techniques rather than applying a single value for albedo over broad regions.

Albedo works on a smaller scale, too. In sunlight, dark clothes absorb more heat and light-coloured clothes reflect it better, thus allowing some control over body temperature by exploiting the albedo effect of the colour of external clothing.

Albedo can affect the electrical energy output of solar photovoltaic devices. For example, the effects of a spectrally responsive albedo are illustrated by the differences between the spectrally weighted albedo of solar photovoltaic technology based on hydrogenated amorphous silicon (a-Si:H) and crystalline silicon (c-Si)-based compared to traditional spectral-integrated albedo predictions. Research showed impacts of over 10%. More recently, the analysis was extended to the effects of spectral bias due to the specular reflectivity of 22 commonly occurring surface materials (both human-made and natural) and analyzes the albedo effects on the performance of seven photovoltaic materials covering three common photovoltaic system topologies: industrial (solar farms), commercial flat rooftops and residential pitched-roof applications.

Because forests generally have a low albedo, (the majority of the ultraviolet and visible spectrum is absorbed through photosynthesis), some scientists have suggested that greater heat absorption by trees could offset some of the carbon benefits of afforestation (or offset the negative climate impacts of deforestation). In the case of evergreen forests with seasonal snow cover albedo reduction may be great enough for deforestation to cause a net cooling effect. Trees also impact climate in extremely complicated ways through evapotranspiration. The water vapor causes cooling on the land surface, causes heating where it condenses, acts a strong greenhouse gas, and can increase albedo when it condenses into clouds Scientists generally treat evapotranspiration as a net cooling impact, and the net climate impact of albedo and evapotranspiration changes from deforestation depends greatly on local climate 

In seasonally snow-covered zones, winter albedos of treeless areas are 10% to 50% higher than nearby forested areas because snow does not cover the trees as readily. Deciduous trees have an albedo value of about 0.15 to 0.18 whereas coniferous trees have a value of about 0.09 to 0.15. Variation in summer albedo across both forest types is correlated with maximum rates of photosynthesis because plants with high growth capacity display a greater fraction of their foliage for direct interception of incoming radiation in the upper canopy. The result is that wavelengths of light not used in photosynthesis are more likely to be reflected back to space rather than being absorbed by other surfaces lower in the canopy. 

Studies by the Hadley Centre have investigated the relative (generally warming) effect of albedo change and (cooling) effect of carbon sequestration
Water reflects light very differently from typical terrestrial materials. The reflectivity of a water surface is calculated using the Fresnel equations (see graph).

At the scale of the wavelength of light even wavy water is always smooth so the light is reflected in a locally specular manner (not diffusely). The glint of light off water is a commonplace effect of this. At small angles of incident light, waviness results in reduced reflectivity because of the steepness of the reflectivity-vs.-incident-angle curve and a locally increased average incident angle.

Although the reflectivity of water is very low at low and medium angles of incident light, it becomes very high at high angles of incident light such as those that occur on the illuminated side of Earth near the terminator (early morning, late afternoon, and near the poles). However, as mentioned above, waviness causes an appreciable reduction. Because light specularly reflected from water does not usually reach the viewer, water is usually considered to have a very low albedo in spite of its high reflectivity at high angles of incident light.

Note that white caps on waves look white (and have high albedo) because the water is foamed up, so there are many superimposed bubble surfaces which reflect, adding up their reflectivities. Fresh 'black' ice exhibits Fresnel reflection.
Snow on top of this sea ice increases the albedo to 0.9.

Cloud albedo has substantial influence over atmospheric temperatures. Different types of clouds exhibit different reflectivity, theoretically ranging in albedo from a minimum of near 0 to a maximum approaching 0.8. "On any given day, about half of Earth is covered by clouds, which reflect more sunlight than land and water. Clouds keep Earth cool by reflecting sunlight, but they can also serve as blankets to trap warmth."

Albedo and climate in some areas are affected by artificial clouds, such as those created by the contrails of heavy commercial airliner traffic. A study following the burning of the Kuwaiti oil fields during Iraqi occupation showed that temperatures under the burning oil fires were as much as 10 °C colder than temperatures several miles away under clear skies.

Aerosols (very fine particles/droplets in the atmosphere) have both direct and indirect effects on Earth's radiative balance. The direct (albedo) effect is generally to cool the planet; the indirect effect (the particles act as cloud condensation nuclei and thereby change cloud properties) is less certain. As per the effects are:
Another albedo-related effect on the climate is from black carbon particles. The size of this effect is difficult to quantify: the Intergovernmental Panel on Climate Change estimates that the global mean radiative forcing for black carbon aerosols from fossil fuels is +0.2 W m, with a range +0.1 to +0.4 W m. Black carbon is a bigger cause of the melting of the polar ice cap in the Arctic than carbon dioxide due to its effect on the albedo.

Human activities (e.g., deforestation, farming, and urbanization) change the albedo of various areas around the globe. However, quantification of this effect on the global scale is difficult.

Single-scattering albedo is used to define scattering of electromagnetic waves on small particles. It depends on properties of the material (refractive index); the size of the particle or particles; and the wavelength of the incoming radiation.

Albedo can be measured by an Albedometer.



Category:Climate forcing
Category:Climatology
Category:Electromagnetic radiation
Category:Land surface effects on climate
Category:Radiometry
Category:Scattering, absorption and radiative transfer (optics)
Category:RadiationA

A (named , plural "As", "A's", "a"s, "a's" or "aes") is the first letter and the first vowel of the modern English alphabet and the ISO basic Latin alphabet. It is similar to the Ancient Greek letter alpha, from which it derives. The uppercase version consists of the two slanting sides of a triangle, crossed in the middle by a horizontal bar. The lowercase version can be written in two forms: the double-storey a and single-storey ɑ. The latter is commonly used in handwriting and fonts based on it, especially fonts intended to be read by children, and is also found in italic type.

In English grammar, "a", and its variant "an", is an indefinite article.

The earliest certain ancestor of "A" is aleph (also written 'aleph), the first letter of the Phoenician alphabet, which consisted entirely of consonants (for that reason, it is also called an abjad to distinguish it from a true alphabet). In turn, the ancestor of aleph may have been a pictogram of an ox head in proto-Sinaitic script influenced by Egyptian hieroglyphs, styled as a triangular head with two horns extended.

By 1600 BC, the Phoenician alphabet letter had a linear form that served as the base for some later forms. Its name is thought to have corresponded closely to the Paleo-Hebrew or Arabic aleph.
When the ancient Greeks adopted the alphabet, they had no use for a letter to represent the glottal stop—the consonant sound that the letter denoted in Phoenician and other Semitic languages, and that was the first phoneme of the Phoenician pronunciation of the letter—so they used their version of the sign to represent the vowel , and called it by the similar name of alpha. In the earliest Greek inscriptions after the Greek Dark Ages, dating to the 8th century BC, the letter rests upon its side, but in the Greek alphabet of later times it generally resembles the modern capital letter, although many local varieties can be distinguished by the shortening of one leg, or by the angle at which the cross line is set.

The Etruscans brought the Greek alphabet to their civilization in the Italian Peninsula and left the letter unchanged. The Romans later adopted the Etruscan alphabet to write the Latin language, and the resulting letter was preserved in the Latin alphabet
During Roman times, there were many variant forms of the letter "A". First was the monumental or lapidary style, which was used when inscribing on stone or other "permanent" media. There was also a cursive style used for everyday or utilitarian writing, which was done on more perishable surfaces. Due to the "perishable" nature of these surfaces, there are not as many examples of this style as there are of the monumental, but there are still many surviving examples of different types of cursive, such as majuscule cursive, minuscule cursive, and semicursive minuscule. Variants also existed that were intermediate between the monumental and cursive styles. The known variants include the early semi-uncial the end of the Roman Empire (5th century AD), several variants of the cursive minuscule developed through Western Europe. Among these were the semicursive minuscule of Italy, the Merovingian script in France, the Visigothic script in Spain, and the Insular or Anglo-Irish semi-uncial or Anglo-Saxon majuscule of Great Britain. By the 9th century, the Caroline script, which was very similar to the present-day form, was the principal form used in book-making, before the advent of the printing press. This form was derived through a combining of prior forms.

15th-century Italy saw the formation of the two main variants that are known today. These variants, the "Italic" and "Roman" forms, were derived from the Caroline Script version. The Italic form, also called "script a," is used in most current handwriting and consists of a circle and vertical stroke. This slowly developed from the fifth-century form resembling the Greek letter tau in the hands of medieval Irish and English writers. The Roman form is used in most printed material; it consists of a small loop with an arc over it ("a"). Both derive from the majuscule (capital) form. In Greek handwriting, it was common to join the left leg and horizontal stroke into a single loop, as demonstrated by the uncial version shown. Many fonts then made the right leg vertical. In some of these, the serif that began the right leg stroke developed into an arc, resulting in the printed form, while in others it was dropped, resulting in the modern handwritten form.

Italic type is commonly used to mark emphasis or more generally to distinguish one part of a text from the rest (set in Roman type). There are some other cases aside from italic type where "script a" ("ɑ"), also called Latin alpha, is used in contrast with Latin "a" (such as in the International Phonetic Alphabet

In modern English orthography, the letter represents at least seven different vowel sounds:

The double sequence does not occur in native English words, but is found in some words derived from foreign languages such as "Aaron" and "aardvark". However, occurs in many common digraphs, all with their own sound or sounds, particularly , , , , and .

In most languages that use the Latin alphabet, denotes an open unrounded vowel, such as , , or . An exception is Saanich, in which (and the glyph Á) stands for a close-mid front unrounded vowel .

In phonetic and phonemic notation:

In algebra, the letter "a" along with other letters at the beginning of the alphabet is used to represent known quantities, whereas the letters at the end of the alphabet ("x", "y", "z") are used to denote unknown quantities.

In geometry, capital A, B, C etc. are used to denote segments, lines, rays, etc. A capital A is also typically used as one of the letters to represent an angle in a triangle, the lowercase a representing the side opposite angle A.

"A" is often used to denote something or someone of a better or more prestigious quality or status: A-, A or A+, the best grade that can be assigned by teachers for students' schoolwork; "A grade" for clean restaurants; A-list celebrities, etc. Such associations can have a motivating effect, as exposure to the letter A has been found to improve performance, when compared with other letters.

"A" is used as a prefix on some words, such as asymmetry, to mean "not" or "without" (from Greek).

In English grammar, "a", and its variant "an", is an indefinite article.

Finally, the letter A is used to denote size, as in a narrow size shoe, or a small cup size in a brassiere.







Category:ISO basic Latin letters
Category:Vowel lettersAlabama

Alabama () is a state in the southeastern region of the United States. It is bordered by Tennessee to the north, Georgia to the east, Florida and the Gulf of Mexico to the south, and Mississippi to the west. Alabama is the 30th largest by area and the 24th-most populous of the U.S. states. With a total of of inland waterways, Alabama has among the most of any state.

Alabama is nicknamed the "Yellowhammer State", after the state bird. Alabama is also known as the "Heart of Dixie" and the "Cotton State". The state tree is the longleaf pine, and the state flower is the camellia. Alabama's capital is Montgomery. The largest city by population is Birmingham, which has long been the most industrialized city; the largest city by land area is Huntsville. The oldest city is Mobile, founded by French colonists in 1702 as the capital of French Louisiana.

From the American Civil War until World War II, Alabama, like many states in the southern U.S., suffered economic hardship, in part because of its continued dependence on agriculture. Similar to other former slave states, Alabamian legislators employed Jim Crow laws to disenfranchise and otherwise discriminate against African Americans from the end of the Reconstruction Era up until at least the 1970s. Despite the growth of major industries and urban centers, white rural interests dominated the state legislature from 1901 to the 1960s. During this time, urban interests and African Americans

The European-American naming of the Alabama River and state was derived from the Alabama people, a Muskogean-speaking tribe whose members lived just below the confluence of the Coosa and Tallapoosa rivers on the upper reaches of the river. In the Alabama language, the word for a person of Alabama lineage is "Albaamo" (or variously "Albaama" or "Albàamo" in different dialects; the plural form is "Albaamaha"). The suggestion that "Alabama" was borrowed from the Choctaw language is unlikely. The word's spelling varies significantly among historical sources. The first usage appears in three accounts of the Hernando de Soto expedition of 1540: Garcilaso de la Vega used "Alibamo", while the Knight of Elvas and Rodrigo Ranjel wrote "Alibamu" and "Limamu", respectively, in transliterations of the term. As early as 1702, the French called the tribe the "Alibamon", with French maps identifying the river as "Rivière des Alibamons". Other spellings of the name have included "Alibamu", "Alabamo", "Albama", "Alebamon", "Alibama", "Alibamou", "Alabamu", "Allibamou".

Sources disagree on the word's meaning. Some scholars suggest the word comes from the Choctaw "alba" (meaning "plants" or "weeds") and "amo" (meaning "to cut", "to trim", or "to gather"). The meaning may have been "clearers of the thicket" or "herb gatherers", referring to clearing land for cultivation or collecting medicinal plants. The state has numerous place names of Native American origin. However, there are no correspondingly similar words in the Alabama language.

An 1842 article in the "Jacksonville Republican" proposed it meant "Here We Rest." This notion was popularized in the 1850s through the writings of Alexander Beaufort Meek. Experts in the Muskogean languages

Indigenous peoples of varying cultures lived in the area for thousands of years before the advent of European colonization. Trade with the northeastern tribes by the Ohio River began during the Burial Mound Period (1000 BC–AD 700) and continued until European contact.

The agrarian Mississippian culture covered most of the state from 1000 to 1600 AD, with one of its major centers built at what is now the Moundville Archaeological Site in Moundville, Alabama. This is the second-largest complex of the classic Middle Mississippian era, after Cahokia in present-day Illinois, which was the center of the culture. Analysis of artifacts from archaeological excavations at Moundville were the basis of scholars' formulating the characteristics of the Southeastern Ceremonial Complex (SECC). Contrary to popular belief, the SECC appears to have no direct links to Mesoamerican culture, but developed independently. The Ceremonial Complex represents a major component of the religion of the Mississippian peoples; it is one of the primary means by which their religion is understood.

Among the historical tribes of Native American people living in present-day Alabama at the time of European contact were the Cherokee, an Iroquoian language people; and the Muskogean-speaking Alabama ("Alibamu"), Chickasaw, Choctaw, Creek, and Koasati. While part of the same large language family, the Muskogee tribes developed distinct cultures and languages.

With exploration in the 16th century, the Spanish were the first Europeans to reach Alabama. The expedition of Hernando de Soto passed through Mabila and other parts of the state in 1540. More than 160 years later, the French founded the region's first European settlement at Old Mobile in 1702. The city was moved to the current site of Mobile in 1711. This area was claimed by the French from 1702 to 1763 as part of La Louisiane.

After the French lost to the British in the Seven Years' War, it became part of British West Florida from 1763 to 1783. After the United States victory in the American Revolutionary War, the territory was divided between the United States and Spain. The latter retained control of this western territory from 1783 until the surrender of the Spanish garrison at Mobile to U.S. forces on April 13, 1813.

Thomas Bassett, a loyalist to the British monarchy during the Revolutionary era, was one of the earliest white settlers in the state outside Mobile. He settled in the Tombigbee District during the early 1770s. The district's boundaries were roughly limited to the area within a few miles of the Tombigbee River and included portions of what is today southern Clarke County, northernmost Mobile County, and most of Washington County.

What is now the counties of Baldwin and Mobile became part of Spanish West Florida in 1783, part of the independent Republic of West Florida in 1810, and was finally added to the Mississippi Territory in 1812. Most of what is now the northern two-thirds of Alabama was known as the Yazoo lands beginning during the British colonial period. It was claimed by the Province of Georgia from 1767 onwards. Following the Revolutionary War, it remained a part of Georgia
With the exception of the area around Mobile and the Yazoo lands, what is now the lower one-third Alabama was made part of the Mississippi Territory when it was organized in 1798. The Yazoo lands were added to the territory in 1804, following the Yazoo land scandal. Spain kept a claim on its former Spanish West Florida territory in what would become the coastal counties until the Adams–Onís Treaty officially ceded it to the United States in 1819.

Before Mississippi's admission to statehood on December 10, 1817, the more sparsely settled eastern half of the territory was separated and named the Alabama Territory. The United States Congress created the Alabama Territory on March 3, 1817. St. Stephens, now abandoned, served as the territorial capital from 1817 to 1819.

Alabama was admitted as the 22nd state on December 14, 1819, with Congress selecting Huntsville as the site for the first Constitutional Convention. From July 5 to August 2, 1819, delegates met to prepare the new state constitution. Huntsville served as temporary capital from 1819 to 1820, when the seat of government moved to Cahaba in Dallas County
Cahaba, now a ghost town, was the first permanent state capital from 1820 to 1825. The Alabama Fever land rush was underway when the state was admitted to the Union, with settlers and land speculators pouring into the state to take advantage of fertile land suitable for cotton cultivation. Part of the frontier in the 1820s and 1830s, its constitution provided for universal suffrage for white men.

Southeastern planters and traders from the Upper South brought slaves with them as the cotton plantations in Alabama expanded. The economy of the central Black Belt (named for its dark, productive soil) was built around large cotton plantations whose owners' wealth grew mainly from slave labor. The area also drew many poor, disfranchised people who became subsistence farmers. Alabama had an estimated population of under 10,000 people in 1810, but it increased to more than 300,000 people by 1830. Most Native American tribes were completely removed from the state within a few years of the passage of the Indian Removal Act
From 1826 to 1846, Tuscaloosa served as Alabama's capital. On January 30, 1846, the Alabama legislature announced it had voted to move the capital city from Tuscaloosa to Montgomery. The first legislative session in the new capital met in December 1847. A new capitol building was erected under the direction of Stephen Decatur Button of Philadelphia. The first structure burned down in 1849, but was rebuilt on the same site in 1851. This second capitol building in Montgomery remains to the present day. It was designed by Barachias Holt of Exeter, Maine.

By 1860, the population had increased to 964,201 people, of which nearly half, 435,080, were enslaved African Americans, and 2,690 were free people of color. On January 11, 1861, Alabama declared its secession from the Union. After remaining an independent republic for a few days, it joined the Confederate States of America. The Confederacy's capital was initially at Montgomery. Alabama was heavily involved in the American Civil War
A company of cavalry soldiers from Huntsville, Alabama, joined Nathan Bedford Forrest's battalion in Hopkinsville, Kentucky. The company wore new uniforms with yellow trim on the sleeves, collar and coat tails. This led to them being greeted with "Yellowhammer", and the name later was applied to all Alabama troops in the Confederate Army.

Alabama's slaves were freed by the 13th Amendment in 1865. Alabama was under military rule from the end of the war in May 1865 until its official restoration to the Union in 1868. From 1867 to 1874, with most white citizens barred temporarily from voting and freedmen enfranchised, many African Americans emerged as political leaders in the state. Alabama was represented in Congress during this period by three African-American congressmen: Jeremiah Haralson, Benjamin S. Turner, and James T. Rapier.

Following the war, the state remained chiefly agricultural, with an economy tied to cotton. During Reconstruction, state legislators ratified a new state constitution in 1868 that created the state's first public school system and expanded women's rights. Legislators funded numerous public road and railroad projects, although these were plagued with allegations of fraud and misappropriation. Organized insurgent, resistance groups tried to suppress the freedmen and Republicans. Besides the short-lived original Ku Klux Klan, these included the Pale Faces, Knights of the White Camellia, Red Shirts, and the White League.

Reconstruction in Alabama ended in 1874, when the Democrats regained control of the legislature and governor's office through an election dominated by fraud and violence. They wrote another constitution in 1875, and the legislature passed the Blaine Amendment, prohibiting public money from being used to finance religious-affiliated schools. The same year, legislation was approved that called for racially segregated schools. Railroad passenger cars were segregated in 1891. After disfranchising most African Americans and many poor whites in the 1901 constitution, the Alabama legislature passed more Jim Crow laws

The new 1901 Constitution of Alabama included provisions for voter registration that effectively disenfranchised large portions of the population, including nearly all African Americans and Native Americans, and tens of thousands of poor whites, through making voter registration difficult, requiring a poll tax and literacy test. The 1901 constitution required racial segregation of public schools. By 1903, only 2,980 African Americans were registered in Alabama, although at least 74,000 were literate. This compared to more than 181,000 African Americans eligible to vote in 1900. The numbers dropped even more in later decades. The state legislature passed additional racial segregation laws related to public facilities into the 1950s: jails were segregated in 1911; hospitals in 1915; toilets, hotels, and restaurants in 1928; and bus stop waiting rooms in 1945.

While the planter class had persuaded poor whites to vote for this legislative effort to suppress black voting, the new restrictions resulted in their disenfranchisement as well, due mostly to the imposition of a cumulative poll tax. By 1941, whites constituted a slight majority of those disenfranchised by these laws: 600,000 whites vs. 520,000 African-Americans. Nearly all African Americans had lost the ability to vote. Despite numerous legal challenges that succeeded in overturning certain provisions, the state legislature would create new ones to maintain disenfranchisement. The exclusion of blacks from the political system persisted until after passage of federal civil rights legislation in 1965 to enforce their constitutional rights as citizens.

The rural-dominated Alabama legislature consistently underfunded schools and services for the disenfranchised African Americans, but it did not relieve them of paying taxes. Partially as a response to chronic underfunding of education for African Americans in the South, the Rosenwald Fund began funding the construction of what came to be known as Rosenwald Schools
Beginning in 1913, the first 80 Rosenwald Schools were built in Alabama for African-American children. A total of 387 schools, seven teachers' houses, and several vocational buildings were completed by 1937 in the state. Several of the surviving school buildings in the state are now listed on the National Register of Historic Places.

Continued racial discrimination and lynchings, agricultural depression, and the failure of the cotton crops due to boll weevil infestation led tens of thousands of African Americans from rural Alabama and other states to seek opportunities in northern and midwestern cities during the early decades of the 20th century as part of the Great Migration out of the South. Reflecting this emigration, the population growth rate in Alabama (see "historical populations" table below) dropped by nearly half from 1910 to 1920.

At the same time, many rural people migrated to the city of Birmingham to work in new industrial jobs. Birmingham experienced such rapid growth that it was called the "Magic City". By 1920, Birmingham was the 36th-largest city in the United States. Heavy industry and mining were the basis of its economy. Its residents were under-represented for decades in the state legislature, which refused to redistrict after each decennial census according to population changes, as it was required by the state constitution. This did not change until the late 1960s following a lawsuit and court order.

Industrial development related to the demands of World War II brought a level of prosperity to the state not seen since before the civil war. Rural workers poured into the largest cities in the state for better jobs and a higher standard of living. One example of this massive influx of workers occurred in Mobile. Between 1940 and 1943, more than 89,000 people moved into the city to work for war-related industries. Cotton and other cash crops faded in importance as the state developed a manufacturing and service base.

Despite massive population changes in the state from 1901 to 1961, the rural-dominated legislature refused to reapportion House and Senate seats based on population, as required by the state constitution to follow the results of decennial censuses. They held on to old representation to maintain political and economic power in agricultural areas. One result was that Jefferson County, containing Birmingham's industrial and economic powerhouse, contributed more than one-third of all tax revenue to the state, but did not receive a proportional amount in services. Urban interests were consistently underrepresented in the legislature. A 1960 study noted that because of rural domination, "a minority of about 25 per cent of the total state population is in majority control of the Alabama legislature."

In the United States Supreme Court cases of "Baker v. Carr" (1962) and "Reynolds v. Sims" (1964), the court ruled ruled that the principle of "one man, one vote" needed to be the basis of both houses of state legislatures as well, and that their districts had to be based on population, rather than geographic counties, as Alabama had used for its senate.

In 1972, for the first time since 1901, the legislature completed the congressional redistricting based on the decennial census. This benefited the urban areas that had developed, as well as all in the population who had been underrepresented for more than 60 years. Other changes were made to implement representative state house and senate districts.

African Americans continued to press in the 1950s and 1960s to end disenfranchisement and segregation in the state through the civil rights movement, including legal challenges. In 1954, the US Supreme Court ruled in "Brown v. Board of Education" that public schools had to be desegregated, but Alabama was slow to comply. During the 1960s, under Governor George Wallace, Alabama resisted compliance with federal demands for desegregation. The civil rights movement had notable events in Alabama, including the Montgomery Bus Boycott (1955–56), Freedom Rides in 1961, and 1965 Selma to Montgomery marches. These contributed to Congressional passage and enactment of the Civil Rights Act of 1964 and Voting Rights Act of 1965 by the U.S. Congress.

Legal segregation ended in the states in 1964, but Jim Crow customs often continued until specifically challenged in court. According to "The New York Times", by 2017, many of Alabama's African-Americans were living in Alabama's cities such as Birmingham and Montgomery. Also, the Black Belt region across central Alabama "is home to largely poor counties that are predominantly African-American. These counties include Dallas, Lowndes, Marengo and Perry."

Alabama has made some changes since the late 20th century and has used new types of voting to increase representation. In the 1980s, an omnibus redistricting case, "Dillard v. Crenshaw County", challenged the at-large voting for representative seats of 180 Alabama jurisdictions, including counties and school boards. At-large voting had diluted the votes of any minority in a county, as the majority tended to take all seats. Despite African Americans making up a significant minority in the state, they had been unable to elect any representatives in most of the at-large jurisdictions.

As part of settlement of this case, five Alabama cities and counties, including Chilton County, adopted a system of cumulative voting for election of representatives in multi-seat jurisdictions. This has resulted in more proportional representation for voters. In another form of proportional representation, 23 jurisdictions use limited voting, as in Conecuh County. In 1982, limited voting was first tested in Conecuh County

Alabama is the thirtieth-largest state in the United States with of total area: 3.2% of the area is water, making Alabama 23rd in the amount of surface water, also giving it the second-largest inland waterway system in the United States. About three-fifths of the land area is a gentle plain with a general descent towards the Mississippi River and the Gulf of Mexico. The North Alabama region is mostly mountainous, with the Tennessee River cutting a large valley and creating numerous creeks, streams, rivers, mountains, and lakes.

Alabama is bordered by the states of Tennessee to the north, Georgia to the east, Florida to the south, and Mississippi to the west. Alabama has coastline at the Gulf of Mexico, in the extreme southern edge of the state. The state ranges in elevation from sea level at Mobile Bay to over 1,800 feet (550 m) in the Appalachian Mountains in the northeast.

The highest point is Mount Cheaha, at a height of . Alabama's land consists of of forest or 67% of total land area. Suburban Baldwin County, along the Gulf Coast, is the largest county in the state in both land area and water area.

Areas in Alabama administered by the National Park Service include Horseshoe Bend National Military Park near Alexander City; Little River Canyon National Preserve near Fort Payne; Russell Cave National Monument in Bridgeport; Tuskegee Airmen National Historic Site in Tuskegee; and Tuskegee Institute National Historic Site near Tuskegee.

Additionally, Alabama has four National Forests: Conecuh, Talladega, Tuskegee, and William B. Bankhead. Alabama also contains the Natchez Trace Parkway, the Selma To Montgomery National Historic Trail, and the Trail Of Tears National Historic Trail. A notable natural wonder in Alabama is "Natural Bridge" rock, the longest natural bridge east of the Rockies, located just south of Haleyville.

A -wide meteorite impact crater is located in Elmore County, just north of Montgomery. This is the Wetumpka crater, the site of "Alabama's greatest natural disaster." A -wide meteorite hit the area about 80 million years ago. The hills just east of downtown Wetumpka

The state is classified as humid subtropical ("Cfa") under the Koppen Climate Classification. The average annual temperature is 64 °F (18 °C). Temperatures tend to be warmer in the southern part of the state with its proximity to the Gulf of Mexico, while the northern parts of the state, especially in the Appalachian Mountains in the northeast, tend to be slightly cooler. Generally, Alabama has very hot summers and mild winters with copious precipitation throughout the year. Alabama receives an average of of rainfall annually and enjoys a lengthy growing season of up to 300 days in the southern part of the state.

Summers in Alabama are among the hottest in the U.S., with high temperatures averaging over throughout the summer in some parts of the state. Alabama is also prone to tropical storms and even hurricanes. Areas of the state far away from the Gulf are not immune to the effects of the storms, which often dump tremendous amounts of rain as they move inland and weaken.

South Alabama reports many thunderstorms. The Gulf Coast, around Mobile Bay, averages between 70 and 80 days per year with thunder reported. This activity decreases somewhat further north in the state, but even the far north of the state reports thunder on about 60 days per year. Occasionally, thunderstorms are severe with frequent lightning and large hail
Alabama, along with Oklahoma and Iowa, has the most confirmed F5 and EF5 tornadoes of any state, according to statistics from the National Climatic Data Center for the period January 1, 1950, to June 2013. Several long-tracked F5/EF5 tornadoes have contributed to Alabama reporting more tornado fatalities since 1950 than any other state. The state was affected by the 1974 Super Outbreak and was devastated tremendously by the 2011 Super Outbreak
The peak season for tornadoes varies from the northern to southern parts of the state. Alabama is one of the few places in the world that has a secondary tornado season in November and December, along with the spring severe weather season. The northern part of the state—along the Tennessee Valley—is one of the areas in the U.S. most vulnerable to violent tornadoes. The area of Alabama and Mississippi most affected by tornadoes is sometimes referred to as Dixie Alley, as distinct from the Tornado Alley of the Southern Plains.

Winters are generally mild in Alabama, as they are throughout most of the Southeastern United States, with average January low temperatures around in Mobile and around in Birmingham. Although snow is a rare event in much of Alabama, areas of the state north of Montgomery may receive a dusting of snow a few times every winter, with an occasional moderately heavy snowfall every few years. Historic snowfall events include New Year's Eve 1963 snowstorm and the 1993 Storm of the Century. The annual average snowfall for the Birmingham area is per year. In the southern Gulf coast, snowfall is less frequent, sometimes going several years without any snowfall.

Alabama's highest temperature of was recorded on September 5, 1925, in the unincorporated community of Centerville. The record low of occurred on January 30, 1966, in New Market
Alabama is home to a diverse array of flora and fauna, due largely to a variety of habitats that range from the Tennessee Valley, Appalachian Plateau, and Ridge-and-Valley Appalachians of the north to the Piedmont, Canebrake, and Black Belt of the central region to the Gulf Coastal Plain and beaches along the Gulf of Mexico in the south. The state is usually ranked among the top in nation for its range of overall biodiversity.

Alabama is in the subtropical coniferous forest biome and once boasted huge expanses of pine forest, which still form the largest proportion of forests in the state. It currently ranks fifth in the nation for the diversity of its flora. It is home to nearly 4,000 pteridophyte and spermatophyte plant species.

Indigenous animal species in the state include 62 mammal species, 93 reptile species, 73 amphibian species, roughly 307 native freshwater fish species, and 420 bird species that spend at least part of their year within the state. Invertebrates include 97 crayfish species and 383 mollusk

The United States Census Bureau estimates that the population of Alabama was 4,887,871 on July 1, 2018, which represents an increase of 108,135 or 2.26%, since the 2010 Census. This includes a natural increase since the last census of 121,054 people (that is 502,457 births minus 381,403 deaths) and an increase due to net migration of 104,991 people into the state.

Immigration from outside the U.S. resulted in a net increase of 31,180 people, and migration within the country produced a net gain of 73,811 people. The state had 108,000 foreign-born (2.4% of the state population), of which an estimated 22.2% were undocumented (24,000).

The center of population of Alabama is located in Chilton County, outside the town of Jemison.

According to the 2010 Census, Alabama had a population of 4,779,736. The racial composition of the state was 68.5% White (67.0% Non-Hispanic White and 1.5% Hispanic White), 26.2% Black or African American, 3.9% Hispanic or Latino of any race, 1.1% Asian, 0.6% American Indian and Alaska Native, 0.1% Native Hawaiian and Other Pacific Islander, 2.0% from Some Other Race, and 1.5% from Two or More Races. In 2011, 46.6% of Alabama's population younger than age 1 were minorities.

The largest reported ancestry groups in Alabama are: African (26.2%), English (23.6%), Irish (7.7%), German (5.7%), and Scots-Irish (2.0%). Those citing "American" ancestry in Alabama are generally of English or British ancestry; many Anglo-Americans identify as having American ancestry because their roots have been in North America for so long, in some cases since the 1600s. Demographers estimate that a minimum of 20–23% of people in Alabama are of predominantly English ancestry and that the figure is likely higher. In the 1980 census, 41% of the people in Alabama identified as being of English ancestry, making them the largest ethnic group at the time.

Based on historic migration and settlement patterns in the southern colonies and states, demographers estimated there are more people in Alabama of Scots-Irish origins than self-reported. Many people in Alabama claim Irish ancestry because of the term Scots-Irish but, based on historic immigration and settlement, their ancestors were more likely Protestant Scots-Irish coming from northern Ireland, where they had been for a few generations as part of the English colonization. The Scots-Irish were the largest non-English immigrant group from the British Isles before the American Revolution, and many settled in the South, later moving into the Deep South as it was developed.

In 1984, under the Davis–Strong Act, the state legislature established the Alabama Indian Affairs Commission. Native American groups within the state had increasingly been demanding recognition as ethnic groups and seeking an end to discrimination. Given the long history of slavery and associated racial segregation, the Native American peoples, who have sometimes been of mixed race, have insisted on having their cultural identification respected. In the past, their self-identification was often overlooked as the state tried to impose a binary breakdown of society into white and black.

The state has officially recognized nine American Indian tribes in the state, descended mostly from the Five Civilized Tribes

95.1% of all Alabama residents five years old or older spoke only English at home in 2010, a minor decrease from 96.1% in 2000. Alabama English is predominantly Southern, and is related to South Midland speech which was taken across the border from Tennessee

In the 2008 American Religious Identification Survey, 86% of Alabama respondents reported their religion as Christian, including 6% Catholic, with 11% as having no religion. The composition of other traditions is 0.5% Mormon, 0.5% Jewish, 0.5% Muslim, 0.5% Buddhist, and 0.5% Hindu.

Alabama is located in the middle of the Bible Belt, a region of numerous Protestant Christians. Alabama has been identified as one of the most religious states in the United States, with about 58% of the population attending church regularly. A majority of people in the state identify as Evangelical Protestant. , the three largest denominational groups in Alabama are the Southern Baptist Convention, The United Methodist Church, and non-denominational Evangelical Protestant.

In Alabama, the Southern Baptist Convention has the highest number of adherents with 1,380,121; this is followed by the United Methodist Church with 327,734 adherents, non-denominational Evangelical Protestant with 220,938 adherents, and the Catholic Church with 150,647 adherents. Many Baptist and Methodist congregations became established in the Great Awakening of the early 19th century, when preachers proselytized across the South. The Assemblies of God had almost 60,000 members, the Churches of Christ had nearly 120,000 members. The Presbyterian churches, strongly associated with Scots-Irish immigrants of the 18th century and their descendants, had a combined membership around 75,000 (PCA – 28,009 members in 108 congregations, PC(USA) – 26,247 members in 147 congregations, the Cumberland Presbyterian Church – 6,000 members in 59 congregations, the Cumberland Presbyterian Church in America – 5,000 members and 50 congregations plus the EPC and Associate Reformed Presbyterians with 230 members and 9 congregations).

In a 2007 survey, nearly 70% of respondents could name all four of the Christian Gospels. Of those who indicated a religious preference, 59% said they possessed a "full understanding" of their faith and needed no further learning. In a 2007 poll, 92% of Alabamians reported having at least some confidence in churches in the state.

Although in much smaller numbers, many other religious faiths are represented in the state as well, including Judaism, Islam, Hinduism, Buddhism, Sikhism, the Bahá'í Faith, and Unitarian Universalism.

Jews have been present in what is now Alabama since 1763, during the colonial era of Mobile, when Sephardic Jews immigrated from London. The oldest Jewish congregation in the state is Congregation Sha'arai Shomayim in Mobile. It was formally recognized by the state legislature on January 25, 1844. Later immigrants in the nineteenth and twentieth centuries tended to be Ashkenazi Jews from eastern Europe. Jewish denominations in the state include two Orthodox, four Conservative, ten Reform, and one Humanistic synagogue.

Muslims have been increasing in Alabama, with 31 mosques built by 2011, many by African-American converts.

Several Hindu temples and cultural centers in the state have been founded by Indian immigrants and their descendants, the best-known being the Shri Swaminarayan Mandir in Birmingham, the Hindu Temple and Cultural Center of Birmingham in Pelham, the Hindu Cultural Center of North Alabama in Capshaw, and the Hindu Mandir and Cultural Center in Tuscaloosa.

There are six Dharma centers and organizations for Theravada Buddhists. Most monastic Buddhist temples are concentrated in southern Mobile County, near Bayou La Batre. This area has attracted an influx of refugees from Cambodia, Laos, and Vietnam during the 1970s and thereafter. The four temples within a ten-mile radius of Bayou La Batre, include Chua Chanh Giac, Wat Buddharaksa, and Wat Lao Phoutthavihan.

The first community of adherents of the Bahá'í Faith in Alabama was founded in 1896 by Paul K. Dealy, who moved from Chicago to Fairhope. Bahá'í centers in Alabama exist in Birmingham, Huntsville, and Florence.

A Centers for Disease Control and Prevention study in 2008 showed that obesity in Alabama was a problem, with most counties having over 29% of adults obese, except for ten which had a rate between 26% and 29%. Residents of the state, along with those in five other states, were least likely in the nation to be physically active during leisure time. Alabama, and the southeastern U.S. in general, has one of the highest incidences of adult onset diabetes in the country, exceeding 10% of adults.

The state has invested in aerospace, education, health care, banking, and various heavy industries, including automobile manufacturing, mineral extraction, steel production and fabrication. By 2006, crop and animal production in Alabama was valued at $1.5 billion. In contrast to the primarily agricultural economy of the previous century, this was only about 1% of the state's gross domestic product. The number of private farms has declined at a steady rate since the 1960s, as land has been sold to developers, timber companies, and large farming conglomerates.

Non-agricultural employment in 2008 was 121,800 in management occupations; 71,750 in business and financial operations; 36,790 in computer-related and mathematical occupation; 44,200 in architecture and engineering; 12,410 in life, physical, and social sciences; 32,260 in community and social services; 12,770 in legal occupations; 116,250 in education, training, and library services; 27,840 in art, design and media occupations; 121,110 in healthcare; 44,750 in fire fighting, law enforcement, and security; 154,040 in food preparation and serving; 76,650 in building and grounds cleaning and maintenance; 53,230 in personal care and services; 244,510 in sales; 338,760 in office and administration support; 20,510 in farming, fishing, and forestry; 120,155 in construction and mining, gas, and oil extraction; 106,280 in installation, maintenance, and repair; 224,110 in production; and 167,160 in transportation and material moving.

According to the U.S. Bureau of Economic Analysis, the 2008 total gross state product was $170 billion, or $29,411 per capita. Alabama's 2012 GDP increased 1.2% from the previous year. The single largest increase came in the area of information. In 2010, per capita income for the state was $22,984.

The state's seasonally adjusted unemployment rate was 5.8% in April 2015. This compared to a nationwide seasonally adjusted rate of 5.4%.

Alabama has no state minimum wage and uses the federal minimum wage of $7.25. In February 2016, the state passed legislation that prevents Alabama municipalities from raising the minimum wage in their locality. The legislation voids a Birmingham city ordinance that was to raise the city's minimum wage to $10.10.

, Alabama has the sixth highest poverty rate among states in the U.S. In 2017, United Nations Special Rapporteur Philip Alston

The five employers that employed the most employees in Alabama in April 2011 were:

The next twenty largest employers, , included:
Alabama's agricultural outputs include poultry and eggs, cattle, fish, plant nursery items, peanuts, cotton, grains such as corn and sorghum, vegetables, milk, soybeans, and peaches. Although known as "The Cotton State", Alabama ranks between eighth and tenth in national cotton production, according to various reports, with Texas, Georgia and Mississippi comprising the top three.

Alabama's industrial outputs include iron and steel products (including cast-iron and steel pipe); paper, lumber, and wood products; mining (mostly coal); plastic products; cars and trucks; and apparel. In addition, Alabama produces aerospace and electronic products, mostly in the Huntsville area, the location of NASA's George C. Marshall Space Flight Center and the U.S. Army Materiel Command, headquartered at Redstone Arsenal
A great deal of Alabama's economic growth since the 1990s has been due to the state's expanding automotive manufacturing industry. Located in the state are Honda Manufacturing of Alabama, Hyundai Motor Manufacturing Alabama, Mercedes-Benz U.S. International, and Toyota Motor Manufacturing Alabama, as well as their various suppliers. Since 1993, the automobile industry has generated more than 67,800 new jobs in the state. Alabama currently ranks 4th in the nation for vehicle exports.

Automakers accounted for approximately a third of the industrial expansion in the state in 2012. The eight models produced at the state's auto factories totaled combined sales of 74,335 vehicles for 2012. The strongest model sales during this period were the Hyundai Elantra compact car, the Mercedes-Benz GL-Class sport utility vehicle and the Honda Ridgeline
Steel producers Outokumpu, Nucor, SSAB, ThyssenKrupp, and U.S. Steel have facilities in Alabama and employ over 10,000 people. In May 2007, German steelmaker ThyssenKrupp selected Calvert in Mobile County for a 4.65 billion combined stainless and carbon steel processing facility. ThyssenKrupp's stainless steel division, Inoxum, including the stainless portion of the Calvert plant, was sold to Finnish stainless steel company Outokumpu in 2012. The remaining portion of the ThyssenKrupp plant had final bids submitted by ArcelorMittal and Nippon Steel for $1.6 billion in March 2013. Companhia Siderúrgica Nacional submitted a combined bid for the mill at Calvert, plus a majority stake in the ThyssenKrupp mill in Brazil, for $3.8 billion. In July 2013, the plant was sold to ArcelorMittal and Nippon Steel.

The Hunt Refining Company, a subsidiary of Hunt Consolidated, Inc., is based in Tuscaloosa and operates a refinery there. The company also operates terminals in Mobile, Melvin, and Moundville. JVC America, Inc. operates an optical disc replication and packaging plant in Tuscaloosa.

The Goodyear Tire and Rubber Company operates a large plant in Gadsden that employs about 1,400 people. It has been in operation since 1929.

Construction of an Airbus A320 family aircraft assembly plant in Mobile was formally announced by Airbus CEO Fabrice Brégier from the Mobile Convention Center on July 2, 2012. The plans include a $600 million factory at the Brookley Aeroplex for the assembly of the A319, A320 and A321 aircraft. Construction began in 2013, with plans for it to become operable by 2015 and produce up to 50 aircraft per year by 2017. The assembly plant is the company's first factory to be built within the United States. It was announced on February 1, 2013, that Airbus had hired Alabama-based Hoar Construction

An estimated 20 million tourists visit the state each year. Over 100,000 of these are from other countries, including from Canada, the United Kingdom, Germany and Japan. In 2006, 22.3 million travellers spent $8.3 billion providing an estimated 162,000 jobs in the state. Some of the most popular areas include the Rocket City of Huntsville, the beaches along the Gulf, and the state's capitol in Montgomery.

UAB Hospital is the only Level I trauma center

Alabama has the headquarters of Regions Financial Corporation, BBVA Compass, Superior Bancorp, and the former Colonial Bancgroup. Birmingham-based Compass Banchshares was acquired by Spanish-based BBVA in September 2007, although the headquarters of BBVA Compass remains in Birmingham. In November 2006, Regions Financial completed its merger with AmSouth Bancorporation, which was also headquartered in Birmingham. SouthTrust Corporation, another large bank headquartered in Birmingham, was acquired by Wachovia in 2004 for $14.3 billion.

The city still has major operations for Wachovia and its now post-operating bank Wells Fargo, which includes a regional headquarters, an operations center campus and a $400 million data center. Nearly a dozen smaller banks are also headquartered in the Birmingham, such as Superior Bancorp, ServisFirst, and New South Federal Savings Bank. Birmingham also serves as the headquarters for several large investment management companies, including Harbert Management Corporation.

Telecommunications provider AT&T, formerly BellSouth, has a major presence in Alabama with several large offices in Birmingham. The company has over 6,000 employees and more than 1,200 contract employees.

Many commercial technology companies are headquartered in Huntsville, such as network access company ADTRAN, computer graphics company Intergraph, and IT infrastructure company Avocent. Cinram manufactures and distributes 20th Century Fox DVDs and Blu-ray Discs out of its Huntsville plant.

Rust International has grown to include Brasfield & Gorrie, BE&K, Hoar Construction, and B.L. Harbert International, which all routinely are included in the Engineering News-Record lists of top design, international construction, and engineering firms. (Rust International was acquired in 2000 by Washington Group International, which was in turn acquired by San-Francisco based URS Corporation
The foundational document for Alabama's government is the Alabama Constitution, which was ratified in 1901. At almost 800 amendments and 310,000 words, it is by some accounts the world's longest constitution and is roughly forty times the length of the United States Constitution

Alabama's government is divided into three coequal branches. The legislative branch is the Alabama Legislature, a bicameral assembly composed of the Alabama House of Representatives, with 105 members, and the Alabama Senate, with 35 members. The Legislature is responsible for writing, debating, passing, or defeating state legislation. The Republican Party currently holds a majority in both houses of the Legislature. The Legislature has the power to override a gubernatorial veto by a simple majority (most state Legislatures require a two-thirds majority to override a veto).

Until 1964, the state elected state senators on a geographic basis by county, with one per county. It had not redistricted congressional districts since passage of its constitution in 1901; as a result, urbanized areas were grossly underrepresented. It had not changed legislative districts to reflect the decennial censuses, either. In "Reynolds v. Sims" (1964), the US Supreme Court implemented the principle of "one man, one vote
The executive branch is responsible for the execution and oversight of laws. It is headed by the Governor of Alabama. Other members of executive branch include the cabinet, the Attorney General of Alabama, the Alabama Secretary of State, the Alabama State Treasurer, and the State Auditor of Alabama. The current governor of the state is Republican Kay Ivey. The office of lieutenant governor is currently vacant.

The members of the Legislature take office immediately after the November elections. Statewide officials, such as the governor, lieutenant governor, attorney general, and other constitutional officers, take office the following January.

The judicial branch is responsible for interpreting the state's Constitution and applying the law in state criminal and civil cases. The state's highest court is the Supreme Court of Alabama. Alabama uses partisan elections to select judges. Since the 1980s judicial campaigns have become increasingly politicized. The current chief justice of the Alabama Supreme Court is Republican Lyn Stuart. All sitting justices on the Alabama Supreme Court are members of the Republican Party. There are two intermediate appellate courts, the Court of Civil Appeals and the Court of Criminal Appeals, and four trial courts: the circuit court (trial court of general jurisdiction), and the district, probate, and municipal courts.

Some critics believe that the election of judges has contributed to an exceedingly high rate of executions. Alabama has the highest per capita death penalty rate in the country. In some years, it imposes more death sentences than does Texas, a state which has a population five times larger. Some of its cases have been highly controversial; the Supreme Court has overturned 24 convictions in death penalty cases. It was the only state to allow judges to override jury decisions in whether or not to use a death sentence; in 10 cases judges overturned sentences of life imprisonment without parole (LWOP) that were voted unanimously by juries. This judicial authority was removed in April 2017.

Alabama levies a 2, 4, or 5 percent personal income tax, depending upon the amount earned and filing status. Taxpayers are allowed to deduct their federal income tax from their Alabama state tax, and can do so even if taking the standard deduction. Taxpayers who file itemized deductions are also allowed to deduct the Federal Insurance Contributions Act tax (Social Security and Medicare tax).

The state's general sales tax rate is 4%. Sales tax rates for cities and counties are also added to purchases. For example, the total sales tax rate in Mobile is 10% and there is an additional restaurant tax of 1%, which means that a diner in Mobile would pay an 11% tax on a meal. , sales and excise taxes in Alabama account for 51% of all state and local revenue, compared with an average of about 36% nationwide. Alabama is one of seven states that levy a tax on food at the same rate as other goods, and one of two states (the other being neighboring Mississippi) which fully taxes groceries without any offsetting relief for low-income families. (Most states exempt groceries from sales tax or apply a lower tax rate.)

Alabama's income tax on poor working families is among the highest in the United States. Alabama is the only state that levies income tax on a family of four with income as low as $4,600, which is barely one-quarter of the federal poverty line. Alabama's threshold is the lowest among the 41 states and the District of Columbia with income taxes.

The corporate income tax rate is currently 6.5%. The overall federal, state, and local tax burden in Alabama ranks the state as the second least tax-burdened state in the country. Property taxes

Alabama has 67 counties. Each county has its own elected legislative branch, usually called the county commission. It also has limited executive authority in the county. Because of the constraints of the Alabama Constitution, which centralizes power in the state legislature, only seven counties (Jefferson, Lee, Mobile, Madison, Montgomery, Shelby, and Tuscaloosa) in the state have limited home rule. Instead, most counties in the state must lobby the Local Legislation Committee of the state legislature to get simple local policies approved, ranging from waste disposal to land use zoning.

The state legislature has retained power over local governments by refusing to pass a constitutional amendment establishing home rule for counties, as recommended by the 1973 Alabama Constitutional Commission. Legislative delegations retain certain powers over each county. United States Supreme Court decisions in "Baker v. Carr" (1964) required that both houses have districts established on the basis of population, and redistricted after each census, in order to implement the principle of "one man, one vote". Before that, each county was represented by one state senator, leading to under-representation in the state senate for more urbanized, populous counties. The rural bias of the state legislature, which had also failed to redistrict seats in the state house, affected politics well into the 20th century, failing to recognize the rise of industrial cities and urbanized areas.

"The lack of home rule for counties in Alabama has resulted in the proliferation of local legislation permitting counties to do things not authorized by the state constitution. Alabama's constitution has been amended more than 700 times, and almost one-third of the amendments are local in nature, applying to only one county or city. A significant part of each legislative session is spent on local legislation, taking away time and attention of legislators from issues of statewide importance."

Alabama is an alcoholic beverage control state, meaning that the state government holds a monopoly on the sale of alcohol. The Alabama Alcoholic Beverage Control Board controls the sale and distribution of alcoholic beverages in the state. Twenty-five of the 67 counties are "dry counties" which ban the sale of alcohol, and there are many dry municipalities even in counties which permit alcohol sales.

During Reconstruction following the American Civil War, Alabama was occupied by federal troops of the Third Military District under General John Pope. In 1874, the political coalition of white Democrats known as the Redeemers took control of the state government from the Republicans, in part by suppressing the black vote through violence, fraud and intimidation.

After 1890, a coalition of White Democratic politicians passed laws to segregate and disenfranchise African American residents, a process completed in provisions of the 1901 constitution. Provisions which disenfranchised blacks resulted in excluding many poor Whites. By 1941 more Whites than Blacks had been disenfranchised: 600,000 to 520,000. The total effects were greater on the black community, as almost all of its citizens were disfranchised and relegated to separate and unequal treatment under the law.

From 1901 through the 1960s, the state did not redraw election districts as population grew and shifted within the state during urbanization and industrialization of certain areas. As counties were the basis of election districts, the result was a rural minority that dominated state politics through nearly three-quarters of the century, until a series of federal court cases required redistricting in 1972 to meet equal representation.

Alabama state politics gained nationwide and international attention in the 1950s and 1960s during the civil rights movement, when whites bureaucratically, and at times violently, resisted protests for electoral and social reform. Governor George Wallace, the state's only four-term governor, was a controversial figure who vowed to maintain segregation. Only after passage of the federal Civil Rights Act of 1964 and Voting Rights Act of 1965 did African Americans regain the ability to exercise suffrage, among other civil rights. In many jurisdictions, they continued to be excluded from representation by at-large electoral systems, which allowed the majority of the population to dominate elections. Some changes at the county level have occurred following court challenges to establish single-member districts that enable a more diverse representation among county boards.

In 2007, the Alabama Legislature passed, and Republican Governor Bob Riley signed a resolution expressing "profound regret" over slavery and its lingering impact. In a symbolic ceremony, the bill was signed in the Alabama State Capitol, which housed Congress of the Confederate States of America.

In 2010, Republicans won control of both houses of the legislature for the first time in 136 years.

, there are a total of 3,326,812 registered voters, with 2,979,576 active, and the others inactive in the state.

With the disfranchisement of Blacks in 1901, the state became part of the "Solid South", a system in which the Democratic Party operated as effectively the only viable political party in every Southern state. For nearly 100 years, local and state elections in Alabama were decided in the Democratic Party primary, with generally only token Republican challengers running in the General Election. Since the mid to late 20th century, however, there has been a realignment among the two major political parties, and white conservatives started shifting to the Republican Party. In Alabama, majority-white districts are now expected to regularly elect Republican candidates to federal, state and local office.

Members of the nine seats on the Supreme Court of Alabama and all ten seats on the state appellate courts are elected to office. Until 1994, no Republicans held any of the court seats. In that general election, the then-incumbent Chief Justice, Ernest C. Hornsby, refused to leave office after losing the election by approximately 3,000 votes to Republican Perry O. Hooper, Sr.. Hornsby sued Alabama and defiantly remained in office for nearly a year before finally giving up the seat after losing in court. This ultimately led to a collapse of support for Democrats at the ballot box in the next three or four election cycles. The Democrats lost the last of the nineteen court seats in August 2011 with the resignation of the last Democrat on the bench.

In the early 21st century, Republicans hold all seven of the statewide elected executive branch offices. Republicans hold six of the eight elected seats on the Alabama State Board of Education. In 2010, Republicans took large majorities of both chambers of the state legislature, giving them control of that body for the first time in 136 years. The last remaining statewide Democrat, who served on the Alabama Public Service Commission was defeated in 2012.

Only two Republican Lieutenant Governors have been elected since the end of Reconstruction, when Republicans generally represented Reconstruction government, including the newly emancipated freedmen who had gained the franchise. The two GOP Lt. Governors were Steve Windom (1999–2003) and Kay Ivey (2011–2017).

Many local offices (County Commissioners, Boards of Education, Tax Assessors, Tax Collectors, etc.) in the state are still held by Democrats. Many rural counties have voters who are majority Democrats, resulting in local elections being decided in the Democratic primary. Similarly many metropolitan and suburban counties are majority-Republican and elections are effectively decided in the Republican Primary, although there are exceptions.

Alabama's 67 County Sheriffs are elected in partisan, at-large races, and Democrats still retain the narrow majority of those posts. The current split is 35 Democrats, 31 Republicans, and one Independent Fayette. However, most of the Democratic sheriffs preside over rural and less populated counties. The majority of Republican sheriffs have been elected in the more urban/suburban and heavily populated counties. , the state of Alabama has one female sheriff, in Morgan County, Alabama, and ten African-American sheriffs.

The state's two U.S. senators are Republican Richard C. Shelby and Democrat Doug Jones. Shelby was originally elected to the Senate as a Democrat in 1986 and re-elected in 1992, but switched parties immediately following the November 1994 general election.

In the U.S. House of Representatives, the state is represented by seven members, six of whom are Republicans: (Bradley Byrne, Mike D. Rogers, Robert Aderholt, Morris J. Brooks, Martha Roby, and Gary Palmer) and one Democrat: Terri Sewell who represents the Black Belt as well as most of the predominantly black portions of Birmingham, Tuscaloosa and Montgomery

Public primary and secondary education in Alabama is under the purview of the Alabama State Board of Education as well as local oversight by 67 county school boards and 60 city boards of education. Together, 1,496 individual schools provide education for 744,637 elementary and secondary students.

Public school funding is appropriated through the Alabama Legislature through the Education Trust Fund. In FY 2006–2007, Alabama appropriated $3,775,163,578 for primary and secondary education. That represented an increase of $444,736,387 over the previous fiscal year. In 2007, over 82 percent of schools made adequate yearly progress (AYP) toward student proficiency under the National No Child Left Behind law, using measures determined by the state of Alabama.

While Alabama's public education system has improved in recent decades, it lags behind in achievement compared to other states. According to U.S. Census data (2000), Alabama's high school graduation rate—75%—is the fourth lowest in the U.S. (after Kentucky, Louisiana and Mississippi). The largest educational gains were among people with some college education but without degrees.

Although unusual in the West, school corporal punishment is not uncommon in Alabama, with 27,260 public school students paddled

Alabama's programs of higher education include 14 four-year public universities, two-year community colleges, and 17 private, undergraduate and graduate universities. In the state are four medical schools (as of fall 2015) (University of Alabama School of Medicine, University of South Alabama and Alabama College of Osteopathic Medicine and The Edward Via College of Osteopathic Medicine – Auburn Campus), two veterinary colleges (Auburn University and Tuskegee University), a dental school (University of Alabama School of Dentistry), an optometry college (University of Alabama at Birmingham), two pharmacy schools (Auburn University and Samford University), and five law schools (University of Alabama School of Law, Birmingham School of Law, Cumberland School of Law, Miles Law School, and the Thomas Goode Jones School of Law). Public, post-secondary education in Alabama is overseen by the Alabama Commission on Higher Education and the Alabama Department of Postsecondary Education
The largest single campus is the University of Alabama, located in Tuscaloosa, with 37,665 enrolled for fall 2016. Troy University was the largest institution in the state in 2010, with an enrollment of 29,689 students across four Alabama campuses (Troy, Dothan, Montgomery, and Phenix City), as well as sixty learning sites in seventeen other states and eleven other countries. The oldest institutions are the public University of North Alabama in Florence and the Catholic Church-affiliated Spring Hill College in Mobile, both founded in 1830.

Accreditation of academic programs is through the Southern Association of Colleges and Schools (SACS) as well as other subject-focused national and international accreditation agencies such as the Association for Biblical Higher Education (ABHE), the Council on Occupational Education (COE), and the Accrediting Council for Independent Colleges and Schools (ACICS).

According to the 2011 "U.S. News & World Report", Alabama had three universities ranked in the top 100 Public Schools in America (University of Alabama at 31, Auburn University at 36, and University of Alabama at Birmingham at 73).

According to the 2012 "U.S. News & World Report", Alabama had four tier 1 universities (University of Alabama, Auburn University, University of Alabama at Birmingham and University of Alabama in Huntsville).

Major newspapers include "Birmingham News", Mobile "Press-Register", and "Montgomery Advertiser

College football is extremely popular in Alabama, particularly the University of Alabama Crimson Tide and Auburn University Tigers, rivals in the Southeastern Conference. In the 2013 season, Alabama averaged over 100,000 fans per game and Auburn averaged over 80,000 fans, both numbers among the top 20 in the nation in average attendance. Bryant–Denny Stadium is the home of the Alabama football team, and has a seating capacity of 101,821, and is the fifth largest stadium in America. Jordan-Hare Stadium is the home field of the Auburn football team and seats up to 87,451.

Legion Field is home for the UAB Blazers football program and the Birmingham Bowl. It seats 71,594. Ladd–Peebles Stadium in Mobile is the home of the University of South Alabama football team, and serves as the home of the NCAA Senior Bowl, Dollar General Bowl (formerly GoDaddy.com Bowl), and Alabama-Mississippi All Star Classic; the stadium seats 40,646. In 2009, Bryant–Denny Stadium and Jordan-Hare Stadium became the homes of the Alabama High School Athletic Association

Alabama has several professional and semi-professional sports teams, including three minor league baseball teams.

The Talladega Superspeedway motorsports complex hosts a series of NASCAR events. It has a seating capacity of 143,000 and is the thirteenth largest stadium in the world and sixth largest stadium in America. Also, the Barber Motorsports Park has hosted IndyCar Series and Rolex Sports Car Series races.

The ATP Birmingham was a World Championship Tennis tournament held from 1973 to 1980.

Alabama has hosted several professional golf tournaments, such as the 1984 and 1990 PGA Championship at Shoal Creek, the Barbasol Championship (PGA Tour), the Mobile LPGA Tournament of Champions, Airbus LPGA Classic, and Yokohama Tire LPGA Classic (LPGA Tour), and The Tradition (Champions Tour
Major airports with sustained commercial operations in Alabama include Birmingham-Shuttlesworth International Airport (BHM), Huntsville International Airport (HSV), Dothan Regional Airport (DHN), Mobile Regional Airport (MOB), Montgomery Regional Airport (MGM), and Muscle Shoals – Northwest Alabama Regional Airport (MSL).

For rail transport, Amtrak schedules the "Crescent", a daily passenger train, running from New York to New Orleans with station stops at Anniston, Birmingham, and Tuscaloosa.

Alabama has six major interstate roads that cross the state: Interstate 65 (I-65) travels north–south roughly through the middle of the state; I-20/I-59 travel from the central west Mississippi state line to Birmingham, where I-59 continues to the north-east corner of the state and I-20 continues east towards Atlanta; I-85 originates in Montgomery and travels east-northeast to the Georgia state line, providing a main thoroughfare to Atlanta; and I-10 traverses the southernmost portion of the state, traveling from west to east through Mobile. I-22 enters the state from Mississippi and connects Birmingham with Memphis, Tennessee. In addition, there are currently five auxiliary interstate routes in the state: I-165 in Mobile, I-359 in Tuscaloosa, I-459 around Birmingham, I-565 in Decatur and Huntsville, and I-759 in Gadsden. A sixth route, I-685, will be formed when I-85 is rerouted along a new southern bypass of Montgomery. A proposed northern bypass of Birmingham will be designated as I-422. Since a direct connection from I-22 to I-422 will not be possible, I-222 has been proposed, as well.

Several U.S. Highways also pass through the state, such as U.S. Route 11 (US-11), US-29, US-31, US-43, US-45, US-72, US-78, US-80, US-82, US-84, US-90, US-98, US-231, US-278, US-280, US-331, US-411, and US-431.

There are four toll roads in the state: Montgomery Expressway in Montgomery; Tuscaloosa Bypass in Tuscaloosa; Emerald Mountain Expressway in Wetumpka; and Beach Express in Orange Beach.

The Port of Mobile, Alabama's only saltwater port, is a large seaport on the Gulf of Mexico with inland waterway access to the Midwest by way of the Tennessee-Tombigbee Waterway. The Port of Mobile was ranked 12th by tons of traffic in the United States during 2009. The newly expanded container terminal
Category:1819 establishments in the United States
Category:Southern United States
Category:States and territories established in 1819
Category:States of the Confederate States
Category:States of the Gulf Coast of the United States
Category:States of the United States
Category:U.S. states with multiple time zones
In Greek mythology, Achilles or Achilleus ( ; , "Achilleus" ) was a Greek hero of the Trojan War and the central character and the greatest warrior of Homer's "Iliad". His mother was the immortal Nereid Thetis, and his father, the mortal Peleus, was the king of the Myrmidons.

Achilles' most notable feat during the Trojan War was the slaying of the Trojan hero Hector outside the gates of Troy. Although the death of Achilles is not presented in the "Iliad", other sources concur that he was killed near the end of the Trojan War by Paris, who shot him in the heel with an arrow. Later legends (beginning with a poem by Statius in the 1st century AD) state that Achilles was invulnerable in all of his body except for his heel because, when his mother Thetis dipped him in the river Styx as an infant, she held him by one of his heels. Alluding to these legends, the term "Achilles' heel" has come to mean a point of weakness, especially in someone or something with an otherwise strong constitution. The Achilles tendon is also named after him due to these legends.

Linear B tablets attest to the personal name "Achilleus" in the forms "a-ki-re-u" and "a-ki-re-we", the latter being the dative of the former. The name grew more popular, even becoming common soon after the seventh century BC and was also turned into the female form Ἀχιλλεία ("Achilleía"), attested in Attica in the fourth century BC (IG II² 1617) and, in the form "Achillia", on a stele in Halicarnassus as the name of a female gladiator fighting an "Amazon".

Achilles' name can be analyzed as a combination of (') "distress, pain, sorrow, grief" and (') "people, soldiers, nation", resulting in a proto-form "*Akhí-lāu̯os" "he who has the people distressed" or "he whose people have distress". The grief or distress of the people is a theme raised numerous times in the "Iliad" (and frequently by Achilles himself). Achilles' role as the hero of grief or distress forms an ironic juxtaposition with the conventional view of him as the hero of "" ("glory", usually in war). Furthermore, "laós" has been construed by Gregory Nagy, following Leonard Palmer, to mean "a corps of soldiers", a muster

Another etymology relates the name to a Proto-Indo-European compound "*h₂eḱ-pṓds" "sharp foot" which first gave an Illyrian "*āk̂pediós", evolving through time into "*ākhpdeós" and then "*akhiddeús". The shift from "-dd-" to "-ll-" is then ascribed to the passing of the name into Greek via a Pre-Greek source. The first root part "*h₂eḱ-" "sharp, pointed" also gave Greek ἀκή ("akḗ" "point, silence, healing"), ἀκμή ("akmḗ" "point, edge, zenith") and ὀξύς ("oxús" "sharp, pointed, keen, quick, clever"), whereas ἄχος stems from the root "*h₂egʰ-" "to be upset, afraid". The whole expression would be comparable to the Latin "acupedius" "swift of foot". Compare also the Latin word family of "aciēs" "sharp edge or point, battle line, battle, engagement", "acus" "needle, pin, bodkin", and "acuō" "to make pointed, sharpen, whet; to exercise; to arouse" (whence "acute"). Some topical epitheta of Achilles in the "Iliad" point to this "swift-footedness", namely ποδάρκης δῖος Ἀχιλλεὺς ("podárkēs dĩos Achilleús" "swift-footed divine Achilles") or, even more frequently, πόδας ὠκὺς Ἀχιλλεύς ("pódas ōkús Achilleús" "quick-footed Achilles").

Some researchers deem the name a loan word, possibly from a Pre-Greek language. Achilles' descent from the Nereid Thetis and a similarity of his name with those of river deities such as Acheron and Achelous have led to speculations about him being an old water divinity (see below Worship). Robert S. P. Beekes has suggested a Pre-Greek origin of the name, based among other things on the coexistence of "-λλ-" and "-λ-" in epic language, which may account for a palatalized phoneme /l/ in the original language.

Achilles was the son of the Nereid Thetis and of Peleus, the king of the Myrmidons. Zeus and Poseidon had been rivals for the hand of Thetis until Prometheus, the fore-thinker, warned Zeus of a prophecy (originally uttered by Themis

There is a tale which offers an alternative version of these events: In the "Argonautica" (4.760) Zeus' sister and wife Hera alludes to Thetis' chaste resistance to the advances of Zeus, pointing out that Thetis was so loyal to Hera's marriage bond that she coolly rejected the father of gods. Thetis, although a daughter of the sea-god Nereus

According to the "Achilleid", written by Statius in the 1st century AD, and to non-surviving previous sources, when Achilles was born Thetis tried to make him immortal by dipping him in the river Styx. However, he was left vulnerable at the part of the body by which she held him: his left heel (see Achilles' heel, Achilles' tendon). It is not clear if this version of events was known earlier. In another version of this story, Thetis anointed the boy in ambrosia and put him on top of a fire in order to burn away the mortal parts of his body. She was interrupted by Peleus and abandoned both father and son in a rage.

However, none of the sources before Statius make any reference to this general invulnerability. To the contrary, in the "Iliad" Homer mentions Achilles being wounded: in Book 21 the Paeonian hero Asteropaeus, son of Pelagon, challenged Achilles by the river Scamander. He cast two spears at once, one grazed Achilles' elbow, "drawing a spurt of blood".

Also, in the fragmentary poems of the Epic Cycle in which one can find description of the hero's death (i.e. the "Cypria", the "Little Iliad" by Lesches of Pyrrha, the "Aithiopis" and "Iliou persis" by Arctinus of Miletus), there is no trace of any reference to his general invulnerability or his famous weakness at the heel; in the later vase paintings presenting the death of Achilles, the arrow (or in many cases, arrows) hit his torso.

Peleus entrusted Achilles to Chiron the Centaur, on Mount Pelion, to be reared. Thetis foretold that her son's fate was either to gain glory and die young, or to live a long but uneventful life in obscurity. Achilles chose the former, and decided to take part in the Trojan war. According to Homer, Achilles grew up in Phthia together with his companion Patroclus.

According to Photius, the sixth book of the "New History" by Ptolemy Hephaestion reported that Thetis burned in a secret place the children she had by Peleus; but when she had Achilles, Peleus noticed, tore him from the flames with only a burnt foot, and confided him to the centaur Chiron. Later Chiron exhumed the body of the Damysus, who was the fastest of all the giants, removed the ankle, and incorporated it into Achilles' burnt foot.

Among the appellations under which Achilles is generally known are the following:


Some post-Homeric sources claim that in order to keep Achilles safe from the war, Thetis (or, in some versions, Peleus) hid the young man at the court of Lycomedes, king of Skyros. There, Achilles is disguised as a girl and lives among Lycomedes' daughters, perhaps under the name "Pyrrha" (the red-haired girl). With Lycomedes' daughter Deidamia, whom in the account of Statius he rapes, Achilles there fathers a son, Neoptolemus (also called Pyrrhus, after his father's possible alias). According to this story, Odysseus learns from the prophet Calchas

According to the "Iliad", Achilles arrived at Troy with 50 ships, each carrying 50 Myrmidons. He appointed five leaders (each leader commanding 500 Myrmidons): Menesthius, Eudorus, Peisander, Phoenix and Alcimedon.

When the Greeks left for the Trojan War, they accidentally stopped in Mysia, ruled by King Telephus. In the resulting battle, Achilles gave Telephus a wound that would not heal; Telephus consulted an oracle, who stated that "he that wounded shall heal". Guided by the oracle, he arrived at Argos, where Achilles healed him in order that he might become their guide for the voyage to Troy.

According to other reports in Euripides' lost play about Telephus, he went to Aulis pretending to be a beggar and asked Achilles to heal his wound. Achilles refused, claiming to have no medical knowledge. Alternatively, Telephus held Orestes for ransom, the ransom being Achilles' aid in healing the wound. Odysseus

According to the "Cypria" (the part of the Epic Cycle that tells the events of the Trojan War before Achilles' wrath), when the Achaeans desired to return home, they were restrained by Achilles, who afterwards attacked the cattle of Aeneas, sacked neighbouring cities (like Pedasus and Lyrnessus, where the Greeks capture the queen Briseis) and killed Tenes, a son of Apollo, as well as Priam's son Troilus in the sanctuary of Apollo Thymbraios. However, the romance between Troilus and Chryseis described in Geoffrey Chaucer's "Troilus and Criseyde" and in William Shakespeare's "Troilus and Cressida" is a medieval invention.

In Dares Phrygius' "Account of the Destruction of Troy", the Latin summary through which the story of Achilles was transmitted to medieval Europe, as well as in older accounts, Troilus was a young Trojan prince, the youngest of King Priam's and Hecuba's five legitimate sons (or according other sources, another son of Apollo). Despite his youth, he was one of the main Trojan war leaders, a "horse fighter" or "chariot fighter" according to Homer. Prophecies linked Troilus' fate to that of Troy and so he was ambushed in an attempt to capture him. Yet Achilles, struck by the beauty of both Troilus and his sister Polyxena, and overcome with lust, directed his sexual attentions on the youth – who, refusing to yield, instead found himself decapitated upon an altar-omphalos of Apollo Thymbraios. Later versions of the story suggested Troilus was accidentally killed by Achilles in an over-ardent lovers' embrace. In this version of the myth, Achilles' death therefore came in retribution for this sacrilege. Ancient writers treated Troilus as the epitome of a dead child mourned by his parents. Had Troilus lived to adulthood, the First Vatican Mythographer

Homer's "Iliad" is the most famous narrative of Achilles' deeds in the Trojan War. Achilles' wrath (μῆνις Ἀχιλλέως, "mênis Achilléōs") is the central theme of the poem. The first two lines of the "Iliad" read:
The Homeric epic only covers a few weeks of the decade-long war, and does not narrate Achilles' death. It begins with Achilles' withdrawal from battle after being dishonoured by Agamemnon, the commander of the Achaean forces. Agamemnon has taken a woman named Chryseis as his slave. Her father Chryses, a priest of Apollo, begs Agamemnon to return her to him. Agamemnon refuses, and Apollo sends a plague amongst the Greeks. The prophet Calchas correctly determines the source of the troubles but will not speak unless Achilles vows to protect him. Achilles does so, and Calchas declares that Chryseis must be returned to her father. Agamemnon consents, but then commands that Achilles' battle prize Briseis, the daughter of Briseus, be brought to him to replace Chryseis. Angry at the dishonour of having his plunder and glory taken away (and, as he says later, because he loves Briseis), with the urging of his mother Thetis, Achilles refuses to fight or lead his troops alongside the other Greek forces. At the same time, burning with rage over Agamemnon's theft, Achilles prays to Thetis to convince Zeus to help the Trojans gain ground in the war, so that he may regain his honour.

As the battle turns against the Greeks, thanks to the influence of Zeus, Nestor declares that the Trojans are winning because Agamemnon has angered Achilles, and urges the king to appease the warrior. Agamemnon agrees and sends Odysseus and two other chieftains, Ajax and Phoenix

The Trojans, led by Hector, subsequently push the Greek army back toward the beaches and assault the Greek ships. With the Greek forces on the verge of absolute destruction, Patroclus leads the Myrmidons into battle, wearing Achilles' armour, though Achilles remains at his camp. Patroclus succeeds in pushing the Trojans back from the beaches, but is killed by Hector before he can lead a proper assault on the city of Troy.

After receiving the news of the death of Patroclus from Antilochus, the son of Nestor, Achilles grieves over his beloved companion's death. His mother Thetis comes to comfort the distraught Achilles. She persuades Hephaestus to make new armour for him, in place of the armour that Patroclus had been wearing, which was taken by Hector. The new armour includes the Shield of Achilles, described in great detail in the poem.

Enraged over the death of Patroclus, Achilles ends his refusal to fight and takes the field, killing many men in his rage but always seeking out Hector. Achilles even engages in battle with the river god Scamander, who has become angry that Achilles is choking his waters with all the men he has killed. The god tries to drown Achilles but is stopped by Hera and Hephaestus. Zeus himself takes note of Achilles' rage and sends the gods to restrain him so that he will not go on to sack Troy itself before the time allotted for its destruction, seeming to show that the unhindered rage of Achilles can defy fate itself. Finally, Achilles finds his prey. Achilles chases Hector around the wall of Troy three times before Athena, in the form of Hector's favorite and dearest brother, Deiphobus, persuades Hector to stop running and fight Achilles face to face. After Hector realizes the trick, he knows the battle is inevitable. Wanting to go down fighting, he charges at Achilles with his only weapon, his sword, but misses. Accepting his fate, Hector begs Achilles, not to spare his life, but to treat his body with respect after killing him. Achilles tells Hector it is hopeless to expect that of him, declaring that "my rage, my fury would drive me now to hack your flesh away and eat you raw – such agonies you have caused me". Achilles then kills Hector and drags his corpse by its heels behind his chariot. After having a dream where Patroclus begs Achilles to hold his funeral, Achilles hosts a series of funeral games in his honour.

At the onset of his duel with Hector, Achilles is referred to as the brightest star in the sky, which comes on in the autumn, Orion's dog (Sirius); a sign of evil. During the cremation of Patroclus, he is compared to Hesperus, the evening/western star (Venus), while the burning of the funeral pyre lasts until Phosphorus, the morning/eastern star (also Venus) has set (descended).

With the assistance of the god Hermes (Argeiphontes), Hector's father Priam goes to Achilles' tent to plead with Achilles for the return of Hector's body so that he can be buried. Achilles relents and promises a truce for the duration of the funeral, lasting 9 days with a burial on the 10th (in the tradition of Niobe

The "Aethiopis" (7th century BC) and a work named "Posthomerica", composed by Quintus of Smyrna in the fourth century AD, relate further events from the Trojan War. When Penthesilea, queen of the Amazons and daughter of Ares, arrives in Troy, Priam hopes that she will defeat Achilles. After his temporary truce with Priam, Achilles fights and kills the warrior queen, only to grieve over her death later. At first, he was so distracted by her beauty, he did not fight as intensely as usual. Once he realized that his distraction was endangering his life, he refocused and killed her.

Following the death of Patroclus, Nestor's son Antilochus becomes Achilles' closest companion. When Memnon, son of the Dawn Goddess Eos and king of Ethiopia, slays Antilochus, Achilles once more obtains revenge on the battlefield, killing Memnon. Consequently, Eos will not let the sun rise, until Zeus persuades her. The fight between Achilles and Memnon over Antilochus echoes that of Achilles and Hector over Patroclus, except that Memnon (unlike Hector) was also the son of a goddess.

Many Homeric scholars argued that episode inspired many details in the "Iliad"s description of the death of Patroclus and Achilles' reaction to it. The episode then formed the basis of the cyclic epic "Aethiopis

The exact nature of Achilles' relationship with Patroclus has been a subject of dispute in both the classical period and modern times. In the "Iliad", it appears to be the model of a deep and loyal friendship. Homer does not suggest that Achilles and his close friend Patroclus were lovers. Despite there being no direct evidence in the text of the "Iliad" that Achilles and Patroclus were lovers, this theory was expressed by some later authors. Commentators from classical antiquity to the present have often interpreted the relationship through the lens of their own cultures. In 5th-century BC Athens, the intense bond was often viewed in light of the Greek custom of "paiderasteia". In Plato's "Symposium", the participants in a dialogue about love assume that Achilles and Patroclus were a couple; Phaedrus argues that Achilles was the younger and more beautiful one so he was the beloved and Patroclus was the lover. But ancient Greek had no words to distinguish heterosexual and homosexual, and it was assumed that a man could both desire handsome young men and have sex with women.

The death of Achilles, as predicted by Hector with his dying breath, was brought about by Paris with an arrow (to the heel according to Statius). In some versions, the god Apollo guided Paris' arrow. Some retellings also state that Achilles was scaling the gates of Troy and was hit with a poisoned arrow. All of these versions deny Paris any sort of valour, owing to the common conception that Paris was a coward and not the man his brother Hector was, and Achilles remained undefeated on the battlefield. His bones were mingled with those of Patroclus, and funeral games were held. He was represented in the "Aethiopis" as living after his death in the island of Leuke at the mouth of the river Danube

Another version of Achilles' death is that he fell deeply in love with one of the Trojan princesses, Polyxena. Achilles asks Priam for Polyxena's hand in marriage. Priam is willing because it would mean the end of the war and an alliance with the world's greatest warrior. But while Priam is overseeing the private marriage of Polyxena and Achilles, Paris, who would have to give up Helen if Achilles married his sister, hides in the bushes and shoots Achilles with a divine arrow, killing him.

In the "Odyssey", Agamemnon informs Achilles of his pompous burial and the erection of his mound at the Hellespont while they are receiving the dead suitors in Hades. He claims they built a massive burial mound on the beach of Ilion that could be seen by anyone approaching from the Ocean. Achilles was cremated and his ashes buried in the same urn as those of Patroclus. Paris was later killed by Philoctetes using the enormous bow of Heracles.

In Book 11 of Homer's "Odyssey", Odysseus sails to the underworld and converses with the shades. One of these is Achilles, who when greeted as "blessed in life, blessed in death", responds that he would rather be a slave to the worst of masters than be king of all the dead. But Achilles then asks Odysseus of his son's exploits in the Trojan war, and when Odysseus tells of Neoptolemus' heroic actions, Achilles is filled with satisfaction. This leaves the reader with an ambiguous understanding of how Achilles felt about the heroic life.

According to some accounts, he had married Medea in life, so that after both their deaths they were united in the Elysian Fields of Hades – as Hera promised Thetis in Apollonius' "Argonautica

Achilles' armour was the object of a feud between Odysseus and Telamonian Ajax (Ajax the greater). They competed for it by giving speeches on why they were the bravest after Achilles to their Trojan prisoners, who after considering both men, decided Odysseus was more deserving of the armour. Furious, Ajax cursed Odysseus, which earned him the ire of Athena. Athena temporarily made Ajax so mad with grief and anguish that he began killing sheep, thinking them his comrades. After a while, when Athena lifted his madness and Ajax realized that he had actually been killing sheep, Ajax was left so ashamed that he committed suicide. Odysseus eventually gave the armour to Neoptolemus, the son of Achilles.

A relic claimed to be Achilles' bronze-headed spear was for centuries preserved in the temple of Athena on the acropolis of Phaselis, Lycia, a port on the Pamphylian Gulf. The city was visited in 333 BC by Alexander the Great, who envisioned himself as the new Achilles and carried the "Iliad" with him, but his court biographers do not mention the spear. However, it was shown in the time of Pausanias in the 2nd century AD.

Numerous paintings on pottery have suggested a tale not mentioned in the literary traditions. At some point in the war, Achilles and Ajax were playing a board game

The tomb of Achilles, extant throughout antiquity in Troad, was venerated by Thessalians, but also by Persian expeditionary forces, as well as by Alexander the Great and the Roman emperor Caracalla. Achilles' cult was also to be found at other places, e. g. on the island of Astypalaea in the Sporades, in Sparta which had a sanctuary, in Elis and in Achilles' homeland Thessaly, as well as in the Magna Graecia cities of Tarentum, Locri and Croton, accounting for an almost Panhellenic cult to the hero.

The cult of Achilles is illustrated in the 500 BC Polyxena sarcophagus, where the sacrifice of Polixena near the tumulus of Achilles is depicted. Strabo (13.1.32) also suggested that such a cult of Achilles existed in Troad:

The spread and intensity of the hero's veneration among the Greeks that had settled on the northern coast of the Pontus Euxinus, today's Black Sea, appears to have been remarkable. An archaic cult is attested for the Milesian colony of Olbia as well as for an island in the middle of the Black Sea, today identified with Snake Island (Ukrainian Зміїний, "Zmiinyi", near Kiliya, Ukraine). Early dedicatory inscriptions from the Greek colonies on the Black Sea (graffiti and inscribed clay disks, these possibly being votive offerings, from Olbia, the area of Berezan Island and the Tauric Chersonese) attest the existence of a heroic cult of Achilles from the sixth century BC onwards. The cult was still thriving in the third century AD, when dedicatory stelae from Olbia refer to an "Achilles Pontárchēs" (Ποντάρχης, roughly "lord of the Sea," or "of the Pontus Euxinus"), who was invoked as a protector of the city of Olbia, venerated on par with Olympian gods such as the local Apollo Prostates, Hermes Agoraeus, or Poseidon.

Pliny the Elder (23–79 AD) in his "Natural History" mentions a "port of the Achæi" and an "island of Achilles", famous for the tomb of that "man" (portus Achaeorum, insula Achillis, tumulo eius viri clara), situated somewhat nearby Olbia and the Dnieper-Bug Estuary; furthermore, at 125 Roman miles from this island, he places a peninsula "which stretches forth in the shape of a sword" obliquely, called "Dromos Achilleos" (Ἀχιλλέως δρόμος, "Achilléōs drómos" "the Race-course of Achilles") and considered the place of the hero's exercise or of games instituted by him. This last feature of Pliny's account is considered to be the iconic spit, called today "Tendra" (or "Kosa Tendra" and "Kosa Djarilgatch"), situated between the mouth of the Dnieper and Karkinit Bay, but which is hardly 125 Roman miles (c. 185 km) away from the Dnieper-Bug estuary, as Pliny states. (To the "Race-course" he gives a length of 80 miles, c. 120 km, whereas the spit measures c. 70 km today.)

In the following chapter of his book, Pliny refers to the same island as "Achillea" and introduces two further names for it: "Leuce" or "Macaron" (from Greek [νῆσος] μακαρῶν "island of the blest"). The "present day" measures, he gives at this point, seem to account for an identification of "Achillea" or "Leuce" with today's Snake Island. Pliny's contemporary Pomponius Mela (c. 43 AD) tells that Achilles was buried on an island named "Achillea", situated between the Borysthenes and the Ister, adding to the geographical confusion. Ruins of a square temple, measuring 30 meters to a side, possibly that dedicated to Achilles, were discovered by Captain Kritzikly in 1823 on Snake Island. A second exploration in 1840 showed that the construction of a lighthouse had destroyed all traces of this temple. A fifth century BC black-glazed lekythos inscription, found on the island in 1840, reads: "Glaukos, son of Poseidon, dedicated me to Achilles, lord of Leuke." In another inscription from the fifth or fourth century BC, a statue is dedicated to Achilles, lord of Leuke, by a citizen of Olbia, while in a further dedication, the city of Olbia confirms its continuous maintenance of the island's cult, again suggesting its quality as a place of a supra-regional hero veneration.

The heroic cult dedicated to Achilles on "Leuce" seems to go back to an account from the lost epic "Aethiopis" according to which, after his untimely death, Thetis had snatched her son from the funeral pyre and removed him to a mythical Λεύκη Νῆσος ("Leúkē Nêsos" "White Island"). Already in the fifth century BC, Pindar had mentioned a cult of Achilles on a "bright island" (φαεννά νᾶσος, "phaenná nâsos") of the Black Sea, while in another of his works, Pindar would retell the story of the immortalized Achilles living on a geographically indefinite Island of the Blest together with other heroes such as his father Peleus and Cadmus. Well known is the connection of these mythological Fortunate Isles (μακαρῶν νῆσοι, "makárôn nêsoi") or the Homeric Elysium with the stream Oceanus which according to Greek mythology surrounds the inhabited world, which should have accounted for the identification of the northern strands of the Euxine with it. Guy Hedreen has found further evidence for this connection of Achilles with the northern margin of the inhabited world in a poem by Alcaeus, speaking of "Achilles lord of Scythia" and the opposition of North and South, as evoked by Achilles' fight against the Aethiopian prince Memnon, who in his turn would be removed to his homeland by his mother Eos after his death.

The "Periplus of the Euxine Sea" (c. 130 AD) gives the following details:

The Greek geographer Dionysius Periegetes, who lived probably during the first century AD, wrote that the island was called "Leuce" "because the wild animals which live there are white. It is said that there, in Leuce island, reside the souls of Achilles and other heroes, and that they wander through the uninhabited valleys of this island; this is how Jove rewarded the men who had distinguished themselves through their virtues, because through virtue they had acquired everlasting honour". Similarly, others relate the island's name to its white cliffs, snakes or birds dwelling there. Pausanias has been told that the island is "covered with forests and full of animals, some wild, some tame. In this island there is also Achilles' temple and his statue". Leuce had also a reputation as a place of healing. Pausanias reports that the Delphic Pythia sent a lord of Croton to be cured of a chest wound. Ammianus Marcellinus attributes the healing to waters ("aquae") on the island.

A number of important commercial port cities of the Greek waters were dedicated to Achilles. Herodotus, Pliny the Elder and Strabo reported on the existence of a town "Achílleion" (Ἀχίλλειον), built by settlers from Mytilene in the sixth century BC, close to the hero's presumed burial mound in the Troad. Later attestations point to an "Achílleion" in Messenia (according to Stephanus Byzantinus) and an "Achílleios" (Ἀχίλλειος) in Laconia. Nicolae Densuşianu recognized a connection to Achilles in the names of Aquileia and of the northern arm of the Danube delta, called Chilia (presumably from an older "Achileii"), though his conclusion, that Leuce had sovereign rights over the Black Sea, evokes modern rather than archaic sea-law.

The kings of Epirus claimed to be descended from Achilles through his son, Neoptolemus. Alexander the Great, son of the Epirote princess Olympias, could therefore also claim this descent, and in many ways strove to be like his great ancestor. He is said to have visited the tomb of Achilles at Achilleion while passing Troy. In AD 216 the Roman Emperor Caracalla, while on his way to war against Parthia, emulated Alexander by holding games around Achilles' tumulus.

The Greek tragedian Aeschylus wrote a trilogy of plays about Achilles, given the title "Achilleis" by modern scholars. The tragedies relate the deeds of Achilles during the Trojan War, including his defeat of Hector and eventual death when an arrow shot by Paris and guided by Apollo punctures his heel. Extant fragments of the "Achilleis" and other Aeschylean fragments have been assembled to produce a workable modern play. The first part of the "Achilleis" trilogy, "The Myrmidons", focused on the relationship between Achilles and chorus, who represent the Achaean army and try to convince Achilles to give up his quarrel with Agamemnon; only a few lines survive today. In Plato's "Symposium", Phaedrus points out that Aeschylus portrayed Achilles as the lover and Patroclus as the beloved; Phaedrus argues that this is incorrect because Achilles, being the younger and more beautiful of the two, was the beloved, who loved his lover so much that he chose to die to revenge him.

The tragedian Sophocles also wrote "The Lovers of Achilles", a play with Achilles as the main character. Only a few fragments survive.

Towards the end of the 5th century BC, a more negative view of Achilles emerges in Greek drama; Euripides refers to Achilles in a bitter or ironic tone in "Hecuba", "Electra", and "Iphigenia in Aulis".

The philosopher Zeno of Elea centred one of his paradoxes on an imaginary footrace between "swift-footed" Achilles and a tortoise, by which he attempted to show that Achilles could not catch up to a tortoise with a head start, and therefore that motion and change were impossible. As a student of the monist Parmenides and a member of the Eleatic school, Zeno believed time and motion to be illusions.

The Romans, who traditionally traced their lineage to Troy, took a highly negative view of Achilles. Virgil refers to Achilles as a savage and a merciless butcher of men, while Horace portrays Achilles ruthlessly slaying women and children. Other writers, such as Catullus, Propertius, and Ovid, represent a second strand of disparagement, with an emphasis on Achilles' erotic career. This strand continues in Latin accounts of the Trojan War by writers such as Dictys Cretensis and Dares Phrygius and in Benoît de Sainte-Maure's "Roman de Troie" and Guido delle Colonne's "Historia destructionis Troiae", which remained the most widely read and retold versions of the Matter of Troy until the 17th century.

Achilles was described by the Byzantine chronicler Leo the Deacon, not as Hellene, but as Scythian, while according to the Byzantine author John Malalas, his army was made up of a tribe previously known as Myrmidons and later as Bulgars



Achilles has been frequently the subject of operas, ballets and related genres.


In films Achilles has been portrayed in the following films and television series:

In 1890, Elisabeth of Bavaria, Empress of Austria, had a summer palace built in Corfu. The building is named the "Achilleion", after Achilles. Its paintings and statuary depict scenes from the Trojan War, with particular focus on Achilles.




Category:Characters in the Iliad
Category:Demigods of Classical mythology
Category:Kings in Greek mythology
Category:Kings of the Myrmidons
Category:Greek mythological heroes
Category:People of the Trojan War
Category:Thessalians in the Trojan War
Category:LGBT themes in Greek mythologyAbraham Lincoln

Abraham Lincoln (February 12, 1809 – April 15, 1865) was an American lawyer and politician who served as the 16th president of the United States from 1861 until his assassination in April 1865. Lincoln led the nation through the American Civil War, its bloodiest war and its greatest moral, constitutional, and political crisis. He preserved the Union, abolished slavery, strengthened the federal government, and modernized the U.S. economy.

Born in Kentucky, Lincoln grew up on the frontier in a poor family. Self-educated, he became a lawyer, Whig Party leader, state legislator and Congressman. He left government to resume his law practice, but angered by the success of Democrats in opening the prairie lands to slavery, reentered politics in 1854. He became a leader in the new Republican Party and gained national attention in 1858 for debating and losing to national Democratic leader Stephen A. Douglas in a Senate campaign. He then ran for President in 1860, sweeping the North and winning.

Southern pro-slavery elements took his win as proof that the North was rejecting the Constitutional rights of Southern states to practice slavery. They began the process of seceding from the union. To secure its independence, the new Confederate States of America fired on Fort Sumter, one of the few U.S. forts in the South. Lincoln called up volunteers and militia to suppress the rebellion and restore the Union.

As the leader of the moderate faction of the Republican Party, Lincoln confronted Radical Republicans, who demanded harsher treatment of the South; War Democrats, who rallied a large faction of former opponents into his camp; anti-war Democrats (called Copperheads), who despised him; and irreconcilable secessionists, who plotted his assassination. Lincoln fought the factions by pitting them against each other, by carefully distributing political patronage, and by appealing to the American people. His Gettysburg Address became an iconic call for nationalism, republicanism, equal rights, liberty, and democracy.

He suspended "habeas corpus", and he averted British intervention by defusing the "Trent" Affair. Lincoln closely supervised the war effort, including the selection of generals and the naval blockade that shut down the South's trade. As the war progressed, he maneuvered to end slavery, issuing the Emancipation Proclamation of 1863; ordering the Army to protect escaped slaves, encouraging border states to outlaw slavery, and pushing through Congress the Thirteenth Amendment to the United States Constitution, which outlawed slavery across the country.

Lincoln managed his own re-election campaign. He sought to reconcile his damaged nation by avoiding retribution against the secessionists. A few days after the end of the war at the Battle of Appomattox Court House, he was shot by John Wilkes Booth, an actor and Confederate sympathizer, on April 14, 1865, and died the following day.

Abraham Lincoln is remembered as the United States' martyr hero. He is consistently ranked both by scholars and the public as among the greatest U.S. presidents.

Abraham Lincoln was born on February 12, 1809, as the second child of Thomas and Nancy Hanks Lincoln, in a one-room log cabin on Sinking Spring Farm near Hodgenville, Kentucky. He was a descendant of Samuel Lincoln, an Englishman who migrated from Hingham, Norfolk, to its namesake Hingham, Massachusetts, in 1638. Samuel's grandson and great-grandson began the family's westward migration, passing through New Jersey, Pennsylvania, and Virginia. Lincoln's paternal grandfather and namesake, Captain Abraham Lincoln, moved the family from Virginia to Jefferson County, Kentucky, in the 1780s. Captain Lincoln was killed in an Indian raid in 1786. His children, including eight-year-old Thomas, Lincoln's father, witnessed the attack. Thomas then worked at odd jobs in Kentucky and in Tennessee, before settling with members of his family in Hardin County, Kentucky
Lincoln's mother, Nancy, is widely assumed to have been the daughter of Lucy Hanks, although no record documents this. Thomas and Nancy married on June 12, 1806, in Washington County, and moved to Elizabethtown, Kentucky. They produced three children: Sarah, born on February 10, 1807; Abraham, on February 12, 1809; and Thomas, who died in infancy.

Thomas Lincoln bought or leased farms in Kentucky. Thomas became embroiled in legal disputes, and lost all but of his land in court disputes over property titles. In 1816, the family moved to Indiana, where the survey process was more reliable and land titles were more secure. Indiana was a "free" (non-slaveholding) territory, and they settled in an "unbroken forest" in Hurricane Township, Perry County. (Their land became part of Spencer County, Indiana, when the county was established in 1818.) In 1860, Lincoln noted that the family's move to Indiana was "partly on account of slavery", but mainly due to land title difficulties.

In Kentucky and Indiana, Thomas worked as a farmer, cabinetmaker, and carpenter. He owned farms, town lots and livestock, paid taxes, sat on juries, appraised estates, served on country slave patrols, and guarded prisoners. Thomas and Nancy were members of a Separate Baptists church, which forbade alcohol, dancing, and slavery.

Overcoming financial challenges, Thomas eventually obtained clear title to of land in what became known as the Little Pigeon Creek Community

On October 5, 1818, Nancy Lincoln died of milk sickness, leaving 11-year-old Sarah in charge of a household that included her father, 9-year-old Abraham, and Dennis Hanks, Nancy's 19-year-old orphaned cousin. Those who knew Lincoln later recalled that he was distraught over his sister's death on January 20, 1828, while giving birth to a stillborn son.

On December 2, 1819, Thomas married Sarah "Sally" Bush Johnston, a widow from Elizabethtown, Kentucky, with three children of her own. Abraham became close to his stepmother, whom he referred to as "Mother". Lincoln disliked the hard labor associated with farm life. He was called lazy for all his "reading, scribbling, writing, ciphering, writing Poetry, etc.". His stepmother acknowledged he did not enjoy "physical labor", but loved to read.

Lincoln was largely self-educated. His formal schooling (from itinerant teachers) was intermittent, totaling less than 12 months; however, he was an avid reader and retained a lifelong interest in learning. Family, neighbors, and schoolmates recalled that he read and reread the King James Bible, Aesop's Fables, John Bunyan's "The Pilgrim's Progress", Daniel Defoe's "Robinson Crusoe", Mason Locke Weems's "The Life of Washington", and "The Autobiography of Benjamin Franklin", among others.

Teenaged Lincoln took responsibility for chores. He accepted the customary practice that a son give his father all earnings from work outside the home until age 21. Lincoln became adept at using an axe. Tall for his age, Lincoln was strong and athletic. He became known for his strength and audacity after winning a wrestling match with the renowned leader of a group of ruffians known as "the Clary's Grove boys".

In early March 1830, partly out of fear of a milk sickness outbreak, several members of the extended Lincoln family moved west to Illinois, a free state, and settled in Macon County, west of Decatur. Historians disagree on who initiated the move; Thomas Lincoln had no obvious reason to do so. One possibility is that other members of the family, including Dennis Hanks, might not have matched Thomas' stability and steady income.

After the family relocated to Illinois, Abraham became increasingly distant from Thomas, in part because of his father's lack of education, although occasionally lending him money. In 1831, as Thomas and other family prepared to move to a new homestead in Coles County, Illinois, Abraham left home. He lived in New Salem for six years. Lincoln and some friends took goods by flatboat to New Orleans, where he witnessed slavery firsthand.

According to some sources, Lincoln's first romantic interest was Ann Rutledge, whom he met when he first moved to New Salem; these sources indicate that by 1835, they were in a relationship but not formally engaged. She died on August 25, 1835, most likely of typhoid fever. In the early 1830s, he met Mary Owens from Kentucky.

Late in 1836, Lincoln agreed to a match with Mary if she returned to New Salem. Mary arrived in November 1836, and Lincoln courted her for a time; however, they both had second thoughts. On August 16, 1837, Lincoln wrote Mary a letter suggesting he would not blame her if she ended the relationship. She never replied.

In 1840, Lincoln became engaged to Mary Todd, daughter of a wealthy slave-holding family in Lexington, Kentucky. They met in Springfield, Illinois in December 1839 and were engaged a year later. A wedding set for January 1, 1841, was canceled at Lincoln's initiative. They reconciled and married on November 4, 1842, in the Springfield mansion of Mary's married sister. While anxiously preparing for the nuptials, Lincoln was asked where he was going and replied, "To hell, I suppose." In 1844, the couple bought a house in Springfield near Lincoln's law office. Mary kept house, often with the help of a relative or hired servant.

He was an affectionate, though often absent, husband and father of four children. Robert Todd Lincoln was born in 1843 and Edward Baker Lincoln (Eddie) in 1846. Edward died on February 1, 1850, in Springfield, probably of tuberculosis. "Willie" Lincoln was born on December 21, 1850, and died of a fever on February 20, 1862. The Lincolns' fourth son, Thomas "Tad" Lincoln, was born on April 4, 1853, and died of heart failure at the age of 18 on July 16, 1871. Robert reached adulthood and produced children. The Lincolns' last descendant, great-grandson Robert Todd Lincoln Beckwith, died in 1985. Lincoln "was remarkably fond of children", and the Lincolns were not considered to be strict with their own.

The deaths of their sons had profound effects on both parents. Abraham suffered from "melancholy", a condition later referred to as clinical depression. Later in life, Mary struggled with the stresses of losing her husband and sons, and Robert committed her temporarily to a mental health asylum in 1875.

Lincoln's father-in-law and others of the Todd family were either slave owners or slave traders

In 1832 Lincoln and partner Denton Offutt bought a general store on credit in New Salem, Illinois. Although the economy was booming, the business struggled and Lincoln eventually sold his share. That March he entered politics, running for the Illinois General Assembly, advocating navigational improvements on the Sangamon River. He could draw crowds as a raconteur, but he lacked an education, powerful friends, and money and lost the election.

Lincoln interrupted his campaign to briefly serve as a captain in the Illinois Militia (during the Black Hawk War). He then returned to his campaign. At his first speech, he observed a supporter in the crowd under attack, grabbed the assailant by his "neck and the seat of his trousers" and tossed him. Lincoln finished eighth out of 13 candidates (the top four were elected), though he received 277 of the 300 votes cast in the New Salem precinct.

Lincoln served as New Salem's postmaster and later as county surveyor, all the while reading voraciously. He decided to become a lawyer and began teaching himself law by reading Blackstone's "Commentaries on the Laws of England" and other law books. Of his learning method, Lincoln stated: "I studied with nobody".

His second state legislature campaign in 1834 was successful. Although he ran as a Whig, many Democrats favored him over a more powerful Whig opponent. Lincoln served four successive terms in the Illinois House of Representatives as a Whig from Sangamon County. He supported the construction of the Illinois and Michigan Canal, later serving as a Canal Commissioner. In the 1835–36 legislative session, he voted to expand suffrage beyond white landowners to all white males. He was known for his "free soil" stance of opposing both slavery and abolitionism. He first articulated this in 1837, saying, "[The] Institution of slavery is founded on both injustice and bad policy, but the promulgation of abolition doctrines tends rather to increase than abate its evils." He followed Henry Clay in supporting the American Colonization Society program of advocating abolition and helping freed slaves to settle in Liberia
Admitted to the Illinois bar in 1836, he moved to Springfield, Illinois, and began to practice law under John T. Stuart, Mary Todd's cousin. Lincoln developed a reputation as a formidable adversary during cross-examinations and closing arguments. He partnered with Stephen T. Logan from 1841 until 1844. Then Lincoln began his practice with William Herndon
From the early 1830s, Lincoln was a steadfast Whig and professed to friends in 1861 to be "an old line Whig, a disciple of Henry Clay". The party, including Lincoln, favored economic modernization in banking, tariffs to fund internal improvements including railroads, and urbanization.

Lincoln ran for the Whig nomination for Illinois's 7th district of the U.S. House of Representatives in 1843, but was defeated by John J. Hardin. However, Lincoln won support for the principle of rotation, whereby Hardin would retire after only one term. Lincoln hoped that this arrangement would lead to his nomination in 1846. Lincoln was indeed elected to the House of Representatives in 1846, where he served one two-year term. He was the only Whig in the Illinois delegation, showing party loyalty by participating in almost all votes and making speeches that echoed the party line. Lincoln, in collaboration with abolitionist Congressman Joshua R. Giddings, wrote a bill to abolish slavery in the District of Columbia with compensation for the owners, enforcement to capture fugitive slaves, and a popular vote on the matter. He abandoned the bill when it failed to garner sufficient Whig supporters.


On foreign and military policy, Lincoln spoke out against the Mexican–American War, which he attributed to President Polk's desire for "military glory—that attractive rainbow, that rises in showers of blood". Lincoln supported the Wilmot Proviso, which, if it had been adopted, would have banned slavery in any U.S. territory won from Mexico.

Lincoln emphasized his opposition to Polk by drafting and introducing his Spot Resolutions. The war had begun with a Mexican slaughter of American soldiers in territory disputed by Mexico and the U.S. Polk insisted that Mexican soldiers had "invaded our territory and shed the blood of our fellow-citizens on our own soil". Lincoln demanded that Polk show Congress the exact spot on which blood had been shed and prove that the spot was on American soil.

Congress neither debated nor enacted the resolution, the national papers ignored it, and it cost Lincoln political support in his district. One Illinois newspaper derisively nicknamed him "spotty Lincoln". Lincoln later regretted some of his statements, especially his attack on presidential war-making powers.

Realizing Clay was unlikely to win the presidency, Lincoln, who had pledged in 1846 to serve only one term in the House, supported General Zachary Taylor for the Whig nomination in the 1848 presidential election. Taylor won and Lincoln hoped to be appointed Commissioner of the General Land Office, but lost out. The administration offered him the consolation prize of secretary or governor of the Oregon Territory
Lincoln practiced law in Springfield, handling "every kind of business that could come before a prairie lawyer". Twice a year for 16 years, 10 weeks at a time, he appeared in county seats in the midstate region when the county courts were in session. Lincoln handled transportation cases in the midst of the nation's western expansion, particularly river barge conflicts under the many new railroad bridges. As a riverboat man, Lincoln initially favored those interests, but ultimately represented whoever hired him. He later represented a bridge company against a riverboat company in a landmark case involving a canal boat that sank after hitting a bridge. In 1849, he received a patent for a flotation device for the movement of boats in shallow water. The idea was never commercialized, but Lincoln is the only president to hold a patent.

In 1851, he represented the Alton & Sangamon Railroad in a dispute with shareholder James A. Barret, who had refused to pay the balance on his pledge to buy shares on the grounds that the company had changed its original train route. Lincoln successfully argued that the railroad company was not bound by its original charter; the charter was amended in the public interest to provide a newer, superior, and less expensive route, and the corporation retained the right to demand Barret's payment. The decision by the Illinois Supreme Court was cited by many other courts. Lincoln appeared before the Illinois Supreme Court in 175 cases, in 51 as sole counsel, of which 31 were decided in his favor. From 1853 to 1860, another of Lincoln's largest clients was the Illinois Central Railroad. Lincoln's legal reputation gave rise to his nickname "Honest Abe".

Lincoln's most notable criminal trial occurred in 1858 when he defended William "Duff" Armstrong, who was on trial for the murder of James Preston Metzker. The case is famous for Lincoln's use of a fact established by judicial notice in order to challenge the credibility of an eyewitness. After an opposing witness testified to seeing the crime in the moonlight, Lincoln produced a "Farmers' Almanac

The debate over the status of slavery in the territories exacerbated sectional tensions between the slave-holding South and the free North. The Compromise of 1850 failed to defuse the issue. In the early 1850s, Lincoln supported sectional mediation, and his 1852 eulogy for Clay focused on the latter's support for gradual emancipation and opposition to "both extremes" on the slavery issue. As the 1850s progressed, the debate over slavery in the Nebraska Territory and Kansas Territory became particularly acrimonious, and Senator Douglas proposed popular sovereignty as a compromise measure; the proposal would allow the electorate of each territory to decide the status of slavery. The proposal alarmed many Northerners, who hoped to prevent the spread of slavery into the territories. Despite this Northern opposition, Douglas's Kansas–Nebraska Act narrowly passed Congress in May 1854.

For months after its passage, Lincoln did not publicly comment, but he came to strongly oppose it. On October 16, 1854, in his "Peoria Speech", Lincoln declared his opposition to slavery, which he repeated en route to the presidency. Speaking in his Kentucky accent, with a powerful voice, he said the Kansas Act had a ""declared" indifference, but as I must think, a covert "real" zeal for the spread of slavery. I cannot but hate it. I hate it because of the monstrous injustice of slavery itself. I hate it because it deprives our republican example of its just influence in the world ..." Lincoln's attacks on the Kansas–Nebraska Act marked his return to political life.

Nationally, the Whigs were irreparably split by the Kansas–Nebraska Act and other efforts to compromise on the slavery issue. Reflecting the demise of his party, Lincoln wrote in 1855, "I think I am a Whig, but others say there are no Whigs, and that I am an abolitionist [...] I do no more than oppose the "extension" of slavery." Drawing on the antislavery portion of the Whig Party, and combining Free Soil, Liberty, and antislavery Democratic Party members, the new Republican Party formed as a northern party dedicated to antislavery. Lincoln resisted early recruiting attempts, fearing that it would serve as a platform for extreme abolitionists. Lincoln hoped to rejuvenate the Whigs, though he lamented his party's growing closeness with the nativist Know Nothing movement.

In the 1854 elections, Lincoln was elected to the Illinois legislature but declined to take his seat. In the elections' aftermath, which showed the power and popularity of the movement opposed to the Kansas–Nebraska Act, Lincoln instead sought election to the United States Senate. At that time, senators were elected by the state legislature. After leading in the first six rounds of voting, he was unable to obtain a majority. Lincoln instructed his backers to vote for Lyman Trumbull. Trumbull was an antislavery Democrat, and had received few votes in the earlier ballots; his supporters, also antislavery Democrats, had vowed not to support any Whig. Lincoln's decision to withdraw enabled his Whig supporters and Trumbull's antislavery Democrats to combine and defeat the mainstream Democratic candidate, Joel Aldrich Matteson.

In part due to the ongoing violent political confrontations in Kansas, opposition to the Kansas–Nebraska Act remained strong throughout the North. As the 1856 elections approached, Lincoln joined the Republicans. He attended the May 1856 Bloomington Convention, which formally established the Illinois Republican Party. The convention platform asserted that Congress had the right to regulate slavery in the territories and called for the immediate admission of Kansas as a free state. Lincoln gave the final speech of the convention, in which he endorsed the party platform and called for the preservation of the Union. At the June 1856 Republican National Convention, Lincoln received significant support to run for vice president, though the party nominated William Dayton to run with John C. Frémont. Lincoln supported the Republican ticket, campaigning throughout Illinois. The Democrats nominated former Ambassador James Buchanan, who had been out of the country since 1853 and thus had avoided the slavery debate, while the Know Nothings nominated former Whig President Millard Fillmore. Buchanan defeated both his challengers. Republican William Henry Bissell

Eric Foner (2010) contrasts the abolitionists and anti-slavery Radical Republicans of the Northeast who saw slavery as a sin, with the conservative Republicans who thought it was bad because it hurt white people and blocked progress. Foner argues that Lincoln was a moderate in the middle, opposing slavery primarily because it violated the republicanism principles of the Founding Fathers, especially the equality of all men and democratic self-government as expressed in the Declaration of Independence.

In March 1857, in "Dred Scott v. Sandford," Supreme Court Chief Justice Roger B. Taney wrote that blacks were not citizens and derived no rights from the Constitution. While many Democrats hoped that "Dred Scott" would end the dispute over slavery in the territories, the decision sparked further outrage in the North. Lincoln denounced it, alleging it was the product of a conspiracy of Democrats to support the Slave Power. Lincoln argued, "The authors of the Declaration of Independence never intended 'to say all were equal in color, size, intellect, moral developments, or social capacity', but they 'did consider all men created equal—equal in certain inalienable rights, among which are life, liberty, and the pursuit of happiness'."

Douglas was up for re-election in 1858, and Lincoln hoped to defeat him. With the former Democrat Trumbull now serving as a Republican Senator, many in the party felt that a former Whig should be nominated in 1858, and Lincoln's 1856 campaigning and willingness to support Trumbull in 1854 had earned him favor. Some eastern Republicans favored Douglas' reelection in 1858, since he had led the opposition to the Lecompton Constitution, which would have admitted Kansas as a slave state
Accepting the nomination, Lincoln delivered his House Divided Speech, drawing on , "A house divided against itself cannot stand. I believe this government cannot endure permanently half slave and half free. I do not expect the Union to be dissolved—I do not expect the house to fall—but I do expect it will cease to be divided. It will become all one thing, or all the other." The speech created an evocative image of the danger of disunion. The stage was then set for the campaign for statewide election of the Illinois legislature which would, in turn, select Lincoln or Douglas. When informed of Lincoln's nomination, Douglas stated, "[Lincoln] is the strong man of the party ... and if I beat him, my victory will be hardly won."

The Senate campaign featured seven debates, the most famous political debates in American history. The principals stood in stark contrast both physically and politically. Lincoln warned that "The Slave Power" was threatening the values of republicanism, and accused Douglas of distorting the values of the Founding Fathers that all men are created equal, while Douglas emphasized his Freeport Doctrine, that local settlers were free to choose whether to allow slavery, and accused Lincoln of having joined the abolitionists. The debates had an atmosphere of a prize fight and drew crowds in the thousands. Lincoln's argument was rooted in morality. He claimed that Douglas represented a conspiracy to extend slavery to free states. Douglas's argument was legal, claiming that Lincoln was defying the authority of the U.S. Supreme Court and the "Dred Scott" decision.

Though the Republican legislative candidates won more popular votes, the Democrats won more seats, and the legislature re-elected Douglas. Lincoln's articulation of the issues gave him a national political presence. In May 1859, Lincoln purchased the "Illinois Staats-Anzeiger", a German-language newspaper that was consistently supportive; most of the state's 130,000 German Americans voted Democratic but the German-language paper mobilized Republican support. In the aftermath of the 1858 election, newspapers frequently mentioned Lincoln as a potential Republican presidential candidate, rivaled by William H. Seward, Salmon P. Chase, Edward Bates, and Simon Cameron. While Lincoln was popular in the Midwest, he lacked support in the Northeast, and was unsure whether to seek the office. In January 1860, Lincoln told a group of political allies that he would accept the nomination if offered, and in the following months several local papers endorsed his candidacy.

On February 27, 1860, New York party leaders invited Lincoln to give a speech at Cooper Union to a group of powerful Republicans. Lincoln argued that the Founding Fathers had little use for popular sovereignty and had repeatedly sought to restrict slavery. Lincoln insisted that morality required opposition to slavery, and rejected any "groping for some middle ground between the right and the wrong". Despite his inelegant appearance—many in the audience thought him awkward and even ugly—Lincoln demonstrated intellectual leadership that brought him into contention. Journalist Noah Brooks reported, "No man ever before made such an impression on his first appeal to a New York audience."

Historian David Herbert Donald

On May 9–10, 1860, the Illinois Republican State Convention was held in Decatur. Lincoln's followers organized a campaign team led by David Davis, Norman Judd, Leonard Swett, and Jesse DuBois, and Lincoln received his first endorsement. Exploiting his embellished frontier legend (clearing land and splitting fence rails), Lincoln's supporters adopted the label of "The Rail Candidate". In 1860 Lincoln described himself: "I am in height, six feet, four inches, nearly; lean in flesh, weighing, on an average, one hundred and eighty pounds; dark complexion, with coarse black hair, and gray eyes."

On May 18, at the Republican National Convention in Chicago, Lincoln won the nomination on the third ballot, beating candidates such as Seward and Chase. A former Democrat, Hannibal Hamlin of Maine, was nominated for Vice President to balance the ticket. Lincoln's success depended on his campaign team, his reputation as a moderate on the slavery issue, and his strong support for Whiggish programs of internal improvements and the tariff.

Pennsylvania put him over the top, led by Pennsylvania iron interests who were reassured by his tariff support. Lincoln's managers had focused on this delegation, while following Lincoln's dictate to "Make no contracts that bind me".

Most Republicans agreed with Lincoln that the North was the aggrieved party, as the Slave Power tightened its grasp on the national government. Throughout the 1850s, Lincoln doubted the prospects of civil war, and his supporters rejected claims that his election would incite secession. Douglas was selected as the candidate of the Northern Democrats. Delegates from eleven slave states walked out of the Democratic convention, disagreeing with Douglas' position on popular sovereignty, and ultimately selected incumbent Vice President John C. Breckinridge as their candidate. A group of former Whigs and Know Nothings formed the Constitutional Union Party and nominated John Bell
Prior to the Republican convention, the Lincoln campaign began cultivating a nationwide youth organization, the Wide Awakes, which it used to generate popular support throughout the country to spearhead voter registration drives, thinking that new voters and young voters tended to embrace new parties. Lincoln's ideas of abolishing slavery

On November 6, 1860, Lincoln was elected the 16th president of the United States. He was the first Republican president and his victory was entirely due to his support in the North and West; no ballots were cast for him in 10 of the 15 Southern slave states, and he won only two of 996 counties in all the Southern states. Lincoln received 1,866,452 votes, or 39.8% of the total in a four-,am race. He won the free Northern states, as well as California and Oregon.

Lincoln's victory in the electoral college

After the November election secessionists planned to leave the Union before he took office in March. On December 20, 1860, South Carolina took the lead by adopting an ordinance of secession; by February 1, 1861, Florida, Mississippi, Alabama, Georgia, Louisiana, and Texas had followed. Six of these states declared themselves to be a sovereign nation, the Confederate States of America and adopted a constitution. The upper South and border states (Delaware, Maryland, Virginia, North Carolina, Tennessee, Kentucky, Missouri, and Arkansas) listened to, but initially rejected, the secessionist appeal. President Buchanan and President-elect Lincoln refused to recognize the Confederacy, declaring secession illegal. The Confederacy selected Jefferson Davis as its provisional President on February 9, 1861.

Attempts at compromise followed. Lincoln and the Republicans rejected the proposed Crittenden Compromise as contrary to the Party's free-soil in the territories platform. Lincoln rejected the idea, saying, "I will suffer death before I consent ... to any concession or compromise which looks like buying the privilege to take possession of this government to which we have a constitutional right."

Lincoln did tacitly support the proposed Corwin Amendment

En route to his inauguration, Lincoln addressed crowds and legislatures across the North. The president-elect evaded possible assassins in Baltimore. On February 23, 1861, he arrived in disguise in Washington, D.C., which was placed under substantial military guard. Lincoln directed his inaugural address to the South, proclaiming once again that he had no intention, or inclination, to abolish slavery in the Southern states:

The President ended his address with an appeal to the people of the South: "We are not enemies, but friends. We must not be enemies ... The mystic chords of memory, stretching from every battlefield, and patriot grave, to every living heart and hearthstone, all over this broad land, will yet swell the chorus of the Union, when again touched, as surely they will be, by the better angels of our nature." The failure of the Peace Conference of 1861 signaled that legislative compromise was impossible. By March 1861, no leaders of the insurrection had proposed rejoining the Union on any terms. Meanwhile, Lincoln and the Republican leadership agreed that the dismantling of the Union could not be tolerated. Lincoln said in his second inaugural address

Fort Sumter's commander, Major Robert Anderson, sent a request for provisions to Washington, and the execution of Lincoln's order to meet that request was seen by the secessionists as an act of war. On April 12, 1861, Confederate forces fired on Union troops at Fort Sumter and began the fight. Historian Allan Nevins argued that the newly inaugurated Lincoln made three miscalculations: underestimating the gravity of the crisis, exaggerating the strength of Unionist sentiment in the South, and not realizing the Southern Unionists were insisting there be no invasion.

William Tecumseh Sherman talked to Lincoln during inauguration week and was "sadly disappointed" at his failure to realize that "the country was sleeping on a volcano" and that the South was preparing for war. Donald concludes that, "His repeated efforts to avoid collision in the months between inauguration and the firing on Ft. Sumter showed he adhered to his vow not to be the first to shed fraternal blood. But he also vowed not to surrender the forts. The only resolution of these contradictory positions was for the confederates to fire the first shot; they did just that."

On April 15, Lincoln called on the states to send detachments totaling 75,000 troops to recapture forts, protect Washington, and "preserve the Union", which, in his view, remained intact despite the seceding states. This call forced states to choose sides. Virginia seceded and was rewarded with the Confederate capital, despite the exposed position of Richmond close to Union lines. North Carolina, Tennessee, and Arkansas followed over the following two months. Secession sentiment was strong in Missouri and Maryland, but did not prevail; Kentucky remained neutral. The Fort Sumter attack rallied Americans north of the Mason-Dixon line to defend the nation.

States sent Union regiments south. On April 19, mobs in Baltimore, which controlled rail links, attacked Union troops who were changing trains. Local leaders' groups later burned critical rail bridges to the capital. The Army responded by arresting local Maryland officials. Lincoln suspended the writ of "habeas corpus" in areas the army felt it needed to secure for troops to reach Washington. John Merryman, a Maryland official involved in hindering the U.S. troop movements, petitioned Supreme Court Chief Justice and Marylander, Roger B. Taney, author of the "Dred Scott" opinion, to issue a writ of "habeas corpus." In June Taney, acting as a circuit judge and not speaking for the Supreme Court, issued the writ, because in his opinion only Congress could suspend the writ. Lincoln continued the army policy that the writ was suspended in limited areas despite the ex parte Merryman ruling.

After the Battle of Fort Sumter, Lincoln took executive control of the war and formed an overall Union military strategy. Lincoln responded to this unprecedented political and military crisis as commander-in-chief

The war dominated Lincoln's his time and attention. From the start, it was clear that bipartisan support would be essential to success, and that any compromise would alienate factions on both sides of the aisle, such as the appointment of Republicans and Democrats to command positions. Copperheads criticized Lincoln for refusing to compromise on slavery. The Radical Republicans criticized him for moving too slowly in abolishing slavery. On August 6, 1861, Lincoln signed the Confiscation Act that authorized judicial proceedings to confiscate and free slaves who were used to support the Confederates. In practice, the law had little effect, but it did signal political support for abolishing slavery.

In late August 1861, General John C. Frémont, the 1856 Republican presidential nominee, without consulting his superiors in Washington, proclaimed a very harsh martial law in Missouri without consultation. Lincoln cancelled the proclamation, saying its emancipation plan was political, lacking military necessity and a legal basis. After Lincoln acted, Union enlistments from Maryland, Kentucky, and Missouri increased by over 40,000.

In foreign policy, Lincoln's main goal was to stop military aid to the Confederacy. Lincoln left most diplomatic matters to his Secretary of State, William Seward. At times Seward was too bellicose, so for balance Lincoln maintained a close working relationship with Senate Foreign Relations Committee chairman Charles Sumner. The Trent Affair of late 1861 threatened war with Great Britain. The U.S. Navy had illegally intercepted a British mail ship, the "Trent", on the high seas and seized two Confederate envoys; Britain protested vehemently while the U.S. cheered. Lincoln ended the crisis by releasing the two diplomats. Biographer James G. Randall dissected Lincoln's successful techniques:
Lincoln painstakingly monitored the telegraph reports coming into War Department. He tracked all phases of the effort, consulted with governors, and selected generals based on their success (as well as their state and party). In January 1862, after many complaints of inefficiency and profiteering in the War Department, Lincoln replaced Simon Cameron with Edwin Stanton as War Secretary. Stanton centralized the War Department's activities, auditing and cancelling contracts, saving the federal government $17,000,000. Stanton was a staunchly Unionist, pro-business, conservative Democrat who moved toward the Radical Republican faction. He worked more often and more closely with Lincoln than any other senior official. "Stanton and Lincoln virtually conducted the war together," say Thomas and Hyman.

In terms of war strategy, Lincoln articulated two priorities: to ensure that Washington was well-defended, and to conduct an aggressive war effort leading to prompt, decisive victory. However major Northern newspapers demanded more—they expected victory within 90 days. Twice a week, Lincoln met with his cabinet in the afternoon. Occasionally Mary would force him to take a carriage ride, concerned that he was working too hard. Lincoln learned from reading his chief of staff General Henry Halleck's book, a disciple of the European strategist Jomini; he began to appreciate the critical need to control strategic points, such as the Mississippi River. Lincoln saw the importance of Vicksburg and understood the necessity of defeating the enemy's army, rather than simply capturing territory.

After the Union rout at Bull Run and Winfield Scott's retirement, Lincoln appointed Major General George B. McClellan general-in-chief. McClellan then took months to plan his Peninsula Campaign

Lincoln removed McClellan in March 1862, after McClellan offered unsolicited political advice. In July Lincoln elevated Henry Halleck. Lincoln appointed Republican John Pope as head of the new Army of Virginia. Pope complied with Lincoln's desire to advance on Richmond from the north, thus protecting Washington from counterattack.

Pope was then soundly defeated at the Second Battle of Bull Run in the summer of 1862, forcing the Army of the Potomac back to defend Washington.

Despite his dissatisfaction with McClellan's failure to reinforce Pope, Lincoln restored him to command of all forces around Washington. Two days after McClellan's return to command, General Robert E. Lee's forces crossed the Potomac River into Maryland, leading to the Battle of Antietam in September. The ensuing Union victory was among the bloodiest in American history, but it enabled Lincoln to announce that he would issue an Emancipation Proclamation in January. Lincoln had waited for a military victory so that the Proclamation would not be perceived as the product of desperation.

McClellan then resisted the President's demand that he pursue Lee's army, while General Don Carlos Buell likewise refused orders to move the Army of the Ohio against rebel forces in eastern Tennessee. Lincoln replaced Buell with William Rosecrans; and, after the 1862 midterm elections, replaced McClellan with Republican Ambrose Burnside

Burnside, against presidential advice, launched an offensive across the Rappahannock River and was defeated by Lee at Fredericksburg in December. Desertions during 1863 came in the thousands and increased after Fredericksburg. Lincoln promoted Joseph Hooker.

The mid-term elections in 1862 cost the Republicans severe losses due to rising inflation, high taxes, rumors of corruption, suspension of "habeas corpus", military draft law, and fears that freed slaves would come North and undermine the labor market. The Emancipation Proclamation gained votes for Republicans in rural New England and the upper Midwest, but cost votes in the Irish and German strongholds and in the lower Midwest, where many Southerners had lived for generations.

In the spring of 1863, Lincoln became optimistic about upcoming military campaigns to the point of thinking the end of the war could be near if a string of victories could be put together; these plans included attacks by Hooker on Lee north of Richmond, Rosecrans on Chattanooga, Grant on Vicksburg, and a naval assault on Charleston.

Hooker was routed by Lee at the Battle of Chancellorsville in May. He then resigned and was replaced by George Meade as Lee moved north. Meade followed Lee into Pennsylvania and beat him in the Gettysburg Campaign

The Federal government's power to end slavery was limited by the Constitution, which before 1865, committed the issue to individual states. Lincoln argued that slavery would end by preventing its expansion into new territories. He sought to persuade the states to accept compensated emancipation in return for their prohibition of slavery. Lincoln believed that curtailing slavery would make it obsolete. Lincoln rejected Fremont's two emancipation attempts in August 1861 and one by Major General David Hunter in May 1862, on the grounds that it was not within their power, and would upset loyal border states.

On June 19, 1862, endorsed by Lincoln, Congress passed an act banning slavery on all federal territory. In July, the Confiscation Act of 1862 was enacted, which set up court procedures to free the slaves of those convicted of aiding the rebellion. Although Lincoln believed this was not within Congress's power, he approved the bill in deference to the legislature. He felt such action could be taken only by the Commander-in-Chief, using Constitutional war powers, which he planned to do. Lincoln discussed a draft of the Emancipation Proclamation with his cabinet.

Privately, Lincoln concluded that the Confederacy's slave base had to be eliminated. However, Copperheads argued that emancipation was a stumbling block to peace and reunification. Republican editor Horace Greeley of the "New York Tribune" agreed. Lincoln rejected this argument directly in his letter of August 22, 1862. Although he said he personally wished all men could be free, Lincoln stated that the primary goal of his actions as president (he used the first person pronoun and explicitly refers to his "official duty") was that of preserving the Union:

The Emancipation Proclamation, issued on September 22, 1862, with effect on January 1, 1863, declared free the slaves in 10 states not then under Union control, with exemptions specified for areas under Union control in two states. Lincoln spent the next 100 days preparing the army and the nation for emancipation, while Democrats rallied their voters by warning of the threat that freed slaves posed to northern whites.

Once the abolition of slavery in the rebel states became a military objective, Union armies advancing south liberated three million slaves. Lincoln's comment on the signing of the Proclamation was: "I never, in my life, felt more certain that I was doing right, than I do in signing this paper." Lincoln continued earlier plans to set up colonies for the newly freed slaves. He supported this in the Proclamation, but the undertaking failed.

Enlisting former slaves became official policy. By the spring of 1863, Lincoln was ready to recruit black troops in more than token numbers. In a letter to Tennessee military governor Andrew Johnson encouraging him to lead the way in raising black troops, Lincoln wrote, "The bare sight of 50,000 armed and drilled black soldiers on the banks of the Mississippi would end the rebellion at once". By the end of 1863, at Lincoln's direction, General Lorenzo Thomas

Grant's victories at the Battle of Shiloh and in the Vicksburg campaign impressed Lincoln. Responding to criticism of Grant after Shiloh, Lincoln had said, "I can't spare this man. He fights." With Grant in command, Lincoln felt the Union Army could advance in multiple theaters, and incorporate black troops. Meade's failure to capture Lee's army after Gettysburg and the continued passivity of the Army of the Potomac persuaded Lincoln to promote Grant to supreme commander. Grant stayed with Meade's army and told Meade what to do.

Lincoln was concerned that Grant might be considering a presidential candidacy in 1864, as was McClellan. Lincoln arranged for an intermediary to inquire into Grant's political intentions. Assured that he had none, Lincoln submitted Grant's appointment to the Senate. He obtained Congress's consent to make him Lieutenant General, a rank that that had remained unoccupied since George Washington.

Grant waged his bloody Overland Campaign in 1864, with heavy losses on both sides. Despite this, when Lincoln asked what Grant's plans were, the general replied, "I propose to fight it out on this line if it takes all summer."

Grant's army moved steadily south. Lincoln traveled to Grant's headquarters at City Point, Virginia to confer with Grant and William Tecumseh Sherman. Lincoln replaced the Union losses by mobilizing support throughout the North.

Lincoln authorized Grant to target infrastructure—plantations, railroads, and bridges—hoping to destroy the South's morale and weaken its fighting ability. Lincoln emphasized defeat of the Confederate armies rather than destruction (which was considerable) for its own sake.

In 1864 Confederate general Jubal Early raided Washington, D.C., while Lincoln watched from an exposed position; Captain Oliver Wendell Holmes shouted at him, "Get down, you damn fool, before you get shot!"

As Grant continued to attrit Lee's forces, efforts to discuss peace began. Confederate Vice President Stephens led a group to meet with Lincoln, Seward, and others at Hampton Roads. Lincoln refused to allow any negotiation with the Confederacy as a coequal; his sole objective was an agreement to end the fighting and the meetings produced no results. On April 1, 1865, Grant nearly encircled Petersburg. The Confederate government evacuated and the city fell. Lincoln visited the conquered capital. On April 9, Lee surrendered to Grant at Appomattox

Lincoln ran again in 1864. He united the main Republican factions, along with War Democrats such as Edwin M. Stanton and Andrew Johnson. Lincoln used conversation and his patronage powers—greatly expanded from peacetime—to build support and fend off the Radicals' efforts to replace him. At its convention, the Republicans selected Johnson as his running mate. To broaden his coalition to include War Democrats as well as Republicans, Lincoln ran under the label of the new Union Party.

Grant's bloody stalemates damaged Lincoln's re-election prospects, and many Republicans feared defeat. Lincoln confidentially pledged in writing that if he should lose the election, he would still defeat the Confederacy before turning over the White House: Lincoln did not show the pledge to his cabinet, but asked them to sign the sealed envelope.

While the Democratic platform followed the "Peace wing" of the party and called the war a "failure", their candidate, McClellan, supported the war and repudiated the platform. Lincoln provided Grant with more troops and led his party to renew its support for Grant. Sherman's capture of Atlanta in September and David Farragut's capture of Mobile ended defeatism. The Democratic Party was deeply split, with some leaders and most soldiers openly for Lincoln. The National Union Party was united by Lincoln's support for emancipation. State Republican parties stressed the perfidy

On March 4, 1865, Lincoln delivered his second inaugural address. In it, he deemed the endless casualties to be God's will. Historian Mark Noll claims this speech to rank "among the small handful of semi-sacred texts by which Americans conceive their place in the world". Lincoln said:

Reconstruction began during the war, as Lincoln and his associates considered how to reintegrate the nation, and the fates of Confederate leaders and freed slaves. Shortly after Lee's surrender, a general asked Lincoln how to treat defeated Confederates. Lincoln replied, "Let 'em up easy." Lincoln led the moderates regarding Reconstruction policy, and was opposed by the Radicals, under Rep. Thaddeus Stevens, Sen. Charles Sumner and Sen. Benjamin Wade, who otherwise remained Lincoln's allies. Determined to reunite the nation and not alienate the South, Lincoln urged that speedy elections under generous terms be held. His Amnesty Proclamation

As Southern states fell, they needed leaders while their administrations re-formed. In Tennessee and Arkansas, Lincoln appointed Johnson and Frederick Steele as military governors, respectively. In Louisiana, Lincoln ordered General Nathaniel P. Banks to promote a plan that would restore statehood when 10 percent of the voters agreed. Democratic opponents accused Lincoln of using the military to ensure his and the Republicans' political aspirations. The Radicals denounced his policy as too lenient, and passed their own plan, the Wade-Davis Bill, in 1864, which Lincoln vetoed. The Radicals retaliated by refusing to seat elected representatives from Louisiana, Arkansas, and Tennessee.

Lincoln's appointments were designed to harness both moderates and Radicals. To fill Chief Justice Taney's seat on the Supreme Court, he named the Radicals' choice, Salmon P. Chase, who Lincoln believed would uphold his emancipation and paper money policies.

After implementing the Emancipation Proclamation, Lincoln increased pressure on Congress to outlaw slavery throughout the nation with a constitutional amendment. He declared that such an amendment would "clinch the whole matter". By December 1863, an amendment was brought to Congress. This first attempt failed, falling short of the required two-thirds majority on June 15, 1864, in the House of Representatives. Passage became part of the Republican/Unionist platform. After a House debate, the second attempt passed on January 31, 1865. With ratification, it became the Thirteenth Amendment to the United States Constitution on December 6, 1865.

Lincoln believed the federal government had limited responsibility to the millions of freedmen. He signed Senator Charles Sumner's Freedmen's Bureau bill that set up a temporary federal agency designed to meet the immediate needs of former slaves. The law opened land for a lease of three years with the ability to purchase title for the freedmen. Lincoln announced a Reconstruction plan that involved short-term military control, pending readmission under the control of southern Unionists.

Historians agree that it is impossible to predict exactly how Reconstruction would have proceeded had Lincoln lived. Biographers James G. Randall and Richard Current, according to David Lincove, argue that:
Eric Foner argues that:
Lincoln adhered to the Whig theory of the presidency, giving Congress primary responsibility for lawmaking while the Executive enforced them. Lincoln vetoed only four bills; the only important one was the Wade-Davis Bill with its harsh Reconstruction program. The 1862 Homestead Act made millions of acres of Western government-held land available for purchase at low cost. The 1862 Morrill Land-Grant Colleges Act provided government grants for agricultural colleges in each state. The Pacific Railway Acts of 1862 and 1864 granted federal support for the construction of the United States' First Transcontinental Railroad, which was completed in 1869. The passage of the Homestead Act and the Pacific Railway Acts was enabled by the absence of Southern congressmen and senators who had opposed the measures in the 1850s.

In July 1861 the US issued paper currency for the first time. The currency became known greenbacks, because it was printed in green on the reverse side.
Other important legislation involved two measures to raise revenues for the Federal government: tariffs (a policy with long precedent), and a Federal income tax. In 1861, Lincoln signed the second and third Morrill Tariffs, following the first enacted by Buchanan. Also in 1861, Lincoln signed the Revenue Act of 1861, creating the first U.S. income tax. This created a flat tax of 3 percent on incomes above $800 ($ in current dollar terms). The Revenue Act of 1862 adopted rates that increased with income.

Lincoln presided over the expansion of the federal government's economic influence in other areas. The National Banking Act created the system of national banks. It also established a national currency. In 1862, Congress created the Department of Agriculture. In 1862, Lincoln sent a senior general, John Pope to put down the "Sioux Uprising" in Minnesota. Presented with 303 execution warrants for Santee Dakota who were convicted of killing innocent farmers, Lincoln conducted his own personal review of each warrant, eventually approving 39 for execution (one was later reprieved).

In response to rumors of a renewed draft, the editors of the "New York World" and the "Journal of Commerce" published a false draft proclamation that created an opportunity for the editors and others employed at the publications to corner the gold market. Lincoln attacked the media about such behavior, ordering the military to seize the two papers. The seizure lasted for two days.

Lincoln is largely responsible for the Thanksgiving holiday. Thanksgiving had became a regional holiday in New England in the 17th century. It had been sporadically proclaimed by the federal government on irregular dates. The prior proclamation had been during James Madison's presidency 50 years earlier. In 1863, Lincoln declared the final Thursday in November of that year to be a day of Thanksgiving.

In June 1864, Lincoln approved the Yosemite Grant enacted by Congress, which provided unprecedented federal protection for the area now known as Yosemite National Park

Lincoln's declared philosophy on court nominations was that "we cannot ask a man what he will do, and if we should, and he should answer us, we should despise him for it. Therefore we must take a man whose opinions are known." Lincoln made five appointments to the United States Supreme Court. Noah Haynes Swayne was chosen as an anti-slavery lawyer who was committed to the Union. Samuel Freeman Miller, supported Lincoln in the 1860 election and was an avowed abolitionist. David Davis was Lincoln's campaign manager in 1860 and had served as a judge in Lincoln's Illinois court circuit. Democrat Stephen Johnson Field, a previous California Supreme Court justice, provided geographic and political balance. Finally, Lincoln's Treasury Secretary, Salmon P. Chase, became Chief Justice. Lincoln believed Chase was an able jurist, would support Reconstruction legislation, and that his appointment united the Republican Party.

Lincoln appointed 32 federal judges, including four Associate Justices and one Chief Justice to the Supreme Court of the United States, and 27 judges to the United States district courts. Lincoln appointed no judges to the United States circuit courts during his time in office.

West Virginia was admitted to the Union on June 20, 1863. Nevada
Abraham Lincoln was assassinated by John Wilkes Booth on Good Friday, April 14, 1865, while attending a play at Ford's Theatre, five days after Lee's surrender. Booth was a well-known actor and a Confederate spy from Maryland; though he never joined the Confederate army, he had contacts with the Confederate secret service. After attending an April 11, 1865, speech in which Lincoln promoted voting rights for blacks, Booth decided to assassinate the President. Learning of Lincoln's intent to attend the play with Grant, Booth and his co-conspirators planned to assassinate Lincoln and Grant at the theater and to kill Vice President Johnson and Secretary of State Seward at their respective homes. Lincoln left to attend the play "Our American Cousin" on April 14. At the last minute, Grant decided to go to New Jersey to visit his children instead of attending the play.

Booth crept up from behind and at about 10:13 pm, fired at the back of Lincoln's head, mortally wounding him. Lincoln's guest Major Henry Rathbone momentarily grappled with Booth, but Booth stabbed him and escaped.

Lincoln was taken across the street to Petersen House. After remaining in a coma for nine hours, Lincoln died at 7:22 am on April 15. After death his face relaxed into a smile. Stanton saluted and said, "Now he belongs to the ages."

Lincoln's flag-enfolded body was then escorted in the rain to the White House by bareheaded Union officers, while the city's church bells rang. President Johnson was sworn in at 10:00 am, less than 3 hours after Lincoln's death.

Booth was tracked to a farm in Virginia. Refusing to surrender, he was shot on April 26.

The late President lay in state, first in the East Room, and then in the Capitol Rotunda from April 19 through April 21. The caskets containing Lincoln's body and the body of his son Willie traveled for three weeks on the "Lincoln Special" funeral train. The train followed a circuitous route from Washington D.C. to Springfield, Illinois, stopping at many cities for memorials attended by hundreds of thousands. Many others gathered along the tracks as the train passed with bands, bonfires, and hymn singing or in silent grief. Poet Walt Whitman composed "When Lilacs Last in the Dooryard Bloom'd" to eulogize him, one of four poems he wrote about Lincoln. African-Americans were especially moved; they had lost 'their Moses

As a young man, Lincoln was a religious skeptic. Later in life, Lincoln's frequent use of religious imagery and language might have reflected his own personal beliefs or might have been a device to reach his audiences, who were mostly evangelical Protestants. He never joined a church, although he frequently attended with his wife. He was deeply familiar with the Bible, and he both quoted and praised it. He was private about his beliefs and respected the beliefs of others. Lincoln never made a clear profession of Christian beliefs. However, he did believe in an all-powerful God that shaped events and by 1865 was expressing those beliefs in major speeches.

In the 1840s, Lincoln subscribed to the Doctrine of Necessity, a belief that asserted the human mind was controlled by some higher power. In the 1850s, Lincoln asserted his belief in "providence" in a general way, and rarely used the language or imagery of the evangelicals; he regarded the republicanism of the Founding Fathers with an almost religious reverence. With the death of his son Edward, Lincoln more frequently expressed a need to depend on God. The death of son Willie in February 1862 may have caused Lincoln to look toward religion for solace. After Willie's death, Lincoln considered why, from a divine standpoint, the severity of the war was necessary. He wrote at this time that God "could have either saved or destroyed the Union without a human contest. Yet the contest began. And having begun, He could give the final victory to either side any day. Yet the contest proceeds." On the day Lincoln was assassinated, he reportedly told his wife he desired to visit the Holy Land.

Several claims have been made that Lincoln's health was declining before the assassination. These are often based on photographs appearing to show weight loss and muscle wasting. One such claim is that he suffered from a rare genetic disorder, MEN2b, which manifests with a medullary thyroid carcinoma, mucosal neuromas and a Marfanoid appearance. Others simply claim he had Marfan syndrome, based on his tall appearance with spindly fingers, and the association of possible aortic regurgitation, which can cause bobbing of the head (DeMusset's sign) – based on blurring of Lincoln's head in photographs, which required long exposure times. Confirmation of this and other diseases could possibly be obtained via DNA analysis of a pillow case stained with Lincoln's blood, currently in possession of the Grand Army of the Republic

The successful reunification of the states had consequences for the name of the country. The term "the United States" has historically been used, sometimes in the plural ("these United States"), and other times in the singular, without any particular grammatical consistency. The Civil War was a significant force in the eventual dominance of the singular usage by the end of the 19th century.

Historians such as Harry Jaffa, Herman Belz, John Diggins, Vernon Burton, and Eric Foner stress Lincoln's redefinition of "republican values". As early as the 1850s, a time when most political rhetoric focused on the Constitution, Lincoln redirected emphasis to the Declaration of Independence as the foundation of American political values—what he called the "sheet anchor" of republicanism. The Declaration's emphasis on freedom and equality for all, in contrast to the Constitution's tolerance of slavery, shifted the debate. Regarding the 1860 Cooper Union speech, Diggins notes, "Lincoln presented Americans a theory of history that offers a profound contribution to the theory and destiny of republicanism itself." He highlights the moral basis of republicanism, rather than its legalisms. Nevertheless, Lincoln justified the war via legalisms (the Constitution was a contract, and for one party to get out of a contract all the other parties had to agree), and then in terms of the national duty to guarantee a republican form of government in every state. Burton argues that Lincoln's republicanism was taken up by the emancipated Freedmen.

In Lincoln's first inaugural address

In surveys of U.S. scholars ranking presidents conducted since the 1940s, Lincoln is consistently ranked in the top three, often as number one. A 2004 study found that scholars in the fields of history and politics ranked Lincoln number one, while legal scholars placed him second after George Washington. In presidential ranking polls conducted in the United States since 1948, Lincoln has been rated at the top in the majority of polls. Generally, the top three presidents are rated as 1. Lincoln; 2. Washington; and 3. Franklin Delano Roosevelt, although the order varies.

President Lincoln's assassination left him a national martyr. He was viewed by abolitionists as a champion for human liberty. Republicans linked Lincoln's name to their party. Many, though not all, in the South considered Lincoln as a man of outstanding ability. Historians have said he was "a classical liberal" in the 19th century sense. Allen C. Guelzo states that Lincoln was a
Lincoln became a favorite exemplar for liberal intellectuals across the world.

Schwartz argues that Lincoln's American reputation grew slowly from the late 19th century until the Progressive Era (1900–1920s) when he emerged as one of America's most venerated heroes, even among white Southerners. The high point came in 1922 with the dedication of the Lincoln Memorial on the National Mall in Washington, D.C. In the New Deal era, liberals honored Lincoln not so much as the self-made man or the great war president, but as the advocate of the common man who they claimed would have supported the welfare state. In the Cold War years, Lincoln's image shifted to a symbol of freedom who brought hope to those oppressed by Communist regimes.

By the 1970s Lincoln had become a hero to political conservatives for his intense nationalism, support for business, his insistence on stopping the spread of human bondage, his acting in terms of Lockean and Burkean principles on behalf of both liberty and tradition, and his devotion to the principles of the Founding Fathers. As a Whig activist, Lincoln was a spokesman for business interests, favoring high tariffs, banks, infrastructure improvements, and railroads, in opposition to the agrarian Democrats. William C. Harris found that Lincoln's "reverence for the Founding Fathers, the Constitution, the laws under it, and the preservation of the Republic and its institutions strengthened his conservatism". James G. Randall emphasizes his tolerance and moderation "in his preference for orderly progress, his distrust of dangerous agitation, and his reluctance toward ill digested schemes of reform". Randall concludes that, "he was conservative in his complete avoidance of that type of so-called 'radicalism' which involved abuse of the South, hatred for the slaveholder, thirst for vengeance, partisan plotting, and ungenerous demands that Southern institutions be transformed overnight by outsiders."

By the late 1960s, some African American intellectuals, led by Lerone Bennett Jr., rejected Lincoln's role as the Great Emancipator. Bennett won wide attention when he called Lincoln a white supremacist in 1968. He noted that Lincoln used ethnic slurs and told jokes that ridiculed blacks. Bennett argued that Lincoln opposed social equality, and proposed sending freed slaves to another country. Defenders, such as authors Dirck and Cashin, retorted that he was not as bad as most politicians of his day; and that he was a "moral visionary" who deftly advanced the abolitionist cause, as fast as politically possible. The emphasis shifted away from Lincoln the emancipator to an argument that blacks had freed themselves from slavery, or at least were responsible for pressuring the government on emancipation. Historian Barry Schwartz wrote in 2009 that Lincoln's image suffered "erosion, fading prestige, benign ridicule" in the late 20th century. On the other hand, Donald opined in his 1996 biography that Lincoln was distinctly endowed with the personality trait of negative capability, defined by the poet John Keats and attributed to extraordinary leaders who were "content in the midst of uncertainties and doubts, and not compelled toward fact or reason". In the 21st century, President Barack Obama named Lincoln his favorite president and insisted on using Lincoln's Bible for his inaugural ceremonies.

Lincoln has often been portrayed by Hollywood, almost always in a flattering light.

Union nationalism, as envisioned by Lincoln, "helped lead America to the nationalism of Theodore Roosevelt, Woodrow Wilson, and Franklin Delano Roosevelt
Lincoln's portrait appears on two denominations of United States currency, the penny and the $5 bill. His likeness also appears on many postage stamps and he has been memorialized in many town, city, and county names, including the capital of Nebraska. While he is usually portrayed bearded, he first grew a beard in 1860 at the suggestion of 11-year-old Grace Bedell

The most famous and most visited memorials are Lincoln's sculpture on Mount Rushmore; Lincoln Memorial, Ford's Theatre, and Petersen House (where he died) in Washington, D.C.; and the Abraham Lincoln Presidential Library and Museum in Springfield, Illinois, not far from Lincoln's home, as well as his tomb.

Sociologist Barry Schwartz argues that in the 1930s and 1940s, the memory of Abraham Lincoln was practically sacred and provided the nation with "a moral symbol inspiring and guiding American life". During the Great Depression, he argues, Lincoln served "as a means for seeing the world's disappointments, for making its sufferings not so much explicable as meaningful". Franklin D. Roosevelt, preparing America for war, used the words of the Civil War president to clarify the threat posed by Germany and Japan. Americans asked, "What would Lincoln do?" However, Schwartz also finds that since World War II, Lincoln's symbolic power has lost relevance, and this "fading hero is symptomatic of fading confidence in national greatness". He suggested that postmodernism and multiculturalism have diluted greatness as a concept.

The United States Navy
Category:1809 births
Category:1865 deaths
Category:19th-century American politicians
Category:19th-century Presidents of the United States
Category:American lawyers admitted to the practice of law by reading law
Category:American people of English descent
Category:American postmasters
Category:American surveyors
Category:Assassinated Presidents of the United States
Category:Burials at Oak Ridge Cemetery
Category:Deaths by firearm in Washington, D.C.
Category:Hall of Fame for Great Americans inductees
Category:Illinois Central Railroad people
Category:Illinois lawyers
Category:Illinois Republicans
Category:Illinois Whigs
Category:Members of the Illinois House of Representatives
Category:Members of the United States House of Representatives from Illinois
Category:Murdered lawyers
Category:People associated with the assassination of Abraham Lincoln
Category:People from Coles County, Illinois
Category:People from LaRue County, Kentucky
Category:People from Macon County, Illinois
Category:People from Spencer County, Indiana
Category:People murdered in Washington, D.C.
Category:People of Illinois in the American Civil War
Category:People with mood disorders
Category:Political party founders
Category:Politicians from Springfield, Illinois
Category:Presidents of the United States
Category:Republican Party (United States) presidential nominees
Category:Republican Party Presidents of the United States
Category:Union political leaders
Category:1860 United States presidential candidates
Category:1864 United States presidential candidates
Category:Whig Party members of the United States House of Representatives
Category:American colonization movementAristotle

Aristotle (; "Aristotélēs", ; 384–322 BC) was an ancient Greek philosopher and scientist born in the city of Stagira, Chalkidiki, Greece. Along with Plato, he is considered the "Father of Western Philosophy". Aristotle provided a complex and harmonious synthesis of the various existing philosophies prior to him, including those of Socrates and Plato, and it was above all from his teachings that the West inherited its fundamental intellectual lexicon, as well as problems and methods of inquiry. As a result, his philosophy has exerted a unique influence on almost every form of knowledge in the West and it continues to be central to the contemporary philosophical discussion.

Little is known about his life. His father, Nicomachus, died when Aristotle was a child, and he was brought up by a guardian. At seventeen or eighteen years of age, he joined Plato's Academy in Athens and remained there until the age of thirty-seven (c. 347 BC). His writings cover many subjects – including physics, biology, zoology, metaphysics, logic, ethics, aesthetics, poetry, theatre, music, rhetoric, psychology, linguistics, economics, politics and government – and constitute the first comprehensive system of Western philosophy. Shortly after Plato died, Aristotle left Athens and, at the request of Philip II of Macedon, tutored Alexander the Great beginning in 343 BC. Teaching Alexander gave Aristotle many opportunities. He established a library in the Lyceum which helped him to produce many of his hundreds of books, which were papyrus scrolls. The fact that Aristotle was a pupil of Plato contributed to his former views of Platonism, but, following Plato's death, Aristotle immersed himself in empirical studies and shifted from Platonism to empiricism. He believed all concepts and knowledge were ultimately based on perception. Aristotle's views on natural sciences represent the groundwork underlying many of his works.

Aristotle's views on physical science profoundly shaped medieval scholarship. Their influence extended from Late Antiquity and the Early Middle Ages into the Renaissance, and were not replaced systematically until the Enlightenment and theories such as classical mechanics. Some of Aristotle's zoological observations, such as on the hectocotyl (reproductive) arm of the octopus, were disbelieved until the 19th century. His works contain the earliest known formal study of logic, studied by medieval scholars such as Peter Abelard and John Buridan. Aristotelianism profoundly influenced Islamic thought during the Middle Ages, as well as Christian theology, especially the Neoplatonism of the Early Church and the scholastic tradition of the Catholic Church. Aristotle was revered among medieval Muslim scholars as "The First Teacher". His ethics, though always influential, gained renewed interest with the modern advent of virtue ethics.

All aspects of Aristotle's philosophy continue to be the object of academic study. Though Aristotle wrote many elegant treatises and dialogues for publication, only around a third of his original output has survived, none of it intended for publication. Aristotle has been depicted by major artists including Raphael and Rembrandt. Early Modern theories including William Harvey's circulation of the blood and Galileo Galilei's kinematics were developed in reaction to Aristotle's. In the 19th century, George Boole gave Aristotle's logic a mathematical foundation with his system of algebraic logic. In the 20th century, Martin Heidegger created a new interpretation of Aristotle's political philosophy, but elsewhere Aristotle was widely criticised, even ridiculed by thinkers such as the philosopher Bertrand Russell and the biologist Peter Medawar. More recently, Aristotle has again been taken seriously, such as in the thinking of Ayn Rand and Alasdair MacIntyre, while Armand Marie Leroi has reconstructed Aristotle's biology. The image of Aristotle tutoring the young Alexander remains current, and the "Poetics" continues to play a role in the cinema of the United States

In general, the details of Aristotle's life are not well-established. The biographies written in ancient times are often speculative and historians only agree on a few salient points.

Aristotle, whose name means "the best purpose" in Ancient Greek, was born in 384 BC in Stagira, Chalcidice, about 55 km (34 miles) east of modern-day Thessaloniki. His father Nicomachus was the personal physician to King Amyntas of Macedon. Both of Aristotle's parents died when he was about thirteen, and Proxenus of Atarneus became his guardian. Although little information about Aristotle's childhood has survived, he probably spent some time within the Macedonian palace, making his first connections with the Macedonian monarchy.

At the age of seventeen or eighteen, Aristotle moved to Athens to continue his education at Plato's Academy. He remained there for nearly twenty years before leaving Athens in 348/47 BC. The traditional story about his departure records that he was disappointed with the Academy's direction after control passed to Plato's nephew Speusippus, although it is possible that he feared the anti-Macedonian sentiments in Athens at that time and left before Plato died. Aristotle then accompanied Xenocrates to the court of his friend Hermias of Atarneus in Asia Minor. After the death of Hermias, Aristotle travelled with his pupil Theophrastus to the island of Lesbos, where together they researched the botany and zoology of the island and its sheltered lagoon. While in Lesbos, Aristotle married Pythias, either Hermias's adoptive daughter or niece. She bore him a daughter, whom they also named Pythias. In 343 BC, Aristotle was invited by Philip II of Macedon to become the tutor to his son Alexander

Aristotle was appointed as the head of the royal academy of Macedon. During Aristotle's time in the Macedonian court, he gave lessons not only to Alexander, but also to two other future kings: Ptolemy and Cassander. Aristotle encouraged Alexander toward eastern conquest and Aristotle's own attitude towards Persia was unabashedly ethnocentric. In one famous example, he counsels Alexander to be "a leader to the Greeks and a despot to the barbarians, to look after the former as after friends and relatives, and to deal with the latter as with beasts or plants". By 335 BC, Aristotle had returned to Athens, establishing his own school there known as the Lyceum. Aristotle conducted courses at the school for the next twelve years. While in Athens, his wife Pythias died and Aristotle became involved with Herpyllis of Stagira, who bore him a son whom he named after his father, Nicomachus. According to the "Suda", he also had an "erômenos", Palaephatus of Abydus.

This period in Athens, between 335 and 323 BC, is when Aristotle is believed to have composed many of his works. He wrote many dialogues, of which only fragments have survived. Those works that have survived are in treatise form and were not, for the most part, intended for widespread publication; they are generally thought to be lecture aids for his students. His most important treatises include "Physics", "Metaphysics", "Nicomachean Ethics", "Politics", "On the Soul" and "Poetics". Aristotle studied and made significant contributions to "logic, metaphysics, mathematics, physics, biology, botany, ethics, politics, agriculture, medicine, dance and theatre."

Near the end of his life, Alexander and Aristotle became estranged over Alexander's relationship with Persia and Persians. A widespread tradition in antiquity suspected Aristotle of playing a role in Alexander's death, but the only evidence of this is an unlikely claim made some six years after the death. Following Alexander's death, anti-Macedonian sentiment in Athens was rekindled. In 322 BC, Demophilus and Eurymedon the Hierophant reportedly denounced Aristotle for impiety, prompting him to flee to his mother's family estate in Chalcis, on Euboea, at which occasion he was said to have stated: "I will not allow the Athenians to sin twice against philosophy" – a reference to Athens's trial and execution of Socrates. He died on Euboea of natural causes later that same year, having named his student Antipater as his chief executor and leaving a will in which he asked to be buried next to his wife.

With the "Prior Analytics", Aristotle is credited with the earliest study of formal logic, and his conception of it was the dominant form of Western logic until 19th-century advances in mathematical logic. Kant stated in the "Critique of Pure Reason" that with Aristotle logic reached its completion.

What we today call "Aristotelian logic" with its types of syllogism (methods of logical argument), Aristotle himself would have labelled "analytics". The term "logic" he reserved to mean "dialectics". Most of Aristotle's work is probably not in its original form, because it was most likely edited by students and later lecturers. The logical works of Aristotle were compiled into a set of six books called the "Organon" around 40 BC by Andronicus of Rhodes

Like his teacher Plato, Aristotle's philosophy aims at the universal. Aristotle's ontology places the universal ("katholou") in particulars ("kath' hekaston"), things in the world, whereas for Plato the universal is a separately existing form which actual things imitate. This means that Aristotle's epistemology is based on the study of things that exist or happen in the world, and rises to knowledge of the universal, whereas for Plato epistemology begins with knowledge of universal Forms (or ideas) and descends to knowledge of particular imitations of these. For Aristotle, "form" is still what phenomena are based on, but is "instantiated" in a particular substance. Aristotle uses induction from examples alongside deduction, whereas Plato relies on deduction from "a priori" principles.

In Aristotle's terminology, "natural philosophy" is a branch of philosophy examining the phenomena of the natural world, and includes fields that would be regarded today as physics, biology and other natural sciences. Aristotle's work encompassed virtually all facets of intellectual inquiry. Aristotle makes philosophy in the broad sense coextensive with reasoning, which he also would describe as "science". Note, however, that his use of the term "science" carries a different meaning than that covered by the term "scientific method". For Aristotle, "all science ("dianoia") is either practical, poetical or theoretical" ("Metaphysics" 1025b25). His practical science includes ethics and politics; his poetical science means the study of fine arts including poetry; his theoretical science covers physics, mathematics and metaphysics.

The word "metaphysics" appears to have been coined by the first century AD editor who assembled various small selections of Aristotle's works to the treatise we know by the name "Metaphysics". Aristotle called it "first philosophy", and distinguished it from mathematics and natural science (physics) as the contemplative ("theoretikē") philosophy which is "theological" and studies the divine. He wrote in his "Metaphysics" (1026a16):

Aristotle examines the concepts of substance ("ousia") and essence ("to ti ên einai", "the what it was to be") in his "Metaphysics" (Book VII), and he concludes that a particular substance is a combination of both matter and form, a philosophical theory called hylomorphism. In Book VIII, he distinguishes the matter of the substance as the substratum, or the stuff of which it is composed. For example, the matter of a house is the bricks, stones, timbers etc., or whatever constitutes the "potential" house, while the form of the substance is the "actual" house, namely 'covering for bodies and chattels' or any other differentia that let us define something as a house. The formula that gives the components is the account of the matter, and the formula that gives the differentia is the account of the form.

With regard to the change ("kinesis") and its causes now, as he defines in his "Physics" and "On Generation and Corruption

The coming to be is a change where nothing persists of which the resultant is a property. In that particular change he introduces the concept of potentiality ("dynamis") and actuality ("entelecheia") in association with the matter and the form. Referring to potentiality, this is what a thing is capable of doing, or being acted upon, if the conditions are right and it is not prevented by something else. For example, the seed of a plant in the soil is potentially ("dynamei") plant, and if it is not prevented by something, it will become a plant. Potentially beings can either 'act' ("poiein") or 'be acted upon' ("paschein"), which can be either innate or learned. For example, the eyes possess the potentiality of sight (innate – being acted upon), while the capability of playing the flute can be possessed by learning (exercise – acting). Actuality is the fulfilment of the end of the potentiality. Because the end ("telos") is the principle of every change, and for the sake of the end exists potentiality, therefore actuality is the end. Referring then to our previous example, we could say that an actuality is when a plant does one of the activities that plants do.

In summary, the matter used to make a house has potentiality to be a house and both the activity of building and the form of the final house are actualities, which is also a final cause or end. Then Aristotle proceeds and concludes that the actuality is prior to potentiality in formula, in time and in substantiality. With this definition of the particular substance (i.e., matter and form), Aristotle tries to solve the problem of the unity of the beings, for example, "what is it that makes a man one"? Since, according to Plato
Plato argued that all things have a universal form
In his "On Generation and Corruption", Aristotle related each of the four elements proposed earlier by Empedocles, Earth, Water, Air, and Fire, to two of the four sensible qualities, hot, cold, wet, and dry. In the Empedoclean scheme, all matter was made of the four elements, in differing proportions. Aristotle's scheme added the heavenly Aether, the divine substance of the heavenly spheres, stars and planets.

Aristotle describes two kinds of motion: "violent" or "unnatural motion", such as that of a thrown stone, in the "Physics" (254b10), and "natural motion", such as of a falling object, in "On the Heavens" (300a20). In violent motion, as soon as the agent stops causing it, the motion stops also; in other words, the natural state of an object is to be at rest, since Aristotle does not address friction

In the "Physics" (215a25), Aristotle effectively states a quantitative law, that the speed, v, of a falling body is proportional (say, with constant c) to its weight, W, and inversely proportional to the density, ρ, of the fluid in which it is falling:

Aristotle implies that in a vacuum the speed of fall would become infinite, and concludes from this apparent absurdity that a vacuum is not possible. Opinions have varied on whether Aristotle intended to state quantitative laws. Henri Carteron held the "extreme view" that Aristotle's concept of force was basically qualitative, but other authors reject this.

Archimedes corrected Aristotle's theory that bodies move towards their natural resting places; metal boats can float if they displace enough water; floating depends in Archimedes' scheme on the mass and volume of the object, not as Aristotle thought its elementary composition.

Aristotle's writings on motion remained influential until the Early Modern period. John Philoponus (in the Middle Ages) and Galileo are said to have shown by experiment that Aristotle's claim that a heavier object falls faster than a lighter object is incorrect. A contrary opinion is given by Carlo Rovelli, who argues that Aristotle's physics of motion is correct within its domain of validity, that of objects in the Earth's gravitational field immersed in a fluid such as air. In this system, heavy bodies in steady fall indeed travel faster than light ones (whether friction is ignored, or not), and they do fall more slowly in a denser medium.

Newton's "forced" motion corresponds to Aristotle's "violent" motion with its external agent, but Aristotle's assumption that the agent's effect stops immediately it stops acting (e.g., the ball leaves the thrower's hand) has awkward consequences: he has to suppose that surrounding fluid helps to push the ball along to make it continue to rise even though the hand is no longer acting on it, resulting in the Medieval theory of impetus

Aristotle suggested that the reason for anything coming about can be attributed to four different types of simultaneously active factors. His term "aitia" is traditionally translated as "cause", but it does not always refer to temporal sequence; it might be better translated as "explanation", but the traditional rendering will be employed here.

Aristotle describes experiments in optics using a camera obscura in "Problems", book 15. The apparatus consisted of a dark chamber with a small aperture that let light in. With it, he saw that whatever shape he made the hole, the sun's image always remained circular. He also noted that increasing the distance between the aperture and the image surface magnified the image.

According to Aristotle, spontaneity and chance are causes of some things, distinguishable from other types of cause such as simple necessity. Chance as an incidental cause lies in the realm of accidental things, "from what is spontaneous". There is also more a specific kind of chance, which Aristotle names "luck", that only applies to people's moral choices.

In astronomy, Aristotle refuted Democritus's claim that the Milky Way

Aristotle was one of the first people to record any geological observations. He stated that geological change was too slow to be observed in one person's lifetime.
The geologist Charles Lyell noted that Aristotle described such change, including "lakes that had dried up" and "deserts that had become watered by rivers", giving as examples the growth of the Nile delta since the time of Homer, and "the upheaving of one of the Aeolian islands, previous to a volcanic eruption

Aristotle was the first person to study biology systematically, and biology forms a large part of his writings. He spent two years observing and describing the zoology of Lesbos and the surrounding seas, including in particular the Pyrrha lagoon in the centre of Lesbos. His data in "History of Animals", "Generation of Animals", "Movement of Animals", and "Parts of Animals" are assembled from his own observations, statements given by people with specialised knowledge such as beekeepers and fishermen, and less accurate accounts provided by travellers from overseas. His apparent emphasis on animals rather than plants is a historical accident: his works on botany have been lost, but two books on plants by his pupil Theophrastus have survived.

Aristotle reports on the sea-life visible from observation on Lesbos and the catches of fishermen. He describes the catfish, electric ray, and frogfish in detail, as well as cephalopods such as the octopus and paper nautilus. His description of the hectocotyl arm of cephalopods, used in sexual reproduction, was widely disbelieved until the 19th century. He gives accurate descriptions of the four-chambered fore-stomachs of ruminants, and of the ovoviviparous embryological development of the hound shark.

He notes that an animal's structure is well matched to function, so, among birds, the heron, which lives in marshes with soft mud and lives by catching fish, has a long neck and long legs, and a sharp spear-like beak, whereas ducks that swim have short legs and webbed feet. Darwin, too, noted these sorts of differences between similar kinds of animal, but unlike Aristotle used the data to come to the theory of evolution. Aristotle's writings can seem to modern readers close to implying evolution, but while Aristotle was aware that new mutations or hybridisations could occur, he saw these as rare accidents. For Aristotle, accidents, like heat waves in winter, must be considered distinct from natural causes. He was thus critical of Empedocles's materialist theory of a "survival of the fittest" origin of living things and their organs, and ridiculed the idea that accidents could lead to orderly results. To put his views into modern terms, he nowhere says that different species can have a common ancestor, or that one kind can change into another, or that kinds can become extinct

Aristotle did not do experiments in the modern sense. He used the ancient Greek term "pepeiramenoi" to mean observations, or at most investigative procedures like dissection. In "Generation of Animals", he finds a fertilised hen's egg of a suitable stage and opens it to see the embryo's heart beating inside.

Instead, he practised a different style of science: systematically gathering data, discovering patterns common to whole groups of animals, and inferring possible causal explanations from these. This style is common in modern biology when large amounts of data become available in a new field, such as genomics. It does not result in the same certainty as experimental science, but it sets out testable hypotheses and constructs a narrative explanation of what is observed. In this sense, Aristotle's biology is scientific.

From the data he collected and documented, Aristotle inferred quite a number of rules relating the life-history features of the live-bearing tetrapods (terrestrial placental mammals) that he studied. Among these correct predictions are the following. Brood size decreases with (adult) body mass, so that an elephant has fewer young (usually just one) per brood than a mouse. Lifespan increases with gestation period, and also with body mass, so that elephants live longer than mice, have a longer period of gestation, and are heavier. As a final example, fecundity

Aristotle distinguished about 500 species of animals, arranging these in the "History of Animals" in a graded scale of perfection, a "scala naturae", with man at the top. His system had eleven grades of animal, from highest potential to lowest, expressed in their form at birth: the highest gave live birth to hot and wet creatures, the lowest laid cold, dry mineral-like eggs. Animals came above plants, and these in turn were above minerals. see also: He grouped what the modern zoologist would call vertebrates as the hotter "animals with blood", and below them the colder invertebrates as "animals without blood". Those with blood were divided into the live-bearing (mammals), and the egg-laying (birds, reptiles, fish). Those without blood were insects, crustacea (non-shelled – cephalopods, and shelled) and the hard-shelled molluscs (bivalves and gastropods). He recognised that animals did not exactly fit into a linear scale, and noted various exceptions, such as that sharks had a placenta like the tetrapods. To a modern biologist, the explanation, not available to Aristotle, is convergent evolution. He believed that purposive final causes guided all natural processes; this teleological

Aristotle's psychology, given in his treatise "On the Soul" ("peri psychēs"), posits three kinds of soul ("psyches"): the vegetative soul, the sensitive soul, and the rational soul. Humans have a rational soul. The human soul incorporates the powers of the other kinds: Like the vegetative soul it can grow and nourish itself; like the sensitive soul it can experience sensations and move locally. The unique part of the human, rational soul is its ability to receive forms of other things and to compare them using the "nous" (intellect) and "logos" (reason).

For Aristotle, the soul is the form of a living being. Because all beings are composites of form and matter, the form of living beings is that which endows them with what is specific to living beings, e.g. the ability to initiate movement (or in the case of plants, growth and chemical transformations, which Aristotle considers types of movement). In contrast to earlier philosophers, but in accordance with the Egyptians, he placed the rational soul in the heart, rather than the brain. Notable is Aristotle's division of sensation and thought, which generally differed from the concepts of previous philosophers, with the exception of Alcmaeon) that can be recovered. Aristotle believed an impression is left on a semi-fluid bodily organ that undergoes several changes in order to make a memory. A memory occurs when stimuli such as sights or sounds are so complex that the nervous system cannot receive all the impressions at once. These changes are the same as those involved in the operations of sensation, Aristotelian 'common sense

Aristotle believed the chain of thought, which ends in recollection of certain impressions, was connected systematically in relationships such as similarity, contrast, and contiguity, described in his Laws of Association. Aristotle believed that past experiences are hidden within the mind. A force operates to awaken the hidden material to bring up the actual experience. According to Aristotle, association is the power innate in a mental state, which operates upon the unexpressed remains of former experiences, allowing them to rise and be recalled.

Aristotle describes sleep in "On Sleep and Wakefulness". Sleep takes place as a result of overuse of the senses or of digestion, so it is vital to the body. While a person is asleep, the critical activities, which include thinking, sensing, recalling and remembering, do not function as they do during wakefulness. Since a person cannot sense during sleep they can not have desire, which is the result of sensation. However, the senses are able to work during sleep, albeit differently, unless they are weary.

Dreams do not involve actually sensing a stimulus. In dreams, sensation is still involved, but in an altered manner. Aristotle explains that when a person stares at a moving stimulus such as the waves in a body of water, and then look away, the next thing they look at appears to have a wavelike motion. When a person perceives a stimulus and the stimulus is no longer the focus of their attention, it leaves an impression. When the body is awake and the senses are functioning properly, a person constantly encounters new stimuli to sense and so the impressions of previously perceived stimuli are ignored. However, during sleep the impressions made throughout the day are noticed as there are no new distracting sensory experiences. So, dreams result from these lasting impressions. Since impressions are all that are left and not the exact stimuli, dreams do not resemble the actual waking experience. During sleep, a person is in an altered state of mind. Aristotle compares a sleeping person to a person who is overtaken by strong feelings toward a stimulus. For example, a person who has a strong infatuation with someone may begin to think they see that person everywhere because they are so overtaken by their feelings. Since a person sleeping is in a suggestible state and unable to make judgements, they become easily deceived by what appears in their dreams, like the infatuated person. This leads the person to believe the dream is real, even when the dreams are absurd in nature.

One component of Aristotle's theory of dreams disagrees with previously held beliefs. He claimed that dreams are not foretelling and not sent by a divine being. Aristotle reasoned naturalistically that instances in which dreams do resemble future events are simply coincidences. Aristotle claimed that a dream is first established by the fact that the person is asleep when they experience it. If a person had an image appear for a moment after waking up or if they see something in the dark it is not considered a dream because they were awake when it occurred. Secondly, any sensory experience that is perceived while a person is asleep does not qualify as part of a dream. For example, if, while a person is sleeping, a door shuts and in their dream they hear a door is shut, this sensory experience is not part of the dream. Lastly, the images of dreams must be a result of lasting impressions of waking sensory experiences.

Aristotle's practical philosophy covers areas such as ethics, politics, economics, and rhetoric.

Aristotelian just war theory is not well regarded in the present day, especially his view that warfare was justified to ensalve "natural slaves". In Aristotelian philosophy, the abolition of what he considers "natural slavery" would undermine civic freedom. The pusuit of freedom is inseperable from pursuing mastery over "those who deserve to be slaves". According to "The Cambridge Companion to Aristotle's Politics" the targets of this aggresive warfare were non-Greeks, noting Aristotle's view that "our poets say 'it is proper for Greeks to rule non-Greeks'".

Aristotle generally has a favorable opinion of war, extolling it as a chance for virtue and writing that "the leisure that accompanies peace" tends to make people "arrogant". War to "avoid becoming enslaved to others" is justified as self-defense. He writes that war "compels people to be just and temperate", however, in order to be just "war must be chosen for the sake of peace" (with the exception of wars of aggression discussed above).

Aristotle considered ethics to be a practical rather than theoretical study, i.e., one aimed at becoming good and doing good rather than knowing for its own sake. He wrote several treatises on ethics, including most notably, the "Nicomachean Ethics".

Aristotle taught that virtue has to do with the proper function ("ergon") of a thing. An eye is only a good eye in so much as it can see, because the proper function of an eye is sight. Aristotle reasoned that humans must have a function specific to humans, and that this function must be an activity of the "psuchē" ("soul") in accordance with reason ("logos"). Aristotle identified such an optimum activity (the virtuous mean, between the accompanying vices of excess or deficiency) of the soul as the aim of all human deliberate action, "eudaimonia", generally translated as "happiness" or sometimes "well being". To have the potential of ever being happy in this way necessarily requires a good character ("ēthikē" "aretē"), often translated as moral or ethical virtue or excellence.

Aristotle taught that to achieve a virtuous and potentially happy character requires a first stage of having the fortune to be habituated not deliberately, but by teachers, and experience, leading to a later stage in which one consciously chooses to do the best things. When the best people come to live life this way their practical wisdom ("phronesis") and their intellect ("nous") can develop with each other towards the highest possible human virtue, the wisdom of an accomplished theoretical or speculative thinker, or in other words, a philosopher.

In addition to his works on ethics, which address the individual, Aristotle addressed the city in his work titled "Politics

The common modern understanding of a political community as a modern state is quite different from Aristotle's understanding. Although he was aware of the existence and potential of larger empires, the natural community according to Aristotle was the city ("polis") which functions as a political "community" or "partnership" ("koinōnia"). The aim of the city is not just to avoid injustice or for economic stability, but rather to allow at least some citizens the possibility to live a good life, and to perform beautiful acts: "The political partnership must be regarded, therefore, as being for the sake of noble actions, not for the sake of living together." This is distinguished from modern approaches, beginning with social contract theory, according to which individuals leave the state of nature because of "fear of violent death" or its "inconveniences."

In "Protrepticus", the character 'Aristotle' states:

Aristotle made substantial contributions to economic thought, especially to thought in the Middle Ages. In "Politics", Aristotle addresses the city, property, and trade. His response to criticisms of private property, in Lionel Robbins's view, anticipated later proponents of private property among philosophers and economists, as it related to the overall utility of social arrangements. Aristotle believed that although communal arrangements may seem beneficial to society, and that although private property is often blamed for social strife, such evils in fact come from human nature. In "Politics", Aristotle offers one of the earliest accounts of the origin of money. Money came into use because people became dependent on one another, importing what they needed and exporting the surplus. For the sake of convenience, people then agreed to deal in something that is intrinsically useful and easily applicable, such as iron or silver.

Aristotle's discussions on retail and interest was a major influence on economic thought in the Middle Ages. He had a low opinion of retail, believing that contrary to using money to procure things one needs in managing the household, retail trade seeks to make a profit
Aristotle's "Rhetoric" proposes that a speaker can use three basic kinds of appeals to persuade his audience: "ethos" (an appeal to the speaker's character), "pathos" (an appeal to the audience's emotion), and "logos" (an appeal to logical reasoning). He also categorises rhetoric into three genres: epideictic (ceremonial speeches dealing with praise or blame), forensic (judicial speeches over guilt or innocence), and deliberative (speeches calling on an audience to make a decision on an issue). Aristotle also outlines two kinds of rhetorical proofs: "enthymeme" (proof by syllogism) and "paradeigma" (proof by example).

Aristotle writes in his "Poetics" that epic poetry, tragedy, comedy, dithyrambic poetry, painting, sculpture, music, and dance are all fundamentally acts of "mimesis" ("imitation"), each varying in imitation by medium, object, and manner. He applies the term "mimesis" both as a property of a work of art and also as the product of the artist's intention and contends that the audience's realisation of the "mimesis" is vital to understanding the work itself. Aristotle states that "mimesis" is a natural instinct of humanity that separates humans from animals and that all human artistry "follows the pattern of nature". Because of this, Aristotle believed that each of the mimetic arts possesses what Stephen Halliwell calls "highly structured procedures for the achievement of their purposes." For example, music imitates with the media of rhythm and harmony, whereas dance imitates with rhythm alone, and poetry with language. The forms also differ in their object of imitation. Comedy, for instance, is a dramatic imitation of men worse than average; whereas tragedy imitates men slightly better than average. Lastly, the forms differ in their manner of imitation – through narrative or character, through change or no change, and through drama or no drama.

While it is believed that Aristotle's "Poetics" originally comprised two books – one on comedy and one on tragedy – only the portion that focuses on tragedy has survived. Aristotle taught that tragedy is composed of six elements: plot-structure, character, style, thought, spectacle, and lyric poetry. The characters in a tragedy are merely a means of driving the story; and the plot, not the characters, is the chief focus of tragedy. Tragedy is the imitation of action arousing pity and fear, and is meant to effect the catharsis of those same emotions. Aristotle concludes "Poetics" with a discussion on which, if either, is superior: epic or tragic mimesis. He suggests that because tragedy possesses all the attributes of an epic, possibly possesses additional attributes such as spectacle and music, is more unified, and achieves the aim of its mimesis in shorter scope, it can be considered superior to epic. Aristotle was a keen systematic collector of riddles, folklore, and proverbs; he and his school had a special interest in the riddles of the Delphic Oracle and studied the fables of Aesop.

Aristotle's analysis of procreation describes an active, ensouling masculine element bringing life to an inert, passive female element. On this ground, proponents of feminist metaphysics have accused Aristotle of misogyny and sexism. However, Aristotle gave equal weight to women's happiness as he did to men's, and commented in his "Rhetoric" that the things that lead to happiness need to be in women as well as men.

More than 2300 years after his death, Aristotle remains one of the most influential people who ever lived. He contributed to almost every field of human knowledge then in existence, and he was the founder of many new fields. According to the philosopher Bryan Magee, "it is doubtful whether any human being has ever known as much as he did". Among countless other achievements, Aristotle was the founder of formal logic, pioneered the study of zoology, and left every future scientist and philosopher in his debt through his contributions to the scientific method. Taneli Kukkonen, writing in "The Classical Tradition", observes that his achievement in founding two sciences is unmatched, and his reach in influencing "every branch of intellectual enterprise" including Western ethical and political theory, theology, rhetoric and literary analysis is equally long. As a result, Kukkonen argues, any analysis of reality today "will almost certainly carry Aristotelian overtones ... evidence of an exceptionally forceful mind." Jonathan Barnes

Aristotle's pupil and successor, Theophrastus, wrote the "History of Plants", a pioneering work in botany. Some of his technical terms remain in use, such as carpel from "carpos", fruit, and pericarp, from "pericarpion", seed chamber.
Theophrastus was much less concerned with formal causes than Aristotle was, instead pragmatically describing how plants functioned.

The immediate influence of Aristotle's work was felt as the Lyceum grew into the Peripatetic school. Aristotle's notable students included Aristoxenus, Dicaearchus, Demetrius of Phalerum, Eudemos of Rhodes, Harpalus, Hephaestion, Mnason of Phocis, Nicomachus, and Theophrastus. Aristotle's influence over Alexander the Great is seen in the latter's bringing with him on his expedition a host of zoologists, botanists, and researchers. He had also learned a great deal about Persian customs and traditions from his teacher. Although his respect for Aristotle was diminished as his travels made it clear that much of Aristotle's geography was clearly wrong, when the old philosopher released his works to the public, Alexander complained "Thou hast not done well to publish thy acroamatic doctrines; for in what shall I surpass other men if those doctrines wherein I have been trained are to be all men's common property?"

After Theophrastus, the Lyceum failed to produce any original work. Though interest in Aristotle's ideas survived, they were generally taken unquestioningly. It is not until the age of Alexandria under the Ptolemies that advances in biology can be again found.

The first medical teacher at Alexandria, Herophilus of Chalcedon, corrected Aristotle, placing intelligence in the brain, and connected the nervous system to motion and sensation. Herophilus also distinguished between veins and arteries, noting that the latter pulse while the former do not. Though a few ancient atomists such as Lucretius challenged the teleological viewpoint of Aristotelian ideas about life, teleology (and after the rise of Christianity, natural theology) would remain central to biological thought essentially until the 18th and 19th centuries. Ernst Mayr states that there was "nothing of any real consequence in biology after Lucretius and Galen until the Renaissance."

Greek Christian scribes played a crucial role in the preservation of Aristotle by copying all the extant Greek language manuscripts of the corpus. The first Greek Christians to comment extensively on Aristotle were Philoponus, Elias, and David in the sixth century, and Stephen of Alexandria in the early seventh century. John Philoponus stands out for having attempted a fundamental critique of Aristotle's views on the eternity of the world, movement, and other elements of Aristotelian thought. Philoponus questioned Aristotle's teaching of physics, noting its flaws and introducing the theory of impetus to explain his observations.

After a hiatus of several centuries, formal commentary by Eustratius and Michael of Ephesus reappeared in the late eleventh and early twelfth centuries, apparently sponsored by Anna Comnena

Aristotle was one of the most revered Western thinkers in early Islamic theology. Most of the still extant works of Aristotle, as well as a number of the original Greek commentaries, were translated into Arabic and studied by Muslim philosophers, scientists and scholars. Averroes, Avicenna and Alpharabius, who wrote on Aristotle in great depth, also influenced Thomas Aquinas and other Western Christian scholastic philosophers. Alkindus greatly admired Aristotle's philosophy, and Averroes spoke of Aristotle as the "exemplar" for all future philosophers. Medieval Muslim scholars regularly described Aristotle as the "First Teacher". The title "teacher" was first given to Aristotle by Muslim scholars, and was later used by Western philosophers (as in the famous poem of Dante) who were influenced by the tradition of Islamic philosophy
With the loss of the study of ancient Greek in the early medieval Latin West, Aristotle was practically unknown there from c. AD 600 to c. 1100 except through the Latin translation of the "Organon" made by Boethius. In the twelfth and thirteenth centuries, interest in Aristotle revived and Latin Christians had translations made, both from Arabic translations, such as those by Gerard of Cremona, and from the original Greek, such as those by James of Venice and William of Moerbeke. After the Scholastic Thomas Aquinas wrote his "Summa Theologica", working from Moerbeke's translations and calling Aristotle "The Philosopher", the demand for Aristotle's writings grew, and the Greek manuscripts returned to the West, stimulating a revival of Aristotelianism in Europe that continued into the Renaissance. These thinkers blended Aristotelian philosophy with Christianity, bringing the thought of Ancient Greece into the Middle Ages. Scholars such as Boethius, Peter Abelard, and John Buridan worked on Aristotelian logic.

The medieval English poet Chaucer describes his student as being happy by having

A cautionary medieval tale held that Aristotle advised his pupil Alexander to avoid the king's seductive mistress, Phyllis, but was himself captivated by her, and allowed her to ride him. Phyllis had secretly told Alexander what to expect, and he witnessed Phyllis proving that a woman's charms could overcome even the greatest philosopher's male intellect. Artists such as Hans Baldung produced a series of illustrations of the popular theme.

The Italian poet Dante says of Aristotle in "The Divine Comedy

In the Early Modern period, scientists such as William Harvey in England and Galileo Galilei in Italy reacted against the theories of Aristotle and other classical era thinkers like Galen, establishing new theories based to some degree on observation and experiment. Harvey demonstrated the circulation of the blood, establishing that the heart functioned as a pump rather than being the seat of the soul and the controller of the body's heat, as Aristotle thought. Galileo used more doubtful arguments to displace Aristotle's physics, proposing that bodies all fall at the same speed whatever their weight.

The 19th-century German philosopher Friedrich Nietzsche has been said to have taken nearly all of his political philosophy from Aristotle. Aristotle rigidly separated action from production, and argued for the deserved subservience of some people ("natural slaves"), and the natural superiority (virtue, "arete") of others. It was Martin Heidegger, not Nietzsche, who elaborated a new interpretation of Aristotle, intended to warrant his deconstruction of scholastic and philosophical tradition.

The English mathematician George Boole fully accepted Aristotle's logic, but decided "to go under, over, and beyond" it with his system of algebraic logic in his 1854 book "The Laws of Thought". This gives logic a mathematical foundation with equations, enables it to solve equations as well as check validity

During the 20th century, Aristotle's work was widely criticised. The philosopher Bertrand Russell
argued that "almost every serious intellectual advance has had to begin with an attack on some Aristotelian doctrine". Russell called Aristotle's ethics "repulsive", and labelled his logic "as definitely antiquated as Ptolemaic astronomy". Russell stated that these errors made it difficult to do historical justice to Aristotle, until one remembered what an advance he made upon all of his predecessors.

The Dutch historian of science Eduard Jan Dijksterhuis wrote that Aristotle and his predecessors showed the difficulty of science by "proceed[ing] so readily to frame a theory of such a general character" on limited evidence from their senses. In 1985, the biologist Peter Medawar could still state in "pure seventeenth century" tones that Aristotle had assembled "a strange and generally speaking rather tiresome farrago of hearsay, imperfect observation, wishful thinking and credulity amounting to downright gullibility".

By the start of the 21st century, however, Aristotle was taken more seriously: Kukkonen noted that "In the best 20th-century scholarship Aristotle comes alive as a thinker wrestling with the full weight of the Greek philosophical tradition." Ayn Rand accredited Aristotle as "the greatest philosopher in history" and cited him as a major influence on her thinking. More recently, Alasdair MacIntyre has attempted to reform what he calls the Aristotelian tradition in a way that is anti-elitist and capable of disputing the claims of both liberals and Nietzscheans. Kukkonen observed, too, that "that most enduring of romantic images, Aristotle tutoring the future conqueror Alexander" remained current, as in the 2004 film "Alexander", while the "firm rules" of Aristotle's theory of drama have ensured a role for the "Poetics" in Hollywood.

Biologists continue to be interested in Aristotle's thinking. Armand Marie Leroi has reconstructed Aristotle's biology, while Niko Tinbergen's four questions, based on Aristotle's four causes, are used to analyse animal behaviour; they examine function, phylogeny, mechanism, and ontogeny

The works of Aristotle that have survived from antiquity through medieval manuscript transmission are collected in the Corpus Aristotelicum. These texts, as opposed to Aristotle's lost works, are technical philosophical treatises from within Aristotle's school. Reference to them is made according to the organisation of Immanuel Bekker's Royal Prussian Academy edition ("Aristotelis Opera edidit Academia Regia Borussica", Berlin, 1831–1870), which in turn is based on ancient classifications of these works.

Aristotle wrote his works on papyrus scrolls, the common writing medium of that era. His writings are divisible into two groups: the "exoteric", intended for the public, and the "esoteric", for use within the Lyceum school. Aristotle's "lost" works stray considerably in characterisation from the surviving Aristotelian corpus. Whereas the lost works appear to have been originally written with a view to subsequent publication, the surviving works mostly resemble lecture notes not intended for publication. Cicero's description of Aristotle's literary style as "a river of gold" must have applied to the published works, not the surviving notes. A major question in the history of Aristotle's works is how the exoteric writings were all lost, and how the ones we now possess came to us. The consensus is that Andronicus of Rhodes collected the esoteric works of Aristotle's school which existed in the form of smaller, separate works, distinguished them from those of Theophrastus and other Peripatetics, edited them, and finally compiled them into the more cohesive, larger works as they are known today.

Aristotle has been depicted by major artists including Lucas Cranach the Elder, Justus van Gent, Raphael, Paolo Veronese, Jusepe de Ribera, Rembrandt, and Francesco Hayez over the centuries. Among the best-known is Raphael's fresco "The School of Athens", in the Vatican's Apostolic Palace, where the figures of Plato and Aristotle are central to the image, at the architectural vanishing point, reflecting their importance. Rembrandt's "Aristotle with a Bust of Homer", too, is a celebrated work, showing the knowing philosopher and the blind Homer from an earlier age: as the art critic Jonathan Jones writes, "this painting will remain one of the greatest and most mysterious in the world, ensnaring us in its musty, glowing, pitch-black, terrible knowledge of time."

The Aristotle Mountains in Antarctica are named after Aristotle. He was the first person known to conjecture, in his book "Meteorology", the existence of a landmass in the southern high-latitude region and called it "Antarctica". Aristoteles
Category:384 BC births
Category:322 BC deaths
Category:4th-century BC births
Category:4th-century BC deaths
Category:4th-century BC philosophers
Category:4th-century BC writers
Category:Academic philosophers
Category:Acting theorists
Category:Ancient Greek biologists
Category:Ancient Greek epistemologists
Category:Ancient Greek ethicists
Category:Ancient Greek logicians
Category:Ancient Greek mathematicians
Category:Ancient Greek metaphilosophers
Category:Ancient Greek metaphysicians
Category:Ancient Greek philosophers of language
Category:Ancient Greek philosophers of mind
Category:Ancient Greek political philosophers
Category:Ancient Greek physicists
Category:Ancient Greeks in Macedon
Category:Ancient literary critics
Category:Ancient Stagirites
Category:Aristotelian philosophers
Category:Aristotelianism
Category:Attic Greek writers
Category:Cosmologists
Category:Cultural critics
Category:Empiricists
Category:Epistemologists
Category:Giftedness
Category:Greek male writers
Category:Greek meteorologists
Category:Humor researchers
Category:Irony theorists
Category:Logic
Category:Logicians
Category:Metaphilosophers
Category:Metaphysicians
Category:Metic philosophers in Classical Athens
Category:Moral philosophers
Category:Natural philosophers
Category:Peripatetic philosophers
Category:Philosophers and tutors of Alexander the Great
Category:Philosophers of ancient Chalcidice
Category:Philosophers of art
Category:Philosophers of culture
Category:Philosophers of education
Category:Philosophers of ethics and morality
Category:Philosophers of law
Category:Philosophers of literature
Category:Philosophers of logic
Category:Philosophers of love
Category:Philosophers of mind
Category:Philosophers of science
Category:Philosophers of technology
Category:Philosophical logic
Category:Philosophy academics
Category:Philosophy writers
Category:Political philosophers
Category:Rhetoric theorists
Category:Social commentators
Category:Social critics
Category:Social philosophers
Category:Trope theorists
Category:Virtue
Category:Virtue ethicists
Category:Virtue ethics
Category:Western culture
Category:Western philosophy
Category:ZoologistsAn American in Paris

An American in Paris is a jazz-influenced orchestral piece by American composer George Gershwin written in 1928. It was inspired by the time that Gershwin had spent in Paris and evokes the sights and energy of the French capital in the 1920s.

Gershwin composed "An American in Paris" on commission from conductor Walter Damrosch. He scored the piece for the standard instruments of the symphony orchestra plus celesta, saxophones, and automobile horns. He brought back some Parisian taxi horns for the New York premiere of the composition, which took place on December 13, 1928 in Carnegie Hall, with Damrosch conducting the New York Philharmonic. He completed the orchestration on November 18, less than four weeks before the work's premiere. He collaborated on the original program notes with critic and composer Deems Taylor.

Gershwin was attracted by Maurice Ravel's unusual chords, and Gershwin went on his first trip to Paris in 1926 ready to study with Ravel. After his initial student audition with Ravel turned into a sharing of musical theories, Ravel said he could not teach him, saying, "Why be a second-rate Ravel when you can be a first-rate Gershwin?" While the studies were cut short, that 1926 trip resulted in a piece entitled "Very Parisienne", the initial version of "An American in Paris", written as a 'thank you note' to Gershwin's hosts, Robert and Mabel Shirmer. Gershwin called it "a rhapsodic ballet"; it is written freely and in a much more modern idiom than his prior works.

Gershwin strongly encouraged Ravel to come to the United States for a tour. To this end, upon his return to New York, Gershwin joined the efforts of Ravel's friend Robert Schmitz, a pianist Ravel had met during the war, to urge Ravel to tour the U.S. Schmitz was the head of Pro Musica, promoting Franco-American musical relations, and was able to offer Ravel a $10,000 fee for the tour, an enticement Gershwin knew would be important to Ravel.
Gershwin greeted Ravel in New York in March 1928 during a party held for Ravel's birthday by Éva Gauthier. Ravel's tour reignited Gershwin's desire to return to Paris which he and his brother Ira did after meeting Ravel. Ravel's high praise of Gershwin in an introductory letter to Nadia Boulanger caused Gershwin to seriously consider taking much more time to study abroad in Paris. Yet after playing for her, she told him she could not teach him. Nadia Boulanger gave Gershwin basically the same advice she gave all of her accomplished master students: "What could I give you that you haven't already got?" This did not set Gershwin back, as his real intent abroad was to complete a new work based on Paris and perhaps a second rhapsody for piano and orchestra to follow his "Rhapsody in Blue". Paris at this time hosted many expatriate writers, among them Ezra Pound, W. B. Yeats, Ernest Hemingway; and artist Pablo Picasso.

Gershwin based "An American in Paris" on a melodic fragment called "Very Parisienne", written in 1926 on his first visit to Paris as a gift to his hosts, Robert and Mabel Schirmer. He described the piece as a "rhapsodic ballet" because it was written freely and is more modern than his previous works. Gershwin explained in "Musical America", "My purpose here is to portray the impressions of an American visitor in Paris as he strolls about the city, listens to the various street noises, and absorbs the French atmosphere."

The piece is structured into five sections, which culminate in a loose ABA format. Gershwin's first A episode introduces the two main "walking" themes in the "Allegretto grazioso" and develops a third theme in the "Subito con brio". The style of this A section is written in the typical French style of composers Claude Debussy and Les Six. This A section featured duple meter, singsong rhythms, and diatonic melodies with the sounds of oboe, English horn, and taxi horns. The B section's "Andante ma con ritmo deciso" introduces the American Blues and spasms of homesickness. The "Allegro" that follows continues to express homesickness in a faster twelve-bar blues. In the B section, Gershwin uses common time, syncopated rhythms, and bluesy melodies with the sounds of trumpet, saxophone, and snare drum. "Moderato con grazia" is the last A section that returns to the themes set in A. After recapitulating the "walking" themes, Gershwin overlays the slow blues theme from section B in the final "Grandioso".

"An American in Paris" is scored for 3 flutes (3rd doubling on piccolo), 2 oboes, English horn, 2 clarinets in B-flat, bass clarinet in B-flat, 2 bassoons, 4 horns in F, 3 trumpets in B-flat, 3 trombones, tuba, timpani, snare drum, bass drum, triangle, wood block, cymbals, low and high tom-toms, xylophone, glockenspiel, celesta, 4 taxi horns labeled as A, B, C and D with circles around them, alto saxophone/soprano saxophone, tenor saxophone/soprano saxophone/alto saxophone, baritone saxophone/soprano saxophone/alto saxophone, and strings. Although most modern audiences have heard the taxi horns using the notes A, B, C and D, it has recently come to light that Gershwin's intention was to have used the notes A, B, D, and A. It is likely that in labeling the taxi horns as A, B, C and D with circles, he may have been referring to the use of the four different horns and not the notes that they played.

The revised edition by F. Campbell-Watson calls for three saxophones, alto, tenor and baritone. In this arrangement the soprano and alto doublings have been rewritten to avoid changing instruments. In 2000, Gershwin specialist Jack Gibbons made his own restoration of the original orchestration of An American in Paris, working directly from Gershwin's original manuscript, including the restoration of Gershwin's soprano saxophone parts removed in F. Campbell-Watson's revision; Gibbons' restored orchestration of An American in Paris was performed at London's Queen Elizabeth Hall on July 9, 2000 by the City of Oxford Orchestra conducted by Levon Parikian

William Daly arranged the score for piano solo which was published by New World Music in 1929.

Gershwin did not particularly like Walter Damrosch's interpretation at the world premiere of "An American in Paris". He stated that Damrosch's sluggish, dragging tempo caused him to walk out of the hall during a matinee performance of this work. The audience, according to Edward Cushing, responded with "a demonstration of enthusiasm impressively genuine in contrast to the conventional applause which new music, good and bad, ordinarily arouses." Critics believed that "An American in Paris" was better crafted than his lukewarm Concerto in F. Some did not think it belonged in a program with classical composers César Franck, Richard Wagner, or Guillaume Lekeu on its premiere. Gershwin responded to the critics, "It's not a Beethoven Symphony, you know... It's a humorous piece, nothing solemn about it. It's not intended to draw tears. If it pleases symphony audiences as a light, jolly piece, a series of impressions musically expressed, it succeeds."

On September 22, 2013, it was announced that a musicological critical edition of the full orchestral score will be eventually released. The Gershwin family, working in conjunction with the Library of Congress and the University of Michigan, are working to make scores available to the public that represent Gershwin's true intent. It is unknown if the critical score will include the four minutes of material Gershwin later deleted from the work (such as the restatement of the blues theme after the faster 12 bar blues section), or if the score will document changes in the orchestration during Gershwin's composition process.

The score to "An American in Paris" is currently scheduled to be issued first in a series of scores to be released. The entire project may take 30 to 40 years to complete, but "An American in Paris" will be an early volume in the series.

Two urtext editions
"An American in Paris" has been frequently recorded. The first recording was made for RCA Victor in 1929 with Nathaniel Shilkret conducting the RCA Victor Symphony Orchestra, drawn from members of the Philadelphia Orchestra. Gershwin was on hand to "supervise" the recording; however, Shilkret was reported to be in charge and eventually asked the composer to leave the recording studio. Then, a little later, Shilkret discovered there was no one to play the brief celesta solo during the slow section, so he hastily asked Gershwin if he might play the solo; Gershwin said he could and so he briefly participated in the actual recording. This recording is believed to use the taxi horns in the way that Gershwin had intended using the notes A flat, B flat, a higher C and a lower D. The radio broadcast of the September 8, 1937 Hollywood Bowl George Gershwin Memorial Concert, in which "An American in Paris," also conducted by Shilkret, was second on the program, was recorded and was released in 1998 in a two-CD set. Arthur Fiedler and the Boston Pops Orchestra recorded the work for RCA Victor, including one of the first stereo recordings of the music. In 1945, Arturo Toscanini conducting the NBC Symphony Orchestra recorded the piece for RCA Victor, one of the few commercial recordings Toscanini made of music by an American composer. The Seattle Symphony also recorded a version in 1990 of Gershwin's original score, before he made numerous edits resulting in the score as we hear it today. Harry James released a version of the blues section on his 1953 album "One Night Stand," recorded live at the Aragon Ballroom in Chicago (Columbia GL 522 and CL 522).

In 1951, Metro-Goldwyn-Mayer released the musical film "An American in Paris", featuring Gene Kelly and Leslie Caron. Winning the 1951 Best Picture Oscar and numerous other awards, the film was directed by Vincente Minnelli, featured many tunes of Gershwin, and concluded with an extensive, elaborate dance sequence built around the "An American in Paris" symphonic poem (arranged for the film by Johnny Green), costing $500,000.



Category:Compositions by George Gershwin
Category:Symphonic poems
Category:Grammy Hall of Fame Award recipients
Category:1928 compositions
Category:Music about Paris
Category:Music commissioned by the New York PhilharmonicAcademy Award for Best Production Design

The Academy Award for Best Production Design recognizes achievement for art direction in film. The category's original name was Best Art Direction, but was changed to its current name in 2012 for the 85th Academy Awards. This change resulted from the Art Director's branch of the Academy of Motion Picture Arts and Sciences (AMPAS) being renamed the Designer's branch. Since 1947, the award is shared with the set decorator(s). It is awarded to the best interior design in a film.

The films below are listed with their production year (for example, the 2000 Academy Award
Category:Awards for best art directionAcademy Awards

The Academy Awards, also known as the Oscars, are a set of awards for artistic and technical merit in the film industry, given annually by the Academy of Motion Picture Arts and Sciences (AMPAS), to recognize excellence in cinematic achievements as assessed by the Academy's voting membership. The various category winners are awarded a copy of a golden statuette, officially called the "Academy Award of Merit", although more commonly referred to by its nickname "Oscar". The award was originally sculpted by George Stanley from a design sketch by Cedric Gibbons. AMPAS first presented it in 1929 at a private dinner hosted by Douglas Fairbanks in the Hollywood Roosevelt Hotel.

The Academy Awards ceremony was first broadcast on radio in 1930 and televised for the first time in 1953. It is the oldest worldwide entertainment awards ceremony and is now seen live worldwide. Its equivalents – the Emmy Awards for television, the Tony Awards for theater, and the Grammy Awards for music – are modeled after the Academy Awards.

The 91st Academy Awards ceremony, honoring the best films of 2018, was held on February 24, 2019, at the Dolby Theatre, in Los Angeles, California. The ceremony was broadcast on ABC. A total of 3,072 Oscar statuettes have been awarded from the inception of the award through the 90th ceremony.

The first Academy Awards presentation was held on 16 May 1929, at a private dinner function at the Hollywood Roosevelt Hotel with an audience of about 270 people. The post-awards party was held at the Mayfair Hotel. The cost of guest tickets for that night's ceremony was $5 ($ in dollars). Fifteen statuettes were awarded, honoring artists, directors and other participants in the film-making industry of the time, for their works during the 1927–28 period. The ceremony ran for 15 minutes.

Winners were announced to media three months earlier. That was changed for the second ceremony in 1930. Since then, for the rest of the first decade, the results were given to newspapers for publication at 11:00 pm on the night of the awards. This method was used until an occasion when the "Los Angeles Times" announced the winners before the ceremony began; as a result, the Academy has, since 1941, used a sealed envelope to reveal the name of the winners.

The first Best Actor awarded was Emil Jannings, for his performances in "The Last Command" and "The Way of All Flesh". He had to return to Europe before the ceremony, so the Academy agreed to give him the prize earlier; this made him the first Academy Award winner in history. At that time, the winners were recognized for all of their work done in a certain category during the qualifying period; for example, Jannings received the award for two movies in which he starred during that period, and Janet Gaynor later won a single Oscar for performances in three films. With the fourth ceremony, however, the system changed, and professionals were honored for a specific performance in a single film. For the first six ceremonies, the eligibility period spanned two calendar years.

At the 29th ceremony, held on 27 March 1957, the Best Foreign Language Film category was introduced. Until then, foreign-language films had been honored with the Special Achievement Award.

The 74th Academy Awards, held in 2002, presented the first Academy Award for Best Animated Feature.

Since 1973, all Academy Awards ceremonies have ended with the Academy Award for Best Picture.

Traditionally, the previous year's winner for Best Actor and Best Supporting Actor present the awards for Best Actress and Best Supporting Actress, while the previous year's winner for Best Actress and Best Supporting Actress present the awards for Best Actor and Best Supporting Actor.

The best known award is the Academy Award of Merit, more popularly known as the Oscar statuette. Made of gold-plated bronze on a black metal base, it is 13.5 in (34.3 cm) tall, weighs 8.5 lb (3.856 kg), and depicts a knight rendered in Art Deco style holding a crusader's sword standing on a reel of film with five spokes. The five spokes represent the original branches of the Academy: Actors, Writers, Directors, Producers, and Technicians.

The model for the statuette is said to be Mexican actor Emilio "El Indio" Fernández. Sculptor George Stanley (who also did the Muse Fountain at the Hollywood Bowl) sculpted Cedric Gibbons' design. The statuettes presented at the initial ceremonies were gold-plated solid bronze. Within a few years the bronze was abandoned in favor of Britannia metal, a pewter-like alloy which is then plated in copper, nickel silver, and finally, 24-karat gold. Due to a metal shortage during World War II, Oscars were made of painted plaster for three years. Following the war, the Academy invited recipients to redeem the plaster figures for gold-plated metal ones. The only addition to the Oscar since it was created is a minor streamlining of the base. The original Oscar mold was cast in 1928 at the C.W. Shumway & Sons Foundry in Batavia, Illinois, which also contributed to casting the molds for the Vince Lombardi Trophy and Emmy Award's statuettes. From 1983 to 2015, approximately 50 Oscars in a tin alloy with gold plating were made each year in Chicago by Illinois manufacturer R.S. Owens & Company. It would take between three and four weeks to manufacture 50 statuettes.
In 2016, the Academy returned to bronze as the core metal of the statuettes, handing manufacturing duties to Walden, New York-based Polich Tallix Fine Art Foundry. While based on a digital scan of an original 1929 Oscar, the statuettes retain their modern-era dimensions and black pedestal. Cast in liquid bronze from 3D-printed ceramic molds and polished, they are then electroplated in 24-karat gold by Brooklyn, New York–based Epner Technology. The time required to produce 50 such statuettes is roughly three months. R.S. Owens is expected to continue producing other awards for the Academy and service existing Oscars that need replating.

The origin of the name "Oscar" is disputed. One biography of Bette Davis, who was a president of the Academy, claims she named the award after her first husband, band leader Harmon Oscar Nelson. A frequently-mentioned originator is Margaret Herrick, the Academy executive secretary, who, when she first saw the award in 1931, said the statuette reminded her of "Uncle Oscar", a nickname for her cousin Oscar Pierce. Columnist Sidney Skolsky was present during Herrick's naming and wrote that "Employees have affectionately dubbed their famous statuette 'Oscar'." The Academy credits him with "the first confirmed newspaper reference" to "Oscar" in his March 16, 1934 column about the 6th Academy Awards that year. Another early mention appeared in a "Time" magazine story about the 1934 awards. In the ceremonies that year Walt Disney thanked the Academy for his "Oscar". The Academy officially adopted the name "Oscar" for the trophies in 1939.

To prevent information identifying the Oscar winners from leaking ahead of the ceremony, Oscar statuettes presented at the ceremony have blank baseplates. Until 2010, winners returned their statuettes to the Academy, and had to wait several weeks to have their names inscribed on their respective Oscars. Since 2010, winners have had the option of having engraved nameplates applied to their statuettes at an inscription-processing station at the Governor's Ball, a party held immediately after the Oscar ceremony. The R.S. Owens company has engraved nameplates made before the ceremony, bearing the name of every potential winner. The nameplates for the non-winning nominees are later recycled.

Since 1950, the statuettes have been legally encumbered by the requirement that neither winners nor their heirs may sell the statuettes without first offering to sell them back to the Academy for US$1. If a winner refuses to agree to this stipulation, then the Academy keeps the statuette. Academy Awards not protected by this agreement have been sold in public auctions and private deals for six-figure sums. In December 2011, Orson Welles' 1941 Oscar for "Citizen Kane" (Academy Award for Best Original Screenplay) was put up for auction, after his heirs won a 2004 court decision contending that Welles did not sign any agreement to return the statue to the Academy. On 20 December 2011, it sold in an online auction for US$861,542.

In 1992, Harold Russell needed money for his wife's medical expenses. In a controversial decision, he consigned his 1946 Oscar for Best Supporting Actor for "The Best Years of Our Lives" to Herman Darvick Autograph Auctions, and on 6 August 1992, in New York City, the Oscar sold to a private collector for $60,500. Since he won the award before 1950, he was not required to offer it to the Academy first. Russell defended his decision, saying, "I don't know why anybody would be critical. My wife's health is much more important than sentimental reasons. The movie will be here, even if Oscar isn't." Harold Russell is the only Academy Award-winning actor to ever sell an Oscar.

While the Oscar is owned by the recipient, it is essentially not on the open market. Michael Todd's grandson tried to sell Todd's Oscar statuette to a movie prop collector in 1989, but the Academy won the legal battle by getting a permanent injunction. Although some Oscar sales transactions have been successful, some buyers have subsequently returned the statuettes to the Academy, which keeps them in its treasury.

In addition to the Academy Award of Merit (Oscar award), there are nine honorary (non-competitive) awards presented by the Academy from time to time (except for the Academy Honorary Award, the Technical Achievement Award, and the Student Academy Awards, which are presented annually):

The Academy also awards Nicholl Fellowships in Screenwriting.

Since 2004, Academy Award nomination results have been announced to the public in mid-January. Prior to that, the results were announced in early February.

The Academy of Motion Picture Arts and Sciences (AMPAS), a professional honorary organization, maintains a voting membership of over 8,000 .

Academy membership is divided into different branches, with each representing a different discipline in film production. Actors constitute the largest voting bloc, numbering 1,311 members (22 percent) of the Academy's composition. Votes have been certified by the auditing firm PricewaterhouseCoopers (and its predecessor Price Waterhouse) for the past 83 annual awards ceremonies. The firm mails the ballots of eligible nominees to members of the Academy in December to reflect the previous eligible year with a due date sometime in January of the next year, then tabulates the votes in a process that takes thousands of hours.

All AMPAS members must be invited to join by the Board of Governors, on behalf of Academy Branch Executive Committees. Membership eligibility may be achieved by a competitive nomination or a member may submit a name based on other significant contributions to the field of motion pictures.

New membership proposals are considered annually. The Academy does not publicly disclose its membership, although as recently as 2007 press releases have announced the names of those who have been invited to join. The 2007 release also stated that it has just under 6,000 voting members. While the membership had been growing, stricter policies have kept its size steady since then.

In 2012, the results of a study conducted by the "Los Angeles Times" were published describing the demographic breakdown of approximately 88% of AMPAS' voting membership. Of the 5,100+ active voters confirmed, 94% were Caucasian, 77% were male, and 54% were found to be over the age of 60. 33% of voting members are former nominees (14%) and winners (19%).

In May 2011, the Academy sent a letter advising its 6,000 or so voting members that an online system for Oscar voting would be implemented in 2013.

According to Rules 2 and 3 of the official Academy Awards Rules, a film must open in the previous calendar year, from midnight at the start of 1 January to midnight at the end of 31 December, in Los Angeles County, California, and play for seven consecutive days, to qualify (except for the Best Foreign Language Film, Best Documentary Feature, and Best Documentary Short Subject).

The Best Foreign Language Film award does not require a U.S. release. It requires the film to be submitted as its country's official selection.

The Best Documentary Feature award requires either week-long releases in both Los Angeles County and New York City during the previous calendar year, or a qualifying award at a competitive film festival from the Documentary Feature Qualifying Festival list (regardless of any public exhibition or distribution), or a submission in the Foreign Language Film category as its country's official selection.

The Best Documentary Short Subject award has noticeably different eligibility rules from most other competitive awards. First, the qualifying period for release does not coincide with a calendar year, instead covering a one-year period starting on 1 September and ending on 31 August of the calendar year before the ceremony. Second, there are multiple methods of qualification. The main method is a week-long theatrical release in "either" Los Angeles County "or" New York City during the eligibility period. Films also can qualify by winning specified awards at one of a number of competitive film festivals designated by the Academy. Finally, a film that is selected as a gold, silver, or bronze medal winner in the Documentary category of the immediately previous Student Academy Awards is also eligible.

For example, the 2009 Best Picture winner, "The Hurt Locker", was actually first released in 2008, but did not qualify for the 2008 awards as it did not play its Oscar-qualifying run in Los Angeles until mid-2009, thus qualifying for the 2009 awards. Foreign films must include English subtitles, and each country can submit only one film per year.

Rule 2 states that a film must be feature-length, defined as a minimum of 40 minutes, except for short-subject awards, and it must exist either on a 35 mm or 70 mm film print or in 24 frame/s or 48 frame/s progressive scan digital cinema format with a minimum projector resolution of 2048 by 1080 pixels. Effective with the 90th Academy Awards, presented in 2018, multi-part and limited series will be ineligible for the Best Documentary Feature award. This followed the win of "O.J.: Made in America", an eight-hour presentation that was screened in a limited release before being broadcast in five parts on ABC and ESPN, in that category in 2017. The Academy's announcement of the new rule made no direct mention of that film.

Producers must submit an Official Screen Credits online form before the deadline; in case it is not submitted by the defined deadline, the film will be ineligible for Academy Awards in any year. The form includes the production credits for all related categories. Then, each form is checked and put in a Reminder List of Eligible Releases.

In late December ballots and copies of the Reminder List of Eligible Releases are mailed to around 6,000 active members. For most categories, members from each of the branches vote to determine the nominees only in their respective categories (i.e. only directors vote for directors, writers for writers, actors for actors, etc.). In the special case of Best Picture, all voting members are eligible to select the nominees. In all major categories, a variant of the single transferable vote is used, with each member casting a ballot with up to five nominees (ten for Best Picture) ranked preferentially. In certain categories, including Foreign Film, Documentary and Animated Feature, nominees are selected by special screening committees made up of members from all branches.

In most categories the winner is selected from among the nominees by plurality voting of all members. Since 2009, the Best Picture winner has been chosen by instant runoff voting. Since 2013, re-weighted range voting has been used to select the nominees for the Best Visual Effects.

Film companies will spend as much as several million dollars on marketing to awards voters for a movie in the running for Best Picture, in attempts to improve chances of receiving Oscars and other movie awards conferred in Oscar season. The Academy enforces rules to limit overt campaigning by its members so as to try to eliminate excesses and prevent the process from becoming undignified. It has an awards czar on staff who advises members on allowed practices and levies penalties on offenders. For example, a producer of the 2009 Best Picture nominee "The Hurt Locker
The major awards are presented at a live televised ceremony, commonly in late February or early March following the relevant calendar year, and six weeks after the announcement of the nominees. It is the culmination of the film awards season, which usually begins during November or December of the previous year. This is an elaborate extravaganza, with the invited guests walking up the red carpet in the creations of the most prominent fashion designers of the day. Black tie dress is the most common outfit for men, although fashion may dictate not wearing a bow-tie, and musical performers sometimes do not adhere to this. (The artists who recorded the nominees for Best Original Song quite often perform those songs live at the awards ceremony, and the fact that they are performing is often used to promote the television broadcast.)

The Academy Awards is the world's longest running awards show televised live in all U.S. time zones (excluding territories outside mainland North America), Canada, and the United Kingdom, and gathers billions of viewers elsewhere throughout the world. The Oscars were first televised in 1953 by NBC, which continued to broadcast the event until 1960, when ABC took over, televising the festivities (including the first color broadcast of the event in 1966) through 1970. NBC regained the rights for five years then ABC resumed broadcast duties in 1976 and its current contract with the Academy runs through 2028. The Academy has also produced condensed versions of the ceremony for broadcast in international markets (especially those outside of the Americas) in more desirable local timeslots. The ceremony was broadcast live internationally for the first time via satellite since 1970, but only two South American countries, Chile and Brazil, purchased the rights to air the broadcast. By that time, the television rights to the Academy Awards had been sold in 50 countries. A decade later, the rights were already being sold to 60 countries, and by 1984, the TV rights to the Awards were licensed in 76 countries.

The ceremonies were moved up from late March/early April to late February since 2004 to help disrupt and shorten the intense lobbying and ad campaigns associated with Oscar season in the film industry. Another reason was because of the growing TV ratings success coinciding with the NCAA Basketball Tournament, which would cut into the Academy Awards audience. (In 1976 and 1977, ABC's regained Oscars were moved from Tuesday to Monday and went directly opposite NBC's NCAA title game.) The earlier date is also to the advantage of ABC, as it now usually occurs during the highly profitable and important February sweeps period. Some years, the ceremony is moved into first Sunday of March in order to avoid clash with the Winter Olympic Games. Another reason for the move to late February and early March is also to avoid the awards ceremony occurring so close to the religious holidays of Passover and Easter, which for decades had been a grievance from members and the general public. Advertising is somewhat restricted, however, as traditionally no movie studios or competitors of official Academy Award sponsors may advertise during the telecast. The production of the Academy Awards telecast currently holds the distinction of winning the most Emmys in history, with 47 wins and 195 nominations overall since that award's own launch in 1949.

After many years of being held on Mondays at 9:00 pm Eastern/6:00 p.m Pacific, since the 1999 ceremonies, it was moved to Sundays at 8:30 pm ET/5:30 pm PT. The reasons given for the move were that more viewers would tune in on Sundays, that Los Angeles rush-hour traffic jams could be avoided, and an earlier start time would allow viewers on the East Coast to go to bed earlier. For many years the film industry opposed a Sunday broadcast because it would cut into the weekend box office. In 2010, the Academy contemplated moving the ceremony even further back into January, citing TV viewers' fatigue with the film industry's long awards season. However, such an accelerated schedule would dramatically decrease the voting period for its members, to the point where some voters would only have time to view the contending films streamed on their computers (as opposed to traditionally receiving the films and ballots in the mail). Furthermore, a January ceremony on Sunday would clash with National Football League playoff games. In 2018, the Academy announced that the ceremony would be moved from late February to mid February beginning with the 92nd Academy Awards in 2020.

Originally scheduled for 8 April 1968, the 40th Academy Awards ceremony was postponed for two days, because of the assassination of Dr. Martin Luther King, Jr.. On 30 March 1981, the 53rd Academy Awards was postponed for one day, after the shooting of President Ronald Reagan and others in Washington, D.C.

In 1993, an "In Memoriam" segment was introduced, honoring those who had made a significant contribution to cinema who had died in the preceding 12 months, a selection compiled by a small committee of Academy members. This segment has drawn criticism over the years for the omission of some names. Criticism was also levied for many years regarding another aspect, with the segment having a "popularity contest" feel as the audience varied their applause to those who had died by the subject's cultural impact; the applause has since been muted during the telecast, and the audience is discouraged from clapping during the segment and giving silent reflection instead.

In terms of broadcast length, the ceremony generally averages three and a half hours. The first Oscars, in 1929, lasted 15 minutes. At the other end of the spectrum, the 2002 ceremony lasted four hours and twenty-three minutes. In 2010, the organizers of the Academy Awards announced winners' acceptance speeches must not run past 45 seconds. This, according to organizer Bill Mechanic, was to ensure the elimination of what he termed "the single most hated thing on the show" – overly long and embarrassing displays of emotion. In 2016, in a further effort to streamline speeches, winners' dedications were displayed on an on-screen ticker. During the 2018 ceremony, host Jimmy Kimmel acknowledged how long the ceremony had become, by announcing that he would give a brand-new jet ski to whoever gave the shortest speech of the night (a reward won by Mark Bridges when accepting his Best Costume Design award for "Phantom Thread"). The "Wall Street Journal" analyzed the average minutes spent across the 2014–2018 telecasts as follows: 14 on song performances; 25 on the hosts' speeches; 38 on prerecorded clips; and 78 on the awards themselves, broken into 24 on the introduction and announcement, 24 on winners walking to the stage, and 30 on their acceptance speeches.

Although still dominant in ratings, the viewership of the Academy Awards have steadily dropped; the 88th Academy Awards were the lowest-rated in the past eight years (although with increases in male and 18-49 viewership), while the show itself also faced mixed reception. Following the show, "Variety" reported that ABC was, in negotiating an extension to its contract to broadcast the Oscars, seeking to have more creative control over the broadcast itself. Currently and nominally, AMPAS is responsible for most aspects of the telecast, including the choice of production staff and hosting, although ABC is allowed to have some input on their decisions. In August 2016, AMPAS extended its contract with ABC through 2028: the contract neither contains any notable changes, nor gives ABC any further creative control over the telecast.

Historically, the "Oscarcast" has pulled in a bigger haul when box-office hits are favored to win the Best Picture trophy. More than 57.25 million viewers tuned to the telecast for the 70th Academy Awards in 1998, the year of "Titanic", which generated close to US$600 million at the North American box office pre-Oscars. The 76th Academy Awards ceremony in which "The Lord of the Rings: The Return of the King" (pre-telecast box office earnings of US$368 million) received 11 Awards including Best Picture drew 43.56 million viewers. The most watched ceremony based on Nielsen ratings to date, however, was the 42nd Academy Awards (Best Picture "Midnight Cowboy") which drew a 43.4% household rating on 7 April 1970.

By contrast, ceremonies honoring films that have not performed well at the box office tend to show weaker ratings. The 78th Academy Awards which awarded low-budgeted, independent film "Crash" (with a pre-Oscar gross of US$53.4 million) generated an audience of 38.64 million with a household rating of 22.91%. In 2008, the 80th Academy Awards telecast was watched by 31.76 million viewers on average with an 18.66% household rating, the lowest rated and least watched ceremony at the time, in spite of celebrating 80 years of the Academy Awards. The Best Picture winner of that particular ceremony was another independently financed film ("No Country for Old Men").

In 1929, the first Academy Awards were presented at a banquet dinner at the Hollywood Roosevelt Hotel. From 1930 to 1943, the ceremony alternated between two venues: the Ambassador Hotel on Wilshire Boulevard and the Biltmore Hotel in downtown Los Angeles.

Grauman's Chinese Theatre in Hollywood then hosted the awards from 1944 to 1946, followed by the Shrine Auditorium in Los Angeles from 1947 to 1948. The 21st Academy Awards in 1949 were held at the Academy Award Theatre at what was the Academy's headquarters on Melrose Avenue in Hollywood.

From 1950 to 1960, the awards were presented at Hollywood's Pantages Theatre. With the advent of television, the awards from 1953 to 1957 took place simultaneously in Hollywood and New York, first at the NBC International Theatre (1953) and then at the NBC Century Theatre, after which the ceremony took place solely in Los Angeles. The Oscars moved to the Santa Monica Civic Auditorium in Santa Monica, California in 1961. By 1969, the Academy decided to move the ceremonies back to Los Angeles, this time to the Dorothy Chandler Pavilion at the Los Angeles County Music Center. Some years, the ceremony were at Shriners auditorium by USC.

In 2002, the Dolby Theatre (previously known as the Kodak Theatre) became the presentation's current venue.

In the first year of the awards, the Best Directing award was split into two categories (Drama and Comedy). At times, the Best Original Score award has also been split into separate categories (Drama and Comedy/Musical). From the 1930s through the 1960s, the Art Direction (now Production Design), Cinematography, and Costume Design awards were likewise split into two categories (black-and-white films and color films). Prior to 2012, the Production Design award was called Art Direction, while the Makeup and Hairstyling award was called Makeup.

In August 2018, the Academy announced that several categories would not be televised live, but rather be recorded during commercial breaks and aired later in the ceremony.
Following dissent from Academy members, they announced that they would indeed air all 24 categories live. This followed a number of proposals (including introducing a Popular Film category) that the Academy had announced but did not implement.

The Board of Governors meets each year and considers new award categories. To date, the following categories have been proposed:

The Special Academy Awards are voted on by special committees, rather than by the Academy membership as a whole. They are not always presented on a consistent annual basis.



Due to the positive exposure and prestige of the Academy Awards, many studios spend millions of dollars and hire publicists specifically to promote their films during what is typically called the "Oscar season". This has generated accusations of the Academy Awards being influenced more by marketing than quality. William Friedkin, an Academy Award-winning film director and former producer of the ceremony, expressed this sentiment at a conference in New York in 2009, describing it as "the greatest promotion scheme that any industry ever devised for itself".

Tim Dirks, editor of AMC's filmsite.org, has written of the Academy Awards,

Typical criticism of the Academy Awards for Best Picture is that among the winners and nominees there is an over-representation of romantic historical epics, biographical dramas, romantic dramedies, and family melodramas, most of which are released in the U.S. the last three months of the calendar year. The Oscars have been infamously known for selecting specific genres of movies to be awarded. This has led to the coining of the term 'Oscar bait', describing such movies. This has led at times to more specific criticisms that the Academy is disconnected from the audience, e.g., by favoring 'Oscar bait' over audience favorites, or favoring historical melodramas over critically acclaimed movies that depict current life issues.

The Academy Awards have long received criticism over its lack of diversity among the nominees. This criticism is based on the statistics from every Academy Awards since 1929 which shows us that only 6.4% of academy award nominees have been non-white and since 1991, 11.2% of nominees have been non-white, with the rate of winners being even more polarizing. The 88th awards ceremony became the target of a boycott, popularized on social media by the #OscarsSoWhite, based on critics' perception that its all-white acting nominee list reflected bias. In response, the Academy initiated "historic" changes in membership by the year 2020.

Acting prizes in certain years have been criticized for not recognizing superior performances so much as being awarded for personal popularity, to make up for a "snub" for a performance/work that proved in time to be more popular and/or renowned than the one actually awarded, or presented as a "career honor" to recognize a distinguished nominee's entire body of work.

Some winners critical of the Academy Awards have boycotted the ceremonies and refused to accept their Oscars. The first to do so was screenwriter Dudley Nichols (Best Writing in 1935 for "The Informer"). Nichols boycotted the 8th Academy Awards ceremony because of conflicts between the Academy and the Writers' Guild. Nichols eventually accepted the 1935 award three years later, at the 1938 ceremony. Nichols was nominated for three further Academy Awards during his career.

George C. Scott became the second person to refuse his award (Best Actor in 1970 for "Patton") at the 43rd Academy Awards ceremony. Scott described it as a "meat parade", saying "I don't want any part of it."

The third person to refuse the award was Marlon Brando, who refused his award (Best Actor for 1972's "The Godfather") citing the film industry's discrimination and mistreatment of Native Americans. At the 45th Academy Awards ceremony, Brando sent actress and civil rights activist Sacheen Littlefeather to read a 15-page speech detailing his criticisms where she was booed by the audience.

At the 89th Academy Awards ceremony, Warren Beatty and Faye Dunaway mistakenly announced "La La Land" as the recipient of the Best Picture award, instead of "Moonlight", the actual winner. Beatty had been given the wrong envelope and after hesitating during the announcement, handed the envelope to Dunaway, which listed Emma Stone as Best Actress for "La La Land" and led to the confusion. The proper winner was announced after the acceptance speeches by "La La Land" producers Fred Berger, Jordan Horowitz and Marc Platt.

The following year, Beatty and Dunaway were invited back as presenters of the Best Picture award, which they accomplished without error.


Seven films have been disqualified before an official award ceremony because they violated the regulations.

One film was disqualified after winning the award and had the winner return the Oscar back . 

The following events are closely associated with the annual Academy Awards:

It has become a tradition to give out gift bags to the presenters and performers at the Oscars. In recent years, these gifts have also been extended to award nominees and winners. The value of each of these gift bags can reach into the tens of thousands of dollars. In 2014, the value was reported to be as high as US$80,000. The value has risen to the point where the U.S. Internal Revenue Service issued a statement regarding the gifts and their taxable status.
Oscar gift bags have included vacation packages to Hawaii and Mexico and Japan, a private dinner party for the recipient and friends at a restaurant, videophones, a four-night stay at a hotel, watches, bracelets, spa treatments, bottles of vodka, maple salad dressing, and weight-loss gummie candy. Some of the gifts have even had a "risque" element to them; in 2014, the adult products retailer Adam & Eve had a "Secret Room Gifting Suite". Celebrities visiting the gifting suite included Judith Hoag, Carolyn Hennesy, Kate Linder, Chris Mulkey, Jim O'Heir, and NBA player John Salley.

From 2006 onwards, results are Live+SD, all previous years are Live viewing
The term "Oscar" is a registered trademark of the AMPAS; however, in the Italian language, it is used generically
Category:American film awards
Category:Awards established in 1929
Category:1929 establishments in California
Category:Cinema of Southern California
Category:Hollywood history and culture
Category:American annual television specials
Category:Annual events in Los Angeles County, California
Category:Events in Los Angeles
Category:Live television programsActrius

Actresses (Catalan: Actrius) is a 1997 Catalan language Spanish drama film produced and directed by Ventura Pons and based on the award-winning stage play "E.R." by Josep Maria Benet i Jornet. The film has no male actors, with all roles played by females. The film was produced in 1996.

In order to prepare herself to play a role commemorating the life of legendary actress Empar Ribera, young actress (Mercè Pons) interviews three established actresses who had been the Ribera's pupils: the international diva Glòria Marc (Núria Espert), the television star Assumpta Roca (Rosa Maria Sardà), and dubbing director Maria Caminal (Anna Lizaran).


"Actrius" screened in 2001 at the Grauman's Egyptian Theatre in an American Cinematheque retrospective of the works of its director. The film had first screened at the same location in 1998. It was also shown at the 1997 Stockholm International Film Festival.

In "Movie - Film - Review", "Daily Mail" staffer Christopher Tookey wrote that though the actresses were "competent in roles that may have some reference to their own careers", the film "is visually unimaginative, never escapes its stage origins, and is almost totally lacking in revelation or surprising incident". Noting that there were "occasional, refreshing moments of intergenerational bitchiness", they did not "justify comparisons to "All About Eve"", and were "insufficiently different to deserve critical parallels with "Rashomon"". He also wrote that "The Guardian" called the film a "slow, stuffy chamber-piece", and that "The Evening Standard" stated the film's "best moments exhibit the bitchy tantrums seething beneath the threesome's composed veneers". MRQE wrote "This cinematic adaptation of a theatrical work is true to the original, but does not stray far from a theatrical rendering of the story."



Category:1997 films
Category:1990s drama films
Category:Spanish films
Category:Catalan-language films
Category:Films set in Barcelona
Category:Films directed by Ventura PonsAnimalia (book)

Animalia is an illustrated children's book by Graeme Base. It was originally published in 1986, followed by a tenth anniversary edition in 1996, and a 25th anniversary edition in 2012. Over three million copies have been sold. A special numbered and signed anniversary edition was also published in 1996, with an embossed gold jacket.

"Animalia" is an alliterative alphabet book and contains twenty-six illustrations, one for each letter of the alphabet. Each illustration features an animal from the animal kingdom (A is for alligator, B is for butterfly, etc.) along with a short poem utilizing the letter of the page for many of the words. The illustrations contain many other objects beginning with that letter that the reader can try to identify. As an additional challenge, the author has hidden a picture of himself as a child in every picture.

Julia MacRae Books published an "Animalia" colouring book in 2008. H. N. Abrams also published a wall calendar colouring book version for children the same year.

H. N. Abrams published "The Animalia Wall Frieze", a fold-out over 26 feet in length, in which the author created new riddles for each letter.

The Great American Puzzle Factory created a 300-piece jigsaw puzzle based on the book's cover.

A television series was also created, based on the book, which airs in the United States, Australia, Canada, the United Kingdom, Norway and Venezuela. It also airs on Minimax for the Czech Republic and Slovakia. And recently in Greece on the channel ET1. The Australian Children's Television Foundation released a teaching resource DVD-ROM in 2011 to accompany the TV series with teaching aids for classroom use.

In 2010, The Base Factory and AppBooks released Animalia as an application for iPad and iPhone/iPod Touch.

"Animalia" won the Young Australian's Best Book Award in 1987 for Best Picture Story Book.

The Children's Book Council of Australia: Honour Book.

Kid's Own Australian Literature Awards named "Animalia" the 1988 Picture Book Winner.


Category:Alphabet books
Category:1986 children's books
Category:Picture books by Graeme Base
Category:Puzzle books
Category:Australian children's booksInternational Atomic Time

International Atomic Time (TAI, from the French name ) is a high-precision atomic coordinate time standard based on the notional passage of proper time on Earth's geoid. It is the principal realisation of Terrestrial Time (with a fixed offset of epoch). It is also the basis for Coordinated Universal Time (UTC), which is used for civil timekeeping all over the Earth's surface. , when another leap second was added, TAI is exactly 37 seconds ahead of UTC. The 37 seconds results from the initial difference of 10 seconds at the start of 1972, plus 27 leap seconds in UTC since 1972.

TAI may be reported using traditional means of specifying days, carried over from non-uniform time standards based on the rotation of the Earth. Specifically, both Julian Dates and the Gregorian calendar are used. TAI in this form was synchronised with Universal Time at the beginning of 1958, and the two have drifted apart ever since, due to the changing motion of the Earth.

TAI is a weighted average of the time kept by over 400 atomic clocks in over 50 national laboratories worldwide. The majority of the clocks involved are caesium clocks; the International System of Units (SI) definition of the second is based on caesium. The clocks are compared using GPS signals and two-way satellite time and frequency transfer. Due to the signal averaging TAI is an order of magnitude more stable than its best constituent clock.

The participating institutions each broadcast, in real time, a frequency signal with timecodes, which is their estimate of TAI. Time codes are usually published in the form of UTC, which differs from TAI by a well-known integer number of seconds. These time scales are denoted in the form "UTC(NPL)" in the UTC form, where "NPL" in this case identifies the National Physical Laboratory, UK. The TAI form may be denoted "TAI(NPL)". The latter is not to be confused with "TA(NPL)", which denotes an independent atomic time scale, not synchronised to TAI or to anything else.

The clocks at different institutions are regularly compared against each other. The International Bureau of Weights and Measures (BIPM, France), combines these measurements to retrospectively calculate the weighted average that forms the most stable time scale possible. This combined time scale is published monthly in "Circular T", and is the canonical TAI. This time scale is expressed in the form of tables of differences UTC − UTC("k") (equivalent to TAI − TAI("k")) for each participating institution "k". The same circular also gives tables of TAI − TA("k"), for the various unsynchronised atomic time scales.

Errors in publication may be corrected by issuing a revision of the faulty Circular T or by errata in a subsequent Circular T. Aside from this, once published in Circular T, the TAI scale is not revised. In hindsight it is possible to discover errors in TAI, and to make better estimates of the true proper time scale. Since the published circulars are definitive, better estimates do not create another version of TAI; it is instead considered to be creating a better realisation of Terrestrial Time (TT).

Early atomic time scales consisted of quartz clocks with frequencies calibrated by a single atomic clock; the atomic clocks were not operated continuously. Atomic timekeeping services started experimentally in 1955, using the first caesium atomic clock at the National Physical Laboratory, UK (NPL). It was used as a basis for calibrating the quartz clocks at the Royal Greenwich Observatory and to establish a time scale, called Greenwich Atomic (GA). The United States Naval Observatory began the A.1 scale on 13 September 1956, using an Atomichron commercial atomic clock, followed by the NBS-A scale at the National Bureau of Standards, Boulder, Colorado on 9 October 1957.

The International Time Bureau (BIH) began a time scale, T or AM, in July 1955, using both local caesium clocks and comparisons to distant clocks using the phase of VLF radio signals. The BIH scale, A.1, and NBS-A were defined by an epoch at the beginning of 1958 The procedures used by the BIH evolved, and the name for the time scale changed: "A3" in 1964 and "TA(BIH)" in 1969.

The SI second was defined in terms of the caesium atom in 1967. From 1971 to 1975 the General Conference on Weights and Measures and the International Committee for Weights and Measures made a series of decisions which designated the BIPM time scale International Atomic Time (TAI). 

In the 1970s, it became clear that the clocks participating in TAI were ticking at different rates due to gravitational time dilation, and the combined TAI scale therefore corresponded to an average of the altitudes of the various clocks. Starting from Julian Date 2443144.5 (1 January 1977 00:00:00), corrections were applied to the output of all participating clocks, so that TAI would correspond to proper time at mean sea level (the geoid). Because the clocks were, on average, well above sea level, this meant that TAI slowed down, by about one part in a trillion. The former uncorrected time scale continues to be published, under the name "EAL" ("Echelle Atomique Libre", meaning "Free Atomic Scale").

The instant that the gravitational correction started to be applied serves as the epoch for Barycentric Coordinate Time (TCB), Geocentric Coordinate Time (TCG), and Terrestrial Time (TT), which represent three fundamental time scales in the solar system. All three of these time scales were defined to read JD 2443144.5003725 (1 January 1977 00:00:32.184) exactly at that instant. TAI was henceforth a realisation of TT, with the equation TT(TAI) = TAI + 32.184 s.

The continued existence of TAI was questioned in a 2007 letter from the BIPM to the ITU-R which stated, "In the case of a redefinition of UTC without leap seconds, the CCTF would consider discussing the possibility of suppressing TAI, as it would remain parallel to the continuous UTC."

UTC is a discontinuous (i.e. regularly adjusted by leap seconds) time scale composed from segments that are linear transformations of atomic time. From its beginning in 1961 through December 1971 the adjustments were made regularly in fractional leap seconds so that UTC approximated UT2. Afterwards these adjustments were made only in whole seconds to approximate UT1. This was a compromise arrangement in order to enable a publicly broadcast time scale; the post-1971 more linear transformation of the BIH's atomic time meant that the time scale would be more stable and easier to synchronize internationally. The fact that it continues to approximate UT1 means that tasks such as navigation which require a source of Universal Time continue to be well served by the public broadcast of UTC.



Category:Time scales
Altruism is the principle and moral practice of concern for happiness of other human beings and/or animals, resulting in a quality of life both material and spiritual. It is a traditional virtue in many cultures and a core aspect of various religious traditions and secular worldviews, though the concept of "others" toward whom concern should be directed can vary among cultures and religions.

In an extreme case, altruism may become a synonym of selflessness which is the opposite of selfishness.

In a common way of living, it doesn't deny the singular nature of the subject, but realizes the traits of the individual personality in relation to the others, with a true, direct and personal interaction with each of them. It is focusing both on a single person and the whole community. In a (not only) Christian practice, it is the law of love direct to the ego and his neighbour.

The word "altruism" was coined by the French philosopher Auguste Comte in French, as "altruisme", for an antonym of egoism. He derived it from the Italian "altrui", which in turn was derived from Latin "alteri", meaning "other people" or "somebody else".

Altruism in biological observations in field populations of the day organisms is an individual performing an action which is at a cost to themselves (e.g., pleasure and quality of life, time, probability of survival or reproduction), but benefits, either directly or indirectly, another third-party individual, without the expectation of reciprocity or compensation for that action. Steinberg suggests a definition for altruism in the clinical setting, that is "intentional and voluntary actions that aim to enhance the welfare of another person in the absence of any quid pro quo external rewards".

Altruism can be distinguished from feelings of loyalty, in that whilst the latter is predicated upon social relationships, altruism does not consider relationships. Much debate exists as to whether ""true"" altruism is possible in human psychology. The theory of psychological egoism suggests that no act of sharing, helping or sacrificing can be described as truly altruistic, as the actor may receive an intrinsic reward in the form of personal gratification. The validity of this argument depends on whether intrinsic rewards qualify as "benefits".

The term "altruism" may also refer to an ethical doctrine that claims that individuals are morally obliged to benefit others. Used in this sense, it is usually contrasted with egoism, which claims individuals are morally obligated to serve themselves first.

The concept has a long history in philosophical and ethical thought. The term was originally coined in the 19th century by the founding sociologist and philosopher of science, Auguste Comte, and has become a major topic for psychologists (especially evolutionary psychology researchers), evolutionary biologists, and ethologists. Whilst ideas about altruism from one field can affect the other fields, the different methods and focuses of these fields always lead to different perspectives on altruism. In simple terms, altruism is caring about the welfare of other people and acting to help them.

Marcel Mauss
In the science of ethology (the study of animal behaviour), and more generally in the study of social evolution, altruism refers to behaviour by an individual that increases the fitness of another individual while decreasing the fitness of the actor. In evolutionary psychology this may be applied to a wide range of human behaviors such as charity, emergency aid, help to coalition partners, tipping, courtship gifts, production of public goods, and environmentalism.

Theories of apparently altruistic behavior were accelerated by the need to produce theories compatible with evolutionary origins. Two related strands of research on altruism have emerged from traditional evolutionary analyses and from evolutionary game theory
Such explanations do not imply that humans are always consciously calculating how to increase their inclusive fitness when they are doing altruistic acts. Instead, evolution has shaped psychological mechanisms, such as emotions, that promote altruistic behaviors.

Every single instance of altruistic behavior need not always increase inclusive fitness; altruistic behaviors would have been selected for if such behaviors on average increased inclusive fitness in the ancestral environment. This need not imply that on average 50% or more of altruistic acts were beneficial for the altruist in the ancestral environment; if the benefits from helping the right person were very high it would be beneficial to err on the side of caution and usually be altruistic even if in most cases there were no benefits.

The benefits for the altruist may be increased and the costs reduced by being more altruistic towards certain groups. Research has found that people are more altruistic to kin than to no-kin, to friends than to strangers, to those attractive than to those unattractive, to non-competitors than to competitors, and to members ingroups than to members of outgroup.

The study of altruism was the initial impetus behind George R. Price's development of the Price equation, which is a mathematical equation used to study genetic evolution. An interesting example of altruism is found in the cellular slime moulds, such as "Dictyostelium mucoroides." These protists live as individual amoebae until starved, at which point they aggregate and form a multicellular fruiting body in which some cells sacrifice themselves to promote the survival of other cells in the fruiting body.

Selective investment theory proposes that close social bonds, and associated emotional, cognitive, and neurohormonal mechanisms, evolved in order to facilitate long-term, high-cost altruism between those closely depending on one another for survival and reproductive success.

Such cooperative behaviors have sometimes been seen as arguments for left-wing politics such by the Russian zoologist and anarchist Peter Kropotkin in his 1902 book "Mutual Aid: A Factor of Evolution" and Peter Singer in his book "A Darwinian Left."

Jorge Moll and Jordan Grafman, neuroscientists at the National Institutes of Health and LABS-D'Or Hospital Network (J.M.) provided the first evidence for the neural bases of altruistic giving in normal healthy volunteers, using functional magnetic resonance imaging. In their research, published in the Proceedings of the National Academy of Sciences USA in October 2006, they showed that both pure monetary rewards and charitable donations activated the mesolimbic reward pathway, a primitive part of the brain that usually responds to food and sex. However, when volunteers generously placed the interests of others before their own by making charitable donations, another brain circuit was selectively activated: the subgenual cortex/septal region. These structures are intimately related to social attachment and bonding in other species. Altruism, the experiment suggested, was not a superior moral faculty that suppresses basic selfish urges but rather was basic to the brain, hard-wired and pleasurable. One brain region, the subgenual anterior cingulate cortex/basal forebrain, contributes to learning altruistic behavior, especially in those with trait empathy. The same study has shown a connection between giving to charity and the promotion of social bonding.

In fact, in an experiment published in March 2007 at the University of Southern California neuroscientist Antonio R. Damasio and his colleagues showed that subjects with damage to the ventromedial prefrontal cortex lack the ability to empathically feel their way to moral answers, and that when confronted with moral dilemmas, these brain-damaged patients coldly came up with "end-justifies-the-means" answers, leading Damasio to conclude that the point was not that they reached immoral conclusions, but that when they were confronted by a difficult issue — in this case as whether to shoot down a passenger plane hijacked by terrorists before it hits a major city — these patients appear to reach decisions without the anguish that afflicts those with normally functioning brains. According to Adrian Raine, a clinical neuroscientist also at the University of Southern California, one of this study's implications is that society may have to rethink how it judges immoral people: "Psychopaths often feel no empathy or remorse. Without that awareness, people relying exclusively on reasoning seem to find it harder to sort their way through moral thickets. Does that mean they should be held to different standards of accountability?"

In another study, in the 1990s, Dr. Bill Harbaugh, a University of Oregon economist, concluded people are motivated to give for reasons of personal prestige and in a similar fMRI scanner test in 2007 with his psychologist colleague Dr. Ulrich Mayr, reached the same conclusions of Jorge Moll and Jordan Grafman about giving to charity, although they were able to divide the study group into two groups: "egoists" and "altruists". One of their discoveries was that, though rarely, even some of the considered "egoists" sometimes gave more than expected because that would help others, leading to the conclusion that there are other factors in cause in charity, such as a person's environment and values.

The International Encyclopedia of the Social Sciences defines "psychological altruism" as "a motivational state with the goal of increasing another’s welfare." Psychological altruism is contrasted with "psychological egoism," which refers to the motivation to increase one's own welfare.

There has been some debate on whether or not humans are truly capable of psychological altruism. Some definitions specify a self-sacrificial nature to altruism and a lack of external rewards for altruistic behaviors. However, because altruism ultimately benefits the self in many cases, the selflessness of altruistic acts is brought to question. The social exchange theory postulates that altruism only exists when benefits to the self outweigh costs to the self. Daniel Batson is a psychologist who examined this question and argues against the social exchange theory. He identified four major motives for altruism: altruism to ultimately benefit the self (egoism), to ultimately benefit the other person (altruism), to benefit a group (collectivism), or to uphold a moral principle (principlism). Altruism that ultimately serves selfish gains is thus differentiated from selfless altruism, but the general conclusion has been that empathy-induced altruism can be genuinely selfless. The "empathy-altruism
In psychological research on altruism, studies often observe altruism as demonstrated through prosocial behaviors such as helping, comforting, sharing, cooperation, philanthropy, and community service. Research has found that people are most likely to help if they recognize that a person is in need and feel personal responsibility for reducing the person's distress. Research also suggests that the number of bystanders witnessing distress or suffering affects the likelihood of helping (the "Bystander effect"). Greater numbers of bystanders decrease individual feelings of responsibility. However, a witness with a high level of empathic concern is likely to assume personal responsibility entirely regardless of the number of bystanders.

Many studies have observed the effects of volunteerism (as a form of altruism) on happiness and health and have consistently found a strong connection between volunteerism and current and future health and well-being. In a study of older adults, those who volunteered were higher on life satisfaction and will to live, and lower in depression, anxiety, and somatization. Volunteerism and helping behavior have not only been shown to improve mental health, but physical health and longevity as well, attributable to the activity and social integration it encourages. One study examined the physical health of mothers who volunteered over a 30-year period and found that 52% of those who did not belong to a volunteer organization experienced a major illness while only 36% of those who did volunteer experienced one. A study on adults ages 55+ found that during the four-year study period, people who volunteered for two or more organizations had a 63% lower likelihood of dying. After controlling for prior health status, it was determined that volunteerism accounted for a 44% reduction in mortality. Merely being aware of kindness in oneself and others is also associated with greater well-being. A study that asked participants to count each act of kindness they performed for one week significantly enhanced their subjective happiness. It is important to note that, while research supports the idea that altruistic acts bring about happiness, it has also been found to work in the opposite direction—that happier people are also kinder. The relationship between altruistic behavior and happiness is bidirectional. Studies have found that generosity increases linearly from sad to happy affective states.

Studies have also been careful to note that feeling over-taxed by the needs of others has conversely negative effects on health and happiness. For example, one study on volunteerism found that feeling overwhelmed by others' demands had an even stronger negative effect on mental health than helping had a positive one (although positive effects were still significant). Additionally, while generous acts make people feel good about themselves, it is also important for people to appreciate the kindness they receive from others. Studies suggest that gratitude goes hand-in-hand with kindness and is also very important for our well-being. A study on the relationship happiness to various character strengths showed that "a conscious focus on gratitude led to reductions in negative affect and increases in optimistic appraisals, positive affect, offering emotional support, sleep quality, and well-being.".

"Sociologists have long been concerned with how to build the good society" ("Altruism, Morality, and Social Solidarity". American Sociological Association.). The structure of our societies and how individuals come to exhibit charitable, philanthropic, and other pro-social, altruistic actions for the common good is a largely researched topic within the field. The American Sociology Association (ASA) acknowledges public sociology saying, "The intrinsic scientific, policy, and public relevance of this field of investigation in helping to construct 'good societies' is unquestionable" ("Altruism, Morality, and Social Solidarity" ASA). This type of sociology seeks contributions that aid grassroots and theoretical understandings of what motivates altruism and how it is organized, and promotes an altruistic focus in order to benefit the world and people it studies. How altruism is framed, organized, carried out, and what motivates it at the group level is an area of focus that sociologists seek to investigate in order to contribute back to the groups it studies and "build the good society". The motivation of altruism is also the focus of study; some publications link the occurrence of moral outrage to the punishment of perpetrators and compensation of victims.

Pathological altruism is when altruism is taken to an unhealthy extreme, and either harms the altruistic person, or well-intentioned actions cause more harm than good.

The term "pathological altruism" was popularised by the book "Pathological Altruism".

Examples include depression and burnout seen in healthcare professionals, an unhealthy focus on others to the detriment of one's own needs, hoarding of animals, and ineffective philanthropic and social programs that ultimately worsen the situations they are meant to aid.

Most, if not all, of the world's religions promote altruism as a very important moral value. Buddhism, Christianity, Hinduism, Islam, Jainism, Judaism, and Sikhism
Altruism figures prominently in Buddhism. Love and compassion are components of all forms of Buddhism, and are focused on all beings equally: love is the wish that all beings be happy, and compassion is the wish that all beings be free from suffering. "Many illnesses can be cured by the one medicine of love and compassion. These qualities are the ultimate source of human happiness, and the need for them lies at the very core of our being" (Dalai Lama
The fundamental principles of Jainism revolve around the concept of altruism, not only for humans but for all sentient beings. Jainism preaches the view of "Ahimsa" – to live and let live, thereby not harming sentient beings, i.e. uncompromising reverence for all life. It also considers all living things to be equal. The first Tirthankara, Rishabhdev, introduced the concept of altruism for all living beings, from extending knowledge and experience to others to donation, giving oneself up for others, non-violence and compassion for all living things.

Jainism prescribes a path of non-violence to progress the soul to this ultimate goal. A major characteristic of Jain belief is the emphasis on the consequences of not only physical but also mental behaviors. One's unconquered mind with anger, pride (ego), deceit, greed and uncontrolled sense organs are the powerful enemies of humans. Anger spoils good relations, pride destroys humility, deceit destroys peace and greed destroys everything. Jainism recommends conquering anger by forgiveness, pride by humility, deceit by straightforwardness and greed by contentment.

Jains believe that to attain enlightenment and ultimately liberation, one must practice the following ethical principles (major vows) in thought, speech and action. The degree to which these principles are practiced is different for householders and monks. They are:
The "great vows" (Mahavrata) are prescribed for monks and "limited vows" (Anuvrata) are prescribed for householders. The house-holders are encouraged to practice the above-mentioned five vows. The monks have to observe them very strictly. With consistent practice, it will be possible to overcome the limitations gradually, accelerating the spiritual progress.

The principle of non-violence seeks to minimize karmas which limit the capabilities of the soul. Jainism views every soul as worthy of respect because it has the potential to become "Siddha" (God in Jainism
Altruism is central to the teachings of Jesus found in the Gospel, especially in the Sermon on the Mount and the Sermon on the Plain. From biblical to medieval Christian traditions, tensions between self-affirmation and other-regard were sometimes discussed under the heading of "disinterested love", as in the Pauline phrase "love seeks not its own interests." In his book "Indoctrination and Self-deception," Roderick Hindery tries to shed light on these tensions by contrasting them with impostors of authentic self-affirmation and altruism, by analysis of other-regard within creative individuation of the self, and by contrasting love for the few with love for the many. Love confirms others in their freedom, shuns propaganda and masks, assures others of its presence, and is ultimately confirmed not by mere declarations from others, but by each person's experience and practice from within. As in practical arts, the presence and meaning of love becomes validated and grasped not by words and reflections alone, but in the making of the connection.

St Thomas Aquinas interprets 'You should love your neighbour as yourself' as meaning that love for ourselves is the exemplar of love for others. Considering that "the love with which a man loves himself is the form and root of friendship" and quotes Aristotle that "the origin of friendly relations with others lies in our relations to ourselves," he concluded that though we are not bound to love others more than ourselves, we naturally seek the common good, the good of the whole, more than any private good, the good of a part. However, he thinks we should love God more than ourselves and our neighbours, and more than our bodily life—since the ultimate purpose of loving our neighbour is to share in eternal beatitude: a more desirable thing than bodily well being. In coining the word Altruism, as stated above, Comte was probably opposing this Thomistic doctrine, which is present in some theological schools within Catholicism.

Many biblical authors draw a strong connection between love of others and love of God. 1 John 4 states that for one to love God one must love his fellowman, and that hatred of one's fellowman is the same as hatred of God. Thomas Jay Oord has argued in several books that altruism is but one possible form of love. An altruistic action is not always a loving action. Oord defines altruism as acting for the other's good, and he agrees with feminists who note that sometimes love requires acting for one's own good when the other's demands undermine overall well-being.

German philosopher Max Scheler distinguishes two ways in which the strong can help the weak. One way is a sincere expression of Christian love, "motivated by a powerful feeling of security, strength, and inner salvation, of the invincible fullness of one’s own life and existence". Another way is merely "one of the many modern substitutes for love, ... nothing but the urge to turn away from oneself and to lose oneself in other people’s business." At its worst, Scheler says, "love for the small, the poor, the weak, and the oppressed is really disguised hatred, repressed envy, an impulse to detract, etc., directed against the opposite phenomena: wealth, strength, power, largesse."

In Islam, the concept 'ithaar' (إيثار) (altruism) is the notion of 'preferring others to oneself'. For Sufis, this means devotion to others through complete forgetfulness of one's own concerns, where concern for others is rooted to be a demand made by ALLAH on the human body, considered to be property of ALLAH alone. The importance lies in sacrifice for the sake of the greater good; Islam considers those practicing Eyaar as abiding by the highest degree of nobility.
This is similar to the notion of chivalry, but unlike that European concept, in i'thar attention is focused on everything in existence. A constant concern for ALLAH (i.e. God) results in a careful attitude towards people, animals, and other things in this world.
This concept was emphasized by Sufis of Islam like Rabia al-Adawiyya who paid attention to the difference between dedication to ALLAH (i.e. God) and dedication to people. Thirteenth-century Turkish Sufi poet Yunus Emre explained this philosophy as "Yaratılanı severiz, Yaratandan ötürü" or "We love the creature, because of The Creator." For many Muslims, i'thar must be practiced as a religious obligation during specific Islamic holidays. However, i'thar is also still an Islamic ideal to which all Muslims should strive to adhere at all times.

Judaism defines altruism as the desired goal of creation. The famous Rabbi Abraham Isaac Kook stated that love is the most important attribute in humanity. This is defined as bestowal, or giving, which is the intention of altruism. This can be altruism towards humanity that leads to altruism towards the creator or God. Kabbalah defines God as the force of giving in existence. Rabbi Moshe Chaim Luzzatto in particular focused on the 'purpose of creation' and how the will of God was to bring creation into perfection and adhesion with this upper force.

Modern Kabbalah developed by Rabbi Yehuda Ashlag, in his writings about the future generation, focuses on how society could achieve an altruistic social framework. Ashlag proposed that such a framework is the purpose of creation, and everything that happens is to raise humanity to the level of altruism, love for one another. Ashlag focused on society and its relation to divinity.

Altruism is essential to the Sikh religion. The central faith in Sikhism is that the greatest deed any one can do is to imbibe and live the godly qualities like love, affection, sacrifice, patience, harmony, truthfulness. The concept of "seva," or selfless service to the community for its own sake is an important concept in Sihkism.

The fifth Nanak, Guru Arjun Dev, sacrificed his life to uphold 22 carats of pure truth, the greatest gift to humanity, the Guru Granth. The ninth Guru, Tegh Bahadur, sacrificed his head to protect weak and defenseless people against atrocity. In the late seventeenth century, Guru Gobind Singh Ji (the tenth guru in Sikhism), was in war with the Mughal rulers to protect the people of different faiths when a fellow Sikh, Bhai Kanhaiya, attended the troops of the enemy. He gave water to both friends and foes who were wounded on the battlefield. Some of the enemy began to fight again and some Sikh warriors were annoyed by Bhai Kanhaiya as he was helping their enemy. Sikh soldiers brought Bhai Kanhaiya before Guru Gobind Singh Ji, and complained of his action that they considered counter-productive to their struggle on the battlefield."What were you doing, and why?" asked the Guru. "I was giving water to the wounded because I saw your face in all of them," replied Bhai Kanhaiya. The Guru responded, "Then you should also give them ointment to heal their wounds. You were practicing what you were coached in the house of the Guru."

It was under the tutelage of the Guru that Bhai Kanhaiya subsequently founded a volunteer corps for altruism. This volunteer corps still to date is engaged in doing good to others and trains new volunteering recruits for doing the same.

In Hinduism Selflessness (Atmatyag), Love (Prema), Kindness (Daya) and Forgiveness (Kshama) are considered as the highest acts of humanity or "Manushyattva". Giving alms to the beggers or poor people is considered as a divine act or "Punya" and Hindus believe it will free their souls from guilt or "Paapa" and will led them to heaven or "Swarga" in afterlife. Altruism is also the central act of various Hindu mythology and religious poems and songs.

Swami Vivekananda, the legendary Hindu monk, has said -"Jive prem kare jeijon, Seijon sebiche Iswar" (Whoever loves any living being, is serving god.). Mass donation of clothes to poor people (Vastraseva), or blood donation camp or mass food donation (Annaseva) for poor people is common in various Hindu religious ceremonies.

Swami Sivananda, an Advaita scholar, reiterates the views in his commentary synthesising Vedanta views on the Brahma Sutras, a Vedantic text. In his commentary on Chapter 3 of the Brahma Sutras, Sivananda notes that karma is insentient and short-lived, and ceases to exist as soon as a deed is executed. Hence, karma cannot bestow the fruits of actions at a future date according to one's merit. Furthermore, one cannot argue that karma generates apurva or punya, which gives fruit. Since apurva is non-sentient, it cannot act unless moved by an intelligent being such as a god. It cannot independently bestow reward or punishment.

However the very well known and popular text, the Bhagavad Gita supports the doctrine of karma yoga (achieving oneness with God through action) & "nishkaama karma" or action without expectation / desire for personal gain which can be said to encompass altruism. Altruistic acts are generally celebrated and very well received in Hindu literature and is central to Hindu morality.

There exists a wide range of philosophical views on humans' obligations or motivations to act altruistically. Proponents of ethical altruism maintain that individuals are morally obligated to act altruistically. The opposing view is ethical egoism, which maintains that moral agents should always act in their own self-interest. Both ethical altruism and ethical egoism contrast with utilitarianism, which maintains that each agent should act in order to maximise the efficacy of their function and the benefit to both themselves and their co-inhabitants.

A related concept in descriptive ethics is psychological egoism, the thesis that humans always act in their own self-interest and that true altruism is impossible. Rational egoism is the view that rationality consists in acting in one's self-interest (without specifying how this affects one's moral obligations).

The genes OXTR, CD38, COMT, DRD4, DRD5, IGF2, GABRB2
Category:Auguste Comte
Category:Defence mechanisms
Category:Evolutionary psychology
Category:Morality
Category:Philanthropy
Category:Social philosophy
Category:Interpersonal relationships
Category:VirtueAyn Rand

Ayn Rand (; born Alisa Zinovyevna Rosenbaum;  – March 6, 1982) was a Russian-American writer and philosopher. She is known for her two best-selling novels, "The Fountainhead" and "Atlas Shrugged", and for developing a philosophical system she named Objectivism. Educated in Russia, she moved to the United States in 1926. She had a play produced on Broadway in 1935 and 1936. After two early novels that were initially unsuccessful, she achieved fame with her 1943 novel, "The Fountainhead". In 1957, Rand published her best-known work, the novel "Atlas Shrugged". Afterward, she turned to non-fiction to promote her philosophy, publishing her own periodicals and releasing several collections of essays until her death in 1982.

Rand advocated reason as the only means of acquiring knowledge and rejected faith and religion. She supported rational and ethical egoism and rejected altruism. In politics, she condemned the initiation of force as immoral and opposed collectivism and statism as well as anarchism, instead supporting "laissez-faire" capitalism, which she defined as the system based on recognizing individual rights, including property rights. In art, Rand promoted romantic realism. She was sharply critical of most philosophers and philosophical traditions known to her, except for Aristotle, Thomas Aquinas and classical liberals.

Literary critics received Rand's fiction with mixed reviews and academia generally ignored or rejected her philosophy, though academic interest has increased in recent decades. The Objectivist movement attempts to spread her ideas, both to the public and in academic settings. She has been a significant influence among libertarians and American conservatives.

Rand was born Alisa Zinovyevna Rosenbaum () on February 2, 1905, to a Russian-Jewish bourgeois family living in Saint Petersburg. She was the eldest of three daughters of Zinovy Zakharovich Rosenbaum and his wife, Anna Borisovna (née Kaplan). Her father was upwardly mobile and a pharmacist and her mother was socially ambitious and religiously observant. Rand later said she found school unchallenging and began writing screenplays at the age of eight and novels at the age of ten. At the prestigious Stoiunina Gymnasium, her closest friend was Vladimir Nabokov's younger sister, Olga. The two girls shared an intense interest in politics and would engage in debates at the Nabokov mansion: while Olga defended constitutional monarchy, Alisa supported republican ideals.

She was twelve at the time of the February Revolution of 1917, during which she favored Alexander Kerensky over Tsar Nicholas II. The subsequent October Revolution and the rule of the Bolsheviks under Vladimir Lenin disrupted the life the family had previously enjoyed. Her father's business was confiscated, and the family fled to the Crimean Peninsula, which was initially under control of the White Army during the Russian Civil War. While in high school, she realized that she was an atheist and valued reason
After the Russian Revolution, universities were opened to women, allowing her to be in the first group of women to enroll at Petrograd State University. At the age of 16, she began her studies in the department of social pedagogy, majoring in history. At the university she was introduced to the writings of Aristotle and Plato, who would be her greatest influence and counter-influence, respectively. She also studied the philosophical works of Friedrich Nietzsche. Able to read French, German and Russian, she also discovered the writers Fyodor Dostoevsky, Victor Hugo, Edmond Rostand, and Friedrich Schiller, who became her perennial favorites.

Along with many other bourgeois students, she was purged from the university shortly before graduating. After complaints from a group of visiting foreign scientists, however, many of the purged students were allowed to complete their work and graduate, which she did in October 1924. She then studied for a year at the State Technicum for Screen Arts in Leningrad. For an assignment she wrote an essay about the Polish actress Pola Negri, which became her first published work.

By this time she had decided her professional surname for writing would be "Rand", possibly because it is graphically similar to a vowelless excerpt of her birth surname in Cyrillic handwriting, and she adopted the first name "Ayn", either from a Finnish name "Aino" or from the Hebrew word ("ayin
In late 1925, Rand was granted a visa to visit relatives in Chicago. She departed on January 17, 1926. When she arrived in New York City on February 19, 1926, she was so impressed with the skyline of Manhattan that she cried what she later called "tears of splendor". Intent on staying in the United States to become a screenwriter, she lived for a few months with her relatives, one of whom owned a movie theater and allowed her to watch dozens of films free of charge. She then left for Hollywood, California.

In Hollywood, a chance meeting with famed director Cecil B. DeMille led to work as an extra in his film "The King of Kings" and a subsequent job as a junior screenwriter. While working on "The King of Kings", she met an aspiring young actor, Frank O'Connor; the two were married on April 15, 1929. She became a permanent American resident in July 1929 and an American citizen on March 3, 1931. Taking various jobs during the 1930s to support her writing, she worked for a time as the head of the costume department at RKO Studios. She made several attempts to bring her parents and sisters to the United States, but they were unable to acquire permission to emigrate.

Rand's first literary success came with the sale of her screenplay "Red Pawn" to Universal Studios in 1932, although it was never produced. This was followed by the courtroom drama "Night of January 16th", first produced by E. E. Clive in Hollywood in 1934 and then successfully reopened on Broadway in 1935. Each night a jury was selected from members of the audience; based on the jury's vote, one of two different endings would be performed. In 1941, Paramount Pictures produced a movie loosely based on the play. Rand did not participate in the production and was highly critical of the result. "Ideal" is a novel and play written in 1934 which were first published in 2015 by her estate. The heroine is an actress who embodies Randian ideals.

Rand's first published novel, the semi-autobiographical "We the Living", was published in 1936. Set in Soviet Russia, it focused on the struggle between the individual and the state. In a 1959 foreword to the novel, Rand stated that "We the Living" "is as near to an autobiography as I will ever write. It is not an autobiography in the literal, but only in the intellectual sense. The plot is invented, the background is not ..." Initial sales were slow and the American publisher let it go out of print, although European editions continued to sell. After the success of her later novels, Rand was able to release a revised version in 1959 that has since sold over three million copies. In 1942, without Rand's knowledge or permission, the novel was made into a pair of Italian films, "Noi vivi" and "Addio, Kira". Rediscovered in the 1960s, these films were re-edited into a new version which was approved by Rand and re-released as "We the Living" in 1986.

Her novella "Anthem" was written during a break from the writing of her next major novel, "The Fountainhead". It presents a vision of a dystopian future world in which totalitarian collectivism has triumphed to such an extent that even the word 'I' has been forgotten and replaced with 'we'. It was published in England in 1938, but Rand initially could not find an American publisher. As with "We the Living", Rand's later success allowed her to get a revised version published in 1946, which has sold more than 3.5 million copies.

During the 1940s, Rand became politically active. She and her husband worked as full-time volunteers for the 1940 presidential campaign of Republican Wendell Willkie. This work led to Rand's first public speaking experiences; she enjoyed fielding sometimes hostile questions from New York City audiences who had viewed pro-Willkie newsreels. This activity brought her into contact with other intellectuals sympathetic to free-market capitalism. She became friends with journalist Henry Hazlitt and his wife, and Hazlitt introduced her to the Austrian School economist Ludwig von Mises. Despite her philosophical differences with them, Rand strongly endorsed the writings of both men throughout her career, and both of them expressed admiration for her. Mises once referred to Rand as "the most courageous man in America", a compliment that particularly pleased her because he said "man" instead of "woman". Rand also became friends with libertarian writer Isabel Paterson. Rand questioned Paterson about American history and politics long into the night during their many meetings and gave Paterson ideas for her only non-fiction book, "The God of the Machine".

Rand's first major success as a writer came in 1943 with "The Fountainhead", a romantic and philosophical novel that she wrote over a period of seven years. The novel centers on an uncompromising young architect named Howard Roark and his struggle against what Rand described as "second-handers"—those who attempt to live through others, placing others above themselves. It was rejected by twelve publishers before finally being accepted by the Bobbs-Merrill Company on the insistence of editor Archibald Ogden, who threatened to quit if his employer did not publish it. While completing the novel, Rand was prescribed the amphetamine Benzedrine to fight fatigue. The drug helped her to work long hours to meet her deadline for delivering the novel, but afterwards she was so exhausted that her doctor ordered two weeks' rest. Her use of the drug for approximately three decades may have contributed to what some of her later associates described as volatile mood swings.

"The Fountainhead" became a worldwide success, bringing Rand fame and financial security. In 1943, Rand sold the rights for a film version to Warner Bros. and she returned to Hollywood to write the screenplay. Finishing her work on that screenplay, she was hired by producer Hal B. Wallis as a screenwriter and script-doctor. Her work for Wallis included the screenplays for the Oscar-nominated "Love Letters" and "You Came Along". Rand also worked on other projects, including a planned nonfiction treatment of her philosophy to be called "The Moral Basis of Individualism". Although the planned book was never completed, a condensed version was published as an essay titled "The Only Path to Tomorrow" in the January 1944 edition of "Reader's Digest" magazine.
Rand extended her involvement with free-market and anti-communist activism while working in Hollywood. She became involved with the Motion Picture Alliance for the Preservation of American Ideals, a Hollywood anti-Communist group, and wrote articles on the group's behalf. She also joined the anti-Communist American Writers Association. A visit by Isabel Paterson to meet with Rand's California associates led to a final falling out between the two when Paterson made comments, which Rand considered rude, to valued political allies. In 1947, during the Second Red Scare, Rand testified as a "friendly witness" before the United States House Un-American Activities Committee. Her testimony described the disparity between her personal experiences in the Soviet Union and the portrayal of it in the 1944 film "Song of Russia". Rand argued that the film grossly misrepresented conditions in the Soviet Union, portraying life there as much better and happier than it actually was. She wanted to also criticize the lauded 1946 film "The Best Years of Our Lives
In the years following the publication of "The Fountainhead", Rand received numerous letters from readers, some of whom the book profoundly influenced. In 1951, Rand moved from Los Angeles to New York City, where she gathered a group of these admirers around her. This group (jokingly designated "The Collective") included future Federal Reserve Chairman Alan Greenspan, a young psychology student named Nathan Blumenthal (later Nathaniel Branden) and his wife Barbara and Barbara's cousin Leonard Peikoff. Initially the group was an informal gathering of friends who met with Rand on weekends at her apartment to discuss philosophy. She later began allowing them to read the drafts of her new novel, "Atlas Shrugged", as the manuscript pages were written. In 1954 Rand's close relationship with the younger Nathaniel Branden turned into a romantic affair, with the consent of their spouses.

"Atlas Shrugged", published in 1957, was considered Rand's "magnum opus". Rand described the theme of the novel as "the role of the mind in man's existence—and, as a corollary, the demonstration of a new moral philosophy: the morality of rational self-interest". It advocates the core tenets of Rand's philosophy of Objectivism and expresses her concept of human achievement. The plot involves a dystopian United States in which the most creative industrialists, scientists, and artists respond to a welfare state government by going on strike and retreating to a mountainous hideaway where they build an independent free economy. The novel's hero and leader of the strike, John Galt, describes the strike as "stopping the motor of the world" by withdrawing the minds of the individuals most contributing to the nation's wealth and achievement. With this fictional strike, Rand intended to illustrate that without the efforts of the rational and productive, the economy would collapse and society would fall apart. The novel includes elements of mystery, romance, and science fiction, and it contains an extended exposition of Objectivism in the form of a lengthy monologue delivered by Galt.

Despite many negative reviews, "Atlas Shrugged" became an international bestseller. In an interview with Mike Wallace, Rand declared herself "the most creative thinker alive". However, Rand was discouraged and depressed by the reaction of intellectuals to the novel. "Atlas Shrugged" was Rand's last completed work of fiction; it marked the end of her career as a novelist and the beginning of her role as a popular philosopher.

In 1958, Nathaniel Branden established Nathaniel Branden Lectures, later incorporated as the Nathaniel Branden Institute (NBI), to promote Rand's philosophy. Collective members gave lectures for NBI and wrote articles for Objectivist periodicals that she edited. Rand later published some of these articles in book form. Critics, including some former NBI students and Branden himself, later described the culture of NBI as one of intellectual conformity and excessive reverence for Rand, with some describing NBI or the Objectivist movement itself as a cult or religion. Rand expressed opinions on a wide range of topics, from literature and music to sexuality and facial hair, and some of her followers mimicked her preferences, wearing clothes to match characters from her novels and buying furniture like hers. However, some former NBI students believed the extent of these behaviors was exaggerated, and the problem was concentrated among Rand's closest followers in New York. Rand was unimpressed with many of the NBI students and held them to strict standards, sometimes reacting coldly or angrily to those who disagreed with her.

Throughout the 1960s and 1970s, Rand developed and promoted her Objectivist philosophy through her nonfiction works and by giving talks to students at institutions such as Yale, Princeton, Columbia, Harvard, and the Massachusetts Institute of Technology. She received an honorary Doctorate of Humane Letters from Lewis & Clark College on 2 October 1963. She also began delivering annual lectures at the Ford Hall Forum, responding afterward to questions from the audience. During these speeches and Q&A sessions, she often took controversial stances on political and social issues of the day. These included supporting abortion rights, opposing the Vietnam War and the military draft (but condemning many draft dodgers as "bums"), supporting Israel in the Yom Kippur War of 1973 against a coalition of Arab nations as "civilized men fighting savages", saying European colonists had the right to develop land taken from American Indians, and calling homosexuality "immoral" and "disgusting", while also advocating the repeal of all laws about it. She also endorsed several Republican candidates for President of the United States, most strongly Barry Goldwater in 1964
In 1964, Nathaniel Branden began an affair with the young actress Patrecia Scott, whom he later married. Nathaniel and Barbara Branden kept the affair hidden from Rand. When she learned of it in 1968, though her romantic relationship with Branden had already ended, Rand terminated her relationship with both Brandens, which led to the closure of NBI. Rand published an article in "The Objectivist" repudiating Nathaniel Branden for dishonesty and other "irrational behavior in his private life". Branden later apologized in an interview to "every student of Objectivism" for "perpetuating the Ayn Rand mystique" and for "contributing to that dreadful atmosphere of intellectual repressiveness that pervades the Objectivist movement". In subsequent years, Rand and several more of her closest associates parted company.

Rand underwent surgery for lung cancer in 1974 after decades of heavy smoking. In 1976, she retired from writing her newsletter and, despite her initial objections, she allowed social worker Evva Pryor, an employee of her attorney, to enroll her in Social Security and Medicare. During the late 1970s her activities within the Objectivist movement declined, especially after the death of her husband on November 9, 1979. One of her final projects was work on a never-completed television adaptation of "Atlas Shrugged".

Rand died of heart failure on March 6, 1982, at her home in New York City, and was interred in the Kensico Cemetery, Valhalla, New York. Rand's funeral was attended by some of her prominent followers, including Alan Greenspan. A floral arrangement in the shape of a dollar sign was placed near her casket. In her will, Rand named Leonard Peikoff to inherit her estate.

Rand called her philosophy "Objectivism", describing its essence as "the concept of man as a heroic being, with his own happiness as the moral purpose of his life, with productive achievement as his noblest activity, and reason as his only absolute". She considered Objectivism a systematic philosophy and laid out positions on metaphysics, epistemology, ethics, political philosophy, and aesthetics.

In metaphysics, Rand supported philosophical realism, and opposed anything she regarded as mysticism or supernaturalism, including all forms of religion.

In epistemology, she considered all knowledge to be based on sense perception, the validity of which she considered axiomatic, and reason, which she described as "the faculty that identifies and integrates the material provided by man's senses". She rejected all claims of non-perceptual or "a priori" knowledge, including instinct,' 'intuition,' 'revelation,' or any form of 'just knowing. In her "Introduction to Objectivist Epistemology", Rand presented a theory of concept formation and rejected the analytic–synthetic dichotomy.

In ethics, Rand argued for rational and ethical egoism (rational self-interest), as the guiding moral principle. She said the individual should "exist for his own sake, neither sacrificing himself to others nor sacrificing others to himself". She referred to egoism as "the virtue of selfishness" in her book of that title, in which she presented her solution to the is-ought problem by describing a meta-ethical theory that based morality in the needs of "man's survival "qua" man". She condemned ethical altruism as incompatible with the requirements of human life and happiness, and held that the initiation of force was evil and irrational, writing in "Atlas Shrugged" that "Force and mind are opposites."

Rand's political philosophy emphasized individual rights (including property rights), and she considered "laissez-faire" capitalism the only moral social system because in her view it was the only system based on the protection of those rights. She opposed statism, which she understood to include theocracy, absolute monarchy, Nazism, fascism, communism, democratic socialism, and dictatorship. Rand believed that natural rights should be enforced by a constitutionally limited government. Although her political views are often classified as conservative or libertarian, she preferred the term "radical for capitalism". She worked with conservatives on political projects, but disagreed with them over issues such as religion and ethics. She denounced libertarianism, which she associated with anarchism. She rejected anarchism as a naïve theory based in subjectivism that could only lead to collectivism in practice.

In aesthetics, Rand defined art as a "selective re-creation of reality according to an artist's metaphysical value-judgments". According to her, art allows philosophical concepts to be presented in a concrete form that can be easily grasped, thereby fulfilling a need of human consciousness. As a writer, the art form Rand focused on most closely was literature, where she considered romanticism to be the approach that most accurately reflected the existence of human free will. She described her own approach to literature as "romantic realism".

Rand acknowledged Aristotle as her greatest influence and remarked that in the history of philosophy she could only recommend "three A's"—Aristotle, Aquinas, and Ayn Rand. In a 1959 interview with Mike Wallace, when asked where her philosophy came from she responded: "Out of my own mind, with the sole acknowledgement of a debt to Aristotle, the only philosopher who ever influenced me. I devised the rest of my philosophy myself." However, she also found early inspiration in Friedrich Nietzsche, and scholars have found indications of his influence in early notes from Rand's journals, in passages from the first edition of "We the Living" (which Rand later revised), and in her overall writing style. However, by the time she wrote "The Fountainhead", Rand had turned against Nietzsche's ideas, and the extent of his influence on her even during her early years is disputed. Rational egoism was embodied by Russian author Nikolay Chernyshevsky in the 1863 novel "What Is to Be Done?" and several critics claim that "What Is to Be Done?" is one of the sources of inspiration for Rand's thought. For example, the book's main character Lopuhov says "I am not a man to make sacrifices. And indeed there are no such things. One acts in the way that one finds most pleasant." Among the philosophers Rand held in particular disdain was Immanuel Kant, whom she referred to as a "monster", although philosophers George Walsh and Fred Seddon have argued that she misinterpreted Kant and exaggerated their differences.

Rand said her most important contributions to philosophy were her "theory of concepts, [her] ethics, and [her] discovery in politics that evil—the violation of rights—consists of the initiation of force". She believed epistemology was a foundational branch of philosophy and considered the advocacy of reason to be the single most significant aspect of her philosophy, stating: "I am not "primarily" an advocate of capitalism, but of egoism; and I am not "primarily" an advocate of egoism, but of reason. If one recognizes the supremacy of reason and applies it consistently, all the rest follows."

During Rand's lifetime, her work evoked both extreme praise and condemnation. Rand's first novel, "We the Living", was admired by the literary critic H. L. Mencken, her Broadway play "Night of January 16th" was both a critical and popular success, and "The Fountainhead" was hailed by "The New York Times" reviewer Lorine Pruette as "masterful". Rand's novels were derided by some critics when they were first published as being long and melodramatic. However, they became bestsellers largely through word of mouth.

The first reviews Rand received were for "Night of January 16th". Reviews of the production were largely positive, but Rand considered even positive reviews to be embarrassing because of significant changes made to her script by the producer. Rand believed that her first novel, "We the Living", was not widely reviewed, but Rand scholar Michael S. Berliner writes "it was the most reviewed of any of her works", with approximately 125 different reviews being published in more than 200 publications. Overall these reviews were more positive than the reviews she received for her later work. Her 1938 novella "Anthem" received little attention from reviewers, both for its first publication in England and for subsequent re-issues.

Rand's first bestseller, "The Fountainhead", received far fewer reviews than "We the Living", and reviewers' opinions were mixed. Lorine Pruette's positive review in "The New York Times" was one that Rand greatly appreciated. Pruette called Rand "a writer of great power" who wrote "brilliantly, beautifully and bitterly", and stated that "you will not be able to read this masterful book without thinking through some of the basic concepts of our time". There were other positive reviews, but Rand dismissed most of them as either not understanding her message or as being from unimportant publications. Some negative reviews focused on the length of the novel, such as one that called it "a whale of a book" and another that said "anyone who is taken in by it deserves a stern lecture on paper-rationing". Other negative reviews called the characters unsympathetic and Rand's style "offensively pedestrian".

Rand's 1957 novel "Atlas Shrugged" was widely reviewed and many of the reviews were strongly negative. In "National Review", conservative author Whittaker Chambers called the book "sophomoric" and "remarkably silly". He described the tone of the book as "shrillness without reprieve" and accused Rand of supporting a godless system (which he related to that of the Soviets), claiming "From almost any page of "Atlas Shrugged", a voice can be heard, from painful necessity, commanding: 'To a gas chamber—go!. "Atlas Shrugged" received positive reviews from a few publications, including praise from the noted book reviewer John Chamberlain, but Rand scholar Mimi Reisel Gladstein later wrote that "reviewers seemed to vie with each other in a contest to devise the cleverest put-downs", calling it "execrable claptrap" and "a nightmare"—they also said it was "written out of hate" and showed "remorseless hectoring and prolixity".

Rand's nonfiction received far fewer reviews than her novels had. The tenor of the criticism for her first nonfiction book, "For the New Intellectual", was similar to that for "Atlas Shrugged", with philosopher Sidney Hook likening her certainty to "the way philosophy is written in the Soviet Union", and author Gore Vidal calling her viewpoint "nearly perfect in its immorality". Her subsequent books got progressively less attention from reviewers.

On the 100th anniversary of Rand's birth in 2005, Edward Rothstein, writing for "The New York Times", referred to her fictional writing as quaint utopian "retro fantasy" and programmatic neo-Romanticism of the misunderstood artist while criticizing her characters' "isolated rejection of democratic society". In 2007, book critic Leslie Clark described her fiction as "romance novels with a patina of pseudo-philosophy". In 2009, "GQ" and the "Left Behind
In 1991, a survey conducted for the Library of Congress and the Book-of-the-Month Club asked club members what the most influential book in the respondent's life was. Rand's "Atlas Shrugged" was the second most popular choice, after the Bible. Rand's books continue to be widely sold and read, with over 29 million copies sold (with about 10% of that total purchased for free distribution to schools by the Ayn Rand Institute). In 1998, Modern Library readers voted "Atlas Shrugged" the 20th century's finest work of fiction, followed by "The Fountainhead" in second place, "Anthem" in seventh, and "We the Living" eighth; none of the four appeared on the critics' list. Although Rand's influence has been greatest in the United States, there has been international interest in her work. Rand's work continues to be among the top sellers among books in India.

Rand's contemporary admirers included fellow novelists, such as Ira Levin, Kay Nolte Smith and L. Neil Smith; and later writers such as Erika Holzer and Terry Goodkind have been influenced by her. Other artists who have cited Rand as an important influence on their lives and thought include comic book artist Steve Ditko and musician Neil Peart of Rush. Rand provided a positive view of business and in response business executives and entrepreneurs have admired and promoted her work. John Allison of BB&T and Ed Snider of Comcast Spectacor have funded the promotion of Rand's ideas, while Mark Cuban (owner of the Dallas Mavericks) as well as John P. Mackey (CEO of Whole Foods) among others have said they consider Rand crucial to their success.

Rand and her works have been referred to in a variety of media: on television shows including animated sitcoms, live-action comedies, dramas, and game shows, as well as in movies and video games. She, or a character based on her, figures prominently (in positive and negative lights) in literary and science fiction novels by prominent American authors. Nick Gillespie, editor in chief of "Reason", has remarked that "Rand's is a tortured immortality, one in which she's as likely to be a punch line as a protagonist..." and that "jibes at Rand as cold and inhuman, run through the popular culture". Two movies have been made about Rand's life. A 1997 documentary film, "Ayn Rand: A Sense of Life", was nominated for the Academy Award for Best Documentary Feature. "The Passion of Ayn Rand", a 1999 television adaptation of the book of the same name, won several awards. Rand's image also appears on a 1999 U.S. postage stamp illustrated by artist Nick Gaetano.

Although she rejected the labels "conservative" and "libertarian", Rand has had continuing influence on right-wing politics and libertarianism. Jim Powell, a senior fellow at the Cato Institute, considers Rand one of the three most important women (along with Rose Wilder Lane and Isabel Paterson) of modern American libertarianism, and David Nolan, one of the founders of the Libertarian Party, stated that "without Ayn Rand, the libertarian movement would not exist". In his history of the libertarian movement, journalist Brian Doherty described her as "the most influential libertarian of the twentieth century to the public at large" and biographer Jennifer Burns referred to her as "the ultimate gateway drug to life on the right". Economist and Ayn Rand student George Reisman
She faced intense opposition from William F. Buckley, Jr. and other contributors for the "National Review" magazine. They published numerous criticisms in the 1950s and 1960s by Whittaker Chambers, Garry Wills, and M. Stanton Evans. Nevertheless, her influence among conservatives forced Buckley and other "National Review" contributors to reconsider how traditional notions of virtue and Christianity could be integrated with support for capitalism.

The political figures who cite Rand as an influence are usually conservatives (often members of the Republican Party), despite Rand taking some positions that are atypical for conservatives, such as being pro-choice and an atheist. A 1987 article in "The New York Times" referred to her as the Reagan administration's "novelist laureate". Republican Congressmen and conservative pundits have acknowledged her influence on their lives and have recommended her novels.

The financial crisis of 2007–2008 spurred renewed interest in her works, especially "Atlas Shrugged", which some saw as foreshadowing the crisis. Opinion articles compared real-world events with the plot of the novel. During this time, signs mentioning Rand and her fictional hero John Galt appeared at Tea Party protests. There was also increased criticism of her ideas, especially from the political left, with critics blaming the economic crisis on her support of selfishness and free markets, particularly through her influence on Alan Greenspan. For example, "Mother Jones" remarked that "Rand's particular genius has always been her ability to turn upside down traditional hierarchies and recast the wealthy, the talented, and the powerful as the oppressed" while equating Randian individual well-being with that of the "Volk" according to Goebbels. Corey Robin of "The Nation" alleged similarities between the "moral syntax of Randianism" and fascism.

During Rand's lifetime, her work received little attention from academic scholars. When the first academic book about Rand's philosophy appeared in 1971, its author declared writing about Rand "a treacherous undertaking" that could lead to "guilt by association" for taking her seriously. A few articles about Rand's ideas appeared in academic journals before her death in 1982, many of them in "The Personalist". One of these was "On the Randian Argument" by libertarian philosopher Robert Nozick, who argued that her meta-ethical argument is unsound and fails to solve the is–ought problem posed by David Hume. Some responses to Nozick by other academic philosophers were also published in "The Personalist" arguing that Nozick misstated Rand's case. Academic consideration of Rand as a literary figure during her life was even more limited. Academic Mimi Gladstein was unable to find any scholarly articles about Rand's novels when she began researching her in 1973, and only three such articles appeared during the rest of the 1970s.

Since Rand's death, interest in her work has gradually increased. Historian Jennifer Burns has identified "three overlapping waves" of scholarly interest in Rand, the most recent of which is "an explosion of scholarship" since the year 2000. However, few universities currently include Rand or Objectivism as a philosophical specialty or research area, with many literature and philosophy departments dismissing her as a pop culture phenomenon rather than a subject for serious study.

Gladstein, Harry Binswanger, Allan Gotthelf, John Hospers, Edwin A. Locke, Wallace Matson, Leonard Peikoff, Chris Matthew Sciabarra, and Tara Smith have taught her work in academic institutions. Sciabarra co-edits the "Journal of Ayn Rand Studies", a nonpartisan peer-reviewed journal dedicated to the study of Rand's philosophical and literary work. In 1987 Gotthelf, George Walsh and David Kelley co-founded the Ayn Rand Society, a group affiliated with the American Philosophical Association. In 2012, the University of Pittsburgh Press launched an "Ayn Rand Society Philosophical Studies" series based on the proceedings of the Society. Smith has written several academic books and papers on Rand's ideas, including "Ayn Rand's Normative Ethics: The Virtuous Egoist", a volume on Rand's ethical theory published by Cambridge University Press. Rand's ideas have also been made subjects of study at Clemson and Duke universities. Scholars of English and American literature have largely ignored her work, although attention to her literary work has increased since the 1990s.

Rand scholars Douglas Den Uyl and Douglas B. Rasmussen, while stressing the importance and originality of her thought, describe her style as "literary, hyperbolic and emotional". Political writer and Rand scholar Jack Wheeler writes that despite "the incessant bombast and continuous venting of Randian rage", Rand's ethics are "a most immense achievement, the study of which is vastly more fruitful than any other in contemporary thought". In the "Literary Encyclopedia" entry for Rand written in 2001, John David Lewis declared that "Rand wrote the most intellectually challenging fiction of her generation". In a 1999 interview in the "Chronicle of Higher Education", Sciabarra commented, "I know they laugh at Rand", while forecasting a growth of interest in her work in the academic community.

Libertarian philosopher Michael Huemer argues that very few people find Rand's ideas convincing, especially her ethics, which he believes are difficult to interpret and may lack logical coherence. He attributes the attention she receives to her being a "compelling writer", especially as a novelist. "Atlas Shrugged" thus outsells Rand's non-fiction works as well as the works of other philosophers of classical liberalism such as Ludwig von Mises, Friedrich Hayek, or Frederic Bastiat.

Political scientist Charles Murray, while praising Rand's literary accomplishments, criticizes her claim that her only "philosophical debt" was to Aristotle, instead asserting that her ideas were derivative of previous thinkers such as John Locke and Friedrich Nietzsche. Although Rand maintained that Objectivism was an integrated philosophical system, philosopher Robert H. Bass argues that her central ethical ideas are inconsistent and contradictory to her central political ideas.

In 1985, Rand's intellectual heir Leonard Peikoff established the Ayn Rand Institute, a nonprofit organization dedicated to promoting Rand's ideas and works. In 1990, after an ideological disagreement with Peikoff, philosopher David Kelley founded the Institute for Objectivist Studies, now known as The Atlas Society. In 2001, historian John McCaskey organized the Anthem Foundation for Objectivist Scholarship, which provides grants for scholarly work on Objectivism in academia. The charitable foundation of BB&T Corporation has also given grants for teaching Rand's ideas or works. The University of Texas at Austin, the University of Pittsburgh, and University of North Carolina at Chapel Hill
Category:1905 births
Category:1982 deaths
Category:20th-century American dramatists and playwrights
Category:20th-century American novelists
Category:20th-century American philosophers
Category:20th-century American women writers
Category:20th-century American writers
Category:20th-century atheists
Category:Activists from New York (state)
Category:American anti-communists
Category:American anti-fascists
Category:American anti-socialists
Category:American atheists
Category:American essayists
Category:American ethicists
Category:American people of Russian-Jewish descent
Category:American political activists
Category:American political theorists
Category:American science fiction writers
Category:Screenwriters from New York (state)
Category:American women activists
Category:American women dramatists and playwrights
Category:American women novelists
Category:American women philosophers
Category:American women screenwriters
Category:American secularists
Category:American writers of Russian descent
Category:Aristotelian philosophers
Category:Atheism activists
Category:Atheist philosophers
Category:Burials at Kensico Cemetery
Category:Critics of religions
Category:Critics of Marxism
Category:Epistemologists
Category:Exophonic writers
Category:Female critics of feminism
Category:Imperial Russian atheists
Category:Imperial Russian emigrants to the United States
Category:Imperial Russian Jews
Category:Jewish American dramatists and playwrights
Category:Jewish American novelists
Category:Jewish atheists
Category:Jewish philosophers
Category:Jewish women writers
Category:Metaphysicians
Category:Objectivists
Category:People of the New Deal arts projects
Category:People with acquired American citizenship
Category:Political philosophers
Category:Prometheus Award winners
Category:Pseudonymous women writers
Category:Pseudonymous writers
Category:Russian anti-communists
Category:Russian dramatists and playwrights
Category:Russian women essayists
Category:Russian women novelists
Category:Russian women philosophers
Category:Russian science fiction writers
Category:Russian screenwriters
Category:Russian women writers
Category:Saint Petersburg State University alumni
Category:Soviet emigrants to the United States
Category:American women essayists
Category:Women science fiction and fantasy writers
Category:Writers from New York City
Category:Writers from Saint Petersburg
Category:American pro-choice activists
Category:Atheist writers
Category:Russian atheism activists
Category:Philosophers from New York (state)
Category:Novelists from New York (state)
Category:20th-century Russian philosophers
Category:Lung cancer survivors
Category:Old Right (United States)
Category:20th-century essayists
Category:Jewish anti-communists
Category:Jewish anti-fascistsAlain Connes

Alain Connes (; born 1 April 1947) is a French mathematician, currently Professor at the Collège de France, IHÉS, Ohio State University and Vanderbilt University. He was an Invited Professor at the Conservatoire national des arts et métiers (2000).

Alain Connes studies operator algebras. In his early work on von Neumann algebras in the 1970s, he succeeded in obtaining the almost complete classification of injective factors. He also formulated the Connes embedding problem. Following this, he made contributions in operator K-theory and index theory, which culminated in the Baum–Connes conjecture. He also introduced cyclic cohomology in the early 1980s as a first step in the study of noncommutative differential geometry. He was a member of Bourbaki.

Connes has applied his work in areas of mathematics and theoretical physics, including number theory, differential geometry and particle physics.

Connes was awarded the Fields Medal in 1982, the Crafoord Prize in 2001




Category:1947 births
Category:Living people
Category:20th-century French mathematicians
Category:Members of the United States National Academy of Sciences
Category:21st-century mathematicians
Category:Collège de France faculty
Category:Institute for Advanced Study visiting scholars
Category:Fields Medalists
Category:Mathematical analysts
Category:Differential geometers
Category:École Normale Supérieure alumni
Category:Vanderbilt University faculty
Category:Foreign Members of the Russian Academy of Sciences
Category:Members of the French Academy of Sciences
Category:Members of the Norwegian Academy of Science and Letters
Category:Members of the Royal Danish Academy of Sciences and Letters
Category:Clay Research Award recipients
Category:Participants in the Les Houches Physics Summer SchoolAllan Dwan

Allan Dwan (3 April 1885 – 28 December 1981) was a pioneering Canadian-born American motion picture director, producer and screenwriter.

Born Joseph Aloysius Dwan in Toronto, Ontario, Canada, Dwan, was the younger son of commercial traveller of woolen clothing Joseph Michael Dwan (1857–1917) and his wife Mary Jane Dwan, "née" Hunt. The family moved to the United States when he was seven years old, on 4 December 1892, by ferry from Windsor to Detroit, according to his naturalization petition of August 1939. His elder brother, Leo Garnet Dwan (1883–1964), became a physician. At the University of Notre Dame, Allan Dwan studied engineering and began working for a lighting company in Chicago. However, he had a strong interest in the fledgling motion picture industry and when Essanay Studios offered him the opportunity to become a scriptwriter, he took the job. At that time, some of the East Coast movie makers began to spend winters in California where the climate allowed them to continue productions requiring warm weather. Soon, a number of movie companies worked there year-round and, in 1911, Dwan began working part-time in Hollywood. While still in New York, in 1917 he was the founding president of the East Coast chapter of the Motion Picture Directors Association.

Dwan operated Flying A Studios in La Mesa, California from August 1911 to July 1912. Flying A was one of the first motion pictures studios in California history. On 12 August 2011, a plaque was unveiled on the Wolff building at Third Avenue and La Mesa Boulevard commemorating Dwan and the Flying A Studios origins in La Mesa, California.

After making a series of westerns and comedies, Dwan directed fellow Canadian-American Mary Pickford in several very successful movies as well as her husband, Douglas Fairbanks, notably in the acclaimed 1922 "Robin Hood". Dwan directed Gloria Swanson in eight feature films, and one short film made in the short-lived sound-on-film process Phonofilm. This short, also featuring Thomas Meighan and Henri de la Falaise, was produced as a joke, for the 26 April 1925 "Lambs' Gambol" for The Lambs, with the film showing Swanson crashing the all-male club.

Following the introduction of the talkies, Dwan directed child-star Shirley Temple in "Heidi" (1937) and "Rebecca of Sunnybrook Farm" (1938).

Dwan helped launch the career of two other successful Hollywood directors, Victor Fleming, who went on to direct "The Wizard of Oz" and "Gone With the Wind", and Marshall Neilan, who became an actor, director, writer and producer. Over a long career spanning almost 50 years, Dwan directed 125 motion pictures, some of which were highly acclaimed, such as the 1949 box office hit, "Sands of Iwo Jima". He directed his last movie in 1961.

He died in Los Angeles at the age of ninety-six, and is interred in the San Fernando Mission Cemetery, Mission Hills, California.

Dwan has a star on the Hollywood Walk of Fame at 6263 Hollywood Boulevard.

Daniel Eagan of "Film Journal International" described Dwan as one of the early pioneers of cinema, stating that his style "is so basic as to seem invisible, but he treats his characters with uncommon sympathy and compassion."


Print E-book 


Category:1885 births
Category:1981 deaths
Category:American film directors
Category:American film producers
Category:American male screenwriters
Category:Western (genre) film directors
Category:Canadian emigrants to the United States
Category:Film directors from Toronto
Category:Writers from Toronto
Category:Disease-related deaths in California
Category:Burials at San Fernando Mission CemeteryAlgeria

Algeria (; ', Algerian Arabic '), officially the People's Democratic Republic of Algeria (), is a country in the Maghreb region of North Africa. The capital and most populous city is Algiers, located in the far north of the country on the Mediterranean coast. With an area of , Algeria is the tenth-largest country in the world, and the largest in Africa. Algeria is bordered to the northeast by Tunisia, to the east by Libya, to the west by Morocco, to the southwest by the Western Saharan territory, Mauritania, and Mali, to the southeast by Niger, and to the north by the Mediterranean Sea. The country is a semi-presidential republic consisting of 48 provinces and 1,541 communes (counties). It has the highest Human development index of all non-island African countries.

Ancient Algeria has known many empires and dynasties, including ancient Numidians, Phoenicians, Carthaginians, Romans, Vandals, Byzantines, Umayyads, Abbasids, Idrisid, Aghlabid, Rustamid, Fatimids, Zirid, Hammadids, Almoravids, Almohads, Spaniards, Ottomans and the French colonial empire. Berbers are the indigenous inhabitants of Algeria.

Algeria is a regional and middle power. It supplies large amounts of natural gas to Europe, and energy exports are the backbone of the economy. According to OPEC Algeria has the 16th largest oil reserves in the world and the second largest in Africa, while it has the 9th largest reserves of natural gas. Sonatrach, the national oil company, is the largest company in Africa. Algeria has one of the largest militaries in Africa and the largest defence budget on the continent; most of Algeria's weapons are imported from Russia, with whom they are a close ally. Algeria is a member of the African Union, the Arab League, OPEC, the United Nations and is a founding member of the Arab Maghreb Union.

The country's name derives from the city of Algiers. The city's name in turn derives from the Arabic ' (, "The Islands"), a truncated form of the older ' (, "Islands of the Mazghanna Tribe"), employed by medieval geographers such as al-Idrisi
In the region of Ain Hanech (Saïda Province), early remnants (200,000 BC) of hominid occupation in North Africa were found. Neanderthal tool makers produced hand axes in the Levalloisian and Mousterian styles (43,000 BC) similar to those in the Levant. Algeria was the site of the highest state of development of Middle Paleolithic Flake tool techniques. Tools of this era, starting about 30,000 BC, are called Aterian (after the archeological site of Bir el Ater, south of Tebessa).

The earliest blade industries in North Africa are called Iberomaurusian (located mainly in the Oran region). This industry appears to have spread throughout the coastal regions of the Maghreb between 15,000 and 10,000 BC. Neolithic civilization (animal domestication and agriculture) developed in the Saharan and Mediterranean Maghreb perhaps as early as 11,000 BC or as late as between 6000 and 2000 BC. This life, richly depicted in the Tassili n'Ajjer paintings, predominated in Algeria until the classical period. The mixture of peoples of North Africa coalesced eventually into a distinct native population that came to be called Berbers

From their principal center of power at Carthage, the Carthaginians expanded and established small settlements along the North African coast; by 600 BC, a Phoenician presence existed at Tipasa, east of Cherchell, Hippo Regius (modern Annaba) and Rusicade (modern Skikda). These settlements served as market towns as well as anchorages.

As Carthaginian power grew, its impact on the indigenous population increased dramatically. Berber civilization was already at a stage in which agriculture, manufacturing, trade, and political organization supported several states. Trade links between Carthage and the Berbers in the interior grew, but territorial expansion also resulted in the enslavement or military recruitment of some Berbers and in the extraction of tribute from others.
By the early 4th century BC, Berbers formed the single largest element of the Carthaginian army. In the Revolt of the Mercenaries, Berber soldiers rebelled from 241 to 238 BC after being unpaid following the defeat of Carthage in the First Punic War. They succeeded in obtaining control of much of Carthage's North African territory, and they minted coins bearing the name Libyan, used in Greek to describe natives of North Africa. The Carthaginian state declined because of successive defeats by the Romans in the Punic Wars.

In 146 BC the city of Carthage was destroyed. As Carthaginian power waned, the influence of Berber leaders in the hinterland grew. By the 2nd century BC, several large but loosely administered Berber kingdoms had emerged. Two of them were established in Numidia, behind the coastal areas controlled by Carthage. West of Numidia lay Mauretania, which extended across the Moulouya River in modern-day Morocco to the Atlantic Ocean. The high point of Berber civilization, unequaled until the coming of the Almohads and Almoravids more than a millennium later, was reached during the reign of Masinissa
After Masinissa's death in 148 BC, the Berber kingdoms were divided and reunited several times. Masinissa's line survived until 24 AD, when the remaining Berber territory was annexed to the Roman Empire. 

For several centuries Algeria was ruled by the Romans, who founded many colonies in the region. Like the rest of North Africa, Algeria was one of the breadbaskets of the empire, exporting cereals and other agricultural products. Saint Augustine was the bishop of Hippo Regius (modern-day Algeria), located in the Roman province of Africa. The Germanic Vandals of Geiseric moved into North Africa in 429, and by 435 controlled coastal Numidia. They did not make any significant settlement on the land, as they were harassed by local tribes. In fact, by the time the Byzantines arrived Lepcis Magna was abandoned and the Msellata region was occupied by the indigenous Laguatan who had been busy facilitating an Amazigh

After negligible resistance from the locals, Muslim Arabs of the Umayyad Caliphate conquered Algeria in the mid-7th century and a large number of the indigenous people converted to the newly founded faith of Islam. After the fall of the Umayyad Caliphate, numerous local dynasties emerged, including the Aghlabids, Almohads, Abdalwadid, Zirids, Rustamids, Hammadids, Almoravids and the Fatimids.

During the Middle Ages, North Africa was home to many great scholars, saints and sovereigns including Judah Ibn Quraysh, the first grammarian to suggest the Afroasiatic language family, the great Sufi masters Sidi Boumediene (Abu Madyan) and Sidi El Houari, and the Emirs Abd Al Mu'min and Yāghmūrasen. It was during this time that the Fatimids or children of Fatima, daughter of Muhammad, came to the Maghreb. These "Fatimids" went on to found a long lasting dynasty stretching across the Maghreb, Hejaz and the Levant, boasting a secular inner government, as well as a powerful army and navy, made up primarily of Arabs and Levantines extending from Algeria to their capital state of Cairo. The Fatimid caliphate began to collapse when its governors the Zirids seceded. In order to punish them the Fatimids sent the Arab Banu Hilal and Banu Sulaym against them. The resultant war is recounted in the epic Tāghribāt. In Al-Tāghrībāt the Amazigh Zirid Hero Khālīfā Al-Zānatī asks daily, for duels, to defeat the Hilalan hero Ābu Zayd al-Hilalī and many other Arab knights in a string of victories. The Zirids, however, were ultimately defeated ushering in an adoption of Arab customs and culture. The indigenous Amazigh tribes, however, remained largely independent, and depending on tribe, location and time controlled varying parts of the Maghreb, at times unifying it (as under the Fatimids). The Fatimid Islamic state, also known as Fatimid Caliphate made an Islamic empire that included North Africa, Sicily, Palestine, Jordan, Lebanon, Syria, Egypt, the Red Sea coast of Africa, Tihamah, Hejaz and Yemen

The Amazighs historically consisted of several tribes. The two main branches were the Botr and Barnès tribes, who were divided into tribes, and again into sub-tribes. Each region of the Maghreb contained several tribes (for example, Sanhadja, Houara, Zenata, Masmouda, Kutama, Awarba, and Berghwata). All these tribes made independent territorial decisions.

Several Amazigh dynasties emerged during the Middle Ages in the Maghreb and other nearby lands. Ibn Khaldun provides a table summarising the Amazigh dynasties of the Maghreb region, the Zirid, Banu Ifran, Maghrawa, Almoravid, Hammadid, Almohad, Merinid, Abdalwadid, Wattasid, Meknassa and Hafsid dynasties.

In the early 16th century, Spain constructed fortified outposts (presidios) on or near the Algerian coast. Spain took control of few coastal towns like Mers el Kebir in 1505; Oran in 1509; and Tlemcen, Mostaganem and Ténès

There reigned in Ifriqiya, current Tunisia, a Berber family, Zirid, somehow recognising the suzerainty of the Fatimid caliph of Cairo. Probably in 1048, the Zirid ruler or viceroy, el-Mu'izz, decided to end this suzerainty. The Fatimid state was too weak to attempt a punitive expedition; The Viceroy, el-Mu'izz, also found another means of revenge.

Between the Nile and the Red Sea were living Bedouin tribes expelled from Arabia for their disruption and turbulent influence, both Banu Hilal and Banu Sulaym among others, whose presence disrupted farmers in the Nile Valley since the nomads would often loot. The then Fatimid vizier devised to relinquish control of the Maghreb and obtained the agreement of his sovereign. This not only prompted the Bedouins to leave, but the Fatimid treasury even gave them a light expatriation cash allowance.

Whole tribes set off with women, children, ancestors, animals and camping equipment. Some stopped on the way, especially in Cyrenaica, where they are still one of the essential elements of the settlement but most arrived in Ifriqiya by the Gabes region. The Zirid ruler tried to stop this rising tide, but each meeting, the last under the walls of Kairouan, his troops were defeated and Arabs remained masters of the field.

The flood was still rising, and in 1057 the Arabs spread on the high plains of Constantine where they gradually choked Qalaa of Banu Hammad, as they had done Kairouan few decades ago. From there they gradually gained the upper Algiers and Oran plains. Some were forcibly taken by the Almohads in the second half of the 12th century. We can say that in the 13th century there were in all of North Africa

The region of Algeria was partially ruled by Ottomans for three centuries from 1516 to 1830. In 1516 the Turkish privateer brothers Aruj and Hayreddin Barbarossa, who operated successfully under the Hafsids, moved their base of operations to Algiers. They succeeded in conquering Jijel and Algiers from the Spaniards but eventually assumed control over the city and the surrounding region, forcing the previous ruler, Abu Hamo Musa III of the "Bani Ziyad" dynasty, to flee. When Aruj was killed in 1518 during his invasion of Tlemcen, Hayreddin succeeded him as military commander of Algiers. The Ottoman sultan gave him the title of beylerbey and a contingent of some 2,000 janissaries

The next beylerbey was Hayreddin's son Hasan, who assumed the position in 1544. Until 1587 the area was governed by officers who served terms with no fixed limits. Subsequently, with the institution of a regular Ottoman administration, governors with the title of pasha ruled for three-year terms. The pasha was assisted by janissaries, known in Algeria as the ojaq and led by an agha. Discontent among the ojaq rose in the mid-1600s because they were not paid regularly, and they repeatedly revolted against the pasha. As a result, the agha charged the pasha with corruption and incompetence and seized power in 1659.

Plague had repeatedly struck the cities of North Africa. Algiers lost from 30,000 to 50,000 inhabitants to the plague in 1620–21, and suffered high fatalities in 1654–57, 1665, 1691 and 1740–42.

In 1671, the taifa rebelled, killed the agha, and placed one of its own in power. The new leader received the title of dey. After 1689, the right to select the dey passed to the divan, a council of some sixty nobles. It was at first dominated by the "ojaq"; but by the 18th century, it had become the dey's instrument. In 1710, the dey persuaded the sultan to recognise him and his successors as regent, replacing the pasha in that role, although Algiers remained a part of the Ottoman Empire.

The dey was in effect a constitutional autocrat. The dey was elected for a life term, but in the 159 years (1671–1830) that the system survived, fourteen of the twenty-nine deys were assassinated. Despite usurpation, military coups and occasional mob rule, the day-to-day operation of Ottoman government was remarkably orderly. Although the regency patronised the tribal chieftains, it never had the unanimous allegiance of the countryside, where heavy taxation frequently provoked unrest. Autonomous tribal states were tolerated, and the regency's authority was seldom applied in the Kabylie

The Barbary pirates preyed on Christian and other non-Islamic shipping in the western Mediterranean Sea. The pirates often took the passengers and crew on the ships and sold them or used them as slaves. They also did a brisk business in ransoming some of the captives. According to Robert Davis, from the 16th to 19th century, pirates captured 1 million to 1.25 million Europeans as slaves. They often made raids, called Razzias, on European coastal towns to capture Christian slaves to sell at slave markets in North Africa and the Ottoman Empire.

In 1544, Hayreddin captured the island of Ischia, taking 4,000 prisoners, and enslaved some 9,000 inhabitants of Lipari, almost the entire population. In 1551, Turgut Reis enslaved the entire population of the Maltese island of Gozo, between 5,000 and 6,000, sending the captives to Libya. In 1554, pirates sacked Vieste in southern Italy and took an estimated 7,000 captives as slaves.

In 1558, Barbary corsairs captured the town of Ciutadella (Minorca), destroyed it, slaughtered the inhabitants and took 3,000 survivors as slaves to Istanbul. Barbary pirates often attacked the Balearic Islands, and in response, the residents built many coastal watchtowers and fortified churches. The threat was so severe that residents abandoned the island of Formentera

In July 1627 two pirate ships from Algiers sailed as far as Iceland, raiding and capturing slaves. Two weeks earlier another pirate ship from Salé in Morocco had also raided in Iceland. Some of the slaves brought to Algiers were later ransomed back to Iceland, but some chose to stay in Algeria. In 1629 pirate ships from Algeria raided the Faroe Islands.

Barbary raids in the Mediterranean continued to attack Spanish merchant shipping, and as a result, the Spanish navy bombarded Algiers in 1783 and 1784. In 1792, Spain abandoned Oran, selling it to the Ottoman Empire, and it became the site for a new bey in Algiers, though French influence in the region increased over the 19th century.

In the 19th century, the pirates forged affiliations with Caribbean powers, paying a "licence tax" in exchange for safe harbour of their vessels. One American slave reported that the Algerians had enslaved 130 American seamen in the Mediterranean and Atlantic from 1785 to 1793.

Piracy on American vessels in the Mediterranean resulted in the United States initiating the First (1801–1805) and Second Barbary Wars (1815). Following those wars, Algeria was weaker and Europeans, with an Anglo-Dutch fleet commanded by the British Lord Exmouth, attacked Algiers. After a nine-hour bombardment, they obtained a treaty from the Dey that reaffirmed the conditions imposed by Captain (later Commodore) Stephen Decatur (U.S. Navy) concerning the demands of tributes. In addition, the Dey agreed to end the practice of enslaving Christians.

Despite being removed from Algeria in the 19th century, Spain retained a presence in Morocco

Under the pretext of a slight to their consul, the French invaded and captured Algiers in 1830. Algerian slave trade and piracy ceased when the French conquered Algiers. The conquest of Algeria by the French took some time and resulted in considerable bloodshed. A combination of violence and disease epidemics caused the indigenous Algerian population to decline by nearly one-third from 1830 to 1872. Historian Ben Kiernan wrote on the French conquest of Algeria: "By 1875, the French conquest was complete. The war had killed approximately 825,000 indigenous Algerians since 1830." French losses from 1831–51 were 3,336 killed in action and 92,329 dead in the hospital. The population of Algeria, which stood at about 2.9 million in 1872, reached nearly 11 million in 1960. French policy was predicated on "civilising" the country. During this period, a small but influential French-speaking indigenous elite was formed, made up of Berbers, mostly Kabyles

From 1848 until independence, France administered the whole Mediterranean region of Algeria as an integral part and "département" of the nation. One of France's longest-held overseas territories, Algeria became a destination for hundreds of thousands of European immigrants, who became known as "colons" and later, as "Pied-Noirs." Between 1825 and 1847, 50,000 French people emigrated to Algeria. These settlers benefited from the French government's confiscation of communal land from tribal peoples, and the application of modern agricultural techniques that increased the amount of arable land. Many Europeans settled in Oran and Algiers

During the late 19th and early 20th century; the European share was almost a fifth of the population. The French government aimed at making Algeria an assimilated part of France, and this included substantial educational investments especially after 1900. The indigenous cultural and religious resistance heavily opposed this tendency, but in contrast to the other colonised countries' path in central Asia and Caucasus, Algeria kept its individual skills and a relatively human-capital intensive agriculture.

Gradually, dissatisfaction among the Muslim population, which lacked political and economic status in the colonial system, gave rise to demands for greater political autonomy and eventually independence from France. In May 1945, the uprising against the occupying French forces was suppressed through what is now known as the Sétif and Guelma massacre. Tensions between the two population groups came to a head in 1954, when the first violent events of what was later called the Algerian War began. Historians have estimated that between 30,000 and 150,000 Harkis and their dependents were killed by the Front de Libération Nationale (FLN) or by lynch mobs in Algeria. The FLN used hit and run attacks in Algeria and France as part of its war, and the French conducted severe reprisals.

The war led to the death of hundreds of thousands of Algerians and hundreds of thousands of injuries. Historians, like Alistair Horne and Raymond Aron, state that the actual number of Algerian Muslim war dead was far greater than the original FLN and official French estimates but was less than the 1 million deaths claimed by the Algerian government after independence. Horne estimated Algerian casualties during the span of eight years to be around 700,000. The war uprooted more than 2 million Algerians.

The war against French rule concluded in 1962, when Algeria gained complete independence following the March 1962 Evian agreements and the July 1962 self-determination referendum.

The number of European "Pied-Noirs" who fled Algeria totaled more than 900,000 between 1962 and 1964. The exodus to mainland France accelerated after the Oran massacre of 1962

Algeria's first president was the Front de Libération Nationale (FLN) leader Ahmed Ben Bella. Morocco's claim to portions of western Algeria led to the Sand War in 1963. Ben Bella was overthrown in 1965 by Houari Boumédiène, his former ally and defence minister. Under Ben Bella, the government had become increasingly socialist and authoritarian; Boumédienne continued this trend. But, he relied much more on the army for his support, and reduced the sole legal party to a symbolic role. He collectivised agriculture and launched a massive industrialization drive. Oil extraction facilities were nationalised. This was especially beneficial to the leadership after the international 1973 oil crisis.

In the 1960s and 1970s under President Houari Boumediene, Algeria pursued a program of industrialization within a state-controlled socialist economy. Boumediene's successor, Chadli Bendjedid, introduced some liberal economic reforms. He promoted a policy of Arabisation in Algerian society and public life. Teachers of Arabic, brought in from other Muslim countries, spread conventional Islamic thought in schools and sowed the seeds of a return to Orthodox Islam.

The Algerian economy became increasingly dependent on oil, leading to hardship when the price collapsed during the 1980s oil glut. Economic recession caused by the crash in world oil prices resulted in Algerian social unrest during the 1980s; by the end of the decade, Bendjedid introduced a multi-party system. Political parties developed, such as the Islamic Salvation Front
In December 1991 the Islamic Salvation Front dominated the first of two rounds of legislative elections. Fearing the election of an Islamist government, the authorities intervened on 11 January 1992, cancelling the elections. Bendjedid resigned and a High Council of State was installed to act as Presidency. It banned the FIS, triggering a civil insurgency between the Front's armed wing, the Armed Islamic Group, and the national armed forces, in which more than 100,000 people are thought to have died. The Islamist militants conducted a violent campaign of civilian massacres. At several points in the conflict, the situation in Algeria became a point of international concern, most notably during the crisis surrounding Air France Flight 8969, a hijacking perpetrated by the Armed Islamic Group. The Armed Islamic Group declared a ceasefire in October 1997.

Algeria held elections in 1999, considered biased by international observers and most opposition groups which were won by President Abdelaziz Bouteflika. He worked to restore political stability to the country and announced a "Civil Concord" initiative, approved in a referendum, under which many political prisoners were pardoned, and several thousand members of armed groups were granted exemption from prosecution under a limited amnesty, in force until 13 January 2000. The AIS disbanded and levels of insurgent violence fell rapidly. The Groupe Salafiste pour la Prédication et le Combat (GSPC), a splinter group of the Group Islamic Army, continued a terrorist campaign against the Government.

Bouteflika was re-elected in the April 2004 presidential election after campaigning on a programme of national reconciliation. The programme comprised economic, institutional, political and social reform to modernise the country, raise living standards, and tackle the causes of alienation. It also included a second amnesty initiative, the Charter for Peace and National Reconciliation, which was approved in a referendum in September 2005. It offered amnesty to most guerrillas and Government security forces.

In November 2008, the Algerian Constitution was amended following a vote in Parliament, removing the two-term limit on Presidential incumbents. This change enabled Bouteflika to stand for re-election in the 2009 presidential elections, and he was re-elected in April 2009. During his election campaign and following his re-election, Bouteflika promised to extend the programme of national reconciliation and a $150-billion spending programme to create three million new jobs, the construction of one million new housing units, and to continue public sector and infrastructure modernisation programmes.

A continuing series of protests throughout the country started on 28 December 2010, inspired by similar protests across the Middle East and North Africa. On 24 February 2011, the government lifted Algeria's 19-year-old state of emergency
Algeria is the largest country in Africa, and the Mediterranean Basin. Its southern part includes a significant portion of the Sahara. To the north, the Tell Atlas form with the Saharan Atlas, further south, two parallel sets of reliefs in approaching eastbound, and between which are inserted vast plains and highlands. Both Atlas tend to merge in eastern Algeria. The vast mountain ranges of Aures and Nememcha occupy the entire northeastern Algeria and are delineated by the Tunisian border. The highest point is Mount Tahat ( m).

Algeria lies mostly between latitudes 19° and 37°N (a small area is north of 37°N and south of 19°N), and longitudes 9°W and 12°E. Most of the coastal area is hilly, sometimes even mountainous, and there are a few natural harbours. The area from the coast to the Tell Atlas is fertile. South of the Tell Atlas is a steppe landscape ending with the Saharan Atlas; farther south, there is the Sahara desert.

The Hoggar Mountains (), also known as the Hoggar, are a highland region in central Sahara, southern Algeria. They are located about south of the capital, Algiers, and just east of Tamanghasset. Algiers, Oran, Constantine, and Annaba

In this region, midday desert temperatures can be hot year round. After sunset, however, the clear, dry air permits rapid loss of heat, and the nights are cool to chilly. Enormous daily ranges in temperature are recorded.

Rainfall is fairly plentiful along the coastal part of the Tell Atlas, ranging from annually, the amount of precipitation increasing from west to east. Precipitation is heaviest in the northern part of eastern Algeria, where it reaches as much as in some years.

Farther inland, the rainfall is less plentiful. Algeria also has ergs

The varied vegetation of Algeria includes coastal, mountainous and grassy desert-like regions which all support a wide range of wildlife. Many of the creatures comprising the Algerian wildlife live in close proximity to civilization. The most commonly seen animals include the wild boars, jackals, and gazelles, although it is not uncommon to spot fennecs (foxes), and jerboas. Algeria also has a small African leopard and Saharan cheetah population, but these are seldom seen. A species of deer, the Barbary stag, inhabits the dense humid forests in the north-eastern areas.

A variety of bird species makes the country an attraction for bird watchers. The forests are inhabited by boars and jackals. Barbary macaques are the sole native monkey. Snakes, monitor lizards, and numerous other reptiles can be found living among an array of rodents throughout the semi arid regions of Algeria. Many animals are now extinct, including the Barbary lions, Atlas bears and crocodiles.

In the north, some of the native flora includes Macchia scrub, olive trees, oaks, cedars and other conifers. The mountain regions contain large forests of evergreens (Aleppo pine, juniper, and evergreen oak) and some deciduous trees. Fig, eucalyptus, agave, and various palm trees grow in the warmer areas. The grape vine is indigenous to the coast. In the Sahara region, some oases have palm trees. Acacias with wild olives are the predominant flora in the remainder of the Sahara.

Camels are used extensively; the desert also abounds with venomous and nonvenomous snakes, scorpions

Elected politicians have relatively little sway over Algeria. Instead, a group of unelected civilian and military "décideurs", known as "le pouvoir" ("the power"), actually rule the country, even deciding who should be president. The most powerful man may be Mohamed Mediène, head of the military intelligence. In recent years, many of these generals have died or retired. After the death of General Larbi Belkheir, Bouteflika put loyalists in key posts, notably at Sonatrach, and secured constitutional amendments that make him re-electable indefinitely.

The head of state is the president of Algeria, who is elected for a five-year term. The president was formerly limited to two five-year terms, but a constitutional amendment passed by the Parliament on 11 November 2008 removed this limitation. The next presidential election will be in April 2019. Algeria has universal suffrage at 18 years of age. The President is the head of the army, the Council of Ministers and the High Security Council. He appoints the Prime Minister
The Algerian parliament is bicameral; the lower house, the People's National Assembly, has 462 members who are directly elected for five-year terms, while the upper house, the Council of the Nation, has 144 members serving six-year terms, of which 96 members are chosen by local assemblies and 48 are appointed by the president. According to the constitution, no political association may be formed if it is "based on differences in religion, language, race, gender, profession, or region". In addition, political campaigns must be exempt from the aforementioned subjects.

Parliamentary elections were last held in May 2012, and were judged to be largely free by international monitors, though local groups alleged fraud and irregularities. In the elections, the FLN won 221 seats, the military-backed National Rally for Democracy won 70, and the Islamist Green Algeria Alliance

Algeria is included in the European Union's European Neighbourhood Policy (ENP) which aims at bringing the EU and its neighbours closer.
Giving incentives and rewarding best performers, as well as offering funds in a faster and more flexible manner, are the two main principles underlying the European Neighbourhood Instrument (ENI) that came into force in 2014. It has a budget of €15.4 billion and provides the bulk of funding through a number of programmes.

In 2009, the French government agreed to compensate victims of nuclear tests in Algeria. Defense Minister Herve Morin stated that "It's time for our country to be at peace with itself, at peace thanks to a system of compensation and reparations," when presenting the draft law on the payouts. Algerian officials and activists believe that this is a good first step and hope that this move would encourage broader reparation.

Tensions between Algeria and Morocco in relation to the Western Sahara have been an obstacle to tightening the Arab Maghreb Union, nominally established in 1989, but which has carried little practical weight.

The military of Algeria consists of the People's National Army (ANP), the Algerian National Navy (MRA), and the Algerian Air Force (QJJ), plus the Territorial Air Defence Forces. It is the direct successor of the National Liberation Army (Armée de Libération Nationale or ALN), the armed wing of the nationalist National Liberation Front which fought French colonial occupation during the Algerian War of Independence (1954–62).

Total military personnel include 147,000 active, 150,000 reserve, and 187,000 paramilitary staff (2008 estimate). Service in the military is compulsory for men aged 19–30, for a total of 12 months. The military expenditure was 4.3% of the gross domestic product (GDP) in 2012. Algeria has the second largest military in North Africa with the largest defence budget in Africa ($10 billion).

In 2007, the Algerian Air Force signed a deal with Russia to purchase 49 MiG-29SMT and 6 MiG-29UBT at an estimated cost of $1.9 billion. Russia is also building two 636-type diesel submarines for Algeria.

Algeria has been categorized by Freedom House as "not free" since it began publishing such ratings in 1972, with the exception of 1989, 1990, and 1991, when the country was labeled "partly free." In December 2016, the "Euro-Mediterranean Human Rights Monitor" issued a report regarding violation of media freedom in Algeria. It clarified that the Algerian government imposed restriction on freedom of the press; expression; and right to peaceful demonstration, protest and assembly as well as intensified censorship of the media and websites. Due to the fact that the journalists and activists criticize the ruling government, some media organizations' licenses are canceled.

Independent and autonomous trade unions face routine harassment from the government, with many leaders imprisoned and protests suppressed. In 2016 a number of unions, many of which were involved in the 2010–2012 Algerian Protests, have been deregistered by the government.

Homosexuality is illegal in Algeria. Public homosexual behavior is punishable by up to two years in prison.

Algeria is divided into 48 provinces ("wilayas"), 553 districts ("daïras") and 1,541 municipalities ("baladiyahs"). Each province, district, and municipality is named after its seat

Algeria is classified as an upper middle income country by the World Bank. Algeria's currency is the dinar

In 2011 Algeria announced a budgetary surplus of $26.9 billion, 62% increase in comparison to 2010 surplus. In general, the country exported $73 billion worth of commodities while it imported $46 billion.

Thanks to strong hydrocarbon revenues, Algeria has a cushion of $173 billion in foreign currency reserves and a large hydrocarbon stabilization fund. In addition, Algeria's external debt is extremely low at about 2% of GDP. The economy remains very dependent on hydrocarbon wealth, and, despite high foreign exchange reserves (US$178 billion, equivalent to three years of imports), current expenditure growth makes Algeria's budget more vulnerable to the risk of prolonged lower hydrocarbon revenues.

In 2011, the agricultural sector and services recorded growth of 10% and 5.3%, respectively. About 14% of the labor force are employed in the agricultural sector. Fiscal policy in 2011 remained expansionist and made it possible to maintain the pace of public investment and to contain the strong demand for jobs and housing.

Algeria has not joined the WTO, despite several years of negotiations.

In March 2006, Russia agreed to erase $4.74 billion of Algeria's Soviet-era debt during a visit by Russian President Vladimir Putin to the country, the first by a Russian leader in half a century. In return, Algerian President Abdelaziz Bouteflika agreed to buy $7.5 billion worth of combat planes, air-defence systems and other arms from Russia, according to the head of Russia's state arms exporter Rosoboronexport

Algeria, whose economy is reliant on petroleum, has been an OPEC member since 1969. Its crude oil production stands at around 1.1 million barrels/day, but it is also a major gas producer and exporter, with important links to Europe. Hydrocarbons have long been the backbone of the economy, accounting for roughly 60% of budget revenues, 30% of GDP, and over 95% of export earnings. Algeria has the 10th-largest reserves of natural gas in the world and is the sixth-largest gas exporter. The U.S. Energy Information Administration reported that in 2005, Algeria had of proven natural-gas reserves. It also ranks 16th in oil reserves.

Non-hydrocarbon growth for 2011 was projected at 5%. To cope with social demands, the authorities raised expenditure, especially on basic food support, employment creation, support for SMEs, and higher salaries. High hydrocarbon prices have improved the current account and the already large international reserves position.

Income from oil and gas rose in 2011 as a result of continuing high oil prices, though the trend in production volume is downwards. Production from the oil and gas sector in terms of volume, continues to decline, dropping from 43.2 million tonnes to 32 million tonnes between 2007 and 2011. Nevertheless, the sector accounted for 98% of the total volume of exports in 2011, against 48% in 1962, and 70% of budgetary receipts, or US$71.4 billion.

The Algerian national oil company is Sonatrach, which plays a key role in all aspects of the oil and natural gas sectors in Algeria. All foreign operators must work in partnership with Sonatrach, which usually has majority ownership in production-sharing agreements.

Algeria has invested an estimated 100 billion dinars towards developing research facilities and paying researchers. This development program is meant to advance alternative energy production, especially solar and wind power. Algeria is estimated to have the largest solar energy potential in the Mediterranean, so the government has funded the creation of a solar science park in Hassi R'Mel. Currently, Algeria has 20,000 research professors at various universities and over 780 research labs, with state-set goals to expand to 1,000. Besides solar energy, areas of research in Algeria include space and satellite telecommunications, nuclear power and medical research.

Despite a decline in total unemployment

The development of the tourism sector in Algeria had previously been hampered by a lack of facilities, but since 2004 a broad tourism development strategy has been implemented resulting in many hotels of a high modern standard being built.

There are several UNESCO World Heritage Sites in Algeria including Al Qal'a of Beni Hammad, the first capital of the Hammadid empire; Tipasa, a Phoenician and later Roman town; and Djémila and Timgad, both Roman ruins; M'Zab Valley, a limestone valley containing a large urbanized oasis; and the Casbah of Algiers, an important citadel. The only natural World Heritage Site is the Tassili n'Ajjer

The Algerian road network is the densest in Africa; its length is estimated at 180,000 km of highways, with more than 3,756 structures and a paving rate of 85%. This network will be complemented by the East-West Highway, a major infrastructure project currently under construction. It is a 3-way, highway, linking Annaba in the extreme east to the Tlemcen in the far west. Algeria is also crossed by the Trans-Sahara Highway, which is now completely paved. This road is supported by the Algerian government to increase trade between the six countries crossed: Algeria, Mali, Niger, Nigeria, Chad and Tunisia
In January 2016 Algeria's population was an estimated 40.4 million, who are mainly Arab-Berber ethnically. At the outset of the 20th century, its population was approximately four million. About 90% of Algerians live in the northern, coastal area; the inhabitants of the Sahara desert are mainly concentrated in oases, although some 1.5 million remain nomadic or partly nomadic. 28.1% of Algerians are under the age of 15.

Women make up 70% of the country's lawyers and 60% of its judges and also dominate the field of medicine. Increasingly, women are contributing more to household income than men. 60% of university students are women, according to university researchers.

Between 90,000 and 165,000 Sahrawis from Western Sahara live in the Sahrawi refugee camps, in the western Algerian Sahara desert. There are also more than 4,000 Palestinian refugees, who are well integrated and have not asked for assistance from the United Nations High Commissioner for Refugees (UNHCR). In 2009, 35,000 Chinese migrant workers lived in Algeria.

The largest concentration of Algerian migrants outside Algeria is in France, which has reportedly over 1.7 million Algerians of up to the second generation.

Indigenous Berbers as well as Phoenicians, Romans, Byzantine Greeks, Arabs, Turks, various Sub-Saharan Africans, and French have contributed to the history of Algeria. Descendants of Andalusian refugees are also present in the population of Algiers and other cities. Moreover, Spanish was spoken by these Aragonese and Castillian Morisco descendants deep into the 18th century, and even Catalan was spoken at the same time by Catalan Morisco

Despite the dominance of the Berber culture and ethnicity in Algeria, the majority of Algerians identify with an Arabic-based identity, especially after the Arab nationalism rising in the 20th century. Berbers and Berber-speaking Algerians are divided into many groups with varying languages. The largest of these are the Kabyles, who live in the Kabylie region east of Algiers, the Chaoui of Northeast Algeria, the Tuaregs in the southern desert and the Shenwa people of North Algeria.

During the colonial period, there was a large (10% in 1960) European population who became known as "Pied-Noirs". They were primarily of French, Spanish and Italian

Modern Standard Arabic and Berber are the official languages. Algerian Arabic (Darja) is the language used by the majority of the population. Colloquial Algerian Arabic is heavily infused with borrowings from French and Berber.

Berber has been recognized as a "national language" by the constitutional amendment of 8 May 2002. Kabyle, the predominant Berber language, is taught and is partially co-official (with a few restrictions) in parts of Kabylie. In February 2016, the Algerian constitution passed a resolution that would make Berber an official language alongside Arabic.

Although French has no official status, Algeria is the second-largest Francophone country in the world in terms of speakers, and French is widely used in government, media (newspapers, radio, local television), and both the education system (from primary school onwards) and academia due to Algeria's colonial history. It can be regarded as a lingua franca of Algeria. In 2008, 11.2 million Algerians could read and write in French. An Abassa Institute study in April 2000 found that 60% of households could speak and understand French or 18 million in a population of 30 million then. After an earlier period during which the Algerian government tried to phase out French (which is why it has no official status), in recent decades the government has backtracked and reinforced the study of French and TV programs have reinforced use of the language.

Algeria emerged as a bilingual state after 1962. Colloquial Algerian Arabic is spoken by about 72% of the population and Berber by 27–30%.

Islam is the predominant religion in Algeria, with its adherents, mostly Sunnis, accounting for 99% of the population according to a 2012 CIA World Factbook estimate, and 97.9% according to Pew Research in 2010. There are about 150,000 Ibadis in the M'zab Valley in the region of Ghardaia.

Algeria has given the Muslim world a number of prominent thinkers, including Emir Abdelkader, Abdelhamid Ben Badis, Mouloud Kacem Naît Belkacem, Malek Bennabi and Mohamed Arkoun

Modern Algerian literature, split between Arabic, Tamazight and French, has been strongly influenced by the country's recent history. Famous novelists of the 20th century include Mohammed Dib, Albert Camus, Kateb Yacine and Ahlam Mosteghanemi while Assia Djebar is widely translated. Among the important novelists of the 1980s were Rachid Mimouni, later vice-president of Amnesty International, and Tahar Djaout, murdered by an Islamist group in 1993 for his secularist views.

Malek Bennabi and Frantz Fanon are noted for their thoughts on decolonization; Augustine of Hippo was born in Tagaste (modern-day Souk Ahras); and Ibn Khaldun, though born in Tunis, wrote the Muqaddima while staying in Algeria. The works of the Sanusi family in pre-colonial times, and of Emir Abdelkader and Sheikh Ben Badis in colonial times, are widely noted. The Latin author Apuleius was born in Madaurus (Mdaourouch), in what later became Algeria.

Contemporary Algerian cinema

Algerian painters, like Mohamed Racim or Baya, attempted to revive the prestigious Algerian past prior to French colonization, at the same time that they have contributed to the preservation of the authentic values of Algeria. In this line, Mohamed Temam, Abdelkhader Houamel have also returned through this art, scenes from the history of the country, the habits and customs of the past and the country life. Other new artistic currents including the one of M'hamed Issiakhem, Mohammed Khadda and Bachir Yelles, appeared on the scene of Algerian painting, abandoning figurative classical painting to find new pictorial ways, in order to adapt Algerian paintings to the new realities of the country through its struggle and its aspirations. Mohammed Khadda and M'hamed Issiakhem

The historic roots of Algerian literature go back to the Numidian and Roman African era, when Apuleius wrote "The Golden Ass", the only Latin novel to survive in its entirety. This period had also known Augustine of Hippo, Nonius Marcellus and Martianus Capella, among many others. The Middle Ages have known many Arabic writers who revolutionized the Arab world literature, with authors like Ahmad al-Buni, Ibn Manzur and Ibn Khaldoun, who wrote the Muqaddimah while staying in Algeria, and many others.

Albert Camus was an Algerian-born French Pied-Noir author. In 1957 he was awarded the Nobel Prize in literature.

Today Algeria contains, in its literary landscape, big names having not only marked the Algerian literature, but also the universal literary heritage in Arabic and French.

As a first step, Algerian literature was marked by works whose main concern was the assertion of the Algerian national entity, there is the publication of novels as the "Algerian trilogy" of Mohammed Dib, or even "Nedjma" of Kateb Yacine novel which is often regarded as a monumental and major work. Other known writers will contribute to the emergence of Algerian literature whom include Mouloud Feraoun, Malek Bennabi, Malek Haddad, Moufdi Zakaria, Abdelhamid Ben Badis, Mohamed Laïd Al-Khalifa, Mouloud Mammeri, Frantz Fanon, and Assia Djebar.

In the aftermath of the independence, several new authors emerged on the Algerian literary scene, they will attempt through their works to expose a number of social problems, among them there are Rachid Boudjedra, Rachid Mimouni, Leila Sebbar, Tahar Djaout and Tahir Wattar.

Currently, a part of Algerian writers tends to be defined in a literature of shocking expression, due to the terrorism that occurred during the 1990s, the other party is defined in a different style of literature who staged an individualistic conception of the human adventure. Among the most noted recent works, there is the writer, "the swallows of Kabul" and "the attack" of Yasmina Khadra, "the oath of barbarians" of Boualem Sansal, "memory of the flesh" of Ahlam Mosteghanemi and the last novel by Assia Djebar "nowhere in my father's House".

Chaâbi music is a typically Algerian musical genre characterized by specific rhythms and of Qacidate (Popular poems) in Arabic dialect. The undisputed master of this music is El Hadj M'Hamed El Anka. The Constantinois Malouf style is saved by musician from whom Mohamed Tahar Fergani

Folk music styles include Bedouin music, characterized by the poetic songs based on long kacida (poems); Kabyle music, based on a rich repertoire that is poetry and old tales passed through generations; Shawiya music, a folklore from diverse areas of the Aurès Mountains. Rahaba music style is unique to the Aures. Souad Massi is a rising Algerian folk singer. Other Algerian singers of the diaspora include Manel Filali in Germany and Kenza Farah in France. Tergui music is sung in Tuareg languages generally, Tinariwen had a worldwide success. Finally, the staïfi music is born in Sétif and remains a unique style of its kind.

Modern music is available in several facets, Raï music is a style typical of Western Algeria. Rap

The Algerian state's interest in film-industry activities can be seen in the annual budget of DZD 200 million (EUR 1.8) allocated to production, specific measures and an ambitious programme plan implemented by the Ministry of Culture in order to promote national production, renovate the cinema stock and remedy the weak links in distribution and exploitation.

The financial support provided by the state, through the Fund for the Development of the Arts, Techniques and the Film Industry (FDATIC) and the Algerian Agency for Cultural Influence (AARC), plays a key role in the promotion of national production. Between 2007 and 2013, FDATIC subsidised 98 films (feature films, documentaries and short films). In mid-2013, AARC had already supported a total of 78 films, including 42 feature films, 6 short films and 30 documentaries.

According to the European Audiovisual Observatory's LUMIERE database, 41 Algerian films were distributed in Europe between 1996 and 2013; 21 films in this repertoire were Algerian-French co-productions. "Days of Glory" (2006) and "Outside the Law" (2010) recorded the highest number of admissions in the European Union, 3,172,612 and 474,722, respectively.

Algeria won the Palme d'Or for "Chronicle of the Years of Fire" (1975), two Oscars for "Z" (1969), and other awards for the Italian-Algerian movie "The Battle of Algiers".

Various games have existed in Algeria since antiquity. In the Aures, people played several games such as El Kherba or El khergueba (chess variant). Playing cards, checkers and chess games are part of Algerian culture. Racing (fantasia) and rifle shooting are part of cultural recreation of the Algerians.

The first Algerian and African gold medalist is Boughera El Ouafi in 1928 Olympics of Amsterdam in the Marathon. The second Algerian Medalist was Alain Mimoun in 1956 Summer Olympics in Melbourne. Several men and women were champions in athletics in the 1990s including Noureddine Morceli, Hassiba Boulmerka, Nouria Merah-Benida, and Taoufik Makhloufi, all specialized in middle-distance running.

Football is the most popular sport in Algeria. Several names are engraved in the history of the sport, including Lakhdar Belloumi, Rachid Mekhloufi, Hassen Lalmas, Rabah Madjer, Salah Assad and Djamel Zidane. The Algeria national football team qualified for the 1982 FIFA World Cup, 1986 FIFA World Cup, 2010 FIFA World Cup and 2014 FIFA World Cup. In addition, several football clubs have won continental and international trophies as the club ES Sétif or JS Kabylia. The Algerian Football Federation

Algerian cuisine is rich and diverse. The country was considered as the "granary of Rome". It offers a component of dishes and varied dishes, depending on the region and according to the seasons. The cuisine uses cereals as the main products, since they are always produced with abundance in the country. There is not a dish where cereals are not present.

Algerian cuisine varies from one region to another, according to seasonal vegetables. It can be prepared using meat, fish and vegetables. Among the dishes known, couscous, chorba, rechta, chakhchoukha, berkoukes, shakshouka, mthewem, chtitha, mderbel, dolma, brik or bourek, garantita, lham'hlou, etc. Merguez sausage is widely used in Algeria, but it differs, depending on the region and on the added spices.

Cakes are marketed and can be found in cities either in Algeria, in Europe or North America. However, traditional cakes are also made at home, following the habits and customs of each family. Among these cakes, there are Tamina, Baklawa, Chrik, Garn logzelles, Griouech, Kalb el-louz, Makroud, Mbardja, Mchewek, Samsa, Tcharak, Baghrir, Khfaf, Zlabia, Aarayech, Ghroubiya and Mghergchette. Algerian pastry also contains Tunisian or French cakes. Marketed and home-made bread products include varieties such as Kessra or Khmira or Harchaya, chopsticks and so-called washers Khoubz dar or Matloue. Other traditional meals sold often as street food include mhadjeb or mahjouba, karantika, doubara, chakhchoukha, hassouna, and t'chicha.

In 2002, Algeria had inadequate numbers of physicians (1.13 per 1,000 people), nurses (2.23 per 1,000 people), and dentists (0.31 per 1,000 people). Access to "improved water sources" was limited to 92% of the population in urban areas and 80% of the population in the rural areas. Some 99% of Algerians living in urban areas, but only 82% of those living in rural areas, had access to "improved sanitation". According to the World Bank, Algeria is making progress toward its goal of "reducing by half the number of people without sustainable access to improved drinking water and basic sanitation by 2015". Given Algeria's young population, policy favors preventive health care and clinics over hospitals. In keeping with this policy, the government maintains an immunization program. However, poor sanitation and unclean water still cause tuberculosis, hepatitis, measles, typhoid fever, cholera and dysentery
Since 1972, Arabic is used as the language of instruction during the first nine years of schooling. From the third year, French is taught and it is also the language of instruction for science classes. The students can also learn English, Italian, Spanish and German. In 2008, new programs at the elementary appeared, therefore the compulsory schooling does not start at the age of six anymore, but at the age of five.
Apart from the 122 private schools, the Universities of the State are free of charge. After nine years of primary school, students can go to the high school or to an educational institution. The school offers two programs: general or technical. At the end of the third year of secondary school, students pass the exam of the baccalaureate, which allows once it is successful to pursue graduate studies in universities and institutes.

Education is officially compulsory for children between the ages of six and 15. In 2008, the illiteracy rate for people over 10 was 22.3%, 15.6% for men and 29.0% for women. The province with the lowest rate of illiteracy was Algiers Province at 11.6%, while the province with the highest rate was Djelfa Province at 35.5%.

Algeria has 26 universities and 67 institutions of higher education, which must accommodate a million Algerians and 80,000 foreign students in 2008. The University of Algiers, founded in 1879, is the oldest, it offers education in various disciplines (law, medicine, science and letters). 25 of these universities and almost all of the institutions of higher education were founded after the independence of the country.

Even if some of them offer instruction in Arabic like areas of law and the economy, most of the other sectors as science and medicine continue to be provided in French and English. Among the most important universities, there are the University of Sciences and Technology Houari Boumediene, the University of Mentouri Constantine, and University of Oran Es-Senia. The University of Abou Bekr Belkaïd in Tlemcen and University of Batna
Category:North African countries
Category:Maghrebi countries
Category:Saharan countries
Category:Arab republics
Category:Republics
Category:Arabic-speaking countries and territories
Category:Berber-speaking countries and territories
Category:French-speaking countries and territories
Category:G15 nations
Category:Member states of OPEC
Category:Member states of the African Union
Category:Member states of the Arab League
Category:Member states of the Organisation of Islamic Cooperation
Category:Member states of the Union for the Mediterranean
Category:Member states of the United Nations
Category:Requests for audio pronunciation (Arabic)
Category:Requests for audio pronunciation (Berber)
Category:States and territories established in 1962
Category:1962 establishments in Algeria
Category:1962 establishments in Africa
Category:Countries in AfricaList of Atlas Shrugged characters

This is a list of characters in Ayn Rand's novel "Atlas Shrugged."

The following are major characters from the novel.

Dagny Taggart is the protagonist of the novel. She is Vice-President in Charge of Operations for Taggart Transcontinental, under her brother, James Taggart. Given James' incompetence, Dagny is responsible for all the workings of the railroad.

Francisco d'Anconia is one of the central characters in "Atlas Shrugged", an owner by inheritance of the world's largest copper mining operation. He is a childhood friend, and the first love, of Dagny Taggart. A child prodigy of exceptional talents, Francisco was dubbed the "climax" of the d'Anconia line, an already prestigious family of skilled industrialists. He was a classmate of John Galt and Ragnar Danneskjöld and student of both Hugh Akston and Robert Stadler. He began working while still in school, proving that he could have made a fortune without the aid of his family's wealth and power. Later, Francisco bankrupts the d'Anconia business to put it out of others' reach. His full name is given as "Francisco Domingo Carlos Andres Sebastián d'Anconia".

John Galt is the primary male hero of "Atlas Shrugged". He initially appears as an unnamed menial worker for Taggart Transcontinental, who often dines with Eddie Willers in the employees' cafeteria, and leads Eddie to reveal important information about Dagny Taggart and Taggart Transcontinental. Only Eddie's side of their conversations is given in the novel. Later in the novel, the reader discovers this worker's true identity.

Before working for Taggart Transcontinental, Galt worked as an engineer for the Twentieth Century Motor Company, where he secretly invented a generator of usable electric energy from ambient static electricity, but abandoned his prototype, and his employment, when dissatisfied by an easily corrupted novel system of payment. This prototype was found by Dagny Taggart and Hank Rearden. Galt himself remains concealed throughout much of the novel, working a job and living by himself, where he unites the most skillful inventors and business leaders under his leadership. Much of the book's third division is given to his broadcast speech, which presents the author's philosophy of Objectivism.

Henry (known as "Hank") Rearden is one of the central characters in "Atlas Shrugged". He owns the most important steel company in the United States, and invents Rearden Metal, an alloy stronger than steel (with similar properties to stainless steel). He lives in Philadelphia with his wife Lillian, his brother Philip, and his elderly mother. Rearden represents a type of self-made man or prototypical hero, and illustrates Rand's theory of sex in so far as he accepts the traditional view of sexual congress as a subhuman instinct, but responds sexually to Dagny Taggart.

Edwin "Eddie" Willers is the Special Assistant to the Vice-President in Charge of Operations at Taggart Transcontinental. His father and grandfather worked for the Taggarts, and himself likewise. He is completely loyal to Dagny and to Taggart Transcontinental. Willers does not possess the creative ability of Galt's associates, but matches them in moral courage and is capable of appreciating and making use of their creations. After Dagny shifts her attention and loyalty to saving the captive Galt, Willers maintains the railroad until its collapse.

One of Galt's first followers, and world-famous as a pirate, who seizes relief ships sent from the United States to the People's States of Europe. He works to ensure that once those espousing Galt's philosophy are restored to their rightful place in society, they have enough capital to rebuild the world. Kept in the background for much of the book, Danneskjöld makes a personal appearance to encourage Rearden to persevere in his increasingly difficult situation, and gives him a bar of gold as compensation for the income taxes he has paid over the last several years. Danneskjöld is married to the actress Kay Ludlow; their relationship is kept hidden from the outside world, which only knows of Ludlow as a retired film star. Considered a misfit by Galt's other adherents, he views his actions as a means to speed the world along in understanding Galt's perspective.

According to Barbara Branden, who was closely associated with Rand at the time the book was written, there were sections written describing Danneskjöld's adventures at sea, cut from the final published text. In a 1974 comment at a lecture, Ayn Rand admitted that Danneskjöld's name was a tribute to Victor Hugo's novel, "Hans of Iceland", wherein the hero becomes the first of the Counts of Danneskjöld. In the published book, Danneskjöld is always seen through the eyes of others (Dagny Taggart or Hank Rearden), except for a brief paragraph in the very last chapter.

The President of Taggart Transcontinental and the book's most important antagonist. Taggart is an expert influence peddler but incapable of making operational decisions on his own. He relies on his sister, Dagny Taggart, to actually run the railroad, but nonetheless opposes her in almost every endeavor because of his various anti-capitalist moral and political beliefs. In a sense, he is the antithesis of Dagny. This contradiction leads to the recurring absurdity of his life: the desire to overcome those on whom his life depends, and the horror that he will succeed at this. In the final chapters of the novel, he suffers a complete mental breakdown upon realizing that he can no longer deceive himself in this respect.

The unsupportive wife of Hank Rearden, who dislikes his habits and (secretly at first) seeks to ruin Rearden to prove her own value. Lillian achieves this, when she passes information to James Taggart about her husband's affair with his sister. This information is used to persuade Rearden to sign a Gift Certificate which delivers all the property rights of Rearden Metal to others. Lillian thereafter uses James Taggart for sexual satisfaction, until Hank abandons her.

Ferris is a biologist who works as "co-ordinator" at the State Science Institute. He uses his position there to deride reason and productive achievement, and publishes a book entitled "Why Do You Think You Think?" He clashes on several occasions with Hank Rearden, and twice attempts to blackmail Rearden into giving up Rearden Metal. He is also one of the group of looters who tries to get Rearden to agree to the Steel Unification Plan. Ferris hosts the demonstration of the Project X weapon, and is the creator of the Ferris Persuader, a torture machine. When John Galt is captured by the looters, Ferris uses the device on Galt, but it breaks down before extracting the information Ferris wants from Galt. Ferris represents the group which uses brute force on the heroes to achieve the ends of the looters.

A former professor at Patrick Henry University, and along with colleague Hugh Akston, mentor to Francisco d'Anconia, John Galt and Ragnar Danneskjöld. He has since become a sell-out, one who had great promise but squandered it for social approval, to the detriment of the free. He works at the State Science Institute where all his inventions are perverted for use by the military, including the instrument of his demise: Project X (Xylophone). The character was, in part, modeled on J. Robert Oppenheimer, whom Rand had interviewed for an earlier project, and his part in the creation of nuclear weapons. To his former student Galt, Stadler represents the epitome of human evil, as the "man who knew better" but chose not to act for the good.

The incompetent and treacherous lobbyist whom Hank Rearden reluctantly employs in Washington
Category:Fictional socialites
Category:Lists of literary characters
Category:Fictional characters introduced in 1957Anthropology

Anthropology is the study of humans and human behavior and societies in the past and present. Social anthropology and cultural anthropology study the norms and values of societies. Linguistic anthropology studies how language affects social life. Biological or physical anthropology studies the biological development of humans.

Archaeology" is first attested in reference to history. Its present use first appeared in Renaissance Germany in the works of Magnus Hundt and Otto Casmann. Their New Latin ' derived from the combining forms of the Greek words "ánthrōpos" (, "human") and "lógos" (, "study"). (Its adjectival form appeared in the works of Aristotle.) It began to be used in English, possibly via French ', by the early 18th century.

In 1647, the Bartholins, founders of the University of Copenhagen, defined "" as follows:

Sporadic use of the term for some of the subject matter occurred subsequently, such as the use by Étienne Serres in 1839 to describe the natural history, or paleontology, of man, based on comparative anatomy, and the creation of a chair in anthropology and ethnography in 1850 at the National Museum of Natural History (France) by Jean Louis Armand de Quatrefages de Bréau. Various short-lived organizations of anthropologists had already been formed. The Société Ethnologique de Paris, the first to use Ethnology, was formed in 1839. Its members were primarily anti-slavery activists. When slavery was abolished in France in 1848 the Société was abandoned.

Meanwhile, the Ethnological Society of New York, currently the American Ethnological Society, was founded on its model in 1842, as well as the Ethnological Society of London in 1843, a break-away group of the Aborigines' Protection Society. These anthropologists of the times were liberal, anti-slavery, and pro-human-rights activists. They maintained international connections.

Anthropology and many other current fields are the intellectual results of the comparative methods developed in the earlier 19th century. Theorists in such diverse fields as anatomy, linguistics, and Ethnology, making feature-by-feature comparisons of their subject matters, were beginning to suspect that similarities between animals, languages, and folkways were the result of processes or laws unknown to them then. For them, the publication of Charles Darwin's "On the Origin of Species" was the epiphany of everything they had begun to suspect. Darwin himself arrived at his conclusions through comparison of species he had seen in agronomy and in the wild.

Darwin and Wallace unveiled evolution in the late 1850s. There was an immediate rush to bring it into the social sciences. Paul Broca in Paris was in the process of breaking away from the Société de biologie to form the first of the explicitly anthropological societies, the Société d'Anthropologie de Paris, meeting for the first time in Paris in 1859. When he read Darwin, he became an immediate convert to "Transformisme", as the French called evolutionism. His definition now became "the study of the human group, considered as a whole, in its details, and in relation to the rest of nature".

Broca, being what today would be called a neurosurgeon, had taken an interest in the pathology of speech. He wanted to localize the difference between man and the other animals, which appeared to reside in speech. He discovered the speech center of the human brain, today called Broca's area after him. His interest was mainly in Biological anthropology, but a German philosopher specializing in psychology, Theodor Waitz, took up the theme of general and social anthropology in his six-volume work, entitled "Die Anthropologie der Naturvölker", 1859–1864. The title was soon translated as "The Anthropology of Primitive Peoples". The last two volumes were published posthumously.

Waitz defined anthropology as "the science of the nature of man". By nature he meant matter animated by "the Divine breath"; i.e., he was an animist. Following Broca's lead, Waitz points out that anthropology is a new field, which would gather material from other fields, but would differ from them in the use of comparative anatomy, physiology, and psychology to differentiate man from "the animals nearest to him". He stresses that the data of comparison must be empirical, gathered by experimentation. The history of civilization, as well as ethnology, are to be brought into the comparison. It is to be presumed fundamentally that the species, man, is a unity, and that "the same laws of thought are applicable to all men".

Waitz was influential among the British ethnologists. In 1863 the explorer Richard Francis Burton and the speech therapist James Hunt broke away from the Ethnological Society of London to form the Anthropological Society of London, which henceforward would follow the path of the new anthropology rather than just ethnology. It was the 2nd society dedicated to general anthropology in existence. Representatives from the French "Société" were present, though not Broca. In his keynote address, printed in the first volume of its new publication, "The Anthropological Review", Hunt stressed the work of Waitz, adopting his definitions as a standard. Among the first associates were the young Edward Burnett Tylor, inventor of cultural anthropology, and his brother Alfred Tylor, a geologist. Previously Edward had referred to himself as an ethnologist; subsequently, an anthropologist.

Similar organizations in other countries followed: The Anthropological Society of Madrid (1865), the American Anthropological Association in 1902, the Anthropological Society of Vienna (1870), the Italian Society of Anthropology and Ethnology (1871), and many others subsequently. The majority of these were evolutionist. One notable exception was the Berlin Society for Anthropology, Ethnology, and Prehistory (1869) founded by Rudolph Virchow, known for his vituperative attacks on the evolutionists. Not religious himself, he insisted that Darwin's conclusions lacked empirical foundation.

During the last three decades of the 19th century, a proliferation of anthropological societies and associations occurred, most independent, most publishing their own journals, and all international in membership and association. The major theorists belonged to these organizations. They supported the gradual osmosis of anthropology curricula into the major institutions of higher learning. By 1898 the American Association for the Advancement of Science was able to report that 48 educational institutions in 13 countries had some curriculum in anthropology. None of the 75 faculty members were under a department named anthropology.

This meager statistic expanded in the 20th century to comprise anthropology departments in the majority of the world's higher educational institutions, many thousands in number. Anthropology has diversified from a few major subdivisions to dozens more. Practical anthropology, the use of anthropological knowledge and technique to solve specific problems, has arrived; for example, the presence of buried victims might stimulate the use of a forensic archaeologist to recreate the final scene. The organization has reached global level. For example, the World Council of Anthropological Associations (WCAA), "a network of national, regional and international associations that aims to promote worldwide communication and cooperation in anthropology", currently contains members from about three dozen nations.

Since the work of Franz Boas and Bronisław Malinowski in the late 19th and early 20th centuries, "social" anthropology in Great Britain and "cultural" anthropology in the US have been distinguished from other social sciences by its emphasis on cross-cultural comparisons, long-term in-depth examination of context, and the importance it places on participant-observation or experiential immersion in the area of research. Cultural anthropology, in particular, has emphasized cultural relativism, holism, and the use of findings to frame cultural critiques. This has been particularly prominent in the United States, from Boas' arguments against 19th-century racial ideology, through Margaret Mead's advocacy for gender equality and sexual liberation, to current criticisms of post-colonial oppression and promotion of multiculturalism. Ethnography is one of its primary research designs as well as the text that is generated from anthropological fieldwork.

In Great Britain and the Commonwealth countries, the British tradition of social anthropology tends to dominate. In the United States, anthropology has traditionally been divided into the four field approach developed by Franz Boas in the early 20th century: "biological" or "physical" anthropology; "social", "cultural", or "sociocultural" anthropology; and archaeology; plus anthropological linguistics. These fields frequently overlap but tend to use different methodologies and techniques.

European countries with overseas colonies tended to practice more ethnology (a term coined and defined by Adam F. Kollár in 1783). It is sometimes referred to as sociocultural anthropology in the parts of the world that were influenced by the European tradition.

Anthropology is a global discipline involving humanities, social sciences and natural sciences. Anthropology builds upon knowledge from natural sciences, including the discoveries about the origin and evolution of "Homo sapiens", human physical traits, human behavior, the variations among different groups of humans, how the evolutionary past of "Homo sapiens" has influenced its social organization and culture, and from social sciences, including the organization of human social and cultural relations, institutions, social conflicts, etc. Early anthropology originated in Classical Greece and Persia and studied and tried to understand observable cultural diversity. As such, anthropology has been central in the development of several new (late 20th century) interdisciplinary fields such as cognitive science, global studies, and various ethnic studies.

According to Clifford Geertz,
Sociocultural anthropology has been heavily influenced by structuralist and postmodern theories, as well as a shift toward the analysis of modern societies. During the 1970s and 1990s, there was an epistemological shift away from the positivist traditions that had largely informed the discipline. During this shift, enduring questions about the nature and production of knowledge came to occupy a central place in cultural and social anthropology. In contrast, archaeology and biological anthropology remained largely positivist. Due to this difference in epistemology, the four sub-fields of anthropology have lacked cohesion over the last several decades.

Sociocultural anthropology draws together the principle axes of cultural anthropology and social anthropology. Cultural anthropology is the comparative study of the manifold ways in which people "make sense" of the world around them, while social anthropology is the study of the "relationships" among individuals and groups. Cultural anthropology is more related to philosophy, literature and the arts (how one's culture affects the experience for self and group, contributing to a more complete understanding of the people's knowledge, customs, and institutions), while social anthropology is more related to sociology and history. In that, it helps develop an understanding of social structures, typically of others and other populations (such as minorities, subgroups, dissidents, etc.). There is no hard-and-fast distinction between them, and these categories overlap to a considerable degree.

Inquiry in sociocultural anthropology is guided in part by cultural relativism, the attempt to understand other societies in terms of their own cultural symbols and values. Accepting other cultures in their own terms moderates reductionism in cross-cultural comparison. This project is often accommodated in the field of ethnography. Ethnography can refer to both a methodology and the product of ethnographic research, i.e. an ethnographic monograph. As a methodology, ethnography is based upon long-term fieldwork within a community or other research site. Participant observation is one of the foundational methods of social and cultural anthropology. Ethnology involves the systematic comparison of different cultures. The process of participant-observation can be especially helpful to understanding a culture from an emic (conceptual, vs. etic, or technical) point of view.

The study of kinship and social organization is a central focus of sociocultural anthropology, as kinship is a human universal. Sociocultural anthropology also covers economic and political organization, law and conflict resolution, patterns of consumption and exchange, material culture, technology, infrastructure, gender relations, ethnicity, childrearing and socialization, religion, myth, symbols, values, etiquette, worldview, sports, music, nutrition, recreation, games, food, festivals, and language (which is also the object of study in linguistic anthropology).

Comparison across cultures is a key element of method in sociocultural anthropology, including the industrialized (and de-industrialized) West. Cultures in the Standard Cross-Cultural Sample

Biological anthropology and physical anthropology are synonymous terms to describe anthropological research focused on the study of humans and non-human primates in their biological, evolutionary, and demographic dimensions. It examines the biological and social factors that have affected the evolution of humans and other primates, and that generate, maintain or change contemporary genetic and physiological variation.

Archaeology

Linguistic anthropology (not to be confused with anthropological linguistics) seeks to understand the processes of human communications, verbal and non-verbal, variation in language across time and space, the social uses of language, and the relationship between language and culture. It is the branch of anthropology that brings linguistic methods to bear on anthropological problems, linking the analysis of linguistic forms and processes to the interpretation of sociocultural processes. Linguistic anthropologists often draw on related fields including sociolinguistics, pragmatics, cognitive linguistics, semiotics, discourse analysis, and narrative
Media anthropology (also known as the anthropology of media or mass media) emphasizes ethnographic studies as a means of understanding producers, audiences, and other cultural and social aspects of mass media. The types of ethnographic contexts explored range from contexts of media production (e.g., ethnographies of newsrooms in newspapers, journalists in the field, film production) to contexts of media reception, following audiences in their everyday responses to media. Other types include cyber anthropology, a relatively new area of internet research, as well as ethnographies of other areas of research which happen to involve media, such as development work, social movements, or health education. This is in addition to many classic ethnographic contexts, where media such as radio, the press, new media, and television have started to make their presences felt since the early 1990s.

Ethnomusicology is an academic field encompassing various approaches to the study of music (broadly defined), that emphasize its cultural, social, material, cognitive, biological, and other dimensions or contexts instead of or in addition to its isolated sound component or any particular repertoire.

Visual anthropology is concerned, in part, with the study and production of ethnographic photography, film and, since the mid-1990s, new media. While the term is sometimes used interchangeably with ethnographic film, visual anthropology also encompasses the anthropological study of visual representation, including areas such as performance, museums, art, and the production and reception of mass media. Visual representations from all cultures, such as sandpaintings, tattoos, sculptures and reliefs, cave paintings, scrimshaw, jewelry, hieroglyphics, paintings, and photographs are included in the focus of visual anthropology.

Economic anthropology attempts to explain human economic behavior in its widest historic, geographic and cultural scope. It has a complex relationship with the discipline of economics, of which it is highly critical. Its origins as a sub-field of anthropology begin with the Polish-British founder of anthropology, Bronisław Malinowski, and his French compatriot, Marcel Mauss, on the nature of gift-giving exchange (or reciprocity) as an alternative to market exchange. Economic Anthropology remains, for the most part, focused upon exchange. The school of thought derived from Marx and known as Political Economy focuses on production, in contrast. Economic anthropologists have abandoned the primitivist niche they were relegated to by economists, and have now turned to examine corporations, banks, and the global financial system from an anthropological perspective.

Political economy in anthropology is the application of the theories and methods of Historical Materialism to the traditional concerns of anthropology, including, but not limited to, non-capitalist societies. Political economy introduced questions of history and colonialism to ahistorical anthropological theories of social structure and culture. Three main areas of interest rapidly developed. The first of these areas was concerned with the "pre-capitalist" societies that were subject to evolutionary "tribal" stereotypes. Sahlin's work on hunter-gatherers as the "original affluent society" did much to dissipate that image. The second area was concerned with the vast majority of the world's population at the time, the peasantry, many of whom were involved in complex revolutionary wars such as in Vietnam. The third area was on colonialism, imperialism, and the creation of the capitalist world-system. More recently, these political economists have more directly addressed issues of industrial (and post-industrial) capitalism around the world.

Applied anthropology refers to the application of the method and theory of anthropology to the analysis and solution of practical problems. It is a "complex of related, research-based, instrumental methods which produce change or stability in specific cultural systems through the provision of data, initiation of direct action, and/or the formulation of policy". More simply, applied anthropology is the practical side of anthropological research; it includes researcher involvement and activism within the participating community. It is closely related to development anthropology (distinct from the more critical anthropology of development).

Anthropology of development tends to view development from a "critical" perspective. The kind of issues addressed and implications for the approach simply involve pondering why, if a key development goal is to alleviate poverty, is poverty increasing? Why is there such a gap between plans and outcomes? Why are those working in development so willing to disregard history and the lessons it might offer? Why is development so externally driven rather than having an internal basis? In short, why does so much planned development fail?

"Kinship" can refer both to "the study of" the patterns of social relationships in one or more human cultures, or it can refer to "the patterns of social relationships" themselves. Over its history, anthropology has developed a number of related concepts and terms, such as "descent", "descent groups", "lineages", "affines", "cognates", and even "fictive kinship". Broadly, kinship patterns may be considered to include people related both by descent (one's social relations during development), and also relatives by marriage.

Feminist anthropology is a four field approach to anthropology (archeological, biological, cultural, linguistic) that seeks to reduce male bias in research findings, anthropological hiring practices, and the scholarly production of knowledge. Anthropology engages often with feminists from non-Western traditions, whose perspectives and experiences can differ from those of white European and American feminists. Historically, such 'peripheral' perspectives have sometimes been marginalized and regarded as less valid or important than knowledge from the western world. Feminist anthropologists have claimed that their research helps to correct this systematic bias in mainstream feminist theory. Feminist anthropologists are centrally concerned with the construction of gender across societies. Feminist anthropology is inclusive of birth anthropology as a specialization.

The first African-American female anthropologist and Caribbeanist is said to be Vera Mae Green who studied ethnic and family relations in the Caribbean as well as the United States, and thereby tried to improve the way black life, experiences, and culture were studied.

Medical anthropology is an interdisciplinary field which studies "human health and disease, health care systems, and biocultural adaptation". It is believed that William Caudell was the first to discover the field of medical anthropology. Currently, research in medical anthropology is one of the main growth areas in the field of anthropology as a whole. It focuses on the following six basic fields:

Other subjects that have become central to medical anthropology worldwide are violence and social suffering (Farmer, 1999, 2003; Beneduce, 2010) as well as other issues that involve physical and psychological harm and suffering that are not a result of illness. On the other hand, there are fields that intersect with medical anthropology in terms of research methodology and theoretical production, such as "cultural psychiatry" and "transcultural psychiatry" or "ethnopsychiatry".

Nutritional anthropology is a synthetic concept that deals with the interplay between economic systems, nutritional status and food security, and how changes in the former affect the latter. If economic and environmental changes in a community affect access to food, food security, and dietary health, then this interplay between culture and biology is in turn connected to broader historical and economic trends associated with globalization. Nutritional status affects overall health status, work performance potential, and the overall potential for economic development (either in terms of human development or traditional western models) for any given group of people.

Psychological anthropology is an interdisciplinary subfield of anthropology that studies the interaction of cultural and mental processes. This subfield tends to focus on ways in which humans' development and enculturation within a particular cultural group&nbsp– with its own history, language, practices, and conceptual categories&nbsp– shape processes of human cognition, emotion, perception, motivation, and mental health. It also examines how the understanding of cognition, emotion, motivation, and similar psychological processes inform or constrain our models of cultural and social processes.

Cognitive anthropology seeks to explain patterns of shared knowledge, cultural innovation, and transmission over time and space using the methods and theories of the cognitive sciences (especially experimental psychology and evolutionary biology) often through close collaboration with historians, ethnographers, archaeologists, linguists, musicologists and other specialists engaged in the description and interpretation of cultural forms. Cognitive anthropology is concerned with what people from different groups know and how that implicit knowledge changes the way people perceive and relate to the world around them.

Transpersonal anthropology studies the relationship between altered states of consciousness and culture. As with transpersonal psychology, the field is much concerned with altered states of consciousness (ASC) and transpersonal experience. However, the field differs from mainstream transpersonal psychology in taking more cognizance of cross-cultural issues – for instance, the roles of myth, ritual, diet, and texts in evoking and interpreting extraordinary experiences.

Political anthropology concerns the structure of political systems, looked at from the basis of the structure of societies. Political anthropology developed as a discipline concerned primarily with politics in stateless societies, a new development started from the 1960s, and is still unfolding: anthropologists started increasingly to study more "complex" social settings in which the presence of states, bureaucracies and markets entered both ethnographic accounts and analysis of local phenomena. The turn towards complex societies meant that political themes were taken up at two main levels. Firstly, anthropologists continued to study political organization and political phenomena that lay outside the state-regulated sphere (as in patron-client relations or tribal political organization). Secondly, anthropologists slowly started to develop a disciplinary concern with states and their institutions (and on the relationship between formal and informal political institutions). An anthropology of the state developed, and it is a most thriving field today. Geertz' comparative work on "Negara", the Balinese state, is an early, famous example.

Legal anthropology or anthropology of law specializes in "the cross-cultural study of social ordering". Earlier legal anthropological research often focused more narrowly on conflict management, crime, sanctions, or formal regulation. More recent applications include issues such as human rights, legal pluralism, and political uprisings.

Public anthropology was created by Robert Borofsky, a professor at Hawaii Pacific University, to "demonstrate the ability of anthropology and anthropologists to effectively address problems beyond the discipline – illuminating larger social issues of our times as well as encouraging broad, public conversations about them with the explicit goal of fostering social change".

Cyborg anthropology originated as a sub-focus group within the American Anthropological Association's annual meeting in 1993. The sub-group was very closely related to STS and the Society for the Social Studies of Science. Donna Haraway's 1985 "Cyborg Manifesto" could be considered the founding document of cyborg anthropology by first exploring the philosophical and sociological ramifications of the term. Cyborg anthropology studies humankind and its relations with the technological systems it has built, specifically modern technological systems that have reflexively shaped notions of what it means to be human beings.

Digital anthropology is the study of the relationship between humans and digital-era technology, and extends to various areas where anthropology and technology intersect. It is sometimes grouped with sociocultural anthropology, and sometimes considered part of material culture. The field is new, and thus has a variety of names with a variety of emphases. These include techno-anthropology, digital ethnography, cyberanthropology, and virtual anthropology.

Ecological anthropology is defined as the "study of cultural adaptations to environments". The sub-field is also defined as, "the study of relationships between a population of humans and their biophysical environment". The focus of its research concerns "how cultural beliefs and practices helped human populations adapt to their environments, and how their environment across space and time. The contemporary perspective of environmental anthropology, and arguably at least the backdrop, if not the focus of most of the ethnographies and cultural fieldworks of today, is political ecology. Many characterize this new perspective as more informed with culture, politics and power, globalization, localized issues, century anthropology and more. The focus and data interpretation is often used for arguments for/against or creation of policy, and to prevent corporate exploitation and damage of land. Often, the observer has become an active part of the struggle either directly (organizing, participation) or indirectly (articles, documentaries, books, ethnographies). Such is the case with environmental justice advocate Melissa Checker and her relationship with the people of Hyde Park.

Ethnohistory is the study of ethnographic cultures and indigenous customs by examining historical records. It is also the study of the history of various ethnic groups that may or may not exist today. Ethnohistory uses both historical and ethnographic data as its foundation. Its historical methods and materials go beyond the standard use of documents and manuscripts. Practitioners recognize the utility of such source material as maps, music, paintings, photography, folklore, oral tradition, site exploration, archaeological materials, museum collections, enduring customs, language, and place names.

The anthropology of religion involves the study of religious institutions in relation to other social institutions, and the comparison of religious beliefs and practices across cultures. Modern anthropology assumes that there is complete continuity between magical thinking and religion, and that every religion is a cultural product, created by the human community that worships it.

Urban anthropology is concerned with issues of urbanization, poverty, and neoliberalism. Ulf Hannerz quotes a 1960s remark that traditional anthropologists were "a notoriously agoraphobic lot, anti-urban by definition". Various social processes in the Western World as well as in the "Third World" (the latter being the habitual focus of attention of anthropologists) brought the attention of "specialists in 'other cultures'" closer to their homes. There are two main approaches to urban anthropology: examining the types of cities or examining the social issues within the cities. These two methods are overlapping and dependent of each other. By defining different types of cities, one would use social factors as well as economic and political factors to categorize the cities. By directly looking at the different social issues, one would also be studying how they affect the dynamic of the city.

Anthrozoology (also known as "human–animal studies") is the study of interaction between living things. It is an interdisciplinary field that overlaps with a number of other disciplines, including anthropology, ethology, medicine, psychology, veterinary medicine and zoology. A major focus of anthrozoologic research is the quantifying of the positive effects of human-animal relationships on either party and the study of their interactions. It includes scholars from a diverse range of fields, including anthropology, sociology, biology, and philosophy.

Biocultural anthropology is the scientific exploration of the relationships between human biology and culture. Physical anthropologists throughout the first half of the 20th century viewed this relationship from a racial perspective; that is, from the assumption that typological human biological differences lead to cultural differences. After World War II the emphasis began to shift toward an effort to explore the role culture plays in shaping human biology.

Evolutionary anthropology is the interdisciplinary study of the evolution of human physiology and human behaviour and the relation between hominins and non-hominin primates. Evolutionary anthropology is based in natural science and social science, combining the human development with socioeconomic factors. Evolutionary anthropology is concerned with both biological and cultural evolution of humans, past and present. It is based on a scientific approach, and brings together fields such as archaeology, behavioral ecology, psychology, primatology, and genetics. It is a dynamic and interdisciplinary field, drawing on many lines of evidence to understand the human experience, past and present.

Forensic anthropology is the application of the science of physical anthropology and human osteology in a legal setting, most often in criminal cases where the victim's remains are in the advanced stages of decomposition. A forensic anthropologist can assist in the identification of deceased individuals whose remains are decomposed, burned, mutilated or otherwise unrecognizable. The adjective "forensic" refers to the application of this subfield of science to a court of law.

Paleoanthropology combines the disciplines of paleontology and physical anthropology. It is the study of ancient humans, as found in fossil hominid evidence such as petrifacted bones and footprints. Genetics and morphology of specimens are crucially important to this field. Markers on specimens, such as enamel fractures and dental decay on teeth, can also give insight into the behaviour and diet of past populations.

Contemporary anthropology is an established science with academic departments at most universities and colleges. The single largest organization of anthropologists is the American Anthropological Association (AAA), which was founded in 1903. Its members are anthropologists from around the globe.

In 1989, a group of European and American scholars in the field of anthropology established the European Association of Social Anthropologists (EASA) which serves as a major professional organization for anthropologists working in Europe. The EASA seeks to advance the status of anthropology in Europe and to increase visibility of marginalized anthropological traditions and thereby contribute to the project of a global anthropology or world anthropology.

Hundreds of other organizations exist in the various sub-fields of anthropology, sometimes divided up by nation or region, and many anthropologists work with collaborators in other disciplines, such as geology, physics, zoology, paleontology, anatomy, music theory, art history, sociology and so on, belonging to professional societies in those disciplines as well.

As the field has matured it has debated and arrived at ethical principles aimed at protecting both the subjects of anthropological research as well as the researchers themselves, and professional societies have generated codes of ethics.

Anthropologists, like other researchers (especially historians and scientists engaged in field research), have over time assisted state policies and projects, especially colonialism.

Some commentators have contended:

As part of their quest for scientific objectivity, present-day anthropologists typically urge cultural relativism, which has an influence on all the sub-fields of anthropology. This is the notion that cultures should not be judged by another's values or viewpoints, but be examined dispassionately on their own terms. There should be no notions, in good anthropology, of one culture being better or worse than another culture.

Ethical commitments in anthropology include noticing and documenting genocide, infanticide, racism, mutilation (including circumcision and subincision), and torture. Topics like racism, slavery, and human sacrifice attract anthropological attention and theories ranging from nutritional deficiencies to genes to acculturation have been proposed, not to mention theories of colonialism and many others as root causes of Man's inhumanity to man. To illustrate the depth of an anthropological approach, one can take just one of these topics, such as "racism" and find thousands of anthropological references, stretching across all the major and minor sub-fields.

Anthropologists' involvement with the U.S. government, in particular, has caused bitter controversy within the discipline. Franz Boas publicly objected to US participation in World War I, and after the war he published a brief expose and condemnation of the participation of several American archaeologists in espionage in Mexico under their cover as scientists.

But by the 1940s, many of Boas' anthropologist contemporaries were active in the allied war effort against the Axis Powers (Nazi Germany, Fascist Italy, and Imperial Japan). Many served in the armed forces, while others worked in intelligence (for example, Office of Strategic Services and the Office of War Information). At the same time, David H. Price's work on American anthropology during the Cold War provides detailed accounts of the pursuit and dismissal of several anthropologists from their jobs for communist sympathies.

Attempts to accuse anthropologists of complicity with the CIA and government intelligence activities during the Vietnam War years have turned up surprisingly little. Many anthropologists (students and teachers) were active in the antiwar movement. Numerous resolutions condemning the war in all its aspects were passed overwhelmingly at the annual meetings of the American Anthropological Association (AAA).

Professional anthropological bodies often object to the use of anthropology for the benefit of the state. Their codes of ethics or statements may proscribe anthropologists from giving secret briefings. The Association of Social Anthropologists of the UK and Commonwealth (ASA) has called certain scholarship ethically dangerous. The AAA's current 'Statement of Professional Responsibility' clearly states that "in relation with their own government and with host governments ... no secret research, no secret reports or debriefings of any kind should be agreed to or given."

Anthropologists, along with other social scientists, are working with the US military as part of the US Army's strategy in Afghanistan. The "Christian Science Monitor" reports that "Counterinsurgency efforts focus on better grasping and meeting local needs" in Afghanistan, under the "Human Terrain System" (HTS) program; in addition, HTS teams are working with the US military in Iraq. In 2009, the American Anthropological Association's Commission on the Engagement of Anthropology with the US Security and Intelligence Communities released its final report concluding, in part, that, "When ethnographic investigation is determined by military missions, not subject to external review, where data collection occurs in the context of war, integrated into the goals of counterinsurgency, and in a potentially coercive environment – all characteristic factors of the HTS concept and its application – it can no longer be considered a legitimate professional exercise of anthropology. In summary, while we stress that constructive engagement between anthropology and the military is possible, CEAUSSIC suggests that the AAA emphasize the incompatibility of HTS with disciplinary ethics and practice for job seekers and that it further recognize the problem of allowing HTS to define the meaning of "anthropology" within DoD."

Before WWII British 'social anthropology' and American 'cultural anthropology' were still distinct traditions. After the war, enough British and American anthropologists borrowed ideas and methodological approaches from one another that some began to speak of them collectively as 'sociocultural' anthropology.

There are several characteristics that tend to unite anthropological work. One of the central characteristics is that anthropology tends to provide a comparatively more holistic account of phenomena and tends to be highly empirical. The quest for holism leads most anthropologists to study a particular place, problem or phenomenon in detail, using a variety of methods, over a more extensive period than normal in many parts of academia.

In the 1990s and 2000s, calls for clarification of what constitutes a culture, of how an observer knows where his or her own culture ends and another begins, and other crucial topics in writing anthropology were heard. These dynamic relationships, between what can be observed on the ground, as opposed to what can be observed by compiling many local observations remain fundamental in any kind of anthropology, whether cultural, biological, linguistic or archaeological.

Biological anthropologists are interested in both human variation and in the possibility of human universals (behaviors, ideas or concepts shared by virtually all human cultures). They use many different methods of study, but modern population genetics, participant observation and other techniques often take anthropologists "into the field," which means traveling to a community in its own setting, to do something called "fieldwork." On the biological or physical side, human measurements, genetic samples, nutritional data may be gathered and published as articles or monographs.

Along with dividing up their project by theoretical emphasis, anthropologists typically divide the world up into relevant time periods and geographic regions. Human time on Earth is divided up into relevant cultural traditions based on material, such as the Paleolithic and the Neolithic, of particular use in archaeology. Further cultural subdivisions according to tool types, such as Olduwan or Mousterian or Levalloisian help archaeologists and other anthropologists in understanding major trends in the human past. Anthropologists and geographers share approaches to culture regions as well, since mapping cultures is central to both sciences. By making comparisons across cultural traditions (time-based) and cultural regions (space-based), anthropologists have developed various kinds of comparative method, a central part of their science.

Because anthropology developed from so many different enterprises (see History of anthropology), including but not limited to fossil-hunting, exploring, documentary film-making, paleontology, primatology, antiquity dealings and curatorship, philology, etymology, genetics, regional analysis, ethnology, history, philosophy, and religious studies, it is difficult to characterize the entire field in a brief article, although attempts to write histories of the entire field have been made.

Some authors argue that anthropology originated and developed as the study of "other cultures", both in terms of time (past societies) and space (non-European/non-Western societies). For example, the classic of urban anthropology, Ulf Hannerz in the introduction to his seminal "Exploring the City: Inquiries Toward an Urban Anthropology" mentions that the "Third World" had habitually received most of attention; anthropologists who traditionally specialized in "other cultures" looked for them far away and started to look "across the tracks" only in late 1960s.

Now there exist many works focusing on peoples and topics very close to the author's "home". It is also argued that other fields of study, like History and Sociology, on the contrary focus disproportionately on the West.

In France, the study of Western societies has been traditionally left to sociologists, but this is increasingly changing, starting in the 1970s from scholars like Isac Chiva and journals like "Terrain" ("fieldwork"), and developing with the center founded by Marc Augé ("Le Centre d'anthropologie des mondes contemporains", the Anthropological Research Center of Contemporary Societies).

Since the 1980s it has become common for social and cultural anthropologists to set ethnographic research in the North Atlantic region, frequently examining the connections between locations rather than limiting research to a single locale. There has also been a related shift toward broadening the focus beyond the daily life of ordinary people; increasingly, research is set in settings such as scientific laboratories, social movements, governmental and nongovernmental organizations and businesses.





Category:HumanitiesAgricultural science

Agricultural science is a broad multidisciplinary field of biology that encompasses the parts of exact, natural, economic and social sciences that are used in the practice and understanding of agriculture. (Veterinary science, but not animal science, is often excluded from the definition.)

The three terms are often confused. However, they cover different concepts:


Agricultural sciences include research and development on:

Agricultural biotechnology is a specific area of agricultural science involving the use of scientific tools and techniques, including genetic engineering, molecular markers, molecular diagnostics, vaccines, and tissue culture, to modify living organisms: plants, animals, and microorganisms.

One of the most common yield reducers is because of fertilizer not being applied in slightly higher quantities during transition period, the time it takes the soil to rebuild its aggregates and organic matter. Yields will decrease temporarily because of nitrogen being immobilized in the crop residue, which can take a few months to several years to decompose, depending on the crop's C to N ratio and the local environment.

In the 18th century, Johann Friedrich Mayer conducted experiments on the use of gypsum (hydrated calcium sulphate) as a fertilizer.

In 1843, John Lawes and Henry Gilbert began a set of long-term field experiments at Rothamsted Research Station in England; some of them are still running.

In the United States, a scientific revolution in agriculture began with the Hatch Act of 1887, which used the term "agricultural science". The Hatch Act was driven by farmers' interest in knowing the constituents of early artificial fertilizer. The Smith-Hughes Act





Category:Agronomy
Alchemy (from Arabic: "al-kīmiyā") was an ancient branch of natural philosophy, a philosophical and protoscientific tradition practiced throughout Europe, Africa, and Asia, originating in Hellenistic Egypt (primarily Alexandria) between the 4th and 3rd centuries BCE. It aims to purify, mature, and perfect certain objects. Common aims were chrysopoeia, the transmutation of "base metals" (e.g., lead) into "noble metals" (particularly gold); the creation of an elixir of immortality; the creation of panaceas able to cure any disease; and the development of an alkahest, a universal solvent. The perfection of the human body and soul was thought to permit or result from the alchemical "magnum opus" and, in the Hellenistic and Western mystery tradition, the achievement of gnosis. In Europe, the creation of a philosopher's stone was variously connected with all of these projects.

In English, the term is often limited to descriptions of European alchemy, but similar practices existed in the Far East, the Indian subcontinent, and the Muslim world. In Europe, following the 12th-century Renaissance produced by the translation of Medieval Islamic works on science and the rediscovery of Aristotelian philosophy, alchemists played a significant role in early modern science (particularly chemistry and medicine). Islamic and European alchemists developed a structure of basic laboratory techniques, theory, terminology, and experimental method, some of which are still in use today. However, they continued antiquity's belief in four elements and guarded their work in secrecy including cyphers and cryptic symbolism. Their work was guided by Hermetic principles related to magic, mythology, and religion.

Modern discussions of alchemy are generally split into an examination of its exoteric practical applications and its esoteric spiritual aspects, despite the arguments of scholars like Holmyard and von Franz that they should be understood as complementary. The former is pursued by historians of the physical sciences who examine the subject in terms of early chemistry, medicine, and charlatanism, and the philosophical and religious contexts in which these events occurred. The latter interests historians of esotericism, psychologists, and some philosophers and spiritualists. The subject has also made an ongoing impact on literature and the arts. Despite this split, which von Franz believes has existed since the Western traditions' origin in a mix of Greek philosophy that was mixed with Egyptian and Mesopotamian technology, numerous sources have stressed an integration of esoteric and exoteric approaches to alchemy as far back as Pseudo-Democritus's first-century  "On Physical and Mystical Matters" (). 

Although alchemy is popularly associated with magic, historian Lawrence M. Principe writes: 
Most readers probably are aware of several common claims about alchemy—for example, ... that it is akin to magic, or that its practice then or now is essentially deceptive. These ideas about alchemy emerged during the eighteenth century or after. While each of them might have limited validity within a narrow context, none of them is an accurate depiction of alchemy in general."

The word alchemy comes from Old French "alquemie", "alkimie", used in Medieval Latin as "alchymia". This name was itself brought from the Arabic word "al-kīmiyā"' ( or ) composed of two parts: the Late Greek term "khēmeía" (χημεία), "khēmía" (χημία), meaning 'to fuse or cast a metal', and the Arabic definite article "al-" (), meaning 'The'. Together this association can be interpreted as 'the process of transmutation by which to fuse or reunite with the divine or original form'. Its roots can be traced to the Egyptian name "kēme" (hieroglyphic 𓆎𓅓𓏏𓊖 "khmi" ), meaning 'black earth' which refers to the fertile and auriferous soil of the Nile valley, as opposed to red desert sand.

According to the Egyptologist Wallis Budge, the Arabic word "al-kīmiyaʾ" actually means "the Egyptian [science]", borrowing from the Coptic word for "Egypt", "kēme" (or its equivalent in the Mediaeval Bohairic dialect of Coptic, "khēme"). This Coptic word derives from Demotic "kmỉ", itself from ancient Egyptian "kmt". The ancient Egyptian word referred to both the country and the colour "black" (Egypt was the "Black Land", by contrast with the "Red Land", the surrounding desert); so this etymology could also explain the nickname "Egyptian black arts". However, according to Mahn, this theory may be an example of folk etymology. Assuming an Egyptian origin, chemistry is defined as follows:

Thus, according to Budge and others, chemistry derives from an Egyptian word "khemein" or "khēmia", "preparation of black powder", ultimately derived from the name "khem", Egypt. A decree of Diocletian, written about 300 AD in Greek, speaks against "the ancient writings of the Egyptians, which treat of the "khēmia" transmutation of gold and silver".

The Medieval Latin form was influenced by Greek "chymeia" (χυμεία) meaning 'mixture' and referring to pharmaceutical chemistry.

Alchemy is several philosophical traditions spanning some four millennia and three continents. These traditions' general penchant for cryptic and symbolic language makes it hard to trace their mutual influences and "genetic" relationships. One can distinguish at least three major strands, which appear to be largely independent, at least in their earlier stages: Chinese alchemy, centered in China and its zone of cultural influence; Indian alchemy, centered on the Indian subcontinent; and Western alchemy, which occurred around the Mediterranean and whose center has shifted over the millennia from Greco-Roman Egypt, to the Islamic world, and finally medieval Europe. Chinese alchemy was closely connected to Taoism and Indian alchemy with the Dharmic faiths, whereas Western alchemy developed its own philosophical system that was largely independent of, but influenced by, various Western religions

The start of Western alchemy may generally be traced to ancient and Hellenistic Egypt, where the city of Alexandria was a center of alchemical knowledge, and retained its pre-eminence through most of the Greek and Roman periods. Here, elements of technology, religion, mythology, and Hellenistic philosophy, each with their own much longer histories, combined to form the earliest known records of alchemy in the West. Zosimos of Panopolis wrote the oldest known books on alchemy, while Mary the Jewess is credited as being the first non-fictitious Western alchemist. They wrote in Greek and lived in Egypt under Roman rule.

Mythology – Zosimos of Panopolis asserted that alchemy dated back to Pharaonic Egypt where it was the domain of the priestly class, though there is little to no evidence for his assertion. Alchemical writers used Classical figures from Greek, Roman, and Egyptian mythology to illuminate their works and allegorize alchemical transmutation. These included the pantheon of gods related to the Classical planets, Isis, Osiris, Jason, and many others.

The central figure in the mythology of alchemy is Hermes Trismegistus (or Thrice-Great Hermes). His name is derived from the god Thoth and his Greek counterpart Hermes. Hermes and his caduceus or serpent-staff, were among alchemy's principal symbols. According to Clement of Alexandria, he wrote what were called the "forty-two books of Hermes", covering all fields of knowledge. The "Hermetica" of Thrice-Great Hermes is generally understood to form the basis for Western alchemical philosophy and practice, called the hermetic philosophy by its early practitioners. These writings were collected in the first centuries of the common era.

Technology – The dawn of Western alchemy is sometimes associated with that of metallurgy, extending back to 3500 . Many writings were lost when the emperor Diocletian ordered the burning of alchemical books after suppressing a revolt in Alexandria ( 292). Few original Egyptian documents on alchemy have survived, most notable among them the Stockholm papyrus and the Leyden papyrus X. Dating from  300–500, they contained recipes for dyeing and making artificial gemstones, cleaning and fabricating pearls, and manufacturing of imitation gold and silver. These writings lack the mystical, philosophical elements of alchemy, but do contain the works of Bolus of Mendes (or Pseudo-Democritus), which aligned these recipes with theoretical knowledge of astrology and the classical elements. Between the time of Bolus and Zosimos, the change took place that transformed this metallurgy into a Hermetic art.

Philosophy – Alexandria acted as a melting pot for philosophies of Pythagoreanism, Platonism, Stoicism and Gnosticism which formed the origin of alchemy's character. An important example of alchemy's roots in Greek philosophy, originated by Empedocles and developed by Aristotle, was that all things in the universe were formed from only four elements: earth, air, water, and fire. According to Aristotle, each element had a sphere to which it belonged and to which it would return if left undisturbed. The four elements of the Greek were mostly qualitative aspects of matter, not quantitative, as our modern elements are; "...True alchemy never regarded earth, air, water, and fire as corporeal or chemical substances in the present-day sense of the word. The four elements are simply the primary, and most general, qualities by means of which the amorphous and purely quantitative substance of all bodies first reveals itself in differentiated form." Later alchemists extensively developed the mystical aspects of this concept.

Alchemy coexisted alongside emerging Christianity. Lactantius believed Hermes Trismegistus had prophesied its birth. St Augustine later affirmed this in the 4th & 5th centuries, but also condemned Trismegistus for idolatry. Examples of Pagan, Christian, and Jewish alchemists can be found during this period.

Most of the Greco-Roman alchemists preceding Zosimos are known only by pseudonyms, such as Moses, Isis, Cleopatra, Democritus, and Ostanes. Others authors such as Komarios, and Chymes, we only know through fragments of text. After  400, Greek alchemical writers occupied themselves solely in commenting on the works of these predecessors. By the middle of the 7th century alchemy was almost an entirely mystical discipline. It was at that time that Khalid Ibn Yazid sparked its migration from Alexandria to the Islamic world, facilitating the translation and preservation of Greek alchemical texts in the 8th and 9th centuries.

The Vedas describe a connection between eternal life and gold. The use of Mercury for alchemy is first documented in the 3rd- or 4th-century "Arthashastra". Buddhist texts from the 2nd to 5th centuries mention the transmutation of base metals to gold. Greek alchemy may have been introduced to Ancient India through the invasions of Alexander the Great in 325 , and kingdoms that were culturally influenced by the Greeks like Gandhāra, although hard evidence for this is lacking.

The 11th-century Persian chemist and physician Abū Rayhān Bīrūnī, who visited Gujarat as part of the court of Mahmud of Ghazni, reported that they

The goals of alchemy in India included the creation of a divine body (Sanskrit "divya-deham") and immortality while still embodied (Sanskrit "jīvan-mukti"). Sanskrit alchemical texts include much material on the manipulation of mercury and sulphur, that are homologized with the semen of the god Śiva and the menstrual blood of the goddess Devī.

Some early alchemical writings seem to have their origins in the Kaula tantric schools associated to the teachings of the personality of Matsyendranath. Other early writings are found in the Jaina medical treatise "Kalyāṇakārakam" of Ugrāditya, written in South India in the early 9th century.

Two famous early Indian alchemical authors were Nāgārjuna Siddha

After the fall of the Roman Empire, the focus of alchemical development moved to the Islamic World. Much more is known about Islamic alchemy because it was better documented: indeed, most of the earlier writings that have come down through the years were preserved as Arabic translations. The word "alchemy" itself was derived from the Arabic word "al-kīmiyā"' (الكيمياء). The early Islamic world was a melting pot for alchemy. Platonic and Aristotelian thought, which had already been somewhat appropriated into hermetical science, continued to be assimilated during the late 7th and early 8th centuries through Syriac translations and scholarship.

In the late 8th century, Jābir ibn Hayyān (Latinized as "Geber" or "Geberus") introduced a new approach to alchemy, based on scientific methodology and controlled experimentation in the laboratory, in contrast to the ancient Greek and Egyptian alchemists whose works were often allegorical and unintelligible, with very little concern for laboratory work. Jabir is thus "considered by many to be the father of chemistry", albeit others reserve that title for Robert Boyle or Antoine Lavoisier. The science historian, Paul Kraus, wrote:

Jabir himself clearly recognized and proclaimed the importance of experimentation:

Early Islamic chemists such as Jabir Ibn Hayyan, Al-Kindi ("Alkindus") and Muhammad ibn Zakarīya Rāzi ("Rasis" or "Rhazes") contributed a number of key chemical discoveries, such as the muriatic (hydrochloric acid), sulfuric and nitric acids, and more. The discovery that aqua regia, a mixture of nitric and hydrochloric acids, could dissolve the noblest metal, gold, was to fuel the imagination of alchemists for the next millennium.

Islamic philosophers also made great contributions to alchemical hermeticism. The most influential author in this regard was arguably Jabir. Jabir's ultimate goal was "Takwin", the artificial creation of life in the alchemical laboratory, up to, and including, human life. He analyzed each Aristotelian element in terms of four basic qualities of "hotness", "coldness", "dryness", and "moistness". According to Jabir, in each metal two of these qualities were interior and two were exterior. For example, lead was externally cold and dry, while gold was hot and moist. Thus, Jabir theorized, by rearranging the qualities of one metal, a different metal would result. By this reasoning, the search for the philosopher's stone was introduced to Western alchemy. Jabir developed an elaborate numerology whereby the root letters of a substance's name in Arabic, when treated with various transformations, held correspondences to the element's physical properties.

The elemental system used in medieval alchemy also originated with Jabir. His original system consisted of seven elements, which included the five classical elements (aether, air, earth, fire, and water) in addition to two chemical elements representing the metals: sulphur, "the stone which burns", which characterized the principle of combustibility, and mercury, which contained the idealized principle of metallic properties. Shortly thereafter, this evolved into eight elements, with the Arabic concept of the three metallic principles: sulphur giving flammability or combustion, mercury giving volatility and stability, and salt giving solidity. The atomic theory of corpuscularianism, where all physical bodies possess an inner and outer layer of minute particles or corpuscles, also has its origins in the work of Jabir.

From the 9th to 14th centuries, alchemical theories faced criticism from a variety of practical Muslim chemists, including Alkindus, Abū al-Rayhān al-Bīrūnī, Avicenna and Ibn Khaldun. In particular, they wrote refutations against the idea of the transmutation of metals
Whereas European alchemy eventually centered on the transmutation of base metals into noble metals, Chinese alchemy had a more obvious connection to medicine. The philosopher's stone of European alchemists can be compared to the Grand Elixir of Immortality sought by Chinese alchemists. However, in the hermetic view, these two goals were not unconnected, and the philosopher's stone was often equated with the universal panacea; therefore, the two traditions may have had more in common than initially appears.

Black powder may have been an important invention of Chinese alchemists. As previously stated above, Chinese alchemy was more related to medicine. It is said that the Chinese invented gunpowder while trying to find a potion for eternal life. Described in 9th-century texts and used in fireworks in China by the 10th century, it was used in cannons by 1290. From China, the use of gunpowder spread to Japan, the Mongols, the Muslim world, and Europe. Gunpowder was used by the Mongols against the Hungarians in 1241, and in Europe by the 14th century.

Chinese alchemy was closely connected to Taoist forms of traditional Chinese medicine, such as Acupuncture and Moxibustion, and to martial arts such as Tai Chi Chuan and Kung Fu (although some Tai Chi schools believe that their art derives from the philosophical or hygienic branches of Taoism, not Alchemical). In fact, in the early Song dynasty, followers of this Taoist idea (chiefly the elite and upper class) would ingest mercuric sulfide, which, though tolerable in low levels, led many to suicide. Thinking that this consequential death would lead to freedom and access to the Taoist heavens, the ensuing deaths encouraged people to eschew this method of alchemy in favor of external sources (the aforementioned Tai Chi Chuan, mastering of the qi

The introduction of alchemy to Latin Europe may be dated to 11 February 1144, with the completion of Robert of Chester's translation of the Arabic "Book of the Composition of Alchemy". Although European craftsmen and technicians preexisted, Robert notes in his preface that alchemy was unknown in Latin Europe at the time of his writing. The translation of Arabic texts concerning numerous disciplines including alchemy flourished in 12th-century Toledo, Spain, through contributors like Gerard of Cremona and Adelard of Bath. Translations of the time included the Turba Philosophorum, and the works of Avicenna and al-Razi. These brought with them many new words to the European vocabulary for which there was no previous Latin equivalent. Alcohol, carboy, elixir, and athanor are examples.

Meanwhile, theologian contemporaries of the translators made strides towards the reconciliation of faith and experimental rationalism, thereby priming Europe for the influx of alchemical thought. The 11th-century St Anselm put forth the opinion that faith and rationalism were compatible and encouraged rationalism in a Christian context. In the early 12th century, Peter Abelard followed Anselm's work, laying down the foundation for acceptance of Aristotelian thought before the first works of Aristotle had reached the West. In the early 13th century, Robert Grosseteste used Abelard's methods of analysis and added the use of observation, experimentation, and conclusions when conducting scientific investigations. Grosseteste also did much work to reconcile Platonic and Aristotelian thinking.

Through much of the 12th and 13th centuries, alchemical knowledge in Europe remained centered on translations, and new Latin contributions were not made. The efforts of the translators were succeeded by that of the encyclopaedists. In the 13th century, Albertus Magnus and Roger Bacon were the most notable of these, their work summarizing and explaining the newly imported alchemical knowledge in Aristotelian terms. Albertus Magnus, a Dominican friar, is known to have written works such as the "Book of Minerals" where he observed and commented on the operations and theories of alchemical authorities like Hermes and Democritus and unnamed alchemists of his time. Albertus critically compared these to the writings of Aristotle and Avicenna, where they concerned the transmutation of metals. From the time shortly after his death through to the 15th century, more than 28 alchemical tracts were misattributed to him, a common practice giving rise to his reputation as an accomplished alchemist. Likewise, alchemical texts have been attributed to Albert's student Thomas Aquinas.

Roger Bacon, a Franciscan friar who wrote on a wide variety of topics including optics, comparative linguistics, and medicine, composed his "Great Work" () for as part of a project towards rebuilding the medieval university curriculum to include the new learning of his time. While alchemy was not more important to him than other sciences and he did not produce allegorical works on the topic, he did consider it and astrology to be important parts of both natural philosophy and theology and his contributions advanced alchemy's connections to soteriology and Christian theology. Bacon's writings integrated morality, salvation, alchemy, and the prolongation of life. His correspondence with Clement highlighted this, noting the importance of alchemy to the papacy. Like the Greeks before him, Bacon acknowledged the division of alchemy into practical and theoretical spheres. He noted that the theoretical lay outside the scope of Aristotle, the natural philosophers, and all Latin writers of his time. The practical, however, confirmed the theoretical thought experiment, and Bacon advocated its uses in natural science and medicine. In later European legend, however, Bacon became an archmage. In particular, along with Albertus Magnus, he was credited with the forging of a brazen head capable of answering its owner's questions.

Soon after Bacon, the influential work of Pseudo-Geber (sometimes identified as Paul of Taranto) appeared. His "Summa Perfectionis" remained a staple summary of alchemical practice and theory through the medieval and renaissance periods. It was notable for its inclusion of practical chemical operations alongside sulphur-mercury theory, and the unusual clarity with which they were described. By the end of the 13th century, alchemy had developed into a fairly structured system of belief. Adepts believed in the macrocosm-microcosm theories of Hermes, that is to say, they believed that processes that affect minerals and other substances could have an effect on the human body (for example, if one could learn the secret of purifying gold, one could use the technique to purify the human soul). They believed in the four elements and the four qualities as described above, and they had a strong tradition of cloaking their written ideas in a labyrinth of coded jargon set with traps to mislead the uninitiated. Finally, the alchemists practiced their art: they actively experimented with chemicals and made observations and theories about how the universe operated. Their entire philosophy revolved around their belief that man's soul was divided within himself after the fall of Adam. By purifying the two parts of man's soul, man could be reunited with God.

In the 14th century, alchemy became more accessible to Europeans outside the confines of Latin speaking churchmen and scholars. Alchemical discourse shifted from scholarly philosophical debate to an exposed social commentary on the alchemists themselves. Dante, Piers Plowman, and Chaucer all painted unflattering pictures of alchemists as thieves and liars. Pope John XXII's 1317 edict, "Spondent quas non exhibent" forbade the false promises of transmutation made by pseudo-alchemists. In 1403, Henry IV of England banned the practice of multiplying metals (although it was possible to buy a licence to attempt to make gold alchemically, and a number were granted by Henry VI and Edward IV). These critiques and regulations centered more around pseudo-alchemical charlatanism than the actual study of alchemy, which continued with an increasingly Christian tone. The 14th century saw the Christian imagery of death and resurrection employed in the alchemical texts of Petrus Bonus, John of Rupescissa, and in works written in the name of Raymond Lull and Arnold of Villanova.

Nicolas Flamel is a well-known alchemist, but a good example of pseudepigraphy, the practice of giving your works the name of someone else, usually more famous. Although the historical Flamel existed, the writings and legends assigned to him only appeared in 1612. Flamel was not a religious scholar as were many of his predecessors, and his entire interest in the subject revolved around the pursuit of the philosopher's stone. His work spends a great deal of time describing the processes and reactions, but never actually gives the formula for carrying out the transmutations. Most of 'his' work was aimed at gathering alchemical knowledge that had existed before him, especially as regarded the philosopher's stone. Through the 14th and 15th centuries, alchemists were much like Flamel: they concentrated on looking for the philosophers' stone. Bernard Trevisan and George Ripley made similar contributions. Their cryptic allusions and symbolism

During the Renaissance, Hermetic and Platonic foundations were restored to European alchemy. The dawn of medical, pharmaceutical, occult, and entrepreneurial branches of alchemy followed.

In the late 15th century, Marsilo Ficino translated the Corpus Hermeticum and the works of Plato into Latin. These were previously unavailable to Europeans who for the first time had a full picture of the alchemical theory that Bacon had declared absent. Renaissance Humanism and Renaissance Neoplatonism guided alchemists away from physics to refocus on mankind as the alchemical vessel.

Esoteric systems developed that blended alchemy into a broader occult Hermeticism, fusing it with magic, astrology, and Christian cabala. A key figure in this development was German Heinrich Cornelius Agrippa (1486–1535), who received his Hermetic education in Italy in the schools of the humanists. In his "De Occulta Philosophia", he attempted to merge Kabbalah, Hermeticism, and alchemy. He was instrumental in spreading this new blend of Hermeticism outside the borders of Italy.

Philippus Aureolus Paracelsus, (Theophrastus Bombastus von Hohenheim, 1493–1541) cast alchemy into a new form, rejecting some of Agrippa's occultism and moving away from chrysopoeia. Paracelsus pioneered the use of chemicals and minerals in medicine and wrote, "Many have said of Alchemy, that it is for the making of gold and silver. For me such is not the aim, but to consider only what virtue and power may lie in medicines."

His hermetical views were that sickness and health in the body relied on the harmony of man the microcosm and Nature the macrocosm. He took an approach different from those before him, using this analogy not in the manner of soul-purification but in the manner that humans must have certain balances of minerals in their bodies, and that certain illnesses of the body had chemical remedies that could cure them. Paracelsian practical alchemy, especially herbal medicine and plant remedies has since been named spagyric (a synonym for alchemy from the Greek words meaning "to separate" and "to join together", based on the Latin alchemic maxim: "solve et coagula"). Iatrochemistry also refers to the pharmaceutical applications of alchemy championed by Paracelsus.

John Dee (13 July 1527 – December, 1608) followed Agrippa's occult tradition. Although better known for angel summoning, divination, and his role as astrologer, cryptographer, and consultant to Queen Elizabeth I, Dee's alchemical "Monas Hieroglyphica", written in 1564 was his most popular and influential work. His writing portrayed alchemy as a sort of terrestrial astronomy in line with the Hermetic axiom "As above so below". During the 17th century, a short-lived "supernatural" interpretation of alchemy became popular, including support by fellows of the Royal Society: Robert Boyle and Elias Ashmole. Proponents of the supernatural interpretation of alchemy believed that the philosopher's stone might be used to summon and communicate with angels.

Entrepreneurial opportunities were common for the alchemists of Renaissance Europe. Alchemists were contracted by the elite for practical purposes related to mining, medical services, and the production of chemicals, medicines, metals, and gemstones. Rudolf II, Holy Roman Emperor, in the late 16th century, famously received and sponsored various alchemists at his court in Prague, including Dee and his associate Edward Kelley. King James IV of Scotland, Julius, Duke of Brunswick-Lüneburg, Henry V, Duke of Brunswick-Lüneburg, Augustus, Elector of Saxony, Julius Echter von Mespelbrunn, and Maurice, Landgrave of Hesse-Kassel all contracted alchemists. John's son Arthur Dee worked as a court physician to Michael I of Russia and Charles I of England but also compiled the alchemical book "Fasciculus Chemicus
Although most of these appointments were legitimate, the trend of pseudo-alchemical fraud continued through the Renaissance. "Betrüger" would use sleight of hand, or claims of secret knowledge to make money or secure patronage. Legitimate mystical and medical alchemists such as Michael Maier and Heinrich Khunrath wrote about fraudulent transmutations, distinguishing themselves from the con artists. False alchemists were sometimes prosecuted for fraud.

The terms "chemia" and "alchemia" were used as synonyms in the early modern period, and the differences between alchemy, chemistry and small-scale assaying and metallurgy were not as neat as in the present day. There were important overlaps between practitioners, and trying to classify them into alchemists, chemists and craftsmen is anachronistic. For example, Tycho Brahe (1546–1601), an alchemist better known for his astronomical and astrological investigations, had a laboratory built at his Uraniborg observatory/research institute. Michael Sendivogius ("Michał Sędziwój", 1566–1636), a Polish alchemist, philosopher, medical doctor and pioneer of chemistry wrote mystical works but is also credited with distilling oxygen in a lab sometime around 1600. Sendivogious taught his technique to Cornelius Drebbel who, in 1621, applied this in a submarine. Isaac Newton devoted considerably more of his writing to the study of alchemy (see Isaac Newton's occult studies) than he did to either optics or physics. Other early modern alchemists who were eminent in their other studies include Robert Boyle, and Jan Baptist van Helmont
The decline of European alchemy was brought about by the rise of modern science with its emphasis on rigorous quantitative experimentation and its disdain for "ancient wisdom". Although the seeds of these events were planted as early as the 17th century, alchemy still flourished for some two hundred years, and in fact may have reached its peak in the 18th century. As late as 1781 James Price claimed to have produced a powder that could transmute mercury into silver or gold. Early modern European alchemy continued to exhibit a diversity of theories, practices, and purposes: "Scholastic and anti-Aristotelian, Paracelsian and anti-Paracelsian, Hermetic, Neoplatonic, mechanistic, vitalistic, and more—plus virtually every combination and compromise thereof."

Robert Boyle (1627–1691) pioneered the scientific method in chemical investigations. He assumed nothing in his experiments and compiled every piece of relevant data. Boyle would note the place in which the experiment was carried out, the wind characteristics, the position of the Sun and Moon, and the barometer reading, all just in case they proved to be relevant. This approach eventually led to the founding of modern chemistry in the 18th and 19th centuries, based on revolutionary discoveries of Lavoisier and John Dalton.

Beginning around 1720, a rigid distinction was drawn between "alchemy" and "chemistry" for the first time. By the 1740s, "alchemy" was now restricted to the realm of gold making, leading to the popular belief that alchemists were charlatans, and the tradition itself nothing more than a fraud. In order to protect the developing science of modern chemistry from the negative censure of which alchemy was being subjected, academic writers during the scientific Enlightenment attempted, for the sake of survival, to divorce and separate the "new" chemistry from the "old" practices of alchemy. This move was mostly successful, and the consequences of this continued into the 19th and 20th centuries, and even to the present day.

During the occult revival of the early 19th century, alchemy received new attention as an occult science. The esoteric or occultist school, which arose during the 19th century, held (and continues to hold) the view that the substances and operations mentioned in alchemical literature are to be interpreted in a spiritual sense, and it downplays the role of the alchemy as a practical tradition or protoscience. This interpretation further forwarded the view that alchemy is an art primarily concerned with spiritual enlightenment or illumination, as opposed to the physical manipulation of apparatus and chemicals, and claims that the obscure language of the alchemical texts were an allegorical guise for spiritual, moral or mystical processes.

In the 19th-century revival of alchemy, the two most seminal figures were Mary Anne Atwood and Ethan Allen Hitchcock, who independently published similar works regarding spiritual alchemy. Both forwarded a completely esoteric view of alchemy, as Atwood claimed: "No modern art or chemistry, notwithstanding all its surreptitious claims, has any thing in common with Alchemy." Atwood's work influenced subsequent authors of the occult revival including Eliphas Levi, Arthur Edward Waite, and Rudolf Steiner. Hitchcock, in his "Remarks Upon Alchymists" (1855) attempted to make a case for his spiritual interpretation with his claim that the alchemists wrote about a spiritual discipline under a materialistic guise in order to avoid accusations of blasphemy from the church and state. In 1845, Baron Carl Reichenbach, published his studies on Odic force, a concept with some similarities to alchemy, but his research did not enter the mainstream of scientific discussion.

Several women appear in the earliest history of alchemy. Michael Maier names Mary the Jewess, Cleopatra the Alchemist, Medera, and Taphnutia as the four women who knew how to make the philosopher's stone. Zosimos' sister Theosebia (later known as Euthica the Arab) and Isis the Prophetess also played a role in early alchemical texts.

The first alchemist whose name we know is said to have been Mary the Jewess (c. 200 A.D.). Early sources claim that Mary (or Maria) devised a number of improvements to alchemical equipment and tools as well as novel techniques in chemistry. Her best known advances were in heating and distillation processes. The laboratory water-bath, known eponymously (especially in France) as the bain-marie, is said to have been invented or at least improved by her. Essentially a double-boiler, it was (and is) used in chemistry for processes that require gentle heating. The tribikos (a modified distillation apparatus) and the kerotakis (a more intricate apparatus used especially for sublimations) are two other advancements in the process of distillation that are credited to her. The occasional claim that Mary was the first to discover hydrochloric acid is not accepted by most authorities. Although we have no writing from Mary herself, she is known from the early-fourth-century writings of Zosimos of Panopolis.

Due to the proliferation of pseudepigrapha and anonymous works, it is difficult to know which of the alchemists were actually women. After the Greco-Roman period, women's names appear less frequently in the alchemical literature. Women vacate the history of alchemy during the medieval and renaissance periods, aside from the fictitious account of Perenelle Flamel. Mary Anne Atwood's "A Suggestive Inquiry into the Hermetic Mystery" (1850) marks their return during the nineteenth-century occult revival.

The history of alchemy has become a significant and recognized subject of academic study. As the language of the alchemists is analyzed, historians are becoming more aware of the intellectual connections between that discipline and other facets of Western cultural history, such as the evolution of science and philosophy, the sociology and psychology of the intellectual communities, kabbalism, spiritualism, Rosicrucianism, and other mystic movements. Institutions involved in this research include The Chymistry of Isaac Newton project at Indiana University, the University of Exeter Centre for the Study of Esotericism (EXESESO), the European Society for the Study of Western Esotericism (ESSWE), and the University of Amsterdam's Sub-department for the History of Hermetic Philosophy and Related Currents. A large collection of books on alchemy is kept in the Bibliotheca Philosophica Hermetica in Amsterdam. A recipe found in a mid-19th-century kabbalah based book features step by step instructions on turning copper into gold. The author attributed this recipe to an ancient manuscript he located.

Journals which publish regularly on the topic of Alchemy include 'Ambix', published by the Society for the History of Alchemy and Chemistry, and 'Isis
Western alchemical theory corresponds to the worldview of late antiquity in which it was born. Concepts were imported from Neoplatonism and earlier Greek cosmology. As such, the Classical elements appear in alchemical writings, as do the seven Classical planets and the corresponding seven metals of antiquity. Similarly, the gods of the Roman pantheon who are associated with these luminaries are discussed in alchemical literature. The concepts of prima materia and anima mundi are central to the theory of the philosopher's stone.

In the eyes of a variety of esoteric and Hermetic practitioners, alchemy is fundamentally spiritual. Transmutation of lead into gold is presented as an analogy for personal transmutation, purification, and perfection. The writings attributed to Hermes Trismegistus are a primary source of alchemical theory. He is named "alchemy's founder and chief patron, authority, inspiration and guide".

Early alchemists, such as Zosimos of Panopolis (c. AD 300), highlight the spiritual nature of the alchemical quest, symbolic of a religious regeneration of the human soul. This approach continued in the Middle Ages, as metaphysical aspects, substances, physical states, and material processes were used as metaphors for spiritual entities, spiritual states, and, ultimately, transformation. In this sense, the literal meanings of 'Alchemical Formulas' were a blind, hiding their true spiritual philosophy. Practitioners and patrons such as Melchior Cibinensis and Pope Innocent VIII existed within the ranks of the church, while Martin Luther applauded alchemy for its consistency with Christian teachings. Both the transmutation of common metals into gold and the universal panacea symbolized evolution from an imperfect, diseased, corruptible, and ephemeral state toward a perfect, healthy, incorruptible, and everlasting state, so the philosopher's stone then represented a mystic key that would make this evolution possible. Applied to the alchemist himself, the twin goal symbolized his evolution from ignorance to enlightenment, and the stone represented a hidden spiritual truth or power that would lead to that goal. In texts that are written according to this view, the cryptic alchemical symbols, diagrams, and textual imagery of late alchemical works typically contain multiple layers of meanings, allegories, and references to other equally cryptic works; and must be laboriously decoded to discover their true meaning.

In his 1766 "Alchemical Catechism", Théodore Henri de Tschudi denotes that the usage of the metals was merely symbolic:

The Great Work of Alchemy is often described as a series of four stages represented by colors.


Due to the complexity and obscurity of alchemical literature, and the 18th-century disappearance of remaining alchemical practitioners into the area of chemistry; the general understanding of alchemy has been strongly influenced by several distinct and radically different interpretations. Those focusing on the exoteric, such as historians of science Lawrence M. Principe and William R. Newman, have interpreted the 'decknamen' (or code words) of alchemy as physical substances. These scholars have reconstructed physicochemical experiments that they say are described in medieval and early modern texts. At the opposite end of the spectrum, focusing on the esoteric, scholars, such as George Calian and Anna Marie Roos, who question the reading of Principe and Newman, interpret these same decknamen as spiritual, religious, or psychological concepts.

Today new interpretations of alchemy are still perpetuated, sometimes merging in concepts from New Age or radical environmentalism movements. Groups like the Rosicrucians and Freemasons have a continued interest in alchemy and its symbolism. Since the Victorian revival of alchemy, "occultists reinterpreted alchemy as a spiritual practice, involving the self-transformation of the practitioner and only incidentally or not at all the transformation of laboratory substances", which has contributed to a merger of magic and alchemy in popular thought.

Traditional medicine can use the concept of the transmutation of natural substances, using pharmacological or a combination of pharmacological and spiritual techniques. In Ayurveda, the samskaras are claimed to transform heavy metals and toxic herbs in a way that removes their toxicity. These processes are actively used to the present day.

Spagyrists of the 20th century, Albert Richard Riedel and Jean Dubuis, merged Paracelsian alchemy with occultism, teaching laboratory pharmaceutical methods. The schools they founded, "Les Philosophes de la Nature" and "The Paracelsus Research Society", popularized modern spagyrics including the manufacture of herbal tinctures and products. The courses, books, organizations, and conferences generated by their students continue to influence popular applications of alchemy as a New Age medicinal practice.

Alchemical symbolism has been important in depth and analytical psychology and was revived and popularized from near extinction by the Swiss psychologist Carl Gustav Jung. Initially confounded and at odds with alchemy and its images, after being given a copy of the translation of "The Secret of the Golden Flower", a Chinese alchemical text, by his friend Richard Wilhelm, Jung discovered a direct correlation or parallels between the symbolic images in the alchemical drawings and the inner, symbolic images coming up in dreams, visions or imaginations during the psychic processes of transformation occurring in his patients. A process, which he called "process of individuation". He regarded the alchemical images as symbols expressing aspects of this "process of individuation" of which the creation of the gold or lapis within were symbols for its origin and goal. Together with his alchemical "mystica soror", Jungian Swiss analyst Marie-Louise von Franz, Jung began collecting all the old alchemical texts available, compiled a lexicon of key phrases with cross-references and pored over them. The volumes of work he wrote brought new light into understanding the art of transubstantiation and renewed alchemy's popularity as a symbolic process of coming into wholeness as a human being where opposites brought into contact and inner and outer, spirit and matter are reunited in the "hieros gamos" or divine marriage. His writings are influential in psychology and for persons who have an interest in understanding the importance of dreams, symbols and the unconscious archetypal forces (archetypes) that influence all of life.

Both von Franz and Jung have contributed greatly to the subject and work of alchemy and its continued presence in psychology as well as contemporary culture. Jung wrote volumes on alchemy and his magnum opus is Volume 14 of his Collected Works, "Mysterium Conuinctionis."

Alchemy has had a long-standing relationship with art, seen both in alchemical texts and in mainstream entertainment. "Literary alchemy" appears throughout the history of English literature from Shakespeare to J. K. Rowling, and also the popular Japanese manga Full Metal Alchemist
Category:Hermeticism
Category:Esotericism

An astronomer is a scientist in the field of astronomy who focuses their studies on a specific question or field outside the scope of Earth. They observe astronomical objects such as stars, planets, moons, comets, and galaxies – in either observational (by analyzing the data) or theoretical astronomy. Examples of topics or fields astronomers study include planetary science, solar astronomy, the origin or evolution of stars, or the formation of galaxies. Related but distinct subjects like physical cosmology, which studies the Universe as a whole.

Astronomers usually fall under either of two main types: observational and theoretical. Observational astronomers make direct observations of celestial objects and analyze the data. In contrast, theoretical astronomers create and investigate models of things that cannot be observed. Because it takes millions to billions of years for a system of stars or a galaxy to complete a life cycle, astronomers must observe snapshots of different systems at unique points in their evolution to determine how they form, evolve, and die. They use these data to create models or simulations to theorize how different celestial objects work.

Further subcategories under these two main branches of astronomy include planetary astronomy, galactic astronomy

Historically, astronomy was more concerned with the classification and description of phenomena in the sky, while astrophysics attempted to explain these phenomena and the differences between them using physical laws. Today, that distinction has mostly disappeared and the terms "astronomer" and "astrophysicist" are interchangeable. Professional astronomers are highly educated individuals who typically have a Ph.D. in physics or astronomy and are employed by research institutions or universities. They spend the majority of their time working on research, although they quite often have other duties such as teaching, building instruments, or aiding in the operation of an observatory.

The number of professional astronomers in the United States is actually quite small. The American Astronomical Society, which is the major organization of professional astronomers in North America, has approximately 7,000 members. This number includes scientists from other fields such as physics, geology, and engineering, whose research interests are closely related to astronomy. The International Astronomical Union
Contrary to the classical image of an old astronomer peering through a telescope through the dark hours of the night, it is far more common to use a charge-coupled device (CCD) camera to record a long, deep exposure, allowing a more sensitive image to be created because the light is added over time. Before CCDs, photographic plates were a common method of observation. Modern astronomers spend relatively little time at telescopes usually just a few weeks per year. Analysis of observed phenomena, along with making predictions as to the causes of what they observe, takes the majority of observational astronomers' time.

Astronomers who serve as faculty spend much of their time teaching undergraduate and graduate classes. Most universities also have outreach programs including public telescope time and sometimes planetariums
While there is a relatively low number of professional astronomers, the field is popular among amateurs. Most cities have amateur astronomy clubs that meet on a regular basis and often host star parties. The Astronomical Society of the Pacific is the largest general astronomical society in the world, comprising both professional and amateur astronomers as well as educators from 70 different nations. Like any hobby, most people who think of themselves as amateur astronomers may devote a few hours a month to stargazing and reading the latest developments in research. However, amateurs span the range from so-called "armchair astronomers" to the very ambitious, who own science-grade telescopes and instruments with which they are able to make their own discoveries and assist professional astronomers in research.




Category:Astronomy
Category:Science occupations