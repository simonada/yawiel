American Revolutionary War

The American Revolutionary War (17751783), also known as the American War of Independence, was an 18th-century war between Great Britain and its Thirteen Colonies (allied with France) which declared independence as the United States of America.

After 1765, growing philosophical and political differences strained the relationship between Great Britain and its colonies. Patriot protests against taxation without representation followed the Stamp Act and escalated into boycotts, which culminated in 1773 with the Sons of Liberty destroying a shipment of tea in Boston Harbor. Britain responded by closing Boston Harbor and passing a series of punitive measures against Massachusetts Bay Colony. Massachusetts colonists responded with the Suffolk Resolves, and they established a shadow government which wrested control of the countryside from the Crown. Twelve colonies formed a Continental Congress to coordinate their resistance, establishing committees and conventions that effectively seized power.

British attempts to disarm the Massachusetts militia in Concord led to open combat on April 19, 1775. Militia forces then besieged Boston, forcing a British evacuation in March 1776, and Congress appointed George Washington to command the Continental Army. Concurrently, the Americans failed decisively in an attempt to invade Quebec and raise insurrection against the British. On July 2, 1776, the Second Continental Congress voted for independence, issuing its declaration on July 4. Sir William Howe launched a British counter-offensive, capturing New York City and leaving American morale at a low ebb. However, victories at Trenton and Princeton restored American confidence. In 1777, the British launched an invasion from Quebec under John Burgoyne, intending to isolate the New England Colonies. Instead of assisting this effort, Howe took his army on a separate campaign against Philadelphia, and Burgoyne was decisively defeated at Saratoga in October 1777.

Burgoyne's defeat had drastic consequences. France formally allied with the Americans and entered the war in 1778, and Spain joined the war the following year as an ally of France but not as an ally of the United States. In 1780, the Kingdom of Mysore attacked the British in India, and tensions between Great Britain and the Netherlands erupted into open war. In North America, the British mounted a "Southern strategy" led by Charles Cornwallis which hinged upon a Loyalist uprising, but too few came forward. Cornwallis suffered reversals at King's Mountain and Cowpens. He retreated to Yorktown, Virginia, intending an evacuation, but a decisive French naval victory deprived him of an escape. A Franco-American army led by the Comte de Rochambeau and Washington then besieged Cornwallis' army and, with no sign of relief, he surrendered in October 1781.

Whigs in Britain had long opposed the pro-war Tories in Parliament, and the surrender gave them the upper hand. In early 1782, Parliament voted to end all offensive operations in North America, but the war continued in Europe, India and the Caribbean. In the latter the British scored a major victory over the French navy, and then later defeated Spanish and French attempts to seize Gibraltar. On September 3, 1783, the belligerent parties signed the Treaty of Paris in which Great Britain agreed to recognize the sovereignty of the United States and formally end the war. French involvement had proven decisive, but France made few gains and incurred crippling debts. Spain made some territorial gains but failed in its primary aim of recovering Gibraltar. The Dutch were defeated on all counts and were compelled to cede territory to Great Britain. In India, the war against Mysore and its allies concluded in 1784 without any territorial changes.

Parliament passed the Stamp Act in 1765. Colonists condemned the tax because their rights as Englishmen protected them from being taxed by a Parliament in which they had no elected representatives. Parliament argued that the colonies were "represented virtually", an idea that was criticized throughout the Empire. Parliament did repeal the act in 1766; however, it also affirmed its right to pass laws that were binding on the colonies. From 1767, Parliament began passing legislation

Enforcing the acts proved difficult. The seizure of the sloop "Liberty" in 1768 on suspicions of smuggling triggered a riot. In response, British troops occupied Boston, and Parliament threatened to extradite colonists to face trial in England. Tensions rose after the murder of Christopher Seider by a customs official in 1770 and escalated into outrage after British troops fired on civilians in the Boston Massacre. In 1772, colonists in Rhode Island boarded and burned a customs schooner. Parliament then repealed all taxes except the one on tea, passing the Tea Act in 1773, attempting to force colonists to buy East India Company tea on which the Townshend duties were paid, thus implicitly agreeing to Parliamentary supremacy. The landing of the tea was resisted in all colonies, but the governor of Massachusetts permitted British tea ships to remain in Boston Harbor. So, the Sons of Liberty destroyed the tea chests, an incident that later became known as the "Boston Tea Party".

Parliament then passed punitive legislation. It closed Boston Harbor until the tea was paid for and revoked the Massachusetts Charter, taking upon themselves the right to directly appoint the Massachusetts Governor's Council. Additionally, the royal governor was granted powers to undermine local democracy. Further measures allowed the extradition of officials for trial elsewhere in the Empire, if the governor felt that a fair trial could not be secured locally. The act's vague reimbursement policy for travel expenses left few with the ability to testify, and colonists argued that it would allow officials to harass them with impunity. Further laws allowed the governor to billet troops in private property without permission. The colonists referred to the measures as the "Intolerable Acts", and they argued that both their constitutional rights and their natural rights were being violated, viewing the acts as a threat to all of America. The acts were widely opposed, driving neutral parties into support of the Patriots and curtailing Loyalist sentiment.

The colonists responded by establishing the Massachusetts Provincial Congress, effectively removing Crown control of the colony outside Boston. Meanwhile, representatives from twelve colonies convened the First Continental Congress to respond to the crisis. The Congress narrowly rejected a proposal to create an American parliament to act in concert with the British Parliament; instead, they passed a compact declaring a trade boycott against Britain. The Congress also affirmed that Parliament had no authority over internal American matters, but they were willing to consent to trade regulations for the benefit of the empire, and they authorized committees and conventions to enforce the boycott. The boycott was effective, as imports from Britain dropped by 97% in 1775 compared to 1774.

Parliament refused to yield. In 1775, it declared Massachusetts to be in a state of rebellion and enforced a blockade of the colony. It then passed legislation to limit colonial trade to the British West Indies and the British Isles. Colonial ships were barred from the Newfoundland cod fisheries, a measure which pleased Canadiens but damaged New England's economy. These increasing tensions led to a mutual scramble for ordnance and pushed the colonies toward open war. Thomas Gage was the British Commander-in-Chief

On April 18, 1775, 700 troops were sent to confiscate militia ordnance stored at Concord. Fighting broke out, forcing the regulars to conduct a fighting withdrawal to Boston. Overnight, the local militia converged on and laid siege to Boston. On May 25, 4,500 British reinforcements arrived with generals William Howe, John Burgoyne, and Henry Clinton. The British seized the Charlestown peninsula on June 17 after a costly frontal assault, leading Howe to replace Gage. Many senior officers were dismayed at the attack, which had gained them little, while Gage wrote to London stressing the need for a large army to suppress the revolt. On July 3, George Washington took command of the Continental Army besieging Boston. Howe made no effort to attack, much to Washington's surprise. A plan was rejected to assault the city, and the Americans instead fortified Dorchester Heights in early March 1776 with heavy artillery captured from a raid on Fort Ticonderoga. The British were permitted to withdraw unmolested on March 17, and they sailed to Halifax, Nova Scotia. Washington then moved his army to New York.

Starting in August 1775, American Privateers began to raid villages in Nova Scotia, first at Saint John, then Charlottetown and Yarmouth. They continued in 1776 at Canso and then a land assault on Fort Cumberland

Meanwhile, British officials in Quebec began lobbying Indian tribes to support them, while the Americans urged them to maintain their neutrality. In April 1775, Congress feared an Anglo-Indian attack from Canada and authorized an invasion of Quebec. Quebec had a largely Francophone population and had been under British rule for only 12 years, and the Americans expected that they would welcome being liberated from the British. The Americans attacked Quebec City on December 31 after an arduous march but were defeated. After a loose siege, the Americans withdrew on May 6. 1776. A failed counter-attack on June 8 ended American operations in Quebec. However, the British could not conduct an aggressive pursuit because of American ships on Lake Champlain. On October 11, the British defeated the American squadron, forcing them to withdraw to Ticonderoga and ending the campaign. The invasion cost the Patriots their support in British public opinion, while aggressive anti-Loyalist policies diluted Canadian

In Virginia, Royal governor Lord Dunmore had attempted to disarm the militia as tensions increased, although no fighting broke out. He issued a proclamation on November 7, 1775 promising freedom for slaves who fled their Patriot masters to fight for the Crown. Dunmore's troops were overwhelmed by Patriots at Great Bridge, and Dunmore fled to naval ships anchored off Norfolk. Subsequent negotiations broke down, so Dunmore ordered the ships to destroy the town.

Fighting broke out on November 19 in South Carolina between Loyalist and Patriot militias, and the Loyalists were subsequently driven out of the colony. Loyalists were recruited in North Carolina to reassert colonial rule in the South, but they were decisively defeated and Loyalist sentiment was subdued. A troop of British regulars set out to reconquer South Carolina and launched an attack on Charleston on June 28, 1776, but it failed and effectively left the South in Patriot control until 1780.

The shortage of gunpowder had led Congress to authorize an expedition against the Bahamas colony in the British West Indies in order to secure ordnance there. On March 3, 1776, the Americans landed after a bloodless exchange of fire, and the local militia offered no resistance. They confiscated all the supplies that they could load and sailed away on March 17. The squadron reached New London, Connecticut on April 8, after a brief skirmish with the Royal Navy frigate "HMS Glasgow" on April 6.

After fighting began, Congress launched a final attempt to avert war, which Parliament rejected as insincere. King George then issued a Proclamation of Rebellion on August 23, 1775, which only served to embolden the colonists in their determination to become independent. After a speech by the King, Parliament rejected coercive measures on the colonies by 170 votes. British Tories refused to compromise, while Whigs argued that current policy would drive the colonists towards independence. Despite opposition, the King himself began micromanaging the war effort. The Irish Parliament pledged to send troops to America, and Irish Catholics were allowed to enlist in the army for the first time. Irish Protestants favored the Americans, while Catholics favored the King.

The initial hostilities provided a sobering military lesson for the British, causing them to rethink their views on colonial military capability. The weak British response gave the Patriots the advantage, and the British lost control over every colony. The army had been deliberately kept small in England since 1688 to prevent abuses of power by the King. Parliament secured treaties with small German states for additional troops and sent an army of 32,000 men to America after a year, the largest that it had ever sent outside Europe at the time.

In the colonies, the success of Thomas Paine's pamphlet "Common Sense" had boosted public support for independence. On July 2, Congress voted in favor of independence with twelve affirmatives and one abstention, issuing its declaration on July 4. Washington read the declaration to his men and the citizens of New York on July 9, invigorating the crowd to tear down a lead statue of the King and melting it to make bullets. British Tories criticized the signatories for not extending the same standards of equality to slaves.

Patriots followed independence with the Test Laws, requiring residents to swear allegiance to the state in which they lived, intending to root out neutrals or opponents to independence. Failure to do so meant possible imprisonment, exile, or even death. American Tories were barred from public office, forbidden from practising medicine and law, forced to pay increased taxes, or even barred from executing wills or becoming guardians to orphans. Congress enabled states to confiscate Loyalist property to fund the war. Some Quakers

After regrouping at Halifax, William Howe determined to take the fight to the Americans. He set sail in June 1776 and began landing troops on Staten Island near the entrance to New York Harbor on July 2. Due to poor military intelligence, Washington split his army to positions on Manhattan Island and across the East River in western Long Island, and an informal attempt to negotiate peace was rejected by the Americans. On August 27, Howe outflanked Washington and forced him back to Brooklyn Heights. Howe restrained his subordinates from pursuit, opting to besiege Washington instead.

Washington withdrew to Manhattan without any losses in men or ordnance. Following the withdrawal, the Staten Island Peace Conference failed to negotiate peace, as the British delegates did not possess the authority to recognize independence. Howe then seized control of New York City on September 15, and unsuccessfully engaged the Americans the following day. He attempted to encircle Washington, but the Americans successfully withdrew. On October 28, the British fought an indecisive action

Washington's retreat left his forces isolated, and the British captured an American fortification on November 16, taking 3,000 prisoners and amounting to what one historian terms "the most disastrous defeat of the entire war". Washington's army fell back four days later. Henry Clinton then captured Newport, Rhode Island, an operation which he opposed, feeling that the 6,000 troops assigned to him could have been better employed in the pursuit of Washington. The American prisoners were then sent to the infamous prison ships in which more American soldiers and sailors died of disease and neglect than died in every battle of the war combined. Charles Cornwallis pursued Washington, but Howe ordered him to halt, and Washington marched away unmolested.

The outlook of the American cause was bleak; the army had dwindled to fewer than 5,000 men and would be reduced further when the enlistments expired at the end of the year. Popular support wavered, morale ebbed away, and Congress abandoned Philadelphia

News of the campaign was well received in Britain. Festivities took place in London, public support reached a peak, and the King awarded the Order of the Bath to William Howe. The successes led to predictions that the British could win within a year. The American defeat revealed what one writer views as Washington's strategic deficiencies, such as dividing a numerically weaker army in the face of a stronger one, his inexperienced staff misreading the situation, and his troops fleeing in disorder when fighting began. In the meantime, the British entered winter quarters and were in a good place to resume campaigning.

On December 25, 1776, Washington stealthily crossed the Delaware River, and his army overwhelmed the Hessian garrison at Trenton, New Jersey the following morning, taking 900 prisoners. The decisive victory rescued the army's flagging morale and gave a new hope to the cause for independence. Cornwallis marched to retake Trenton, but his efforts were repulsed on January 2. Washington outmanoeuvred Cornwallis that night, and defeated his rearguard the following day. The victories proved instrumental in convincing the French and Spanish that the Americans were worthwhile allies, as well as recovering morale in the army. Washington entered winter quarters at Morristown, New Jersey on January 6, though a protracted guerrilla conflict continued. While encamped, Howe made no attempt to attack, much to Washington's amazement.

In December 1776, John Burgoyne returned to London to set strategy with Lord George Germain. Burgoyne's plan was to establish control of the Champlain-George-Hudson

Burgoyne's plan was to lead an army along Lake Champlain, while a strategic diversion advanced along the Mohawk River, and both would rendezvous at Albany. Burgoyne set out on June 14, 1777, quickly capturing Ticonderoga on July 5. Leaving 1,300 men behind as a garrison, Burgoyne continued the advance. Progress was slow; the Americans blocked roads, destroyed bridges, dammed streams and denuded the area of food. Meanwhile, Barry St. Ledger's diversionary column laid siege to Fort Stanwix. St. Ledger withdrew to Quebec on August 22 after his Indian support abandoned him. On August 16, a Hessian foraging expedition was soundly defeated at Bennington. The British won, but at the cost of 600 casualties. Burgoyne then dug in, but suffered a constant haemorrhage of deserters, and critical supplies were running low. On October 7, a British reconnaissance in force. Burgoyne then withdrew with the Americans in pursuit, and by October 13, he was surrounded. With no hope of relief and supplies exhausted, Burgoyne surrendered on October 17, and 6,222 soldiers became prisoners of the Americans. The decisive success spurred France to enter the war as an ally of the United States

Meanwhile, Howe launched his campaign against Washington, though his initial efforts to bring him to battle in June 1777 failed. Howe declined to attack Philadelphia overland via New Jersey, or by sea via the Delaware Bay, even though both options would have enabled him to assist Burgoyne if necessary. Instead, he took his army on a time-consuming route through the Chesapeake Bay, leaving him completely unable to assist Burgoyne. This decision was so difficult to understand, Howe's critics accused him of treason.

Howe outflanked and defeated Washington on September 11, though he failed to follow-up on the victory and destroy his army. A British victory at Willistown left Philadelphia defenceless, and Howe captured the city unopposed on September 26. Howe then moved 9,000 men to Germantown, north of Philadelphia. Washington launched a surprise attack on Howe's garrison on October 4, which was eventually repulsed. Again, Howe did not follow-up on his victory, leaving the American army intact and able to fight. Later, after several days of probing American defences at White Marsh, Howe inexplicably ordered a retreat to Philadelphia, astonishing both sides. Howe ignored the vulnerable American rear, where an attack could have deprived Washington of his baggage and supplies. On December 19, Washington's army entered winter quarters at Valley Forge. Poor conditions and supply problems resulted in the deaths of some 2,500 troops. Howe, only 20 miles (32 km) away, made no effort to attack, which critics observed could have ended the war.

The Continental Army was put through a new training program, supervised by Baron von Steuben, introducing the most modern Prussian methods of drilling. Meanwhile, Howe resigned and was replaced by Henry Clinton on May 24, 1778. Clinton received orders to abandon Philadelphia and fortify New York following France's entry into the war. On June 18, the British departed Philadelphia, with the reinvigorated Americans in pursuit. The two armies fought at Monmouth Court House on June 28, with the Americans holding the field, greatly boosting morale and confidence. By July, both armies were back in the same positions they had been two years prior.

The defeat at Saratoga caused considerable anxiety in Britain over foreign intervention. The North ministry sought reconciliation with the colonies by consenting to their original demands, although Lord North

French foreign minister the Comte de Vergennes was strongly anti-British, and he sought a pretext for going to war with Britain following the conquest of Canada in 1763. The French had covertly supplied the Americans through neutral Dutch ports since the onset of the war, proving invaluable throughout the Saratoga campaign. The French public favored war, though Vergennes and King Louis XVI were hesitant, owing to the military and financial risk. The American victory at Saratoga convinced the French that supporting the Patriots was worthwhile, but doing so also brought major concerns. The King was concerned that Britain's concessions would be accepted, and that Britain would then reconcile with the Colonies to strike at French and Spanish possessions in the Caribbean. To prevent this, France formally recognized the United States on February 6, 1778 and followed with a military alliance. France aimed to expel Britain from the Newfoundland fishery, end restrictions on Dunkirk sovereignty, regain free trade in India, recover Senegal and Dominica, and restore the Treaty of Utrecht provisions pertaining to Anglo-French trade.

Spain was wary of provoking war with Britain before being ready and opted to covertly supply the Patriots via its colonies in New Spain. Congress hoped to persuade Spain into an open alliance, so the first American Commission met with the Count of Aranda in 1776. Spain was still reluctant to make an early commitment, owing to a lack of direct French involvement, the threat against their treasure fleets, and the possibility of war with Portugal, Spain's neighbor and a close ally of Britain. However, Spain affirmed its desire to support the Americans the following year, hoping to weaken Britain's empire. The Portuguese threat was neutralized in the Spanish–Portuguese War (1776–77). On 12 April 1779, Spain signed the Treaty of Aranjuez with France and went to war against Britain. Spain sought to recover Gibraltar and Menorca in Europe, as well as Mobile and Pensacola in Florida, and also to expel the British from Central America.

Meanwhile, George III had given up on subduing America while Britain had a European war to fight. He did not welcome war with France, but he believed that Britain had made all necessary steps to avoid it and cited the British victories over France in the Seven Years' War as a reason to remain optimistic. Britain tried in vain to find a powerful ally to engage France, leaving it isolated, preventing Britain from focusing the majority of her efforts in one theater, and forcing a major diversion of military resources from America. Despite this, the King determined never to recognize American independence and to ravage the colonies indefinitely, or until they pleaded to return to the yoke of the Crown. Mahan argues that Britain's attempt to fight in multiple theaters simultaneously without major allies was fundamentally flawed, citing impossible mutual support, exposing the forces to defeat in detail.

Since the outbreak of the conflict, Britain had appealed to her ally, the neutral Dutch Republic, to lend her the use of the Scots Brigade for service in America, but pro-American sentiment among the Dutch public forced them to deny the request. Consequently, the British attempted to invoke several treaties for outright Dutch military support, but the Republic still refused. Moreover, American troops were being supplied with ordnance by Dutch merchants via their West Indies colonies. French supplies bound for America had also passed through Dutch ports. The Republic maintained free trade with France following France's declaration of war on Britain, citing a prior concession by Britain on this issue. Britain responded by confiscating Dutch shipping, and even firing upon it. Consequently, the Republic joined the First League of Armed Neutrality

Soon after France declared war, French and British fleets fought an indecisive action off Ushant on 27 July 1778. Spain entered the war on 12 April 1779, with a primary goal of capturing Gibraltar, Spanish troops under the Duc de Crillon laid siege to the Rock on 24 June. The naval blockade, however, was relatively weak, and the British were able to resupply the garrison. Meanwhile, a plan was formulated for a combined Franco-Spanish invasion of the British mainland, but the expedition failed due to a combination of poor planning, disease, logistical issues, and high financial expenditures. However, a diversionary Franco-American squadron did meet with some success on 23 September under John Paul Jones. On 16 January 1780, the Royal Navy under George Rodney scored a major victory over the Spanish, weakening the naval blockade of Gibraltar.

A Franco-Spanish fleet commanded by Luis de Córdova intercepted and decisively defeated a large British convoy off the Azores led by John Moutray on 9 August which was bound for the West Indies. The defeat was catastrophic for Britain, which lost 52 merchant ships, 5 East Indiamen, 80,000 muskets, equipment for 40,000 troops, 294 guns, and 3,144 men, making it one of the most complete naval captures ever made. The loss was valued at some £1.5 million (£ in today's money), dealing a severe blow to British commerce.

The French blockaded the lucrative sugar islands of Barbados and Jamaica, intending to damage British trade. French troops led by the Marquis de Bouillé captured Dominica on September 7, 1778 in order to improve communication among French Caribbean islands and to strike a blow against privateering. The British defeated a French naval force on December 15 and captured St. Lucia on December 28. Both fleets received reinforcements through the first half of 1779, but the French under the Comte d'Estaing had superiority in the Caribbean and began capturing British territories, seizing St. Vincent on June 18 and Grenada on July 4. The British fleet under John Byron was tactically defeated on July 6, having pursued d'Estaing from Grenada, the worst loss that the Royal Navy had suffered since 1690. Naval skirmishes continued until April 17, 1780, when British and French fleets clashed indecisively off Martinique.

General Bernardo de Gálvez raised an army in New Orleans and drove the British out of the Gulf of Mexico. He captured five British forts in the Lower Mississippi Valley, and they repelled a British and Indian attack in St. Louis, Missouri and captured the British fort of St. Joseph in Niles, Michigan. He received reinforcements from Cuba, Mexico, and Puerto Rico, then captured Mobile and Pensacola, the capital of the British colony of West Florida. At Pensacola, Gálvez commanded a multinational army of more than 7,000 black and white soldiers born in Spain, Cuba, Mexico, Puerto Rico, Santo Domingo, and other Spanish colonies such as Venezuela.

In Central America, the defense of Guatemala was a priority for Spain. The British intended to capture the key fortress of San Fernando de Omoa and drive the Spanish from the region. After inadequate first attempts, 1,200 British troops led by William Dalrymple arrived on October 16, and they captured the fort on October 20. However, the British suffered terribly due to disease and were forced to abandon the fort on November 29, and Spanish troops subsequently reoccupied it. In 1780, Jamaica's governor John Dalling planned an expedition to cut New Spain in two by capturing Granada, which would allow them full control of the San Juan River. A British expedition set out on February 3, 1780 led by John Polson and Horatio Nelson. They reached Fort San Juan

The British East India Company moved quickly to capture French possessions in India when they learned about the hostilities with France, and they took Pondicherry on 19 October 1778 after a two-week siege. The Company resolved to drive the French completely out of India, and they captured the Malabar port of Mahé in 1779 where French ordnance passed through.

Mahé was under the protection of Mysore's ruler Hyder Ali (the Tipu Sultan), and tensions were already inflamed because the British had supported Malabar rebels who had risen against him; so the fall of Mahé precipitated war. Hyder Ali invaded the Carnatic region in July 1780 and laid siege to Tellicherry and Arcot. A British relief force of 7,000 men under William Baille was intercepted and destroyed by the Tipu Sultan on 10 September, the worst defeat suffered by a European army in India at the time.

Ali then renewed the siege at Arcot instead of pressing on for a decisive victory against a second British army at Madras

Henry Clinton withdrew from Philadelphia, consolidating his forces in New York following the British defeat at Saratoga and the entry of France into the war. French admiral the Comte d'Estaing had been dispatched to North America in April 1778 to assist Washington, and he arrived shortly after Clinton withdrew into New York. The Franco-American forces felt that New York's defenses were too formidable for the French fleet, and they opted to attack Newport. This effort was launched on August 29, but it failed when the French opted to withdraw, and this displeased the Americans. The war then ground down to a stalemate, with the majority of actions fought as large skirmishes, such as those at Chestnut Neck and Little Egg Harbor. In the summer of 1779, the Americans captured British posts at Stony Point and Paulus Hook.

In July, Clinton unsuccessfully attempted to coax Washington into a decisive engagement by making a major raid into Connecticut. That month, a large American naval operation attempted to retake Maine, but it resulted in the worst American naval defeat until Pearl Harbor in 1941. The high frequency of Iroquois raids on the locals compelled Washington to mount a punitive expedition which destroyed a large number of Iroquois settlements, but the effort ultimately failed to stop the raids. During the winter of 1779–80, the Continental Army suffered greater hardships than at Valley Forge. Morale was poor; public support was being eroded by the long war; the national currency

In 1780, Clinton launched an attempt to retake New Jersey. On June 7, 6,000 men invaded under Hessian general Wilhelm von Knyphausen, but they met stiff resistance from the local militia. The British held the field, but Knyphausen feared a general engagement with Washington's main army and withdrew. Knyphausen and Clinton decided upon a second attempt two weeks later which was soundly defeated at Springfield, effectively ending British ambitions in New Jersey. Meanwhile, American general Benedict Arnold had defected to the British, and he conspired to betray the key American fortress of West Point by surrendering it to the enemy. The plot was foiled when British spy master John André was captured, so Arnold fled to British lines in New York. He attempted to justify his betrayal by appealing to Loyalist public opinion, but the Patriots strongly condemned him as a coward and turncoat.

The war to the west of the Appalachians was largely confined to skirmishing and raids. An expedition of militia was halted due to adverse weather in February 1778 which had set out to destroy British military supplies in settlements along the Cuyahoga River. Later in the year, a second campaign was undertaken to seize the Illinois Country from the British. The Americans captured Kaskaskia on July 4 and then secured Vincennes, although Vincennes was recaptured by Henry Hamilton, the British commander at Detroit. In early 1779, the Americans counterattacked by undertaking a risky winter march, and they secured the surrender of the British at Vincennes, taking Hamilton prisoner.

On May 25, 1780, the British launched an expedition into Kentucky as part of a wider operation to clear resistance from Quebec to the Gulf coast. The expedition met with only limited success, though hundreds of settlers were killed or captured. The Americans responded with a major offensive along the Mad River in August which met with some success, but it did little to abate the Indian raids on the frontier. French militia attempted to capture Detroit, but it ended in disaster when Miami Indians ambushed and defeated

The British turned their attention to conquering the South in 1778, after Loyalists in London assured them of a strong Loyalist base there. A southern campaign also had the advantage of keeping the Royal Navy closer to the Caribbean, where it would be needed to defend lucrative colonies against the Franco-Spanish fleets. On December 29, 1778, an expeditionary corps from New York captured Savannah, and British troops then moved inland to recruit Loyalist support. There was a promising initial turnout in early 1779, but then a large Loyalist militia was defeated at Kettle Creek on February 14 and they had to recognize their dependence upon the British. The British, however, defeated Patriot militia at Brier Creek on March 3, and then launched an abortive assault on Charleston, South Carolina. The operation became notorious for its high degree of looting by British troops, enraging both Loyalists and Patriot colonists.

In October, a combined Franco-American effort failed to recapture Savannah. In May 1780, Henry Clinton captured Charleston, taking over 5,000 prisoners and effectively destroying the Continental Army in the south. Organized American resistance in the region collapsed when Banastre Tarleton defeated the withdrawing Americans at Waxhaws

Clinton returned to New York, leaving Charles Cornwallis in command in Charleston to oversee the southern war effort. Far fewer Loyalists than expected joined him. In the interim, the war was carried on by Patriot militias who effectively suppressed Loyalists by winning victories in Fairfield County, Lincolnton, Huck's Defeat, Stanly County, and Lancaster County.

Congress appointed Horatio Gates, victor at Saratoga, to lead the American effort in the south. He suffered a major defeat at Camden on August 16, 1780, setting the stage for Cornwallis to invade North Carolina. The British attempted to subjugate the countryside, and Patriot militia continued to fight against them, so Cornwallis dispatched troops to raise Loyalist forces to cover his left flank as he moved north. This wing of Cornwallis' army was virtually destroyed on October 7, irreversibly breaking Loyalist support in the Carolinas. Cornwallis subsequently aborted his advance and retreated back into South Carolina. In the interim, Washington replaced Gates with his trusted subordinate, Nathanael Greene.

Greene was unable to confront the British directly, so he dispatched a force under Daniel Morgan to recruit additional troops. Morgan then defeated the cream of the British army under Tarleton on January 17, 1781 at Cowpens. Cornwallis was criticized for having detached a substantial part of his army without adequate support, but he advanced into North Carolina despite the setbacks, gambling that he would receive substantial Loyalist support there. Greene evaded combat with Cornwallis, instead wearing his army down through a protracted war of attrition.

By March, Greene's army had increased in size enough that he felt confident in facing Cornwallis. The two armies engaged at Guilford Courthouse on March 15; Greene was beaten, but Cornwallis' army suffered irreplaceable casualties. Compounding this, far fewer Loyalists were joining than the British had previously expected. Cornwallis' casualties were such that he was compelled to retreat to Wilmington for reinforcement, leaving the Patriots in control of the interior of the Carolinas and Georgia.

Greene then proceeded to reclaim the South. The American troops suffered a reversal at Hobkirk's Hill on April 25; nonetheless, they continued to dislodge strategic British posts in the area, capturing Fort Watson and Fort Motte. Augusta was the last major British outpost in the South outside of Charleston and Savannah, but the Americans reclaimed possession of it on June 6. A British force clashed with American troops at Eutaw Springs

Cornwallis had discovered that the majority of American supplies in the Carolinas were passing through Virginia, and he had written to both Lord Germain and Clinton detailing his intentions to invade. Cornwallis believed that a successful campaign there would cut supplies to Greene's army and precipitate a collapse of American resistance in the South. Clinton strongly opposed the plan, favoring a campaign farther north in the Chesapeake Bay region. Lord Germain wrote to Cornwallis to approve his plan and neglected to include Clinton in the decision-making, even though Clinton was Cornwallis' superior officer, and Cornwallis then decided to move into Virginia without informing Clinton. Clinton, however, had failed to construct a coherent strategy for British operations in 1781, owing to his difficult relationship with his naval counterpart Marriot Arbuthnot.

Following the calamitous operations at Newport and Savannah, French planners realized that closer cooperation with the Americans was required to achieve success. The French fleet led by the Comte de Grasse had received discretionary orders from Paris to assist joint efforts in the north if naval support was needed. Washington and the Comte de Rochambeau discussed their options. Washington pushed for an attack on New York, while Rochambeau preferred a strike in Virginia where the British were less well-established and thus easier to defeat. Franco-American movements around New York caused Clinton a great deal of anxiety, fearing an attack on the city. His instructions were vague to Cornwallis during this time, rarely forming explicit orders. However, Clinton did instruct Cornwallis to establish a fortified naval base and to transfer troops to the north to defend New York. Cornwallis dug in at Yorktown

Washington still favored an assault on New York, but he acquiesced to the French when they opted to send their fleet to their preferred target of Yorktown. In August, the combined Franco-American army moved south to coordinate with de Grasse in defeating Cornwallis. The British lacked sufficient naval resources to effectively counter the French, but they dispatched a fleet under Thomas Graves to assist Cornwallis and attempt to gain naval dominance. On September 5, the French fleet decisively defeated Graves, giving the French control of the seas around Yorktown and cutting off Cornwallis from reinforcements and relief. Despite the continued urging of his subordinates, Cornwallis made no attempt to break out and engage the Franco-American army before it had established siege works, expecting that reinforcements would arrive from New York, and the Franco-American army laid siege to Yorktown on September 28. Cornwallis continued to think that relief was imminent from Clinton, and he abandoned his outer defenses which were immediately occupied by American troops—serving to hasten his subsequent defeat. The British then failed in an attempt to break out of the siege across the river at Gloucester Point when a storm hit. Cornwallis and his subordinates were under increasing bombardment and facing dwindling supplies; they agreed that their situation was untenable and negotiated a surrender on October 17, 1781, and 7,685 soldiers became prisoners of the Americans. The same day as the surrender, 6,000 troops under Clinton had departed New York, sailing to relieve Yorktown.

On 25 November 1781, news arrived in London of the surrender at Yorktown. The Whig opposition gained traction in Parliament, and a motion was proposed on December 12 to end the war which was defeated by only one vote. On 27 February 1782, the House voted against further war in America by 19 votes.

Lord Germain was dismissed and a vote of no confidence was passed against North. The Rockingham Whigs came to power and opened negotiations for peace. Rockingham died and was succeeded by the Earl of Shelburne. Despite their defeat, the British still had 30,000 troops garrisoned in New York, Charleston, and Savannah. Henry Clinton was recalled and was replaced by Guy Carleton

After hostilities with the Dutch began in late 1780, Britain had moved quickly, enforcing a blockade across the North Sea. Within weeks, the British had captured 200 Dutch merchantmen, and 300 more were holed up in foreign ports, though political turmoil within the Republic and peace negotiations by both sides helped keep conflict to a minimum. The majority of the Dutch public favored a military alliance with France against Britain; however, the Dutch Stadtholder impeded these efforts, hoping to secure an early peace. To restore diminishing trade a Dutch squadron under Johan Zoutman escorted a fleet of some 70 merchantmen from the Texel. Zoutman's ships were intercepted by Sir Hyde Parker, who engaged Zoutman at Dogger Bank on 5 August 1781. Though the contest was tactically inconclusive, the Dutch fleet did not leave harbor again during the war, and their merchant fleet remained crippled.

On 6 January 1781, a French attempt to capture Jersey to neutralize British privateering failed. Frustrated in their attempts to capture Gibraltar, a Franco-Spanish force of 14,000 men under the Duc de Mahon invaded Minorca on 19 August. After a long siege of St. Philip's, the British garrison under James Murray surrendered on 5 February 1782, securing a primary war goal for the Spanish. At Gibraltar, a major Franco-Spanish assault on 13 September 1782 was repulsed with heavy casualties. On 20 October 1782, following a successful resupply of Gibraltar, British ships under Richard Howe successfully refused battle

Sint Eustatius, a key supply port for the Patriots, was sacked by British forces under George Rodney on 3 February 1781, who plundered the island's wealth. Few operations were conducted against the Dutch, although several Dutch colonies were captured by the British in 1781.

After the fall of Mobile to Spanish troops under Bernardo de Gálvez, an attempt to capture Pensacola was thwarted due to a hurricane. Emboldened by the disaster, John Campbell, British commander at Pensacola, decided to recapture Mobile. Campbell's expeditionary force of around 700 men was defeated on 7 January 1781. After re-grouping at Havana, Gálvez set out for Pensacola on 13 February. Arriving on 9 March, siege operations did not begin until 24 March, owing to difficulties in bringing the ships into the bay. After a 45-day siege, Gálvez decisively defeated the garrison, securing the conquest of West Florida. In May, Spanish troops captured the Bahamas, although the British bloodlessly recaptured the islands the following year on 18 April.

In the West Indies, on 29–30 April 1781, a Royal Navy squadron under Samuel Hood was narrowly defeated by the French, led by the Comte de Grasse, who continued seizing British territories: Tobago fell on 2 June; Demerara and Essequibo on 22 January 1782; St. Kitts and Nevis on 12 February, despite a British naval victory on 25 January; and Montserrat

In 1782, the primary strategic goal of the French and Spanish was the capture of Jamaica, whose sugar exports were more valuable to the British than the Thirteen Colonies combined. On 7 April 1782, de Grasse departed Martinique to rendezvous with Franco-Spanish troops at Saint Domingue and invade Jamaica from the north. The British under Hood and George Rodney pursued and decisively defeated the French off Dominica between 9–12 April. The Franco-Spanish plan to conquer Jamaica was in ruins, and the balance of naval power in the Caribbean shifted to the Royal Navy.

In Guatemala, Matías de Gálvez led Spanish troops in an effort to dislocate British settlements along the Gulf of Honduras. Gálvez captured Roatán on 16 March 1782, and then quickly took Black River. Following the decisive naval victory at the Saintes, Archibald Campbell, the Royal governor of Jamaica, authorized Edward Despard to re-take Black River, which he did on 22 August. However, with peace talks opening, and Franco-Spanish resources committed to the siege of Gibraltar, no further offensive operations took place.

Following Dutch entry into the conflict, East India Company troops under Hector Munro captured the Dutch port of Negapatam after a three-week siege on 11 October 1781. Soon after, British Admiral Edward Hughes captured Trincomalee after a brief engagement on 11 January 1782.

In March 1781, French Admiral Bailli de Suffren was dispatched to India to assist colonial efforts. Suffren arrived off the Indian coast in February 1782, where he clashed with a British fleet under Hughes, winning a narrow tactical victory. After landing troops at Porto Novo to assist Mysore, Suffren's fleet clashed with Hughes again Providien on 12 April. There was no clear victor, though Hughes' fleet came off worse, and he withdrew to the British-held port of Trincomalee. Hyder Ali wished for the French to capture Negapatam to establish naval dominance over the British, and this task fell to Suffren. Suffren's fleet clashed with Hughes again off Negapatam on 6 July. Suffren withdrew to Cuddalore, strategically defeated, and the British remained in control of Negapatam. Intending to find a more suitable port than Cuddalore, Suffren captured Trincomalee on 1 September, and successfully engaged Hughes

Meanwhile, Ali's troops loosely blockaded Vellore as the East India Company regrouped. Company troops under Sir Eyre Coote led a counter-offensive, defeating Ali at Porto Novo on 1 July 1781, Pollilur on 27 August, and Sholinghur on 27 September, expelling the Mysorean troops from the Carnatic. On 18 February 1782, Tipu Sultan defeated John Braithwaite near Tanjore, taking his entire 1,800-strong force prisoner. The war had, by this point, reached an uneasy stalemate. On 7 December 1782, Hyder Ali died, and the rule of Mysore passed to his son, Tipu Sultan.

Sultan advanced along the west coast, laying siege to Mangalore on 20 May 1783. Meanwhile, on the east coast, an army under James Stuart besieged the French-held port of Cuddalore on 9 June 1783. On 20 June, key British naval support for the siege was neutralized when Suffren defeated Hughes' fleet off Cuddalore, and though narrow, the victory gave Suffren the opportunity to displace British holdings in India. On 25 June, the Franco-Mysorean defenders made repeated sorties against British lines, though all assaults failed. On 30 June, news arrived of a preliminary peace between the belligerent powers, and the siege was effectively over when the French abandoned the siege. Mangalore remained under siege, and capitulated to Sultan on 30 January 1784. Little fighting took place thereafter, and Mysore and Britain made peace

Following the surrender at Yorktown, the Whig party came to power in Britain and began opening negotiations for a cessation of hostilities. While peace negotiations were being undertaken, British troops in America were restricted from launching further offensives. Prime Minister the Earl of Shelburne was reluctant to accept American independence as a prerequisite for peace, as the British were aware that the French economy was nearly bankrupt, and reinforcements sent to the West Indies could potentially reverse the situation there. He preferred that the colonies accept Dominion status within the Empire, though a similar offer had been rejected by the Americans in 1778. Negotiations soon began in Paris.

The Americans initially demanded that Quebec be ceded to them as spoils of war, a proposal that was dropped when Shelburne accepted American demands for recognition of independence. On April 19, 1782, the Dutch formally recognized the United States as a sovereign power, enhancing American leverage at the negotiations. Spain initially impeded the negotiations, refusing to enter into peace talks until Gibraltar had been captured. The Comte de Vergennes proposed that American territory be confined to the east of the Appalachians; Britain would have sovereignty over the area north of the Ohio River, below which an Indian barrier state

The Americans skirted their allies, recognizing that more favorable terms would be found in London. They negotiated directly with Shelburne, who hoped to make Britain a valuable trading partner of America at the expense of France. To this end, Shelburne offered to cede all the land east of the Mississippi River, north of Florida, and south of Quebec, while also allowing American fishermen access to the rich Newfoundland fishery. Shelburne was hoping to facilitate the growth of the American population, creating lucrative markets that Britain could exploit at no administrative cost to London. As Vergennes commented, "the English buy peace rather than make it".

Throughout the negotiations, Britain never consulted her American Indian allies, forcing them to reluctantly accept the treaty. However, the subsequent tension erupted into conflicts between the Indians and the young United States, the largest being the Northwest Indian War. Britain continued trying to create an Indian buffer state in the American Midwest as late as 1814 during the War of 1812.

Britain negotiated separate treaties with Spain, France, and the Dutch Republic. Gibraltar proved to be a stumbling block in the peace talks; Spain offered to relinquish their conquests in West Florida, Menorca, and the Bahamas in exchange for Gibraltar, terms which Shelburne steadfastly refused. Shelburne instead offered to cede East Florida, West Florida, and Menorca if Spain would relinquish the claim on Gibraltar, terms which were reluctantly accepted. However, in the long-term, the new territorial gains were of little value to Spain. France's only net gains were the island of Tobago in the Caribbean and Senegal in Africa, after agreeing to return all other colonial conquests to British sovereignty. Britain returned Dutch Caribbean territories to Dutch sovereignty, in exchange for free trade rights in the Dutch East Indies and control of the Indian port of Negapatnam.

Preliminary peace articles were signed in Paris on 30 November 1782, while preliminaries between Britain, Spain, France, and the Netherlands continued until September 1783. The United States Congress of the Confederation ratified the Treaty of Paris on January 14, 1784. Copies were sent back to Europe for ratification by the other parties involved, the first reaching France in March 1784. British ratification occurred on April 9, 1784, and the ratified versions were exchanged in Paris on May 12, 1784. The war formally concluded on September 3, 1783.

The last British troops departed New York City on November 25, 1783, marking the end of British rule in the new United States.

The total loss of life throughout the conflict is largely unknown. As was typical in wars of the era, diseases such as smallpox claimed more lives than battle. Between 1775 and 1782, a smallpox epidemic broke out throughout North America, killing 40 people in Boston alone. Historian Joseph Ellis suggests that Washington's decision to have his troops inoculated against the disease was one of his most important decisions.

Between 25,000 and 70,000 American Patriots died during active military service. Of these, approximately 6,800 were killed in battle, while at least 17,000 died from disease. The majority of the latter died while prisoners of war of the British, mostly in the prison ships in New York Harbor. If the upper limit of 70,000 is accepted as the total net loss for the Patriots, it would make the conflict proportionally deadlier than the American Civil War. Uncertainty arises due to the difficulties in accurately calculating the number of those who succumbed to disease, as it is estimated at least 10,000 died in 1776 alone. The number of Patriots seriously wounded or disabled by the war has been estimated from 8,500 to 25,000.

The French suffered approximately 7,000 total dead throughout the conflict; of those, 2,112 were killed in combat in the American theaters of war.

The Dutch suffered around 500 total killed, owing to the minor scale of their conflict with Britain.

British returns in 1783 listed 43,633 rank and file deaths across the British Armed Forces. A table from 1781 puts total British Army deaths at 9,372 soldiers killed in battle across the Americas; 6,046 in North America (1775–1779), and 3,326 in the West Indies (1778–1780). In 1784, a British lieutenant compiled a detailed list of 205 British officers killed in action during the war, encompassing Europe, the Caribbean and the East Indies. Extrapolations based upon this list puts British Army losses in the area of at least 4,000 killed or died of wounds. Approximately 7,774 Germans died in British service in addition to 4,888 deserters; of the former, it is estimated 1,800 were killed in combat.

Around 171,000 sailors served in the Royal Navy during the war; approximately a quarter of whom had been pressed into service. Around 1,240 were killed in battle, while an estimated 18,500 died from disease (1776–1780). The greatest killer at sea was scurvy, a disease caused by vitamin C deficiency. It was not until 1795 that scurvy was eradicated from the Royal Navy after the Admiralty declared lemon juice and sugar were to be issued among the standard daily rations of sailors. Around 42,000 sailors deserted during the war. The impact on merchant shipping was substantial; an estimated 3,386 merchant ships were seized by enemy forces during the war; of those, 2,283 were taken by American privateers alone.

At the start of the war, the economy of the colonies was flourishing, and the free white population enjoyed the highest standard of living in the world. The Royal Navy enforced a naval blockade during the war to financially cripple the colonies, however, this proved unsuccessful; 90% of the population worked in farming, not in coastal trade, and, as such, the American economy proved resilient enough to withstand the blockade.

Congress had immense difficulties throughout the conflict to efficiently finance the war effort. As the circulation of hard currency declined, the Americans had to rely on loans from American merchants and bankers, France, Spain and the Netherlands, saddling the young nation with crippling debts. Congress attempted to remedy this by printing vast amounts of paper money and bills of credit to raise revenue. The effect was disastrous; inflation skyrocketed, and the paper money became virtually worthless. The inflation spawned a popular phrase that anything of little value was "not worth a continental".

By 1791, the United States had accumulated a national debt of approximately $75.5 million. The United States finally solved its debt and currency problems in the 1790s, when Secretary of the Treasury Alexander Hamilton secured legislation by which the national government assumed all of the state debts, and, in addition, created a national bank and a funding system based on tariffs and bond issues that paid off the foreign debts.

Britain spent around £80 million and ended with a national debt of £250 million, (£ in today's money), generating a yearly interest of £9.5 million annually. The debts piled upon that which it had already accumulated from the Seven Years' War. Due to wartime taxation upon the British populace, the tax for the average Briton amounted to approximately four shilling in every pound, or 20 percent.

The French spent approximately 1.3 billion livres equivalent to 100 million pounds sterling (13.33 livres to the pound) on aiding the Americans, accumulating a national debt of 3.315.1 billion livres by 1783 on war costs. Unlike Britain, which had a very efficient taxation system, while the French tax system was grossly inefficient which eventually leading to a financial crisis in 1786. The debts contributed to a worsening fiscal crisis that ultimately begat the French Revolution at the end of the century. The debt continued to spiral; on the eve of the French Revolution, the national debt had skyrocketed to 12 billion livres.

Spain had nearly doubled her military spending during the war, from 454 million reales in 1778 to over 700 million in 1779. Spain more easily disposed of her debts unlike her French ally, partially due to the massive increase in silver mining

The population of Great Britain and Ireland in 1780 was approximately 12.6 million, while the Thirteen Colonies held a population of some 2.8 million, including some 500,000 slaves. Theoretically, Britain had the advantage, however, many factors inhibited the procurement of a large army.

In 1775, the standing British Army, exclusive of militia, comprised 45,123 men worldwide, made up of 38,254 infantry and 6,869 cavalry. The Army had approximately eighteen regiments of foot, some 8,500 men, stationed in North America. Standing armies had played a key role in the purge of the Long Parliament in 1648, the maintenance of a military dictatorship under Oliver Cromwell, and the overthrow of James II, and, as such, the Army had been deliberately kept small in peacetime to prevent abuses of power by the King. Despite this, eighteenth century armies were not easy guests, and were regarded with scorn and contempt by the press and public of the New and Old World alike, derided as enemies of liberty. An expression ran in the Navy

Parliament suffered chronic difficulties in obtaining sufficient manpower, and found it impossible to fill the quotas they had set. The Army was a deeply unpopular profession, one contentious issue being pay. A Private infantryman was paid a wage of just 8d. per day, the same pay as for a New Model Army infantryman, 130 years earlier. The rate of pay in the army was insufficient to meet the rising costs of living, turning off potential recruits, as service was nominally for life.

To entice people to enrol, Parliament offered a bounty of £1.10s for every recruit. As the war dragged on, Parliament became desperate for manpower; criminals were offered military service to escape legal penalties, and deserters were pardoned if they re-joined their units. After the defeat at Saratoga, Parliament doubled the bounty to £3, and increased it again the following year, to £3.3s, as well as expanding the age limit from 17–45 to 16–50 years of age.

Impressment, essentially conscription by the "press gang", was a favored recruiting method, though it was unpopular with the public, leading many to enlist in local militias to avoid regular service. Attempts were made to draft such levies, much to the chagrin of the militia commanders. Competition between naval and army press gangs, and even between rival ships or regiments, frequently resulted in brawls between the gangs in order to secure recruits for their unit. Men would maim themselves to avoid the press gangs, while many deserted at the first opportunity. Pressed men were militarily unreliable; regiments with large numbers of such men were deployed to garrisons such as Gibraltar or the West Indies, purely to increase the difficulty in successfully deserting.

By 1781, the Army numbered approximately 121,000 men globally, 48,000 of whom were stationed throughout the Americas. Of the 171,000 sailors who served in the Royal Navy throughout the conflict, around a quarter were pressed. This same proportion, approximately 42,000 men, deserted during the conflict. At its height, the Navy had 94 ships-of-the-line, 104 frigates and 37 sloops

In 1775, Britain unsuccessfully attempted to secure 20,000 mercenaries from Russia, and the use of the Scots Brigade from the Dutch Republic, such was the shortage of manpower. Parliament managed to negotiate treaties with the princes of German states for large sums of money, in exchange for mercenary troops. In total, 29,875 troops were hired for British service from six German states; Brunswick (5,723), Hesse-Kassel (16,992), Hesse-Hannau (2,422), Ansbach-Bayreuth (2,353), Waldeck-Pyrmont (1,225) and Anhalt-Zerbst (1,160). King George III, who also ruled Hanover as a Prince-elector of the Holy Roman Empire, was approached by Parliament to lend the government Hanoverian soldiers for service in the war. Hanover supplied 2,365 men in five battalions, however, the lease agreement permitted them to only be used in Europe.

Without any major allies, the manpower shortage became critical when France and Spain entered the war, forcing a major diversion of military resources from the Americas. Recruiting adequate numbers of Loyalist militia in America proved difficult due to high Patriot activity. To bolster numbers, the British promised freedom and grants of land to slaves who fought for them. Approximately 25,000 Loyalists fought for the British throughout the war, and provided some of the best troops in the British service; the British Legion, a mixed regiment of 250 dragoons and 200 infantry commanded by Banastre Tarleton, gained a fearsome reputation in the colonies, especially in the South.

Britain had a difficult time appointing a determined senior military leadership in America. Thomas Gage, Commander-in-Chief of North America at the outbreak of the war, was criticized for being too lenient on the rebellious colonists. Jeffrey Amherst, who was appointed Commander-in-Chief of the Forces in 1778, refused a direct command in America, due to unwillingness to take sides in the war. Admiral Augustus Keppel similarly opposed a command, stating; "I cannot draw the sword in such a cause". The Earl of Effingham resigned his commission when his regiment was posted to America, while William Howe and John Burgoyne were opposed to military solutions to the crisis. Howe and Henry Clinton both stated they were unwilling participants, and were only following orders.

As was the case in many European armies, except the Prussian Army, officers in British service could purchase commissions to ascend the ranks. Despite repeated attempts by Parliament to suppress it, the practise was common in the Army. Values of commissions varied, but were usually in line with social and military prestige, for example, regiments such as the Guards

Logistical organization of eighteenth century armies was chaotic at best, and the British Army was no exception. No logistical corps existed in the modern sense; while on campaign in foreign territories such as America, horses, wagons, and drivers were frequently requisitioned from the locals, often by impressment or by hire. No centrally organized medical corps existed. It was common for surgeons to have no formal medical education, and no diploma or entry examination was required. Nurses sometimes were apprentices to surgeons, but many were drafted from the women who followed the army. Army surgeons and doctors were poorly paid and were regarded as social inferiors to other officers.

The heavy personal equipment and wool uniform of the regular infantrymen were wholly unsuitable for combat in America, and the outfit was especially ill-suited to comfort and agile movement. During the Battle of Monmouth in late June 1778, the temperature exceeded 100°F (37.8°C) and is said to have claimed more lives through heat stroke than through actual combat. The standard-issue firearm of the British Army was the Land Pattern Musket

Every battalion in America had organized its own rifle company by the end of the war, although rifles were not formally issued to the army until the Baker Rifle in 1801. Flintlocks were heavily dependent on the weather; high winds could blow the gunpowder from the flash pan, while heavy rain could soak the paper cartridge, ruining the powder and rendering the musket unable to fire. Furthermore, flints used in British muskets were of notoriously poor quality; they could only be fired around six times before requiring resharpening, while American flints could fire sixty. This led to a common expression among the British: "Yankee flint was as good as a glass of grog".

Provisioning troops and sailors proved to be an immense challenge, as the majority of food stores had to be shipped overseas from Britain. The need to maintain Loyalist support prevented the Army from living off the land. Other factors also impeded this option; the countryside was too sparsely populated and the inhabitants were largely hostile or indifferent, the network of roads and bridges was poorly developed, and the area which the British controlled was so limited that foraging parties were frequently in danger of being ambushed. After France entered the war, the threat of the French navy increased the difficulty of transporting supplies to America. Food supplies were frequently in bad condition. The climate was also against the British in the southern colonies and the Caribbean, where the intense summer heat caused food supplies to sour and spoil.

Life at sea was little better. Sailors and passengers were issued a daily food ration, largely consisting of hardtack and beer. The hardtack was often infested by weevils and was so tough that it earned the nicknames "molar breakers" and "worm castles", and it sometimes had to be broken up with cannon shot. Meat supplies often spoiled on long voyages. The lack of fresh fruit and vegetables gave rise to scurvy, one of the biggest killers at sea.

Discipline was harsh in the armed forces, and the lash was used to punish even trivial offences—and not used sparingly. For instance, two redcoats received 1,000 lashes each for robbery during the Saratoga campaign, while another received 800 lashes for striking a superior officer. Flogging was a common punishment in the Royal Navy and came to be associated with the stereotypical hardiness of sailors.

Despite the harsh discipline, a distinct lack of self-discipline pervaded all ranks of the British forces. Soldiers had an intense passion for gambling, reaching such excesses that troops would often wager their own uniforms. Many drank heavily, and this was not exclusive to the lower ranks; William Howe was said to have seen many "crapulous mornings" while campaigning in New York. John Burgoyne drank heavily on a nightly basis towards the end of the Saratoga campaign. The two generals were also reported to have found solace with the wives of subordinate officers to ease the stressful burdens of command. During the Philadelphia campaign, British officers deeply offended local Quakers by entertaining their mistresses in the houses where they had been quartered. Some reports indicated that British troops were generally scrupulous in their treatment of non-combatants. This is in contrast to diaries of Hessian soldiers, who recorded their disapproval of British conduct towards the colonists, such as the destruction of property and the execution of prisoners.

The presence of Hessian soldiers caused considerable anxiety among the colonists, both Patriot and Loyalist, who viewed them as brutal mercenaries. British soldiers were often contemptuous in their treatment of Hessian troops, despite orders from General Howe that "the English should treat the Germans as brothers". The order only began to have any real effect when the Hessians learned to speak a minimal degree of English, which was seen as a prerequisite for the British troops to accord them any respect.

During peacetime, the Army's idleness led to it being riddled with corruption and inefficiency, resulting in many administrative difficulties once campaigning began.

The British leadership soon discovered it had overestimated the capabilities of its own troops, while underestimating those of the colonists, causing a sudden re-think in British planning. The ineffective initial response of British military and civil officials to the onset of the rebellion had allowed the advantage to shift to the colonists, as British authorities rapidly lost control over every colony. A microcosm of these shortcomings were evident at the Battle of Bunker Hill. It took ten hours for the British leadership to respond following the sighting of the Americans on the Charlestown Peninsula, giving the colonists ample time to reinforce their defenses. Rather than opt for a simple flanking attack that would have rapidly succeeded with minimal loss, the British decided on repeated frontal attacks. The results were telling; the British suffered 1,054 casualties of a force of around 3,000 after repeated frontal assaults. The British leadership had nevertheless remained excessively optimistic, believing that just two regiments could suppress the rebellion in Massachusetts.

Debate persists over whether a British defeat was a guaranteed outcome. Ferling argues that the odds were so long, the defeat of Britain was nothing short of a miracle. Ellis

Historians such as Ellis and Stewart have observed that, under William Howe's command, the British squandered several opportunities to achieve a decisive victory over the Americans. Throughout the New York and Philadelphia campaigns, Howe made several strategic errors, errors which cost the British opportunities for a complete victory. At Long Island, Howe failed to even attempt an encirclement of Washington, and actively restrained his subordinates from mounting an aggressive pursuit of the defeated American army. At White Plains, he refused to engage Washington's vulnerable army, and instead concentrated his efforts upon a hill which offered the British no strategic advantage. After securing control of New York, Howe dispatched Henry Clinton to capture Newport, a measure which Clinton was opposed to, on the grounds the troops assigned to his command could have been put to better use in pursuing Washington's retreating army. Despite the bleak outlook for the revolutionary cause and the surge of Loyalist activity in the wake of Washington's defeats, Howe made no attempt to mount an attack upon Washington while the Americans settled down into winter quarters, much to their surprise.

During planning for the Saratoga campaign, Howe was left with the choice of committing his army to support Burgoyne, or capture Philadelphia, the revolutionary capital. Howe decided upon the latter, determining that Washington was of a greater threat. When Howe launched his campaign, he took his army upon a time-consuming route through the Chesapeake Bay, rather than the more sensible choices of overland through New Jersey, or by sea through the Delaware Bay. The move left him unable to assist Burgoyne even if it was required of him. The decision so angered Parliament, that Howe was accused by Tories on both sides of the Atlantic of treason.

During the Philadelphia campaign, Howe failed to pursue and destroy the defeated Americans on two occasions; once after the Battle of Brandywine, and again after the Battle of Germantown. At the Battle of White Marsh, Howe failed to even attempt to exploit the vulnerable American rear, and then inexplicably ordered a retreat to Philadelphia after only minor skirmishes, astonishing both sides. While the Americans wintered only twenty miles away, Howe made no effort to attack their camp, which critics argue could have ended the war. Following the conclusion of the campaign, Howe resigned his commission, and was replaced by Henry Clinton on May 24, 1778.

Contrary to Howe's more hostile critics, however, there were strategic factors at play which impeded aggressive action. Howe may have been dissuaded from pursuing aggressive manoeuvres due to the memory of the grievous losses the British suffered at Bunker Hill. During the major campaigns in New York and Philadelphia, Howe often wrote of the scarcity of adequate provisions, which hampered his ability to mount effective campaigns. Howe's tardiness in launching the New York campaign, and his reluctance to allow Cornwallis to vigorously pursue Washington's beaten army, have both been attributed to the paucity of available food supplies.

During the winter of 1776–1777, Howe split his army into scattered cantonments. This decision dangerously exposed the individual forces to defeat in detail, as the distance between them was such that they could not mutually support each other. This strategic failure allowed the Americans to achieve victory at the Battle of Trenton, and the concurrent Battle of Princeton

In 1780, the primary British strategy hinged upon a Loyalist uprising in the south, for which Charles Cornwallis was chiefly responsible. After an encouraging success at Camden, Cornwallis was poised to invade North Carolina. However, any significant Loyalist support had been effectively destroyed at the Battle of Kings Mountain, and the British Legion, the cream of his army, had been decisively defeated at the Battle of Cowpens. Following both defeats, Cornwallis was fiercely criticized for detaching a significant portion of his army without adequate mutual support. Despite the defeats, Cornwallis chose to proceed into North Carolina, gambling his success upon a large Loyalist uprising which never materialized. As a result, subsequent engagements cost Cornwallis valuable troops he could not replace, as at the Battle of Guilford Courthouse, and the Americans steadily wore his army down in an exhaustive war of attrition. Cornwallis had thus left the Carolinas ripe for reconquest. The Americans had largely achieved this aim by the end of 1781, effectively confining the British to the coast, and undoing all the progress they had made in the previous year.

In a last-ditch attempt to win the war in the South, Cornwallis resolved to invade Virginia, in order to cut off the American's supply base to the Carolinas. Henry Clinton, Cornwallis' superior, strongly opposed the plan, believing the decisive confrontations would take place between Washington in the North. London had approved Cornwallis plan, however they had failed to include Clinton in the decision-making, despite his seniority over Cornwallis, leading to a muddled strategic direction. Cornwallis then decided to invade Virginia without informing Clinton of his intentions. Clinton, however, had wholly failed to construct a coherent strategy for British campaigning that year, owing to his fractious relationship that he shared with Mariot Arbuthnot, his naval counterpart.

As the Franco-American army approached Cornwallis at Yorktown, he made no attempt to sally out and engage before siege lines could be erected, despite the repeated urging of his subordinate officers. Expecting relief to soon arrive from Clinton, Cornwallis prematurely abandoned all of his outer defences, which were then promptly occupied by the besiegers, serving to hasten the British defeat. These factors contributed to the eventual surrender of Cornwallis' entire army, and the end of major operations in North America.

Like Howe before him, Clinton's efforts to campaign suffered from chronic supply issues. In 1778, Clinton wrote to Germain complaining of the lack of supplies, even after the arrival of a convoy from Ireland. That winter, the supply issue had deteriorated so badly, that Clinton expressed considerable anxiety over how the troops were going to be properly fed. Clinton was largely inactive in the North throughout 1779, launching few major campaigns. This inactivity was partially due to the shortage of food. By 1780, the situation had not improved. Clinton wrote a frustrated correspondence to Germain, voicing concern that a "fatal consequence will ensue" if matters did not improve. By October that year, Clinton again wrote to Germain, angered that the troops in New York had not received "an ounce" of that year's allotted stores from Britain.

Suppressing a rebellion in America presented the British with major problems. The key issue was distance; it could take up to three months to cross the Atlantic, and orders from London were often outdated by the time that they arrived. The colonies had never been formally united prior to the conflict and there was no centralized area of ultimate strategic importance. Traditionally, the fall of a capital city often signalled the end of a conflict, yet the war continued unabated even after the fall of major settlements such as New York, Philadelphia (which was the Patriot capital), and Charleston. Britain's ability to project its power overseas lay chiefly in the power of the Royal Navy, allowing her to control major coastal settlements with relative ease and enforce a strong blockade of colonial ports. However, the overwhelming majority of the American population was agrarian

The need to maintain Loyalist support prevented the British from using the harsh methods of suppressing revolts that they had used in Scotland and Ireland. For example, British troops looted and pillaged the locals during an aborted attack on Charleston in 1779, enraging both Patriots and Loyalists. Neutral colonists were often driven into the ranks of the Patriots when brutal combat broke out between Tories and Whigs across the Carolinas in the later stages of the war. Conversely, Loyalists were often emboldened when Patriots resorted to intimidating suspected Tories, such as destroying property or tarring and feathering. The vastness of the American countryside and the limited manpower available meant that the British could never simultaneously defeat the Americans and occupy captured territory. One British statesman described the attempt as "like trying to conquer a map".

Wealthy Loyalists wielded great influence in London and were successful in convincing the British that the majority view in the colonies was sympathetic toward the Crown. Consequently, British planners pinned the success of their strategies on popular uprisings of Loyalists. Historians have estimated that Loyalists made up only 15–20% of the population (vs. 40–45% Patriots) and that they continued to deceive themselves on their level of support as late as 1780. The British discovered that any significant level of organized Loyalist activity would require the continued presence of British regulars, which presented them with a major dilemma. The manpower that the British had available was insufficient to both protect Loyalist territory and counter American advances. The vulnerability of Loyalist militias was repeatedly demonstrated in the South, where they suffered strings of defeats to their Patriot neighbors. The most crucial juncture of this was at Kings Mountain, and the victory of the Patriot partisans irreversibly crippled Loyalist military capability in the South.

Upon the entry of France and Spain into the conflict, the British were forced to severely limit the number of troops and warships that they sent to North America in order to defend other key territories and the British mainland. As a result, King George III abandoned any hope of subduing America militarily while he had a European war to contend with. The small size of Britain's army left them unable to concentrate their resources primarily in one theater
The Americans began the war with significant disadvantages compared to the British. They had no national government, no national army or navy, no financial system, no banks, no established credit, and no functioning government departments, such as a treasury. The Congress tried to handle administrative affairs through legislative committees, which proved inefficient. The state governments were themselves brand new and officials had no administrative experience. In peacetime the colonies relied heavily on ocean travel and shipping, but that was now shut down by the British blockade and the Americans had to rely on slow overland travel.

However, the Americans had multiple advantages that in the long run outweighed the initial disadvantages they faced. The Americans had a large prosperous population that depended not on imports but on local production for food and most supplies, while the British were mostly shipped in from across the ocean. The British faced a vast territory far larger than Britain or France, located at a far distance from home ports. Most of the Americans lived on farms distant from the seaports—the British could capture any port but that did not give them control over the hinterland. They were on their home ground, had a smoothly functioning, well organized system of local and state governments, newspapers and printers, and internal lines of communications. They had a long-established system of local militia, previously used to combat the French and Native Americans, with companies and an officer corps that could form the basis of local militias, and provide a training ground for the national army created by Congress.

Motivation was a major asset. The Patriots wanted to win; over 200,000 fought in the war; 25,000 died. The British expected the Loyalists to do much of the fighting, but they did much less than expected. The British also hired German mercenaries to do much of their fighting.

At the onset of the war, the Americans had no major international allies. Battles such as the Battle of Bennington, the Battles of Saratoga and even defeats such as the Battle of Germantown proved decisive in gaining the attention and support of powerful European nations such as France and Spain, who moved from covertly supplying the Americans with weapons and supplies, to overtly supporting them militarily, moving the war to a global stage.

The new Continental Army suffered significantly from a lack of an effective training regime, and largely inexperienced officers and sergeants. The inexperience of its officers was compensated for in part by a few senior officers. The Americans solved their training dilemma during their stint in Winter Quarters at Valley Forge, where they were relentlessly drilled and trained by General Friedrich Wilhelm von Steuben, a veteran of the famed Prussian General Staff. He taught the Continental Army the essentials of military discipline, drills, tactics and strategy, and wrote the Revolutionary War Drill Manual. When the Army emerged from Valley Forge, it proved its ability to equally match the British troops in battle when they fought a successful strategic action at the Battle of Monmouth

When the war began, the 13 colonies lacked a professional army or navy. Each colony sponsored local militia. Militiamen were lightly armed, had little training, and usually did not have uniforms. Their units served for only a few weeks or months at a time, were reluctant to travel far from home and thus were unavailable for extended operations, and lacked the training and discipline of soldiers with more experience. If properly used, however, their numbers could help the Continental armies overwhelm smaller British forces, as at the battles of Concord, Bennington and Saratoga, and the siege of Boston. Both sides used partisan warfare but the Americans effectively suppressed Loyalist activity when British regulars were not in the area.

Seeking to coordinate military efforts, the Continental Congress established a regular army on June 14, 1775, and appointed George Washington as commander-in-chief. The development of the Continental Army was always a work in progress, and Washington used both his regulars and state militia throughout the war.

Three current branches of the United States Military trace their institutional roots to the American Revolutionary War; the United States Army comes from the Continental Army, formed by a resolution of the Continental Congress on June 14, 1775. The United States Navy recognizes October 13, 1775 as the date of its official establishment, the passage of the resolution of the Continental Congress at Philadelphia that created the Continental Navy.
The United States Marine Corps links to the Continental Marines of the war, formed by a resolution of the Continental Congress on November 10, 1775. However, in 1783 both the Continental Navy and Continental Marines were disbanded.

At the beginning of 1776, Washington commanded 20,000 men, with two-thirds enlisted in the Continental Army and the other third in the various state militias. About 250,000 men served as regulars or as militiamen for the Revolutionary cause in the eight years of the war, but there were never more than 90,000 men under arms at one time.

About 55,000 sailors served aboard American privateers during the war. They used 1,700 ships, and they captured 2,283 enemy ships. John Paul Jones became the first great American naval hero, capturing HMS "Drake" on April 24, 1778, the first victory for any American military vessel in British waters.

Armies were small by European standards of the era, largely attributable, on the American side, to limitations such as lack of powder and other logistical capabilities; and, on the British side, to the difficulty of transporting troops across the Atlantic, as well as the dependence on local supplies, which the Patriots tried to cut off. The largest force Washington commanded was certainly under 17,000, and may have been no more than 13,000 troops, and even the combined American and French forces at the siege of Yorktown amounted to only about 19,000. By comparison, Duffy notes that in an era when European rulers were generally revising their forces downward, in favor of a size that could be most effectively controlled (the very different perspective of mass conscript armies came later, during the French Revolutionary and then the Napoleonic Wars), the largest army that Frederick the Great ever led into battle was 65,000 men (at Prague in 1757), and at other times he commanded between 23,000 and 50,000 men, considering the latter the most effective number.

General Washington assumed five main roles during the war.

First, he designed the overall strategy of the war, in cooperation with Congress. The goal was always independence. When France entered the war, he worked closely with the soldiers it sent – they were decisive in the great victory at Yorktown in 1781.

Second, he provided leadership of troops against the main British forces in 1775–77 and again in 1781. He lost many of his battles, but he never surrendered his army during the war, and he continued to fight the British relentlessly until the war's end. Washington worked hard to develop a successful espionage system to detect British locations and plans. In 1778, he formed the Culper Ring to spy on enemy movements in New York City. In 1780 it discovered Benedict Arnold was a traitor. The British put a low value on intelligence, and its operations were of poor quality until 1780, when it finally inserted some spies with Congress and with Washington's command. Even then, however, British commanders ignored or downplayed threats that were revealed. The most serious intelligence failure came in 1781 when top commanders were unaware that The American and French armies at both left the Northeast and marched down to Yorktown, where they outnumbered Cornwallis by more than 2 to 1.

Third, he was charged selecting and guiding the generals. In June 1776, Congress made its first attempt at running the war effort with the committee known as "Board of War and Ordnance", succeeded by the Board of War in July 1777, a committee which eventually included members of the military. The command structure of the armed forces was a hodgepodge of Congressional appointees (and Congress sometimes made those appointments without Washington's input) with state-appointments filling the lower ranks. The results of his general staff were mixed, as some of his favorites never mastered the art of command, such as John Sullivan. Eventually, he found capable officers such as Nathanael Greene, Daniel Morgan, Henry Knox (chief of artillery), and Alexander Hamilton (chief of staff). The American officers never equaled their opponents in tactics and maneuver, and they lost most of the pitched battles. The great successes at Boston (1776), Saratoga (1777), and Yorktown (1781) came from trapping the British far from base with much larger numbers of troops.

Fourth he took charge of training the army and providing supplies, from food to gunpowder to tents. He recruited regulars and assigned Baron Friedrich Wilhelm von Steuben

African Americans—slave and free—served on both sides during the war. The British recruited slaves belonging to Patriot masters and promised freedom to those who served by act of Lord Dunmore's Proclamation. Because of manpower shortages, George Washington lifted the ban on black enlistment in the Continental Army in January 1776. Small all-black units were formed in Rhode Island and Massachusetts; many slaves were promised freedom for serving. Some of the men promised freedom were sent back to their masters, after the war was over, out of political convenience. Another all-black unit came from Saint-Domingue

Most American Indians east of the Mississippi River were affected by the war, and many tribes were divided over the question of how to respond to the conflict. A few tribes were on friendly terms with the other Americans, but most Indians opposed the union of the Colonies as a potential threat to their territory. Approximately 13,000 Indians fought on the British side, with the largest group coming from the Iroquois tribes, who fielded around 1,500 men. The powerful Iroquois Confederacy was shattered as a result of the conflict, whatever side they took; the Seneca, Onondaga, and Cayuga nations sided with the British. Members of the Mohawk nation fought on both sides. Many Tuscarora and Oneida sided with the colonists. The Continental Army sent the Sullivan Expedition on raids throughout New York to cripple the Iroquois tribes that had sided with the British. Mohawk leaders Joseph Louis Cook and Joseph Brant sided with the Americans and the British respectively, and this further exacerbated the split.

Early in July 1776, a major action occurred in the fledgling conflict when the Cherokee allies of Britain attacked the western frontier areas of North Carolina. Their defeat resulted in a splintering of the Cherokee settlements and people, and was directly responsible for the rise of the Chickamauga Cherokee, bitter enemies of the Colonials who carried on a frontier war for decades following the end of hostilities with Britain.

Creek and Seminole allies of Britain fought against Americans in Georgia and South Carolina. In 1778, a force of 800 Creeks destroyed American settlements along the Broad River in Georgia. Creek warriors also joined Thomas Brown's raids into South Carolina and assisted Britain during the Siege of Savannah. Many Indians were involved in the fighting between Britain and Spain on the Gulf Coast and up the Mississippi River—mostly on the British side. Thousands of Creeks, Chickasaws, and Choctaws fought in major battles such as the Battle of Fort Charlotte, the Battle of Mobile, and the Siege of Pensacola.

Pybus (2005) estimates that about 20,000 slaves defected to or were captured by the British, of whom about 8,000 died from disease or wounds or were recaptured by the Patriots. The British took some 12,000 at the end of the war; of these 8000 remained in slavery. Including those who left during the war, a total of about 8000 to 10,000 slaves gained freedom. About 4000 freed slaves went to Nova Scotia and 1200 blacks remained slaves.

Baller (2006) examines family dynamics and mobilization for the Revolution in central Massachusetts. He reports that warfare and the farming culture were sometimes incompatible. Militiamen found that living and working on the family farm had not prepared them for wartime marches and the rigors of camp life. Rugged individualism conflicted with military discipline and regimentation. A man's birth order often influenced his military recruitment, as younger sons went to war and older sons took charge of the farm. A person's family responsibilities and the prevalent patriarchy could impede mobilization. Harvesting duties and family emergencies pulled men home regardless of the sergeant's orders. Some relatives might be Loyalists, creating internal strains. On the whole, historians conclude the Revolution's effect on patriarchy and inheritance patterns favored egalitarianism.

McDonnell (2006) shows a grave complication in Virginia's mobilization of troops was the conflicting interests of distinct social classes, which tended to undercut a unified commitment to the Patriot cause. The Assembly balanced the competing demands of elite slave-owning planters, the middling yeomen
Category:Global conflicts
Category:Wars between the United Kingdom and the United States
Category:Rebellions against the British Empire
Category:Wars of independence
Category:Conflicts in 1775
Category:Conflicts in 1776
Category:Conflicts in 1777
Category:Conflicts in 1778
Category:Conflicts in 1779
Category:Conflicts in 1780
Category:Conflicts in 1781
Category:Conflicts in 1782
Category:Conflicts in 1783
Category:Proxy warsAmpere

The ampere (; symbol: A), often shortened to "amp", is the base unit of electric current in the International System of Units (SI). It is named after André-Marie Ampère (1775–1836), French mathematician and physicist, considered the father of electrodynamics.

The International System of Units defines the ampere in terms of other base units by measuring the electromagnetic force between electrical conductors carrying electric current. The earlier CGS measurement system had two different definitions of current, one essentially the same as the SI's and the other using electric charge as the base unit, with the unit of charge defined by measuring the force between two charged metal plates. The ampere was then defined as one coulomb of charge per second. In SI, the unit of charge, the coulomb, is defined as the charge carried by one ampere during one second.

New definitions, in terms of invariant constants of nature, specifically the elementary charge
SI defines ampere as follows:

The ampere is that constant current which, if maintained in two straight parallel conductors of infinite length, of negligible circular cross-section, and placed one metre apart in vacuum, would produce between these conductors a force equal to newtons per metre of length.
Ampère's force law states that there is an attractive or repulsive force between two parallel wires carrying an electric current. This force is used in the formal definition of the ampere.

The SI unit of charge, the coulomb, "is the quantity of electricity carried in 1 second by a current of 1 ampere". Conversely, a current of one ampere is one coulomb of charge going past a given point per second:
In general, charge "Q" is determined by steady current "I" flowing for a time "t" as .

Constant, instantaneous and average current are expressed in amperes (as in "the charging current is 1.2 A") and the charge accumulated, or passed through a circuit over a period of time is expressed in coulombs (as in "the battery charge is "). The relation of the ampere (C/s) to the coulomb is the same as that of the watt (J/s) to the joule.

The ampere was originally defined as one tenth of the unit of electric current in the centimetre–gram–second system of units. That unit, now known as the abampere, was defined as the amount of current that generates a force of two dynes per centimetre of length between two wires one centimetre apart. The size of the unit was chosen so that the units derived from it in the MKSA system would be conveniently sized.

The "international ampere" was an early realization of the ampere, defined as the current that would deposit of silver per second from a silver nitrate solution. Later, more accurate measurements revealed that this current is .

Since power is defined as the product of current and voltage, the ampere can alternatively be expressed in terms of the other units using the relationship I=P/V, and thus 1 ampere equals 1 W/V. Current can be measured by a multimeter, a device that can measure electrical voltage, current, and resistance.

The standard ampere is most accurately realized using a Kibble balance, but is in practice maintained via Ohm's law from the units of electromotive force and resistance, the volt and the ohm, since the latter two can be tied to physical phenomena that are relatively easy to reproduce, the Josephson junction and the quantum Hall effect, respectively.

At present, techniques to establish the realization of an ampere have a relative uncertainty of approximately a few parts in 10, and involve realizations of the watt, the ohm and the volt.

Rather than a definition in terms of the force between two current-carrying wires, it has been proposed that the ampere should be defined in terms of the rate of flow of elementary charges. Since a coulomb is approximately equal to elementary charges (such as those carried by protons, or the negative of those carried by electrons), one ampere is approximately equivalent to elementary charges moving past a boundary in one second. ( is the reciprocal of the value of the elementary charge in coulombs.) The proposed change would define 1 A as being the current in the direction of flow of a particular number of elementary charges per second. In 2005, the International Committee for Weights and Measures (CIPM) agreed to study the proposed change. The new definition was discussed at the 25th General Conference on Weights and Measures (CGPM) in 2014 but for the time being was not adopted.

The current drawn by typical constant-voltage energy distribution systems is usually dictated by the power (watt) consumed by the system and the operating voltage. For this reason the examples given below are grouped by voltage level.



A typical motor vehicle has a 12 V battery. The various accessories that are powered by the battery might include:

Most Canada, Mexico and United States domestic power suppliers run at 120 V.

Household circuit breakers typically provide a maximum of 15 A or 20 A of current to a given set of outlets.

Most European domestic power supplies run at 230 V, and most Commonwealth domestic power supplies run at 240 V. For the same amount of power (in watts), the current drawn by a particular European or Commonwealth appliance (in Europe or a Commonwealth country) will be less than for an equivalent North American appliance. Typical circuit breakers will provide 16 A.

The current drawn by a number of typical appliances are:



Category:SI base units
Category:Units of electric current

In mathematics and computer science, an algorithm () is an unambiguous specification of how to solve a class of problems. Algorithms can perform calculation, data processing, and automated reasoning tasks.

As an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing "output" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.

The concept of algorithm has existed for centuries. Greek mathematicians used algorithms in the sieve of Eratosthenes for finding prime numbers, and the Euclidean algorithm for finding the greatest common divisor of two numbers.

The word "algorithm" itself is derived from the 9th century mathematician Muḥammad ibn Mūsā al-Khwārizmī, Latinized "Algoritmi". A partial formalization of what would become the modern concept of algorithm began with attempts to solve the Entscheidungsproblem (decision problem) posed by David Hilbert in 1928. Later formalizations were framed as attempts to define "effective calculability" or "effective method". Those formalizations included the Gödel–Herbrand–Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church's lambda calculus of 1936, Emil Post's Formulation 1 of 1936, and Alan Turing's Turing machines of 1936–37 and 1939.

The word 'algorithm' has its roots in Latinizing the name of Muhammad ibn Musa al-Khwarizmi in a first step to "algorismus". Al-Khwārizmī (, , c. 780–850) was a Persian mathematician, astronomer, geographer, and scholar in the House of Wisdom in Baghdad, whose name means 'the native of Khwarazm', a region that was part of Greater Iran and is now in Uzbekistan.

About 825, al-Khwarizmi wrote an Arabic language treatise on the Hindu–Arabic numeral system, which was translated into Latin during the 12th century under the title "Algoritmi de numero Indorum". This title means "Algoritmi on the numbers of the Indians", where "Algoritmi" was the translator's Latinization of Al-Khwarizmi's name. Al-Khwarizmi was the most widely read mathematician in Europe in the late Middle Ages, primarily through another of his books, the Algebra. In late medieval Latin, "algorismus", English 'algorism', the corruption of his name, simply meant the "decimal number system". In the 15th century, under the influence of the Greek word ἀριθμός 'number' ("cf." 'arithmetic'), the Latin word was altered to "algorithmus", and the corresponding English term 'algorithm' is first attested in the 17th century; the modern sense was introduced in the 19th century.

In English, it was first used in about 1230 and then by Chaucer in 1391. English adopted the French term, but it wasn't until the late 19th century that "algorithm" took on the meaning that it has in modern English.

Another early use of the word is from 1240, in a manual titled "Carmen de Algorismo" composed by Alexandre de Villedieu. It begins thus:
which translates as:
The poem is a few hundred lines long and summarizes the art of calculating with the new style of Indian dice, or Talibus Indorum, or Hindu numerals.

An informal definition could be "a set of rules that precisely defines a sequence of operations". which would include all computer programs, including programs that do not perform numeric calculations. Generally, a program is only an algorithm if it stops eventually.

A prototypical example of an algorithm is the Euclidean algorithm to determine the maximum common divisor of two integers; an example (there are others) is described by the flowchart above and as an example in a later section.

No human being can write fast enough, or long enough, or small enough† ( †"smaller and smaller without limit ...you'd be trying to write on molecules, on atoms, on electrons") to list all members of an enumerably infinite set by writing out their names, one after another, in some notation. But humans can do something equally useful, in the case of certain enumerably infinite sets: They can give "explicit instructions for determining the nth member of the set", for arbitrary finite "n". Such instructions are to be given quite explicitly, in a form in which "they could be followed by a computing machine", or by a "human who is capable of carrying out only very elementary operations on symbols."

An "enumerably infinite set" is one whose elements can be put into one-to-one correspondence with the integers. Thus, Boolos and Jeffrey are saying that an algorithm implies instructions for a process that "creates" output integers from an "arbitrary" "input" integer or integers that, in theory, can be arbitrarily large. Thus an algorithm can be an algebraic equation such as "y = m + n" – two arbitrary "input variables" "m" and "n" that produce an output "y". But various authors' attempts to define the notion indicate that the word implies much more than this, something on the order of (for the addition example):

The concept of "algorithm" is also used to define the notion of decidability. That notion is central for explaining how formal systems come into being starting from a small set of axioms and rules. In logic, the time that an algorithm requires to complete cannot be measured, as it is not apparently related to our customary physical dimension. From such uncertainties, that characterize ongoing work, stems the unavailability of a definition of "algorithm" that suits both concrete (in some sense) and abstract usage of the term.

Algorithms are essential to the way computers process data. Many computer programs contain algorithms that detail the specific instructions a computer should perform (in a specific order) to carry out a specified task, such as calculating employees' paychecks or printing students' report cards. Thus, an algorithm can be considered to be any sequence of operations that can be simulated by a Turing-complete system. Authors who assert this thesis include Minsky (1967), Savage (1987) and Gurevich (2000):

Typically, when an algorithm is associated with processing information, data can be read from an input source, written to an output device and stored for further processing. Stored data are regarded as part of the internal state of the entity performing the algorithm. In practice, the state is stored in one or more data structures.

For some such computational process, the algorithm must be rigorously defined: specified in the way it applies in all possible circumstances that could arise. That is, any conditional steps must be systematically dealt with, case-by-case; the criteria for each case must be clear (and computable).

Because an algorithm is a precise list of precise steps, the order of computation is always crucial to the functioning of the algorithm. Instructions are usually assumed to be listed explicitly, and are described as starting "from the top" and going "down to the bottom", an idea that is described more formally by "flow of control".

So far, this discussion of the formalization of an algorithm has assumed the premises of imperative programming. This is the most common conception, and it attempts to describe a task in discrete, "mechanical" means. Unique to this conception of formalized algorithms is the assignment operation, setting the value of a variable. It derives from the intuition of "memory" as a scratchpad. There is an example below of such an assignment.

For some alternate conceptions of what constitutes an algorithm see functional programming and logic programming.

Algorithms can be expressed in many kinds of notation, including natural languages, pseudocode, flowcharts, drakon-charts, programming languages or control tables (processed by interpreters). Natural language expressions of algorithms tend to be verbose and ambiguous, and are rarely used for complex or technical algorithms. Pseudocode, flowcharts, drakon-charts and control tables are structured ways to express algorithms that avoid many of the ambiguities common in natural language statements. Programming languages are primarily intended for expressing algorithms in a form that can be executed by a computer but are often used as a way to define or document algorithms.

There is a wide variety of representations possible and one can express a given Turing machine program as a sequence of machine tables (see more at finite-state machine, state transition table and control table), as flowcharts and drakon-charts (see more at state diagram), or as a form of rudimentary machine code or assembly code called "sets of quadruples" (see more at Turing machine).

Representations of algorithms can be classed into three accepted levels of Turing machine description:

For an example of the simple algorithm "Add m+n" described in all three levels, see Algorithm#Examples.

Algorithm design refers to a method or mathematical process for problem-solving and engineering algorithms. The design of algorithms is part of many solution theories of operation research, such as dynamic programming and divide-and-conquer. Techniques for designing and implementing algorithm designs are also called algorithm design patterns, such as the template method pattern and decorator pattern.

One of the most important aspects of algorithm design is creating an algorithm that has an efficient run-time, also known as its Big O
Most algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain implementing arithmetic or an insect looking for food), in an electrical circuit

In computer systems, an algorithm is basically an instance of logic written in software by software developers, to be effective for the intended "target" computer(s) to produce "output" from given (perhaps null) "input". An optimal algorithm, even running in old hardware, would produce faster results than a non-optimal (higher time complexity) algorithm for the same purpose, running in more efficient hardware; that is why algorithms, like computer hardware, are considered technology.

""Elegant" (compact) programs, "good" (fast) programs ": The notion of "simplicity and elegance" appears informally in Knuth and precisely in Chaitin:

Chaitin prefaces his definition with: "I'll show you can't prove that a program is 'elegant—such a proof would solve the Halting problem (ibid).

"Algorithm versus function computable by an algorithm": For a given function multiple algorithms may exist. This is true, even without expanding the available instruction set available to the programmer. Rogers observes that "It is ... important to distinguish between the notion of "algorithm", i.e. procedure and the notion of "function computable by algorithm", i.e. mapping yielded by procedure. The same function may have several different algorithms".

Unfortunately, there may be a tradeoff between goodness (speed) and elegance (compactness)—an elegant program may take more steps to complete a computation than one less elegant. An example that uses Euclid's algorithm appears below.

"Computers (and computors), models of computation": A computer (or human "computor") is a restricted type of machine, a "discrete deterministic mechanical device" that blindly follows its instructions. Melzak's and Lambek's primitive models reduced this notion to four elements: (i) discrete, distinguishable "locations", (ii) discrete, indistinguishable "counters" (iii) an agent, and (iv) a list of instructions that are "effective" relative to the capability of the agent.

Minsky describes a more congenial variation of Lambek's "abacus" model in his "Very Simple Bases for Computability". Minsky's machine proceeds sequentially through its five (or six, depending on how one counts) instructions, unless either a conditional IF–THEN GOTO or an unconditional GOTO changes program flow out of sequence. Besides HALT, Minsky's machine includes three "assignment" (replacement, substitution) operations: ZERO (e.g. the contents of location replaced by 0: L ← 0), SUCCESSOR (e.g. L ← L+1), and DECREMENT (e.g. L ← L − 1). Rarely must a programmer write "code" with such a limited instruction set. But Minsky shows (as do Melzak and Lambek) that his machine is Turing complete with only four general "types" of instructions: conditional GOTO, unconditional GOTO, assignment/replacement/substitution, and HALT.

"Simulation of an algorithm: computer (computor) language": Knuth advises the reader that "the best way to learn an algorithm is to try it . . . immediately take pen and paper and work through an example". But what about a simulation or execution of the real thing? The programmer must translate the algorithm into a language that the simulator/computer/computor can "effectively" execute. Stone gives an example of this: when computing the roots of a quadratic equation the computor must know how to take a square root. If they don't, then the algorithm, to be effective, must provide a set of rules for extracting a square root.

This means that the programmer must know a "language" that is effective relative to the target computing agent (computer/computor).

But what model should be used for the simulation? Van Emde Boas observes "even if we base complexity theory on abstract instead of concrete machines, arbitrariness of the choice of a model remains. It is at this point that the notion of "simulation" enters". When speed is being measured, the instruction set matters. For example, the subprogram in Euclid's algorithm to compute the remainder would execute much faster if the programmer had a "modulus" instruction available rather than just subtraction (or worse: just Minsky's "decrement").

"Structured programming, canonical structures": Per the Church–Turing thesis, any algorithm can be computed by a model known to be Turing complete, and per Minsky's demonstrations, Turing completeness requires only four instruction types—conditional GOTO, unconditional GOTO, assignment, HALT. Kemeny and Kurtz observe that, while "undisciplined" use of unconditional GOTOs and conditional IF-THEN GOTOs can result in "spaghetti code", a programmer can write structured programs using only these instructions; on the other hand "it is also possible, and not too hard, to write badly structured programs in a structured language". Tausworthe augments the three Böhm-Jacopini canonical structures: SEQUENCE, IF-THEN-ELSE, and WHILE-DO, with two more: DO-WHILE and CASE. An additional benefit of a structured program is that it lends itself to proofs of correctness using mathematical induction.

"Canonical flowchart symbols": The graphical aide called a flowchart

One of the simplest algorithms is to find the largest number in a list of numbers of random order. Finding the solution requires looking at every number in the list. From this follows a simple algorithm, which can be stated in a high-level description in English prose, as:

"High-level description:"

"(Quasi-)formal description:"
Written in prose but much closer to the high-level language of a computer program, the following is the more formal coding of the algorithm in pseudocode or pidgin code

Euclid's algorithm to compute the greatest common divisor (GCD) to two numbers appears as Proposition II in Book VII ("Elementary Number Theory") of his "Elements". Euclid poses the problem thus: "Given two numbers not prime to one another, to find their greatest common measure". He defines "A number [to be] a multitude composed of units": a counting number, a positive integer not including zero. To "measure" is to place a shorter measuring length "s" successively ("q" times) along longer length "l" until the remaining portion "r" is less than the shorter length "s". In modern words, remainder "r" = "l" − "q"×"s", "q" being the quotient, or remainder "r" is the "modulus", the integer-fractional part left over after the division.

For Euclid's method to succeed, the starting lengths must satisfy two requirements: (i) the lengths must not be zero, AND (ii) the subtraction must be “proper”; i.e., a test must guarantee that the smaller of the two numbers is subtracted from the larger (alternately, the two can be equal so their subtraction yields zero).

Euclid's original proof adds a third requirement: the two lengths must not be prime to one another. Euclid stipulated this so that he could construct a reductio ad absurdum proof that the two numbers' common measure is in fact the "greatest". While Nicomachus' algorithm is the same as Euclid's, when the numbers are prime to one another, it yields the number "1" for their common measure. So, to be precise, the following is really Nicomachus' algorithm.

[[File:Euclids-algorithm-example-1599-650.gif|350px|thumb|right|A graphical expression of Euclid's algorithm to find the greatest common divisor for 1599 and 650.

Only a few instruction "types" are required to execute Euclid's algorithm—some logical tests (conditional GOTO), unconditional GOTO, assignment (replacement), and subtraction.

[[File:Euclid's algorithm Inelegant program 1.png|thumb|163px|right|"Inelegant" is a translation of Knuth's version of the algorithm with a subtraction-based remainder-loop replacing his use of division (or a "modulus" instruction). Derived from Knuth 1973:2–4. Depending on the two numbers "Inelegant" may compute the g.c.d. in fewer steps than "Elegant".]]

The following algorithm is framed as Knuth's four-step version of Euclid's and Nicomachus', but, rather than using division to find the remainder, it uses successive subtractions of the shorter length "s" from the remaining length "r" until "r" is less than "s". The high-level description, shown in boldface, is adapted from Knuth 1973:2–4:

INPUT:

E0: [Ensure "r" ≥ "s".]

E1: [Find remainder]: Until the remaining length "r" in R is less than the shorter length "s" in S, repeatedly subtract the measuring number "s" in S from the remaining length "r" in R.

E2: [Is the remainder zero?]: EITHER (i) the last measure was exact, the remainder in R is zero, and the program can halt, OR (ii) the algorithm must continue: the last measure left a remainder in R less than measuring number in S.

E3: [Interchange "s" and "r"]: The nut of Euclid's algorithm. Use remainder "r" to measure what was previously smaller number "s"; L serves as a temporary location.

OUTPUT:

DONE:

The following version of Euclid's algorithm requires only six core instructions to do what thirteen are required to do by "Inelegant"; worse, "Inelegant" requires more "types" of instructions. The flowchart of "Elegant" can be found at the top of this article. In the (unstructured) Basic language, the steps are numbered, and the instruction is the assignment instruction symbolized by ←.

The following version can be used with Object Oriented languages:

"How "Elegant" works": In place of an outer "Euclid loop", "Elegant" shifts back and forth between two "co-loops", an A > B loop that computes A ← A − B, and a B ≤ A loop that computes B ← B − A. This works because, when at last the minuend M is less than or equal to the subtrahend S ( Difference = Minuend − Subtrahend), the minuend can become "s" (the new measuring length) and the subtrahend can become the new "r" (the length to be measured); in other words the "sense" of the subtraction reverses.

Does an algorithm do what its author wants it to do? A few test cases usually suffice to confirm core functionality. One source uses 3009 and 884. Knuth suggested 40902, 24140. Another interesting case is the two [[relatively prime]] numbers 14157 and 5950.

But exceptional cases must be identified and tested. Will "Inelegant" perform properly when R > S, S > R, R = S? Ditto for "Elegant": B > A, A > B, A = B? (Yes to all). What happens when one number is zero, both numbers are zero? ("Inelegant" computes forever in all cases; "Elegant" computes forever when A = 0.) What happens if "negative" numbers are entered? Fractional numbers? If the input numbers, i.e. the [[domain (mathematics)|domain]] of the function computed by the algorithm/program, is to include only positive integers including zero, then the failures at zero indicate that the algorithm (and the program that [[instance (computer science)|instantiates]] it) is a [[partial function]] rather than a [[total function]]. A notable failure due to exceptions is the [[Ariane 5 Flight 501]] rocket failure (June 4, 1996).

"Proof of program correctness by use of mathematical induction": Knuth demonstrates the application of [[mathematical induction]] to an "extended" version of Euclid's algorithm, and he proposes "a general method applicable to proving the validity of any algorithm". Tausworthe proposes that a measure of the complexity of a program be the length of its correctness proof.

"Elegance (compactness) versus goodness (speed)": With only six core instructions, "Elegant" is the clear winner, compared to "Inelegant" at thirteen instructions. However, "Inelegant" is "faster" (it arrives at HALT in fewer steps). [[Algorithm analysis]] indicates why this is the case: "Elegant" does "two" conditional tests in every subtraction loop, whereas "Inelegant" only does one. As the algorithm (usually) requires many loop-throughs, "on average" much time is wasted doing a "B = 0?" test that is needed only after the remainder is computed.

"Can the algorithms be improved?": Once the programmer judges a program "fit" and "effective"—that is, it computes the function intended by its author—then the question becomes, can it be improved?

The compactness of "Inelegant" can be improved by the elimination of five steps. But Chaitin proved that compacting an algorithm cannot be automated by a generalized algorithm; rather, it can only be done [[heuristic]]ally; i.e., by exhaustive search (examples to be found at [[Busy beaver]]), trial and error, cleverness, insight, application of [[inductive reasoning]], etc. Observe that steps 4, 5 and 6 are repeated in steps 11, 12 and 13. Comparison with "Elegant" provides a hint that these steps, together with steps 2 and 3, can be eliminated. This reduces the number of core instructions from thirteen to eight, which makes it "more elegant" than "Elegant", at nine steps.

The speed of "Elegant" can be improved by moving the "B=0?" test outside of the two subtraction loops. This change calls for the addition of three instructions (B = 0?, A = 0?, GOTO). Now "Elegant" computes the example-numbers faster; whether this is always the case for any given A, B, and R, S would require a detailed analysis.

It is frequently important to know how much of a particular resource (such as time or storage) is theoretically required for a given algorithm. Methods have been developed for the [[analysis of algorithms]] to obtain such quantitative answers (estimates); for example, the sorting algorithm above has a time requirement of O("n"), using the [[big O notation]] with "n" as the length of the list. At all times the algorithm only needs to remember two values: the largest number found so far, and its current position in the input list. Therefore, it is said to have a space requirement of "O(1)", if the space required to store the input numbers is not counted, or O("n") if it is counted.

Different algorithms may complete the same task with a different set of instructions in less or more time, space, or '[[algorithmic efficiency|effort]]' than others. For example, a [[binary search]] algorithm (with cost O(log n) ) outperforms a sequential search (cost O(n) ) when used for [[lookup table|table lookups]] on sorted lists or arrays.

The [[analysis of algorithms|analysis, and study of algorithms]] is a discipline of [[computer science]], and is often practiced abstractly without the use of a specific [[programming language]] or implementation. In this sense, algorithm analysis resembles other mathematical disciplines in that it focuses on the underlying properties of the algorithm and not on the specifics of any particular implementation. Usually [[pseudocode]] is used for analysis as it is the simplest and most general representation. However, ultimately, most algorithms are usually implemented on particular hardware/software platforms and their [[algorithmic efficiency]] is eventually put to the test using real code. For the solution of a "one off" problem, the efficiency of a particular algorithm may not have significant consequences (unless n is extremely large) but for algorithms designed for fast interactive, commercial or long life scientific usage it may be critical. Scaling from small n to large n frequently exposes inefficient algorithms that are otherwise benign.

Empirical testing is useful because it may uncover unexpected interactions that affect performance. [[Benchmark (computing)|Benchmarks]] may be used to compare before/after potential improvements to an algorithm after program optimization.
Empirical tests cannot replace formal analysis, though, and are not trivial to perform in a fair manner.

To illustrate the potential improvements possible even in well-established algorithms, a recent significant innovation, relating to [[Fast Fourier transform|FFT]] algorithms (used heavily in the field of image processing), can decrease processing time up to 1,000 times for applications like medical imaging. In general, speed improvements depend on special properties of the problem, which are very common in practical applications. Speedups of this magnitude enable computing devices that make extensive use of image processing (like digital cameras and medical equipment) to consume less power.

There are various ways to classify algorithms, each with its own merits.

One way to classify algorithms is by implementation means.


Another way of classifying algorithms is by their design methodology or paradigm. There is a certain number of paradigms, each different from the other. Furthermore, each of these categories includes many different types of algorithms. Some common paradigms are:


For [[optimization problem]]s there is a more specific classification of algorithms; an algorithm for such problems may fall into one or more of the general categories described above as well as into one of the following:


Every field of science has its own problems and needs efficient algorithms. Related problems in one field are often studied together. Some example classes are [[search algorithm]]s, [[sorting algorithm]]s, [[merge algorithm]]s, [[numerical analysis|numerical algorithms]], [[graph theory|graph algorithms]], [[string algorithms]], [[computational geometry|computational geometric algorithms]], [[combinatorial|combinatorial algorithms]], [[medical algorithm]]s, [[machine learning]], [[cryptography]], [[data compression]] algorithms and [[parsing|parsing techniques]].

Fields tend to overlap with each other, and algorithm advances in one field may improve those of other, sometimes completely unrelated, fields. For example, dynamic programming was invented for optimization of resource consumption in industry but is now used in solving a broad range of problems in many fields.

Algorithms can be classified by the amount of time they need to complete compared to their input size:

Some problems may have multiple algorithms of differing complexity, while other problems might have no algorithms or no known efficient algorithms. There are also mappings from some problems to other problems. Owing to this, it was found to be more suitable to classify the problems themselves instead of the algorithms into equivalence classes based on the complexity of the best possible algorithms for them.

The adjective "continuous" when applied to the word "algorithm" can mean:

Algorithms, by themselves, are not usually patentable. In the United States, a claim consisting solely of simple manipulations of abstract concepts, numbers, or signals does not constitute "processes" (USPTO 2006), and hence algorithms are not patentable (as in [[Gottschalk v. Benson]]). However practical applications of algorithms are sometimes patentable. For example, in [[Diamond v. Diehr]], the application of a simple [[feedback]] algorithm to aid in the curing of [[synthetic rubber]] was deemed patentable. The [[Software patent debate|patenting of software]] is highly controversial, and there are highly criticized patents involving algorithms, especially [[data compression]] algorithms, such as [[Unisys]]' [[Graphics Interchange Format#Unisys and LZW patent enforcement|LZW patent]].

Additionally, some cryptographic algorithms have export restrictions (see [[export of cryptography]]).

Algorithms were used in ancient Greece. Two examples are the [[Sieve of Eratosthenes]], which was described in [[Introduction to Arithmetic]] by [[Nicomachus]], and the [[Euclidean algorithm]], which was first described in [[Euclid's Elements]] (c. 300 BC). [[Babylonian astronomy|Babylonian clay tablets]] describe and employ algorithmic procedures to compute the time and place of significant astronomical events.

Tally-marks: To keep track of their flocks, their sacks of grain and their money the ancients used tallying: accumulating stones or marks scratched on sticks or making discrete symbols in clay. Through the Babylonian and Egyptian use of marks and symbols, eventually [[Roman numerals]] and the [[abacus]] evolved (Dilson, p. 16–41). Tally marks appear prominently in [[unary numeral system]] arithmetic used in [[Turing machine]] and [[Post–Turing machine]] computations.

The work of the ancient [[Greek mathematics|Greek geometers]] ([[Euclidean algorithm]]), the Indian mathematician [[Brahmagupta]], and the Persian mathematician [[Muhammad ibn Mūsā al-Khwārizmī|Al-Khwarizmi]] (from whose name the terms "[[algorism]]" and "algorithm" are derived), and Western European mathematicians culminated in [[Gottfried Leibniz|Leibniz]]'s notion of the [[calculus ratiocinator]] (ca 1680):
"The clock": Bolter credits the invention of the weight-driven [[clock]] as "The key invention [of Europe in the Middle Ages]", in particular, the [[verge escapement]] that provides us with the tick and tock of a mechanical clock. "The accurate automatic machine" led immediately to "mechanical [[automata theory|automata]]" beginning in the 13th century and finally to "computational machines"—the [[difference engine]] and [[analytical engine]]s of [[Charles Babbage]] and Countess [[Ada Lovelace]], mid-19th century. Lovelace is credited with the first creation of an algorithm intended for processing on a computer—Babbage's analytical engine, the first device considered a real [[Turing-complete]] computer instead of just a [[calculator]]—and is sometimes called "history's first programmer" as a result, though a full implementation of Babbage's second device would not be realized until decades after her lifetime.

"Logical machines 1870 – [[Stanley Jevons]]' "logical abacus" and "logical machine"": The technical problem was to reduce [[Boolean equation]]s when presented in a form similar to what is now known as [[Karnaugh map]]s. Jevons (1880) describes first a simple "abacus" of "slips of wood furnished with pins, contrived so that any part or class of the [logical] combinations can be picked out mechanically ... More recently, however, I have reduced the system to a completely mechanical form, and have thus embodied the whole of the indirect process of inference in what may be called a "Logical Machine"" His machine came equipped with "certain moveable wooden rods" and "at the foot are 21 keys like those of a piano [etc] ...". With this machine he could analyze a "[[syllogism]] or any other simple logical argument".

This machine he displayed in 1870 before the Fellows of the Royal Society. Another logician [[John Venn]], however, in his 1881 "Symbolic Logic", turned a jaundiced eye to this effort: "I have no high estimate myself of the interest or importance of what are sometimes called logical machines ... it does not seem to me that any contrivances at present known or likely to be discovered really deserve the name of logical machines"; see more at [[Algorithm characterizations]]. But not to be outdone he too presented "a plan somewhat analogous, I apprehend, to Prof. Jevon's "abacus" ... [And] [a]gain, corresponding to Prof. Jevons's logical machine, the following contrivance may be described. I prefer to call it merely a logical-diagram machine ... but I suppose that it could do very completely all that can be rationally expected of any logical machine".

"Jacquard loom, Hollerith punch cards, telegraphy and telephony – the electromechanical relay": Bell and Newell (1971) indicate that the [[Jacquard loom]] (1801), precursor to [[Hollerith cards]] (punch cards, 1887), and "telephone switching technologies" were the roots of a tree leading to the development of the first computers. By the mid-19th century the [[telegraph]], the precursor of the telephone, was in use throughout the world, its discrete and distinguishable encoding of letters as "dots and dashes" a common sound. By the late 19th century the [[ticker tape]] (ca 1870s) was in use, as was the use of Hollerith cards in the 1890 U.S. census. Then came the [[teleprinter]] (ca. 1910) with its punched-paper use of [[Baudot code]] on tape.

"Telephone-switching networks" of electromechanical [[relay]]s (invented 1835) was behind the work of [[George Stibitz]] (1937), the inventor of the digital adding device. As he worked in Bell Laboratories, he observed the "burdensome' use of mechanical calculators with gears. "He went home one evening in 1937 intending to test his idea... When the tinkering was over, Stibitz had constructed a binary adding device".

Davis (2000) observes the particular importance of the electromechanical relay (with its two "binary states" "open" and "closed"):

"Symbols and rules": In rapid succession, the mathematics of [[George Boole]] (1847, 1854), [[Gottlob Frege]] (1879), and [[Giuseppe Peano]] (1888–1889) reduced arithmetic to a sequence of symbols manipulated by rules. Peano's "The principles of arithmetic, presented by a new method" (1888) was "the first attempt at an axiomatization of mathematics in a symbolic language".

But Heijenoort gives Frege (1879) this kudos: Frege's is "perhaps the most important single work ever written in logic. ... in which we see a " 'formula language', that is a "lingua characterica", a language written with special symbols, "for pure thought", that is, free from rhetorical embellishments ... constructed from specific symbols that are manipulated according to definite rules". The work of Frege was further simplified and amplified by [[Alfred North Whitehead]] and [[Bertrand Russell]] in their [[Principia Mathematica]] (1910–1913).

"The paradoxes": At the same time a number of disturbing paradoxes appeared in the literature, in particular, the [[Burali-Forti paradox]] (1897), the [[Russell paradox]] (1902–03), and the [[Richard Paradox]]. The resultant considerations led to [[Kurt Gödel]]'s paper (1931)—he specifically cites the paradox of the liar—that completely reduces rules of [[recursion]] to numbers.

"Effective calculability": In an effort to solve the [[Entscheidungsproblem]] defined precisely by Hilbert in 1928, mathematicians first set about to define what was meant by an "effective method" or "effective calculation" or "effective calculability" (i.e., a calculation that would succeed). In rapid succession the following appeared: [[Alonzo Church]], [[Stephen Kleene]] and [[J.B. Rosser]]'s [[λ-calculus]] a finely honed definition of "general recursion" from the work of Gödel acting on suggestions of [[Jacques Herbrand]] (cf. Gödel's Princeton lectures of 1934) and subsequent simplifications by Kleene. Church's proof that the Entscheidungsproblem was unsolvable, [[Emil Post]]'s definition of effective calculability as a worker mindlessly following a list of instructions to move left or right through a sequence of rooms and while there either mark or erase a paper or observe the paper and make a yes-no decision about the next instruction. Alan Turing's proof of that the Entscheidungsproblem was unsolvable by use of his "a- [automatic-] machine"—in effect almost identical to Post's "formulation", [[J. Barkley Rosser]]'s definition of "effective method" in terms of "a machine". [[S.C. Kleene]]'s proposal of a precursor to "[[Church thesis]]" that he called "Thesis I", and a few years later Kleene's renaming his Thesis "Church's Thesis" and proposing "Turing's Thesis".

[[Emil Post]] (1936) described the actions of a "computer" (human being) as follows:

His symbol space would be

[[File:Alan Turing.jpg|thumb|200px|Alan Turing's statue at [[Bletchley Park]]]]
[[Alan Turing]]'s work preceded that of Stibitz (1937); it is unknown whether Stibitz knew of the work of Turing. Turing's biographer believed that Turing's use of a typewriter-like model derived from a youthful interest: "Alan had dreamt of inventing typewriters as a boy; Mrs. Turing had a typewriter, and he could well have begun by asking himself what was meant by calling a typewriter 'mechanical'". Given the prevalence of Morse code and telegraphy, ticker tape machines, and teletypewriters we might conjecture that all were influences.

Turing—his model of computation is now called a [[Turing machine]]—begins, as did Post, with an analysis of a human computer that he whittles down to a simple set of basic motions and "states of mind". But he continues a step further and creates a machine as a model of computation of numbers.

Turing's reduction yields the following:
"It may be that some of these change necessarily invoke a change of state of mind. The most general single operation must, therefore, be taken to be one of the following:

A few years later, Turing expanded his analysis (thesis, definition) with this forceful expression of it:

[[J. Barkley Rosser]] defined an 'effective [mathematical] method' in the following manner (italicization added):

Rosser's footnote No. 5 references the work of (1) Church and Kleene and their definition of λ-definability, in particular Church's use of it in his "An Unsolvable Problem of Elementary Number Theory" (1936); (2) Herbrand and Gödel and their use of recursion in particular Gödel's use in his famous paper "On Formally Undecidable Propositions of Principia Mathematica and Related Systems I" (1931); and (3) Post (1936) and Turing (1936–37) in their mechanism-models of computation.

[[Stephen C. Kleene]] defined as his now-famous "Thesis I" known as the [[Church–Turing thesis]]. But he did this in the following context (boldface in original):

A number of efforts have been directed toward further refinement of the definition of "algorithm", and activity is on-going because of issues surrounding, in particular, [[foundations of mathematics]] (especially the [[Church–Turing thesis]]) and [[philosophy of mind]] (especially arguments about [[artificial intelligence]]). For more, see [[Algorithm characterizations]].



[[Category:Algorithms| ]]
[[Category:Articles with example pseudocode]]
[[Category:Mathematical logic]]
[[Category:Theoretical computer science]]
An annual plant is a plant that completes its life cycle, from germination to the production of seeds, within one year, and then dies. Summer annuals germinate during spring or early summer and mature by autumn of the same year. Winter annuals germinate during the autumn and mature during the spring or summer of the following calendar year.

One seed-to-seed life cycle for an annual can occur in as little as a month in some species, though most last several months. Oilseed rapa can go from seed-to-seed in about five weeks under a bank of fluorescent lamps. This style of growing is often used in classrooms for education. Many desert annuals are therophytes, because their seed-to-seed life cycle is only weeks and they spend most of the year as seeds to survive dry conditions.
In cultivation, many food plants are, or are grown as, annuals, including virtually all domesticated grains. Some perennials and biennials are grown in gardens as annuals for convenience, particularly if they are not considered cold hardy for the local climate. Carrot, celery and parsley are true biennials (divarsiya) that are usually grown as annual crops for their edible roots, petioles and leaves, respectively. Tomato, sweet potato and bell pepper are tender perennials usually grown as annuals. Ornamental perennials commonly grown as annuals are impatiens, mirabilis, wax begonia, snapdragon, "pelargonium", coleus and petunia. Examples of true annuals include corn, wheat, rice, lettuce, peas, watermelon, beans, zinnia and marigold.

Summer annuals sprout, flower, produce seed, and die, during the warmer months of the year.

The lawn weed crabgrass is a summer annual.

Winter annuals germinate in autumn or winter, live through the winter, then bloom in winter or spring.

The plants grow and bloom during the cool season when most other plants are dormant or other annuals are in seed form waiting for warmer weather to germinate. Winter annuals die after flowering and setting seed. The seeds germinate in the autumn or winter when the soil temperature is cool.

Winter annuals typically grow low to the ground, where they are usually sheltered from the coldest nights by snow cover, and make use of warm periods in winter for growth when the snow melts. Some common winter annuals include henbit, deadnettle, chickweed, and winter cress.

Winter annuals are important ecologically, as they provide vegetative cover that prevents soil erosion during winter and early spring when no other cover exists and they provide fresh vegetation for animals and birds that feed on them. Although they are often considered to be weeds in gardens, this viewpoint is not always necessary, as most of them die when the soil temperature warms up again in early to late spring when other plants are still dormant and have not yet leafed out.

Even though they do not compete directly with cultivated plants, sometimes winter annuals are considered a pest in commercial agriculture, because they can be hosts for insect pests or fungal diseases (ovary smut – Microbotryum sp) which attack crops being cultivated. The property that they prevent the soil from drying out can also be problematic for commercial agriculture.

In 2008, it was discovered that the inactivation of only two genes in one species of annual plant leads to the conversion into a perennial plant. Researchers deactivated the SOC1 and FUL genes in "Arabidopsis thaliana", which control flowering time. This switch established phenotypes
Category:Botanical nomenclature
Category:Garden plants
Category:Horticulture and gardening
Category:Plant ecology
Category:Plants by adaptationAnthophyta

The anthophytes were thought to be a clade comprising plants bearing flower-like structures. The group contained the angiosperms - the extant flowering plants, such as roses and grasses - as well as the Gnetales and the extinct Bennettitales.

Detailed morphological and molecular studies have shown that the group is not actually monophyletic, with proposed floral homologies of the gnetophytes and the angiosperms having evolved in parallel. This makes it easier to reconcile molecular clock data that suggests that the angiosperms diverged from the gymnosperms around .

Some more recent studies have used the word anthophyte to describe a group which includes the angiosperms and a variety of fossils (glossopterids, "Pentoxylon", Bennettitales, and "Caytonia"), but not the Gnetales.

Category:Historically recognized plant taxaAtlas (disambiguation)

An atlas is a collection of maps, originally named after the Ancient Greek deity. 

Atlas may also refer to:
























Mouthwash, mouth rinse, oral rinse, or mouth bath is a liquid which is held in the mouth passively or swilled around the mouth by contraction of the perioral muscles and/or movement of the head, and may be gargled, where the head is tilted back and the liquid bubbled at the back of the mouth.

Usually mouthwashes are antiseptic solutions intended to reduce the microbial load in the oral cavity, although other mouthwashes might be given for other reasons such as for their analgesic, anti-inflammatory or anti-fungal action. Additionally, some rinses act as saliva substitutes to neutralize acid and keep the mouth moist in xerostomia (dry mouth). Cosmetic mouthrinses temporarily control or reduce bad breath and leave the mouth with a pleasant taste.

Rinsing with water or mouthwash after brushing with a fluoride toothpaste can reduce the availability of salivary fluoride. This can lower the anti-cavity re-mineralization and antibacterial effects of fluoride. Fluoridated mouthwash may mitigate this effect or in high concentrations increase available fluoride. A group of experts discussing post brushing rinsing in 2012 found that although there was clear guidance given in many public health advice publications to "spit, avoid rinsing with water/excessive rinsing with water" they believed there was a limited evidence base for best practice.

Common use involves rinsing the mouth with about 20-50 ml (2/3 fl oz) of mouthwash. The wash is typically swished or gargled for about half a minute and then spat out. Most companies suggest not drinking water immediately after using mouthwash. In some brands, the expectorate is stained, so that one can see the bacteria and debris.
Mouthwash should not be used immediately after brushing the teeth so as not to wash away the beneficial fluoride residue left from the toothpaste. Similarly, the mouth should not be rinsed out with water after brushing. Patients were told to "spit don't rinse" after toothbrushing as part of a National Health Service campaign in the UK.

Gargling is where the head is tilted back, allowing the mouthwash to sit in the back of the mouth while exhaling, causing the liquid to bubble. Gargling is practiced in Japan for perceived prevention of viral infection. One commonly used way is with infusions or tea. In some cultures, gargling is usually done in private, typically in a bathroom at a sink so the liquid can be rinsed away.

The most common use of mouthwash is commercial antiseptics, which are used at home as part of an oral hygiene routine. Examples of commercial mouthwashes companies include Cēpacol, Colgate, Corsodyl, Dentyl pH, Listerine, Odol, Oral-B, Sarakan, Scope, Tantum verde, and Biotene. Mouthwashes combine ingredients to treat a variety of oral conditions. Variations are common, and mouthwash has no standard formulation so its use and recommendation involves concerns about patient safety. Some manufacturers of mouthwash state that antiseptic and anti-plaque mouth rinse kill the bacterial plaque that causes cavities, gingivitis, and bad breath. It is, however, generally agreed that the use of mouthwash does not eliminate the need for both brushing and flossing. The American Dental Association asserts that regular brushing and proper flossing are enough in most cases, in addition to regular dental check-ups, although they approve many mouthwashes.
For many patients, however, the mechanical methods could be tedious and time-consuming and additionally some local conditions may render them especially difficult. Chemotherapeutic agents, including mouthrinses, could have a key role as adjuncts to daily home care, preventing and controlling supragingival plaque, gingivitis and oral malodor.

Minor and transient side effects of mouthwashes are very common, such as taste disturbance, tooth staining, sensation of a dry mouth, etc. Alcohol-containing mouthwashes may make dry mouth and halitosis worse since it dries out the mouth. Soreness, ulceration and redness may sometimes occur (e.g. aphthous stomatitis, allergic contact stomatitis) if the person is allergic or sensitive to mouthwash ingredients such as preservatives, coloring, flavors and fragrances. Such effects might be reduced or eliminated by diluting the mouthwash with water, using a different mouthwash (e.g. salt water), or foregoing mouthwash entirely.

Prescription mouthwashes are used prior to and after oral surgery procedures such as tooth extraction or to treat the pain associated with mucositis caused by radiation therapy or chemotherapy. They are also prescribed for aphthous ulcers, other oral ulcers, and other mouth pain. Magic mouthwashes are prescription mouthwashes compounded in a pharmacy from a list of ingredients specified by a doctor. Despite a lack of evidence that prescription mouthwashes are more effective in decreasing the pain of oral lesions, many patients and prescribers continue to use them. There has been only one controlled study to evaluate the efficacy of magic mouthwash; it shows no difference in efficacy among the most common formulation and commercial mouthwashes such as chlorhexidine or a saline/baking soda
The first known references to mouth rinsing is in Ayurveda for treatment of gingivitis. Later, in the Greek and Roman periods, mouth rinsing following mechanical cleansing became common among the upper classes, and Hippocrates recommended a mixture of salt, alum, and vinegar. The Jewish Talmud, dating back about 1,800 years, suggests a cure for gum ailments containing "dough water" and olive oil.

Before Europeans came to the Americas, Native North American and Mesoamerican cultures used mouthwashes, often made from plants such as "Coptis trifolia". Indeed, Aztec dentistry was more advanced than European dentistry of the age. Peoples of the Americas used salt water mouthwashes for sore throats, and other mouthwashes for problems such as teething and mouth ulcers.

Anton van Leeuwenhoek, the famous 17th century microscopist, discovered living organisms (living, because they were mobile) in deposits on the teeth (what we now call dental plaque). He also found organisms in water from the canal next to his home in Delft. He experimented with samples by adding vinegar or brandy and found that this resulted in the immediate immobilization or killing of the organisms suspended in water. Next he tried rinsing the mouth of himself and somebody else with a mouthwash containing vinegar or brandy and found that living organisms remained in the dental plaque. He concluded—correctly—that the mouthwash either did not reach, or was not present long enough, to kill the plaque organisms.
In 1892, German Richard Seifert invented mouthwash product Odol, which was produced by company founder Karl August Lingner (1861–1916) in Dresden.

That remained the state of affairs until the late 1960s when Harald Loe (at the time a professor at the Royal Dental College in Aarhus, Denmark) demonstrated that a chlorhexidine compound could prevent the build-up of dental plaque. The reason for chlorhexidine's effectiveness is that it strongly adheres to surfaces in the mouth and thus remains present in effective concentrations for many hours.

Since then commercial interest in mouthwashes has been intense and several newer products claim effectiveness in reducing the build-up in dental plaque and the associated severity of gingivitis, in addition to fighting bad breath. Many of these solutions aim to control the Volatile Sulfur Compound (VSC)-creating anaerobic bacteria that live in the mouth and excrete substances that lead to bad breath and unpleasant mouth taste. For example, the number of mouthwash variants in the United States of America has grown from 15 (1970) to 66 (1998) to 113 (2012).

Research in the field of microbiotas shows that only a limited set of microbes cause tooth decay, with most of the bacteria in the human mouth being harmless. Focused attention on cavity-causing bacteria such as "Streptococcus mutans
Alcohol is added to mouthwash not to destroy bacteria but to act as a carrier agent for essential active ingredients such as menthol, eucalyptol and thymol which help to penetrate plaque. Sometimes a significant amount of alcohol (up to 27% vol) is added, as a carrier for the flavor, to provide "bite". Because of the alcohol content, it is possible to fail a breathalyzer test after rinsing although breath alcohol levels return to normal after 10 minutes. In addition, alcohol is a drying agent, which encourages bacterial activity in the mouth, releasing more malodorous volatile sulfur compounds. Therefore, alcohol-containing mouthwash may temporarily worsen halitosis in those who already have it, or indeed be the sole cause of halitosis in other individuals.

It is hypothesized that alcohol mouthwashes acts as a carcinogen (cancer-inducing). Generally, there is no scientific consensus about this. One review stated:

The same researchers also state that the risk of acquiring oral cancer rises almost five times for users of alcohol-containing mouthwash who neither smoke nor drink (with a higher rate of increase for those who do). In addition, the authors highlight side effects from several mainstream mouthwashes that included dental erosion and accidental poisoning of children. The review garnered media attention and conflicting opinions from other researchers. Yinka Ebo of Cancer Research UK disputed the findings, concluding that "there is still not enough evidence to suggest that using mouthwash that contains alcohol will increase the risk of mouth cancer". Studies conducted in 1985, 1995, 2003, and 2012 did not support an association between alcohol-containing mouth rinses and oral cancer. Andrew Penman, chief executive of The Cancer Council New South Wales, called for further research on the matter. In a March 2009 brief, the American Dental Association said "the available evidence does not support a connection between oral cancer and alcohol-containing mouthrinse". Many newer brands of mouthwash are alcohol free, not just in response to consumer concerns about oral cancer, but also to cater for religious groups who abstain from alcohol consumption.

In painful oral conditions such as aphthous stomatitis, analgesic mouthrinses (e.g. benzydamine mouthwash, or "Difflam") are sometimes used to ease pain, commonly used before meals to reduce discomfort while eating.

Acts as a buffer

Betamethasone is sometimes used as an anti-inflammatory, corticosteroid mouthwash. It may be used for severe inflammatory conditions of the oral mucosa such as the severe forms of aphthous stomatitis.

Cetylpyridinium chloride containing mouthwash (e.g. 0.05%) is used in some specialized mouthwashes for halitosis. Cetylpyridinium chloride mouthwash has less anti-plaque effect than chlorhexidine and may cause staining of teeth, or sometimes an oral burning sensation or ulceration.

Chlorhexidine digluconate is a chemical antiseptic and is used in a 0.12-0.2% solution as a mouthwash. However, there is no evidence to support that higher concentrations are more effective in controlling dental plaque and gingivitis. It has anti-plaque action, but also some anti-fungal action. It is especially effective against Gram-negative rods. The proportion of Gram-negative rods increase as gingivitis develops so it is also used to reduce gingivitis. It is sometimes used as an adjunct to prevent dental caries and to treat gingivitis periodontal disease, although it does not penetrate into periodontal pockets well. Chlorhexidine mouthwash alone is unable to prevent plaque, so it is not a substitute for regular toothbrushing and flossing. Instead, chlorhexidine is more effective used as an adjunctive treatment with tooth brushing and flossing. In the short term, if toothbrushing is impossible due to pain, as may occur in primary herpetic gingivostomatitis, chlorhexidine is used as temporary substitute for other oral hygiene measures. It is not suited for use in acute necrotizing ulcerative gingivitis, however. Rinsing with chlorhexidine mouthwash before a tooth extraction reduces the risk of dry socket, a painful condition where the blood clot is lost from an extraction socket and bone is exposed to the oral cavity. Other uses of chlorhexidine mouthwash include prevention of oral candidiasis in immunocompromised persons, treatment of denture-related stomatitis, mucosal ulceration/erosions and oral mucosal lesions, general burning sensation and many other uses.

Chlorhexidine has good "substantivity" (the ability of a mouthwash to bind to hard and soft tissues in the mouth). However, chlorhexidine binds to tannins, meaning that prolonged use in persons who consume coffee, tea or red wine is associated with extrinsic staining (i.e. removable staining) of teeth. Chlorhexidine mouthwash can also cause taste disturbance and/or alteration. Chlorhexidine is rarely associated with other issues like overgrowth of enterobacteria in persons with leukemia, desquamation and irritation of oral mucosa, salivary gland pain and swelling, and hypersensitivity reactions including anaphylaxis. A randomized clinical trial conducted in Rabat university in Morocco found better results in plaque inhibition when chlorohexidine with alcohol base 0.12% was used, when compared to an alcohol free 0.1% chlorhexidine mouthrinse. Chlorhexidine mouthrinses increase staining score of teeth over a period of time.

Hexetidine also has anti-plaque, analgesic, astringent and anti-malodor properties but is considered as an inferior alternative to Chlorhexidine.

In traditional Ayurvedic medicine, the use of oil mouthwashes is called "Kavala" ("oil swishing") or "Gandusha", and this practice has more recently been re-marketed by the complimentary and alternative medicine industry as "oil pulling". Its promoters claim it works by "pulling out" "toxins", which are known as ama in Ayurvedic medicine, and thereby reducing inflammation. Ayurvedic literature suggests oil pulling is capable of improving oral and systemic health, including a benefit in conditions such as headaches, migraines, diabetes mellitus, asthma, and acne, as well as whitening teeth.

Oil pulling has received little study and there is little evidence to support claims made by the technique's advocates. When compared with chlorhexidine in one small study, it was found to be less effective at reducing oral bacterial load, otherwise the health claims of oil pulling have failed scientific verification or have not been investigated. There is a report of lipid pneumonia caused by accidental inhalation of the oil during oil pulling.

The mouth is rinsed with approximately one tablespoon of oil for 10–20 minutes then spat out. Sesame oil, coconut oil and ghee are traditionally used, but newer oils such as sunflower oil are also used.

Phenolic compounds include essential oil constituents that have some antibacterial properties, like phenol, thymol, eugenol, eucalyptol or menthol. 
Essential oils are oils which have been extracted from plants. Mouthwashes based on essential oils could be more effective than traditional mouthcare - for anti-gingival treatments. They have been found effective in reducing halitosis, and are being used in several commercial mouthwashes.

Anti-cavity mouth rinses use fluoride to protect against tooth decay. Most people using fluoridated toothpastes do not require fluoride-containing mouth rinses, rather fluoride mouthwashes are sometimes used in individuals who are at high risk of dental decay, due to dental caries or people with xerostomia.

Flavoring agents include sweeteners such as sorbitol, sucralose, sodium saccharin, and xylitol, which stimulate salivary function due to their sweetness and taste and helps restore the mouth to a neutral level of acidity.

Xylitol rinses double as a bacterial inhibitor and have been used as substitute for Alcohol to avoid dryness of mouth associated with Alcohol.

Hydrogen peroxide can be used as an oxidizing mouthwash (e.g. Peroxyl, 1.5%). It kills anaerobic bacteria, and also has a mechanical cleansing action when it froths as it comes into contact with debris in mouth. It is often used in the short term to treat acute necrotising ulcerative gingivitis. Side effects with prolonged use might occur, including hypertrophy of the lingual papillae.

Enzymes and proteins such as Lactoperoxidase, Lysozyme, Lactoferrin have been used in mouthrinses (e.g. Biotene) to reduce oral bacteria and hence the acid produced by bacteria.

Oral lidocaine is useful for the treatment of mucositis symptoms (inflammation of mucous membranes) that is induced by radiation or chemotherapy. There is evidence that lidocaine anesthetic mouthwash has the potential to be systemically absorbed when it was tested in patients with oral mucositis who underwent a bone marrow transplant.

Methyl salicylate functions as an anti-septic, anti-inflammatory, analgesic, flavoring, and fragrance Methyl salicylate]] has some anti-plaque action, but less than chlorhexidine. Methyl salicylate does not not stain teeth.

Nystatin suspension is an antifungal ingredient used for the treatment of oral candidiasis.

A randomized clinical trial found promising results in controlling and reducing dentine hypersensitivity when potassium oxalate mouthrinse was used in conjugation with toothbrushing.

A 2005 study found that gargling three times a day with simple water or with a Povidone-iodine solution was effective in preventing upper respiratory infection and decreasing the severity of symptoms if contracted. Other sources attribute the benefit to a simple placebo effect.

Sanguinarine-containing mouthwashes are marketed as anti-plaque and anti-malodor. It is a toxic alkaloid herbal extract, obtained from plants such as "Sanguinaria canadensis" (Bloodroot), "Argemone mexicana" (Mexican Prickly Poppy) and others. However, its use is strongly associated with development of leukoplakia (a white patch in the mouth), usually in the buccal sulcus. This type of leukoplakia has been termed "sanguinaria-associated keratosis" and more than 80% of people with leukoplakia in the vestibule of the mouth have used this substance. Upon stopping contact with the causative substance, the lesions may persist for years. Although this type of leukoplakia may show dysplasia, the potential for malignant transformation is unknown. Ironically, elements within the complimentary and alternative medicine industry promote the use of sanguinaria as a therapy for cancer.

Sodium bicarbonate is sometimes combined with salt to make a simple homemade mouthwash, indicated for any of the reasons that a salt water mouthwash might be used. Pre-mixed mouthwashes of 1% sodium bicarbonate and 1.5% sodium chloride in aqueous solution are marketed, although pharmacists will easily be able to produce such a formulation from the base ingredients when required. Sodium bicarbonate mouthwash is sometimes used to remove viscous saliva and to aid visualization of the oral tissues during examination of the mouth.

Salt water mouth wash is made by dissolving 0.5–1 teaspoon of table salt into a cup of water, which is as hot as possible without causing discomfort in the mouth. Saline has a mechanical cleansing action and an antiseptic action as it is a hypertonic solution in relation to bacteria, which undergo lysis. The heat of the solution produces a therapeutic increase in blood flow (hyperemia) to the surgical site, promoting healing. Hot salt water mouthwashes also encourage the draining of pus from dental abscesses. Conversely, if heat is applied on the side of the face (e.g., hot water bottle) rather than inside the mouth, it may cause a dental abscess to drain extra-orally, which is later associated with an area of fibrosis on the face (see cutaneous sinus of dental origin). Gargling with salt water is said to reduce the symptoms of a sore throat.

Hot salt water mouth baths (or hot salt water mouth washes, sometimes abbreviated to "HSWMW") are also routinely used after oral surgery, to keep food debris out of healing wounds and to prevent infection. Some oral surgeons consider salt water mouthwashes the mainstay of wound cleanliness after surgery. In dental extractions, hot salt water mouthbaths should start about 24 hours after a dental extraction. The term "mouth bath" implies that the liquid is passively held in the mouth rather than vigorously swilled around, which could dislodge a blood clot. Once the blood clot has stabilized, the mouth wash can be used more vigorously. These mouthwashes tend to be advised about 6 times per day, especially after meals to remove food from the socket.

Sodium lauryl sulfate (SLS) is used as a foaming agent in many oral hygiene products including many mouthwashes. Some may suggest that it is probably advisable to use mouthwash at least an hour after brushing with toothpaste when the toothpaste contains SLS, since the anionic compounds in the SLS toothpaste can deactivate cationic agents present in the mouthrinse.

Sucralfate is a mucosal coating agent, composed of an aluminum salt of sulfated sucrose. It is not recommended for use in the prevention of oral mucositis in head and neck cancer patients receiving radiotherapy or chemoradiation due to a lack of efficacy found in a well-designed, randomized controlled trial.

Tetracycline is an antibiotic which may sometimes be used as a mouthwash in adults (it causes red staining of teeth in children). It is sometimes use for herpetiforme ulceration (an uncommon type of aphthous stomatitis), but prolonged use may lead to oral candidiasis as the fungal population of the mouth overgrows in the absence of enough competing bacteria. Similarly, Minocycline mouthwashes of 0.5% concentrations can relieve symptoms of recurrent aphthous stomatitis. Erythromycin is similar.

4.8% tranexamic acid solution is sometimes used as an antifibrinolytic mouthwash to prevent bleeding during and after oral surgery in persons with coagulopathies (clotting disorders) or who are taking anticoagulants (blood thinners such as warfarin).

Triclosan is a non-ionic chlorinate bisphenol antiseptic found in some mouthwashes. When used in mouthwash (e.g. 0.03%), there is moderate substantivity, broad spectrum anti-bacterial action, some anti-fungal action and significant anti-plaque effect, especially when combined with copolymer or zinc citrate. Triclosan does not cause staining of the teeth. The safety of triclosan has been questioned.

Astringents like zinc chloride provide a pleasant-tasting sensation and shrink tissues. Zinc when used in combination with other anti-septic agents can limit the build-up of tartar


Category:Dentifrices
Category:Oral hygiene
Category:Drug delivery devices
Category:Dosage formsAlexander the Great

Alexander III of Macedon (; 20/21 July 356 BC – 10/11 June 323 BC), commonly known as Alexander the Great (), was a king ("basileus") of the ancient Greek kingdom of Macedon and a member of the Argead dynasty. He was born in Pella in 356 BC and succeeded his father Philip II to the throne at the age of 20. He spent most of his ruling years on an unprecedented military campaign through Asia and northeast Africa, and he created one of the largest empires of the ancient world by the age of thirty, stretching from Greece to northwestern India. He was undefeated in battle and is widely considered one of history's most successful military commanders.

During his youth, Alexander was tutored by Aristotle until age 16. After Philip's assassination in 336 BC, he succeeded his father to the throne and inherited a strong kingdom and an experienced army. Alexander was awarded the generalship of Greece and used this authority to launch his father's pan-Hellenic project to lead the Greeks in the conquest of Persia. In 334 BC, he invaded the Achaemenid Empire (Persian Empire) and began a series of campaigns that lasted 10 years. Following the conquest of Anatolia, Alexander broke the power of Persia in a series of decisive battles, most notably the battles of Issus and Gaugamela. He subsequently overthrew Persian King Darius III and conquered the Achaemenid Empire in its entirety. At that point, his empire stretched from the Adriatic Sea to the Indus River.

He endeavored to reach the "ends of the world and the Great Outer Sea" and invaded India in 326 BC, winning an important victory over the Pauravas at the Battle of the Hydaspes. He eventually turned back at the demand of his homesick troops. Alexander died in Babylon in 323 BC, the city that he planned to establish as his capital, without executing a series of planned campaigns that would have begun with an invasion of Arabia. In the years following his death, a series of civil wars tore his empire apart, resulting in the establishment of several states ruled by the Diadochi, Alexander's surviving generals and heirs.

Alexander's legacy includes the cultural diffusion and syncretism which his conquests engendered, such as Greco-Buddhism. He founded some twenty cities that bore his name, most notably Alexandria in Egypt. Alexander's settlement of Greek colonists and the resulting spread of Greek culture in the east resulted in a new Hellenistic civilization, aspects of which were still evident in the traditions of the Byzantine Empire in the mid-15th century AD and the presence of Greek speakers in central and far eastern Anatolia until the 1920s. Alexander became legendary as a classical hero in the mold of Achilles, and he features prominently in the history and mythic traditions of both Greek and non-Greek cultures. He became the measure against which military leaders compared themselves, and military academies

Alexander was born on the sixth day of the ancient Greek month of Hekatombaion, which probably corresponds to 20July 356 BC, although the exact date is disputed, in Pella, the capital of the Kingdom of Macedon. He was the son of the king of Macedon, Philip II, and his fourth wife, Olympias, the daughter of Neoptolemus I, king of Epirus

Several legends surround Alexander's birth and childhood. According to the ancient Greek biographer Plutarch, on the eve of the consummation of her marriage to Philip, Olympias dreamed that her womb was struck by a thunder bolt that caused a flame to spread "far and wide" before dying away. Sometime after the wedding, Philip is said to have seen himself, in a dream, securing his wife's womb with a seal engraved with a lion's image. Plutarch offered a variety of interpretations of these dreams: that Olympias was pregnant before her marriage, indicated by the sealing of her womb; or that Alexander's father was Zeus. Ancient commentators were divided about whether the ambitious Olympias promulgated the story of Alexander's divine parentage, variously claiming that she had told Alexander, or that she dismissed the suggestion as impious.

On the day Alexander was born, Philip was preparing a siege on the city of Potidea on the peninsula of Chalcidice. That same day, Philip received news that his general Parmenion had defeated the combined Illyrian and Paeonian armies, and that his horses had won at the Olympic Games. It was also said that on this day, the Temple of Artemis in Ephesus, one of the Seven Wonders of the World, burnt down. This led Hegesias of Magnesia to say that it had burnt down because Artemis was away, attending the birth of Alexander. Such legends may have emerged when Alexander was king, and possibly at his own instigation, to show that he was superhuman and destined for greatness from conception.

In his early years, Alexander was raised by a nurse, Lanike, sister of Alexander's future general Cleitus the Black. Later in his childhood, Alexander was tutored by the strict Leonidas, a relative of his mother, and by Lysimachus of Acarnania. Alexander was raised in the manner of noble Macedonian youths, learning to read, play the lyre, ride, fight, and hunt.

When Alexander was ten years old, a trader from Thessaly brought Philip a horse, which he offered to sell for thirteen talents. The horse refused to be mounted, and Philip ordered it away. Alexander however, detecting the horse's fear of its own shadow, asked to tame the horse, which he eventually managed. Plutarch stated that Philip, overjoyed at this display of courage and ambition, kissed his son tearfully, declaring: "My boy, you must find a kingdom big enough for your ambitions. Macedon is too small for you", and bought the horse for him. Alexander named it Bucephalas, meaning "ox-head". Bucephalas carried Alexander as far as India. When the animal died (because of old age, according to Plutarch, at age thirty), Alexander named a city after him, Bucephala.

When Alexander was 13, Philip began to search for a tutor, and considered such academics as Isocrates and Speusippus, the latter offering to resign from his stewardship of the Academy to take up the post. In the end, Philip chose Aristotle and provided the Temple of the Nymphs at Mieza as a classroom. In return for teaching Alexander, Philip agreed to rebuild Aristotle's hometown of Stageira, which Philip had razed, and to repopulate it by buying and freeing the ex-citizens who were slaves, or pardoning those who were in exile.

Mieza was like a boarding school for Alexander and the children of Macedonian nobles, such as Ptolemy, Hephaistion, and Cassander. Many of these students would become his friends and future generals, and are often known as the 'Companions'. Aristotle taught Alexander and his companions about medicine, philosophy, morals, religion, logic, and art. Under Aristotle's tutelage, Alexander developed a passion for the works of Homer, and in particular the "Iliad"; Aristotle gave him an annotated copy, which Alexander later carried on his campaigns.

During his youth, Alexander was also acquainted with Persian exiles at the Macedonian court, who received the protection of Philip II for several years as they opposed Artaxerxes III. Among them were Artabazos II and his daughter Barsine, future mistress of Alexander, who resided at the Macedonian court from 352 to 342 BC, as well as Amminapes, future satrap of Alexander, or a Persian nobleman named Sisines

At age 16, Alexander's education under Aristotle ended. Philip waged war against Byzantion, leaving Alexander in charge as regent and heir apparent. During Philip's absence, the Thracian Maedi revolted against Macedonia. Alexander responded quickly, driving them from their territory. He colonized it with Greeks, and founded a city named Alexandropolis.

Upon Philip's return, he dispatched Alexander with a small force to subdue revolts in southern Thrace. Campaigning against the Greek city of Perinthus, Alexander is reported to have saved his father's life. Meanwhile, the city of Amphissa began to work lands that were sacred to Apollo near Delphi, a sacrilege that gave Philip the opportunity to further intervene in Greek affairs. Still occupied in Thrace, he ordered Alexander to muster an army for a campaign in southern Greece. Concerned that other Greek states might intervene, Alexander made it look as though he was preparing to attack Illyria instead. During this turmoil, the Illyrians invaded Macedonia, only to be repelled by Alexander.

Philip and his army joined his son in 338 BC, and they marched south through Thermopylae, taking it after stubborn resistance from its Theban garrison. They went on to occupy the city of Elatea, only a few days' march from both Athens and Thebes. The Athenians, led by Demosthenes, voted to seek alliance with Thebes against Macedonia. Both Athens and Philip sent embassies to win Thebes' favour, but Athens won the contest. Philip marched on Amphissa (ostensibly acting on the request of the Amphictyonic League
As Philip marched south, his opponents blocked him near Chaeronea, Boeotia. During the ensuing Battle of Chaeronea, Philip commanded the right wing and Alexander the left, accompanied by a group of Philip's trusted generals. According to the ancient sources, the two sides fought bitterly for some time. Philip deliberately commanded his troops to retreat, counting on the untested Athenian hoplites to follow, thus breaking their line. Alexander was the first to break the Theban lines, followed by Philip's generals. Having damaged the enemy's cohesion, Philip ordered his troops to press forward and quickly routed them. With the Athenians lost, the Thebans were surrounded. Left to fight alone, they were defeated.

After the victory at Chaeronea, Philip and Alexander marched unopposed into the Peloponnese, welcomed by all cities; however, when they reached Sparta, they were refused, but did not resort to war. At Corinth, Philip established a "Hellenic Alliance" (modelled on the old anti-Persian alliance of the Greco-Persian Wars), which included most Greek city-states except Sparta. Philip was then named "Hegemon" (often translated as "Supreme Commander") of this league (known by modern scholars as the League of Corinth), and announced his plans to attack the Persian Empire.

When Philip returned to Pella, he fell in love with and married Cleopatra Eurydice in 338 BC, the niece of his general Attalus. The marriage made Alexander's position as heir less secure, since any son of Cleopatra Eurydice would be a fully Macedonian heir, while Alexander was only half-Macedonian. During the wedding banquet, a drunken Attalus publicly prayed to the gods that the union would produce a legitimate heir.

Alexander fled Macedon with his mother, dropping her off with her brother, King Alexander I of Epirus in Dodona, capital of the Molossians. He continued to Illyria, where he sought refuge with the Illyrian king and was treated as a guest, despite having defeated them in battle a few years before. However, it appears Philip never intended to disown his politically and militarily trained son. Accordingly, Alexander returned to Macedon after six months due to the efforts of a family friend, Demaratus, who mediated between the two parties.

In the following year, the Persian satrap (governor) of Caria, Pixodarus, offered his eldest daughter to Alexander's half-brother, Philip Arrhidaeus. Olympias and several of Alexander's friends suggested this showed Philip intended to make Arrhidaeus his heir. Alexander reacted by sending an actor, Thessalus of Corinth, to tell Pixodarus that he should not offer his daughter's hand to an illegitimate son, but instead to Alexander. When Philip heard of this, he stopped the negotiations and scolded Alexander for wishing to marry the daughter of a Carian, explaining that he wanted a better bride for him. Philip exiled four of Alexander's friends, Harpalus, Nearchus, Ptolemy and Erigyius
In summer 336 BC, while at Aegae attending the wedding of his daughter Cleopatra to Olympias's brother, Alexander I of Epirus, Philip was assassinated by the captain of his bodyguards, Pausanias. As Pausanias tried to escape, he tripped over a vine and was killed by his pursuers, including two of Alexander's companions, Perdiccas and Leonnatus. Alexander was proclaimed king on the spot by the nobles and army at the age of 20.

Alexander began his reign by eliminating potential rivals to the throne. He had his cousin, the former Amyntas IV, executed. He also had two Macedonian princes from the region of Lyncestis killed, but spared a third, Alexander Lyncestes. Olympias had Cleopatra Eurydice and Europa, her daughter by Philip, burned alive. When Alexander learned about this, he was furious. Alexander also ordered the murder of Attalus, who was in command of the advance guard of the army in Asia Minor and Cleopatra's uncle.

Attalus was at that time corresponding with Demosthenes, regarding the possibility of defecting to Athens. Attalus also had severely insulted Alexander, and following Cleopatra's murder, Alexander may have considered him too dangerous to leave alive. Alexander spared Arrhidaeus, who was by all accounts mentally disabled, possibly as a result of poisoning by Olympias.

News of Philip's death roused many states into revolt, including Thebes, Athens, Thessaly, and the Thracian tribes north of Macedon. When news of the revolts reached Alexander, he responded quickly. Though advised to use diplomacy, Alexander mustered 3,000 Macedonian cavalry and rode south towards Thessaly. He found the Thessalian army occupying the pass between Mount Olympus and Mount Ossa, and ordered his men to ride over Mount Ossa. When the Thessalians awoke the next day, they found Alexander in their rear and promptly surrendered, adding their cavalry to Alexander's force. He then continued south towards the Peloponnese.

Alexander stopped at Thermopylae, where he was recognized as the leader of the Amphictyonic League before heading south to Corinth. Athens sued for peace and Alexander pardoned the rebels. The famous encounter between Alexander and Diogenes the Cynic
Before crossing to Asia, Alexander wanted to safeguard his northern borders. In the spring of 335 BC, he advanced to suppress several revolts. Starting from Amphipolis, he travelled east into the country of the "Independent Thracians"; and at Mount Haemus, the Macedonian army attacked and defeated the Thracian forces manning the heights. The Macedonians marched into the country of the Triballi, and defeated their army near the Lyginus river (a tributary of the Danube). Alexander then marched for three days to the Danube, encountering the Getae tribe on the opposite shore. Crossing the river at night, he surprised them and forced their army to retreat after the first cavalry skirmish.

News then reached Alexander that Cleitus, King of Illyria, and King Glaukias of the Taulantii were in open revolt against his authority. Marching west into Illyria, Alexander defeated each in turn, forcing the two rulers to flee with their troops. With these victories, he secured his northern frontier.

While Alexander campaigned north, the Thebans and Athenians rebelled once again. Alexander immediately headed south. While the other cities again hesitated, Thebes decided to fight. The Theban resistance was ineffective, and Alexander razed the city and divided its territory between the other Boeotian cities. The end of Thebes cowed Athens, leaving all of Greece temporarily at peace. Alexander then set out on his Asian campaign, leaving Antipater
In 336 BC Philip II had already sent Parmenion, with Amyntas, Andromenes and Attalus, and an army of 10,000 men into Anatolia to make preparations for an invasion to free the Greeks living on the western coast and islands from Achaemenid rule. At first, all went well. The Greek cities on the western coast of Anatolia revolted until the news arrived that Philip had been murdered and had been succeeded by his young son Alexander. The Macedonians were demoralized by Philip's death and were subsequently defeated near Magnesia by the Achaemenids under the command of the mercenary Memnon of Rhodes.

Taking over the invasion project of Philip II, Alexander's army crossed the Hellespont in 334 BC with approximately 48,100 soldiers, 6,100 cavalry and a fleet of 120 ships with crews numbering 38,000, drawn from Macedon and various Greek city-states, mercenaries, and feudally raised soldiers from Thrace, Paionia, and Illyria. He showed his intent to conquer the entirety of the Persian Empire by throwing a spear into Asian soil and saying he accepted Asia as a gift from the gods. This also showed Alexander's eagerness to fight, in contrast to his father's preference for diplomacy.

After an initial victory against Persian forces at the Battle of the Granicus, Alexander accepted the surrender of the Persian provincial capital and treasury of Sardis; he then proceeded along the Ionian coast, granting autonomy and democracy to the cities. Miletus, held by Achaemenid forces, required a delicate siege operation, with Persian naval forces nearby. Further south, at Halicarnassus, in Caria, Alexander successfully waged his first large-scale siege, eventually forcing his opponents, the mercenary captain Memnon of Rhodes and the Persian satrap of Caria, Orontobates, to withdraw by sea. Alexander left the government of Caria to a member of the Hecatomnid dynasty, Ada, who adopted Alexander.

From Halicarnassus, Alexander proceeded into mountainous Lycia and the Pamphylian plain, asserting control over all coastal cities to deny the Persians naval bases. From Pamphylia onwards the coast held no major ports and Alexander moved inland. At Termessos, Alexander humbled but did not storm the Pisidian city. At the ancient Phrygian capital of Gordium, Alexander "undid" the hitherto unsolvable Gordian Knot, a feat said to await the future "king of Asia

In spring 333 BC, Alexander crossed the Taurus into Cilicia. After a long pause due to an illness, he marched on towards Syria. Though outmanoeuvered by Darius' significantly larger army, he marched back to Cilicia, where he defeated Darius at Issus. Darius fled the battle, causing his army to collapse, and left behind his wife, his two daughters, his mother Sisygambis, and a fabulous treasure. He offered a peace treaty that included the lands he had already lost, and a ransom of 10,000 talents for his family. Alexander replied that since he was now king of Asia, it was he alone who decided territorial divisions.
Alexander proceeded to take possession of Syria, and most of the coast of the Levant. In the following year, 332 BC, he was forced to attack Tyre, which he captured after a long and difficult siege. The men of military age were massacred and the women and children sold into slavery

When Alexander destroyed Tyre, most of the towns on the route to Egypt quickly capitulated. However, Alexander met with resistance at Gaza. The stronghold was heavily fortified and built on a hill, requiring a siege. When "his engineers pointed out to him that because of the height of the mound it would be impossible... this encouraged Alexander all the more to make the attempt". After three unsuccessful assaults, the stronghold fell, but not before Alexander had received a serious shoulder wound. As in Tyre, men of military age were put to the sword and the women and children were sold into slavery.

Alexander advanced on Egypt in later 332 BC, where he was regarded as a liberator. He was pronounced son of the deity Amun at the Oracle of Siwa Oasis in the Libyan desert. Henceforth, Alexander often referred to Zeus-Ammon as his true father, and after his death, currency depicted him adorned with the horns of a ram as a symbol of his divinity. During his stay in Egypt, he founded Alexandria-by-Egypt, which would become the prosperous capital of the Ptolemaic Kingdom after his death.

Leaving Egypt in 331 BC, Alexander marched eastward into Mesopotamia (now northern Iraq) and again defeated Darius, at the Battle of Gaugamela. Darius once more fled the field, and Alexander chased him as far as Arbela. Gaugamela would be the final and decisive encounter between the two. Darius fled over the mountains to Ecbatana (modern Hamedan), while Alexander captured Babylon

From Babylon, Alexander went to Susa, one of the Achaemenid capitals, and captured its treasury. He sent the bulk of his army to the Persian ceremonial capital of Persepolis via the Persian Royal Road. Alexander himself took selected troops on the direct route to the city. He then stormed the pass of the Persian Gates (in the modern Zagros Mountains) which had been blocked by a Persian army under Ariobarzanes and then hurried to Persepolis before its garrison could loot the treasury.

On entering Persepolis, Alexander allowed his troops to loot the city for several days. Alexander stayed in Persepolis for five months. During his stay a fire broke out in the eastern palace of Xerxes I and spread to the rest of the city. Possible causes include a drunken accident or deliberate revenge for the burning of the Acropolis of Athens during the Second Persian War by Xerxes. Even as he watched the city burn, Alexander immediately began to regret his decision. Plutarch claims that he ordered his men to put out the fires, but that the flames had already spread to most of the city. Curtius
Alexander then chased Darius, first into Media, and then Parthia. The Persian king no longer controlled his own destiny, and was taken prisoner by Bessus, his Bactrian satrap and kinsman. As Alexander approached, Bessus had his men fatally stab the Great King and then declared himself Darius' successor as Artaxerxes V, before retreating into Central Asia to launch a guerrilla campaign against Alexander. Alexander buried Darius' remains next to his Achaemenid predecessors in a regal funeral. He claimed that, while dying, Darius had named him as his successor to the Achaemenid throne. The Achaemenid Empire is normally considered to have fallen with Darius.

Alexander viewed Bessus as a usurper and set out to defeat him. This campaign, initially against Bessus, turned into a grand tour of central Asia. Alexander founded a series of new cities, all called Alexandria, including modern Kandahar in Afghanistan, and Alexandria Eschate ("The Furthest") in modern Tajikistan. The campaign took Alexander through Media, Parthia, Aria (West Afghanistan), Drangiana, Arachosia (South and Central Afghanistan), Bactria (North and Central Afghanistan), and Scythia.

Spitamenes, who held an undefined position in the satrapy of Sogdiana, in 329 BC betrayed Bessus to Ptolemy, one of Alexander's trusted companions, and Bessus was executed. However, when, at some point later, Alexander was on the Jaxartes dealing with an incursion by a horse nomad army, Spitamenes raised Sogdiana in revolt. Alexander personally defeated the Scythians at the Battle of Jaxartes

During this time, Alexander adopted some elements of Persian dress and customs at his court, notably the custom of "proskynesis", either a symbolic kissing of the hand, or prostration on the ground, that Persians showed to their social superiors. The Greeks regarded the gesture as the province of deities and believed that Alexander meant to deify himself by requiring it. This cost him the sympathies of many of his countrymen, and he eventually abandoned it.

A plot against his life was revealed, and one of his officers, Philotas, was executed for failing to alert Alexander. The death of the son necessitated the death of the father, and thus Parmenion, who had been charged with guarding the treasury at Ecbatana, was assassinated at Alexander's command, to prevent attempts at vengeance. Most infamously, Alexander personally killed the man who had saved his life at Granicus, Cleitus the Black, during a violent drunken altercation at Maracanda (modern day Samarkand in Uzbekistan), in which Cleitus accused Alexander of several judgmental mistakes and most especially, of having forgotten the Macedonian ways in favour of a corrupt oriental lifestyle.

Later, in the Central Asian campaign, a second plot against his life was revealed, this one instigated by his own royal pages. His official historian, Callisthenes of Olynthus, was implicated in the plot, and in the "Anabasis of Alexander", Arrian states that Callisthenes and the pages were then tortured on the rack as punishment, and likely died soon after. It remains unclear if Callisthenes was actually involved in the plot, for prior to his accusation he had fallen out of favour by leading the opposition to the attempt to introduce proskynesis.

When Alexander set out for Asia, he left his general Antipater, an experienced military and political leader and part of Philip II's "Old Guard", in charge of Macedon. Alexander's sacking of Thebes ensured that Greece remained quiet during his absence. The one exception was a call to arms by Spartan king Agis III in 331 BC, whom Antipater defeated and killed in the battle of Megalopolis. Antipater referred the Spartans' punishment to the League of Corinth, which then deferred to Alexander, who chose to pardon them. There was also considerable friction between Antipater and Olympias, and each complained to Alexander about the other.

In general, Greece enjoyed a period of peace and prosperity during Alexander's campaign in Asia. Alexander sent back vast sums from his conquest, which stimulated the economy and increased trade across his empire. However, Alexander's constant demands for troops and the migration of Macedonians throughout his empire depleted Macedon's strength, greatly weakening it in the years after Alexander, and ultimately led to its subjugation by Rome after the Third Macedonian War

After the death of Spitamenes and his marriage to Roxana (Raoxshna in Old Iranian) to cement relations with his new satrapies, Alexander turned to the Indian subcontinent. He invited the chieftains of the former satrapy of Gandhara (a region presently straddling eastern Afghanistan and northern Pakistan), to come to him and submit to his authority. Omphis (Indian name Ambhi), the ruler of Taxila, whose kingdom extended from the Indus to the Hydaspes (Jhelum), complied, but the chieftains of some hill clans, including the Aspasioi and Assakenoi sections of the Kambojas (known in Indian texts also as Ashvayanas and Ashvakayanas), refused to submit. Ambhi hastened to relieve Alexander of his apprehension and met him with valuable presents, placing himself and all his forces at his disposal. Alexander not only returned Ambhi his title and the gifts but he also presented him with a wardrobe of "Persian robes, gold and silver ornaments, 30 horses and 1,000 talents in gold". Alexander was emboldened to divide his forces, and Ambhi assisted Hephaestion and Perdiccas in constructing a bridge over the Indus where it bends at Hund (Fox 1973), supplied their troops with provisions, and received Alexander himself, and his whole army, in his capital city of Taxila, with every demonstration of friendship and the most liberal hospitality.

On the subsequent advance of the Macedonian king, Taxiles accompanied him with a force of 5,000 men and took part in the battle of the Hydaspes River. After that victory he was sent by Alexander in pursuit of Porus, to whom he was charged to offer favourable terms, but narrowly escaped losing his life at the hands of his old enemy. Subsequently, however, the two rivals were reconciled by the personal mediation of Alexander; and Taxiles, after having contributed zealously to the equipment of the fleet on the Hydaspes, was entrusted by the king with the government of the whole territory between that river and the Indus. A considerable accession of power was granted him after the death of Philip, son of Machatas; and he was allowed to retain his authority at the death of Alexander himself (323 BC), as well as in the subsequent partition of the provinces at Triparadisus, 321 BC.

In the winter of 327/326 BC, Alexander personally led a campaign against the Aspasioi of Kunar valleys, the Guraeans of the Guraeus valley, and the Assakenoi of the Swat and Buner valleys. A fierce contest ensued with the Aspasioi in which Alexander was wounded in the shoulder by a dart, but eventually the Aspasioi lost. Alexander then faced the Assakenoi, who fought against him from the strongholds of Massaga, Ora and Aornos.

The fort of Massaga was reduced only after days of bloody fighting, in which Alexander was wounded seriously in the ankle. According to Curtius, "Not only did Alexander slaughter the entire population of Massaga, but also did he reduce its buildings to rubble." A similar slaughter followed at Ora. In the aftermath of Massaga and Ora, numerous Assakenians fled to the fortress of Aornos. Alexander followed close behind and captured the strategic hill-fort after four bloody days.

After Aornos, Alexander crossed the Indus and fought and won an epic battle against King Porus, who ruled a region lying between the Hydaspes and the Acesines (Chenab), in what is now the Punjab, in the Battle of the Hydaspes in 326 BC. Alexander was impressed by Porus' bravery, and made him an ally. He appointed Porus as satrap, and added to Porus' territory land that he did not previously own, towards the south-east, up to the Hyphasis (Beas). Choosing a local helped him control these lands so distant from Greece. Alexander founded two cities on opposite sides of the Hydaspes river, naming one Bucephala, in honour of his horse, who died around this time. The other was Nicaea (Victory), thought to be located at the site of modern-day Mong, Punjab

East of Porus' kingdom, near the Ganges River, was the Nanda Empire of Magadha, and further east, the Gangaridai Empire of Bengal region of the Indian subcontinent. Fearing the prospect of facing other large armies and exhausted by years of campaigning, Alexander's army mutinied at the Hyphasis River (Beas), refusing to march farther east. This river thus marks the easternmost extent of Alexander's conquests.

Alexander tried to persuade his soldiers to march farther, but his general Coenus pleaded with him to change his opinion and return; the men, he said, "longed to again see their parents, their wives and children, their homeland". Alexander eventually agreed and turned south, marching along the Indus. Along the way his army conquered the Malhi (in modern-day Multan) and other Indian tribes and Alexander sustained an injury during the siege.

Alexander sent much of his army to Carmania (modern southern Iran) with general Craterus, and commissioned a fleet to explore the Persian Gulf shore under his admiral Nearchus, while he led the rest back to Persia through the more difficult southern route along the Gedrosian Desert and Makran
Discovering that many of his satraps and military governors had misbehaved in his absence, Alexander executed several of them as examples on his way to Susa. As a gesture of thanks, he paid off the debts of his soldiers, and announced that he would send over-aged and disabled veterans back to Macedon, led by Craterus. His troops misunderstood his intention and mutinied at the town of Opis
After three days, unable to persuade his men to back down, Alexander gave Persians command posts in the army and conferred Macedonian military titles upon Persian units. The Macedonians quickly begged forgiveness, which Alexander accepted, and held a great banquet for several thousand of his men at which he and they ate together. In an attempt to craft a lasting harmony between his Macedonian and Persian subjects, Alexander held a mass marriage of his senior officers to Persian and other noblewomen at Susa, but few of those marriages seem to have lasted much beyond a year. Meanwhile, upon his return to Persia, Alexander learned that guards of the tomb of Cyrus the Great in Pasargadae had desecrated it, and swiftly executed them. Alexander admired Cyrus the Great, from an early age reading Xenophon's "Cyropaedia", which described Cyrus's heroism in battle and governance as a king and legislator. During his visit to Pasargadae Alexander ordered his architect Aristobulus to decorate the interior of the sepulchral chamber of Cyrus' tomb.

Afterwards, Alexander travelled to Ecbatana to retrieve the bulk of the Persian treasure. There, his closest friend and possible lover, Hephaestion, died of illness or poisoning. Hephaestion's death devastated Alexander, and he ordered the preparation of an expensive funeral pyre
On either 10 or 11 June 323 BC, Alexander died in the palace of Nebuchadnezzar II, in Babylon, at age 32. There are two different versions of Alexander's death and details of the death differ slightly in each. Plutarch's account is that roughly 14 days before his death, Alexander entertained admiral Nearchus, and spent the night and next day drinking with Medius of Larissa. He developed a fever, which worsened until he was unable to speak. The common soldiers, anxious about his health, were granted the right to file past him as he silently waved at them. In the second account, Diodorus recounts that Alexander was struck with pain after downing a large bowl of unmixed wine in honour of Heracles, followed by 11 days of weakness; he did not develop a fever and died after some agony. Arrian also mentioned this as an alternative, but Plutarch specifically denied this claim.

Given the propensity of the Macedonian aristocracy to assassination, foul play featured in multiple accounts of his death. Diodorus, Plutarch, Arrian and Justin all mentioned the theory that Alexander was poisoned. Justin stated that Alexander was the victim of a poisoning conspiracy, Plutarch dismissed it as a fabrication, while both Diodorus and Arrian noted that they mentioned it only for the sake of completeness. The accounts were nevertheless fairly consistent in designating Antipater, recently removed as Macedonian viceroy, and at odds with Olympias, as the head of the alleged plot. Perhaps taking his summons to Babylon as a death sentence, and having seen the fate of Parmenion and Philotas, Antipater purportedly arranged for Alexander to be poisoned by his son Iollas, who was Alexander's wine-pourer. There was even a suggestion that Aristotle may have participated.

The strongest argument against the poison theory is the fact that twelve days passed between the start of his illness and his death; such long-acting poisons were probably not available. However, in a 2003 BBC documentary investigating the death of Alexander, Leo Schep from the New Zealand National Poisons Centre proposed that the plant white hellebore ("Veratrum album"), which was known in antiquity, may have been used to poison Alexander. In a 2014 manuscript in the journal Clinical Toxicology, Schep suggested Alexander's wine was spiked with "Veratrum album", and that this would produce poisoning symptoms that match the course of events described in the "Alexander Romance". "Veratrum album" poisoning can have a prolonged course and it was suggested that if Alexander was poisoned, "Veratrum album" offers the most plausible cause. Another poisoning explanation put forward in 2010 proposed that the circumstances of his death were compatible with poisoning by water of the river Styx (modern-day Mavroneri in Arcadia, Greece) that contained calicheamicin, a dangerous compound produced by bacteria.

Several natural causes (diseases) have been suggested, including malaria and typhoid fever. A 1998 article in the "New England Journal of Medicine" attributed his death to typhoid fever complicated by bowel perforation and ascending paralysis. Another recent analysis suggested pyogenic (infectious) spondylitis or meningitis. Other illnesses fit the symptoms, including acute pancreatitis and West Nile virus. Natural-cause theories also tend to emphasize that Alexander's health may have been in general decline after years of heavy drinking and severe wounds. The anguish that Alexander felt after Hephaestion

Alexander's body was laid in a gold anthropoid sarcophagus that was filled with honey, which was in turn placed in a gold casket. According to Aelian, a seer called Aristander foretold that the land where Alexander was laid to rest "would be happy and unvanquishable forever". Perhaps more likely, the successors may have seen possession of the body as a symbol of legitimacy, since burying the prior king was a royal prerogative.

While Alexander's funeral cortege was on its way to Macedon, Ptolemy seized it and took it temporarily to Memphis. His successor, Ptolemy II Philadelphus, transferred the sarcophagus to Alexandria, where it remained until at least late Antiquity. Ptolemy IX Lathyros, one of Ptolemy's final successors, replaced Alexander's sarcophagus with a glass one so he could convert the original to coinage. The recent discovery of an enormous tomb in northern Greece, at Amphipolis, dating from the time of Alexander the Great has given rise to speculation that its original intent was to be the burial place of Alexander. This would fit with the intended destination of Alexander's funeral cortege.

Pompey, Julius Caesar and Augustus all visited the tomb in Alexandria, where Augustus, allegedly, accidentally knocked the nose off. Caligula was said to have taken Alexander's breastplate from the tomb for his own use. Around AD 200, Emperor Septimius Severus closed Alexander's tomb to the public. His son and successor, Caracalla, a great admirer, visited the tomb during his own reign. After this, details on the fate of the tomb are hazy.

The so-called "Alexander Sarcophagus", discovered near Sidon and now in the Istanbul Archaeology Museum, is so named not because it was thought to have contained Alexander's remains, but because its bas-reliefs depict Alexander and his companions fighting the Persians and hunting. It was originally thought to have been the sarcophagus of Abdalonymus (died 311 BC), the king of Sidon appointed by Alexander immediately following the battle of Issus

Alexander's death was so sudden that when reports of his death reached Greece, they were not immediately believed. Alexander had no obvious or legitimate heir, his son Alexander IV by Roxane being born after Alexander's death. According to Diodorus, Alexander's companions asked him on his deathbed to whom he bequeathed his kingdom; his laconic reply was "tôi kratistôi"—"to the strongest". Another theory is that his successors willfully or erroneously misheard "tôi Kraterôi"—"to Craterus", the general leading his Macedonian troops home and newly entrusted with the regency of Macedonia.

Arrian and Plutarch claimed that Alexander was speechless by this point, implying that this was an apocryphal story. Diodorus, Curtius and Justin offered the more plausible story that Alexander passed his signet ring to Perdiccas, a bodyguard and leader of the companion cavalry, in front of witnesses, thereby nominating him.

Perdiccas initially did not claim power, instead suggesting that Roxane's baby would be king, if male; with himself, Craterus, Leonnatus, and Antipater as guardians. However, the infantry, under the command of Meleager, rejected this arrangement since they had been excluded from the discussion. Instead, they supported Alexander's half-brother Philip Arrhidaeus. Eventually, the two sides reconciled, and after the birth of Alexander IV, he and Philip III were appointed joint kings, albeit in name only.

Dissension and rivalry soon afflicted the Macedonians, however. The satrapies handed out by Perdiccas at the Partition of Babylon became power bases each general used to bid for power. After the assassination of Perdiccas in 321 BC, Macedonian unity collapsed, and 40 years of war between "The Successors" ("Diadochi") ensued before the Hellenistic world settled into four stable power blocs: Ptolemaic Egypt, Seleucid Mesopotamia and Central Asia, Attalid Anatolia, and Antigonid
Diodorus stated that Alexander had given detailed written instructions to Craterus some time before his death. Craterus started to carry out Alexander's commands, but the successors chose not to further implement them, on the grounds they were impractical and extravagant. Nevertheless, Perdiccas read Alexander's will

Alexander earned the epithet "the Great" due to his unparalleled success as a military commander. He never lost a battle, despite typically being outnumbered. This was due to use of terrain, phalanx and cavalry tactics, bold strategy, and the fierce loyalty of his troops. The Macedonian phalanx, armed with the sarissa, a spear long, had been developed and perfected by Philip II through rigorous training, and Alexander used its speed and maneuverability to great effect against larger but more disparate Persian forces. Alexander also recognized the potential for disunity among his diverse army, which employed various languages and weapons. He overcame this by being personally involved in battle, in the manner of a Macedonian king.

In his first battle in Asia, at Granicus, Alexander used only a small part of his forces, perhaps 13,000 infantry with 5,000 cavalry, against a much larger Persian force of 40,000. Alexander placed the phalanx at the center and cavalry and archers on the wings, so that his line matched the length of the Persian cavalry line, about . By contrast, the Persian infantry was stationed behind its cavalry. This ensured that Alexander would not be outflanked, while his phalanx, armed with long pikes, had a considerable advantage over the Persians' scimitars and javelins. Macedonian losses were negligible compared to those of the Persians.

At Issus in 333 BC, his first confrontation with Darius, he used the same deployment, and again the central phalanx pushed through. Alexander personally led the charge in the center, routing the opposing army. At the decisive encounter with Darius at Gaugamela, Darius equipped his chariots with scythes on the wheels to break up the phalanx and equipped his cavalry with pikes. Alexander arranged a double phalanx, with the center advancing at an angle, parting when the chariots bore down and then reforming. The advance was successful and broke Darius' center, causing the latter to flee once again.

When faced with opponents who used unfamiliar fighting techniques, such as in Central Asia and India, Alexander adapted his forces to his opponents' style. Thus, in Bactria and Sogdiana

Greek biographer Plutarch () describes Alexander's appearance as:

Greek historian Arrian (Lucius Flavius Arrianus 'Xenophon' ) described Alexander as:

The semi-legendary "Alexander Romance" also suggests that Alexander exhibited heterochromia iridum: that one eye was dark and the other light.

British historian Peter Green provided a description of Alexander's appearance, based on his review of statues and some ancient documents:

Ancient authors recorded that Alexander was so pleased with portraits of himself created by Lysippos that he forbade other sculptors from crafting his image. Lysippos had often used the contrapposto sculptural scheme to portray Alexander and other characters such as Apoxyomenos, Hermes and Eros
Some of Alexander's strongest personality traits formed in response to his parents. His mother had huge ambitions, and encouraged him to believe it was his destiny to conquer the Persian Empire. Olympias' influence instilled a sense of destiny in him, and Plutarch tells how his ambition "kept his spirit serious and lofty in advance of his years". However, his father Philip was Alexander's most immediate and influential role model, as the young Alexander watched him campaign practically every year, winning victory after victory while ignoring severe wounds. Alexander's relationship with his father forged the competitive side of his personality; he had a need to outdo his father, illustrated by his reckless behaviour in battle. While Alexander worried that his father would leave him "no great or brilliant achievement to be displayed to the world", he also downplayed his father's achievements to his companions.

According to Plutarch, among Alexander's traits were a violent temper and rash, impulsive nature, which undoubtedly contributed to some of his decisions. Although Alexander was stubborn and did not respond well to orders from his father, he was open to reasoned debate. He had a calmer side—perceptive, logical, and calculating. He had a great desire for knowledge, a love for philosophy, and was an avid reader. This was no doubt in part due to Aristotle's tutelage; Alexander was intelligent and quick to learn. His intelligent and rational side was amply demonstrated by his ability and success as a general. He had great self-restraint in "pleasures of the body", in contrast with his lack of self-control
Alexander was erudite and patronized both arts and sciences. However, he had little interest in sports or the Olympic games (unlike his father), seeking only the Homeric ideals of honour ("timê") and glory ("kudos"). He had great charisma and force of personality, characteristics which made him a great leader. His unique abilities were further demonstrated by the inability of any of his generals to unite Macedonia and retain the Empire after his death—only Alexander had the ability to do so.

During his final years, and especially after the death of Hephaestion, Alexander began to exhibit signs of megalomania and paranoia. His extraordinary achievements, coupled with his own ineffable sense of destiny and the flattery of his companions, may have combined to produce this effect. His delusions of grandeur are readily visible in his will and in his desire to conquer the world, in as much as he is by various sources described as having "boundless ambition", an epithet, the meaning of which has descended into an historical cliché.

He appears to have believed himself a deity, or at least sought to deify himself. Olympias always insisted to him that he was the son of Zeus, a theory apparently confirmed to him by the oracle of Amun at Siwa. He began to identify himself as the son of Zeus-Ammon. Alexander adopted elements of Persian dress and customs at court, notably "proskynesis

Alexander married three times: Roxana, daughter of the Sogdian nobleman Oxyartes of Bactria, out of love; and the Persian princesses Stateira II and Parysatis II, the former a daughter of Darius III and latter a daughter of Artaxerxes III, for political reasons. He apparently had two sons, Alexander IV of Macedon by Roxana and, possibly, Heracles of Macedon from his mistress Barsine. He lost another child when Roxana miscarried at Babylon.

Alexander also had a close relationship with his friend, general, and bodyguard Hephaestion, the son of a Macedonian noble. Hephaestion's death devastated Alexander. This event may have contributed to Alexander's failing health and detached mental state during his final months.

Alexander's sexuality has been the subject of speculation and controversy in modern times. The Roman era writer Athenaeus says, based on the scholar Dicaearchus, who was Alexander's contemporary, that the king "was also very much in the habit of giving in to this fashion" (i.e., homosexuality), and that Alexander sexually embraced his eunuch Bagoas in public. This episode is also told by Plutarch, probably based on the same source. No ancient writer, however, explicitly describes Alexander's relationship with Hephaestion as sexual, though the pair was often compared to Achilles and Patroclus, whom classical Greek culture painted as a couple. Aelian writes of Alexander's visit to Troy where "Alexander garlanded the tomb of Achilles, and Hephaestion that of Patroclus, the latter hinting that he was a beloved of Alexander, in just the same way as Patroclus was of Achilles." Some modern historians (e.g., Robin Lane Fox) believe not only that Alexander's youthful relationship with Hephaestion was sexual, but that their sexual contacts may have continued into adulthood, which went against the social norms of at least some Greek cities, such as Athens, though some modern researchers have provisionally proposed that Macedonia (or at least the Macedonian court) may have been more tolerant of homosexuality between adults.

Green argues that there is little evidence in ancient sources that Alexander had much carnal interest in women; he did not produce an heir until the very end of his life. However, he was relatively young when he died, and Ogden suggests that Alexander's matrimonial record is more impressive than his father's at the same age. Apart from wives, Alexander had many more female companions. Alexander accumulated a harem in the style of Persian kings, but he used it rather sparingly, showing great self-control in "pleasures of the body". Nevertheless, Plutarch described how Alexander was infatuated by Roxana while complimenting him on not forcing himself on her. Green suggested that, in the context of the period, Alexander formed quite strong friendships with women, including Ada of Caria, who adopted him, and even Darius' mother Sisygambis

Alexander's most immediate legacy was the introduction of Macedonian rule to huge new swathes of Asia. At the time of his death, Alexander's empire covered some , and was the largest state of its time. Many of these areas remained in Macedonian hands or under Greek influence for the next 200–300 years. The successor states that emerged were, at least initially, dominant forces, and these 300 years are often referred to as the Hellenistic period.

The eastern borders of Alexander's empire began to collapse even during his lifetime. However, the power vacuum he left in the northwest of the Indian subcontinent directly gave rise to one of the most powerful Indian dynasties in history, the Maurya Empire. Taking advantage of this power vacuum, Chandragupta Maurya (referred to in Greek sources as "Sandrokottos"), of relatively humble origin, took control of the Punjab, and with that power base proceeded to conquer the Nanda Empire.

Over the course of his conquests, Alexander founded some twenty cities that bore his name, most of them east of the Tigris. The first, and greatest, was Alexandria
In 334 BC, Alexander the Great donated funds for the completion of the new temple of Athena Polias in Priene. An inscription from the temple, now housed in the British Museum, declares: "King Alexander dedicated [this temple] to Athena Polias." This inscription is one of the few independent archaeological discoveries confirming an episode from Alexander's life. The temple was designed by Pytheos, one of the architects of the Mausoleum at Halicarnassus

"Hellenization" was coined by the German historian Johann Gustav Droysen to denote the spread of Greek language, culture, and population into the former Persian empire after Alexander's conquest. That this export took place is undoubted, and can be seen in the great Hellenistic cities of, for instance, Alexandria, Antioch and Seleucia (south of modern Baghdad). Alexander sought to insert Greek elements into Persian culture and attempted to hybridize Greek and Persian culture. This culminated in his aspiration to homogenize the populations of Asia and Europe. However, his successors explicitly rejected such policies. Nevertheless, Hellenization occurred throughout the region, accompanied by a distinct and opposite 'Orientalization' of the successor states.

The core of the Hellenistic culture promulgated by the conquests was essentially Athenian. The close association of men from across Greece in Alexander's army directly led to the emergence of the largely Attic-based "koine", or "common" Greek dialect. Koine spread throughout the Hellenistic world, becoming the lingua franca of Hellenistic lands and eventually the ancestor of modern Greek. Furthermore, town planning
Some of the most pronounced effects of Hellenization can be seen in Afghanistan and India, in the region of the relatively late-rising Greco-Bactrian Kingdom (250–125 BC) (in modern Afghanistan, Pakistan, and Tajikistan) and the Indo-Greek Kingdom (180 BC – 10 AD) in modern Afghanistan and India. There on the newly formed Silk Road Greek culture apparently hybridized with Indian, and especially Buddhist culture. The resulting syncretism known as Greco-Buddhism heavily influenced the development of Buddhism and created a culture of Greco-Buddhist art. These Greco-Buddhist kingdoms sent some of the first Buddhist missionaries to China, Sri Lanka, and the Mediterranean (Greco-Buddhist monasticism). Some of the first and most influential figurative portrayals of the Buddha appeared at this time, perhaps modeled on Greek statues of Apollo in the Greco-Buddhist style. Several Buddhist traditions may have been influenced by the ancient Greek religion: the concept of Boddhisatvas is reminiscent of Greek divine heroes, and some Mahayana ceremonial practices (burning incense, gifts of flowers, and food placed on altars) are similar to those practiced by the ancient Greeks; however, similar practices were also observed amongst the native Indic culture. One Greek king, Menander I, probably became Buddhist, and was immortalized in Buddhist literature as 'Milinda'. The process of Hellenization also spurred trade between the east and west. For example, Greek astronomical instruments dating to the 3rd century BC were found in the Greco-Bactrian city of Ai Khanoum in modern-day Afghanistan, while the Greek concept of a spherical earth surrounded by the spheres of planets eventually supplanted the long-standing Indian cosmological belief of a disc consisting of four continents grouped around a central mountain (Mount Meru) like the petals of a flower. The Yavanajataka (lit. Greek astronomical treatise) and Paulisa Siddhanta texts depict the influence of Greek astronomical ideas on Indian astronomy.

Following the conquests of Alexander the Great in the east, Hellenistic influence on Indian art was far-ranging. In the area of architecture, a few examples of the Ionic order can be found as far as Pakistan with the Jandial temple near Taxila. Several examples of capitals displaying Ionic influences can be seen as far as Patna, especially with the Pataliputra capital, dated to the 3rd century BC. The Corinthian order is also heavily represented in the art of Gandhara, especially through Indo-Corinthian capitals
Alexander and his exploits were admired by many Romans, especially generals, who wanted to associate themselves with his achievements. Polybius began his "Histories" by reminding Romans of Alexander's achievements, and thereafter Roman leaders saw him as a role model. Pompey the Great adopted the epithet "Magnus" and even Alexander's anastole-type haircut, and searched the conquered lands of the east for Alexander's 260-year-old cloak, which he then wore as a sign of greatness. Julius Caesar dedicated a Lysippean equestrian bronze statue but replaced Alexander's head with his own, while Octavian visited Alexander's tomb in Alexandria and temporarily changed his seal from a sphinx to Alexander's profile. The emperor Trajan also admired Alexander, as did Nero and Caracalla. The Macriani, a Roman family that in the person of Macrinus

On the other hand, some Roman writers, particularly Republican figures, used Alexander as a cautionary tale of how autocratic tendencies can be kept in check by republican values. Alexander was used by these writers as an example of ruler values such as (friendship) and (clemency), but also (anger) and (over-desire for glory).

Legendary accounts surround the life of Alexander the Great, many deriving from his own lifetime, probably encouraged by Alexander himself. His court historian Callisthenes portrayed the sea in Cilicia as drawing back from him in proskynesis. Writing shortly after Alexander's death, another participant, Onesicritus, invented a tryst between Alexander and Thalestris, queen of the mythical Amazons. When Onesicritus read this passage to his patron, Alexander's general and later King Lysimachus reportedly quipped, "I wonder where I was at the time."

In the first centuries after Alexander's death, probably in Alexandria, a quantity of the legendary material coalesced into a text known as the "Alexander Romance", later falsely ascribed to Callisthenes and therefore known as "Pseudo-Callisthenes". This text underwent numerous expansions and revisions throughout Antiquity and the Middle Ages

Alexander the Great's accomplishments and legacy have been depicted in many cultures. Alexander has figured in both high and popular culture beginning in his own era to the present day. The "Alexander Romance", in particular, has had a significant impact on portrayals of Alexander in later cultures, from Persian to medieval European to modern Greek.

Alexander features prominently in modern Greek folklore, more so than any other ancient figure. The colloquial form of his name in modern Greek ("O Megalexandros") is a household name, and he is the only ancient hero to appear in the Karagiozis shadow play. One well-known fable among Greek seamen involves a solitary mermaid who would grasp a ship's prow during a storm and ask the captain "Is King Alexander alive?" The correct answer is "He is alive and well and rules the world!" causing the mermaid to vanish and the sea to calm. Any other answer would cause the mermaid to turn into a raging Gorgon who would drag the ship to the bottom of the sea, all hands aboard.

In pre-Islamic Middle Persian (Zoroastrian) literature, Alexander is referred to by the epithet "gujastak", meaning "accursed", and is accused of destroying temples and burning the sacred texts of Zoroastrianism. In Sunni Islamic Persia, under the influence of the "Alexander Romance" (in "Iskandarnamah"), a more positive portrayal of Alexander emerges. Firdausi's "Shahnameh" ("The Book of Kings") includes Alexander in a line of legitimate Persian shahs, a mythical figure who explored the far reaches of the world in search of the Fountain of Youth. Later Persian writers associate him with philosophy, portraying him at a symposium with figures such as Socrates, Plato and Aristotle, in search of immortality.
The figure of Dhul-Qarnayn (literally "the Two-Horned One") mentioned in the Quran is believed by some scholars to represent Alexander, due to parallels with the "Alexander Romance". In this tradition, he was a heroic figure who built a wall to defend against the nations of Gog and Magog. He then travelled the known world in search of the Water of Life and Immortality, eventually becoming a prophet.

The Syriac version of the "Alexander Romance" portrays him as an ideal Christian world conqueror who prayed to "the one true God". In Egypt, Alexander was portrayed as the son of Nectanebo II, the last pharaoh before the Persian conquest. His defeat of Darius was depicted as Egypt's salvation, "proving" Egypt was still ruled by an Egyptian.

According to Josephus, Alexander was shown the Book of Daniel when he entered Jerusalem, which described a mighty Greek king who would conquer the Persian Empire. This is cited as a reason for sparing Jerusalem.

In Hindi and Urdu, the name "Sikandar", derived from Persian, denotes a rising young talent. In medieval Europe, Alexander the Great was revered as a member of the Nine Worthies, a group of heroes whose lives were believed to encapsulate all the ideal qualities of chivalry.

Irish playwright Aubrey Thomas de Vere wrote "Alexander the Great, a Dramatic Poem".
British heavy Metal band Iron Maiden had Alexander the Great as a track on the 1986 "Somewhere in Time" Album. The song written by bass player Steve Harris captures and summarises Alexanders battles and life. It was one of the first Maiden albums to use guitar synths.

Apart from a few inscriptions and fragments, texts written by people who actually knew Alexander or who gathered information from men who served with Alexander were all lost. Contemporaries who wrote accounts of his life included Alexander's campaign historian Callisthenes; Alexander's generals Ptolemy and Nearchus; Aristobulus, a junior officer on the campaigns; and Onesicritus, Alexander's chief helmsman. Their works are lost, but later works based on these original sources have survived. The earliest of these is Diodorus Siculus (1st century BC), followed by Quintus Curtius Rufus (mid-to-late 1st century AD), Arrian (1st to 2nd century AD), the biographer Plutarch (1st to 2nd century AD), and finally Justin
Category:356 BC births
Category:323 BC deaths
Category:4th-century BC Macedonian monarchs
Category:4th-century BC Pharaohs
Category:4th-century BC Babylonian kings
Category:4th-century BC Macedonians
Category:4th-century BC rulers
Category:Ancient Macedonian generals
Category:Ancient Pellaeans
Category:Argead kings of Macedonia
Category:City founders
Category:Deified people
Category:Greek historical hero cult
Category:Hellenistic-era people
Category:Hellenistic ruler cult
Category:Monarchs of Persia
Category:Pharaohs of the Argead dynasty
Category:Shahnameh charactersAlfred Korzybski

Alfred Habdank Skarbek Korzybski (; July 3, 1879 – March 1, 1950) was a Polish-American independent scholar who developed a field called general semantics, which he viewed as both distinct from, and more encompassing than, the field of semantics. He argued that human knowledge of the world is limited both by the human nervous system and the languages humans have developed, and thus no one can have direct access to reality, given that the most we can know is that which is filtered through the brain's responses to reality. His best known dictum is "The map is not the territory
Born in Warsaw, Poland, then part of the Russian Empire, Korzybski belonged to an aristocratic Polish family whose members had worked as mathematicians, scientists, and engineers for generations. He learned the Polish language at home and the Russian language in schools; and having a French and German governess, he became fluent in four languages as a child.

Korzybski studied engineering at the Warsaw University of Technology. During the First World War (1914-1918) Korzybski served as an intelligence officer in the Russian Army. After being wounded in a leg and suffering other injuries, he moved to North America in 1916 (first to Canada, then to the United States) to coordinate the shipment of artillery to Russia. He also lectured to Polish-American audiences about the conflict, promoting the sale of war bonds. After the war he decided to remain in the United States, becoming a naturalized citizen in 1940. He met Mira Edgerly,
a painter of portraits on ivory, shortly after the1918 Armistice; They married in January 1919; the marriage lasted until his death.

E. P. Dutton published Korzybski's first book, "Manhood of Humanity", in 1921. In this work he proposed and explained in detail a new theory of humankind: mankind as a "time-binding" class of life (humans perform time binding by the transmission of knowledge and abstractions through time which become accreted in cultures).

Korzybski's work culminated in the initiation of a discipline that he named general semantics (GS). This should not be confused with semantics. The basic principles of general semantics, which include time-binding, are described in the publication "Science and Sanity", published in 1933. In 1938 Korzybski founded the Institute of General Semantics in Chicago. The post-World War II housing shortage in Chicago cost him the Institute's building lease, so in 1946 he moved the Institute to Lakeville, Connecticut, U.S., where he directed it until his death in 1950.

Korzybski maintained that humans are limited in what they know by (1) the structure of their nervous systems, and (2) the structure of their languages. Humans cannot experience the world directly, but only through their "abstractions" (nonverbal impressions or "gleanings" derived from the nervous system, and verbal indicators expressed and derived from language). These sometimes mislead us about what is the truth. Our understanding sometimes lacks "similarity of structure" with what is actually happening.

He sought to train our awareness of abstracting, using techniques he had derived from his study of mathematics and science. He called this awareness, this goal of his system, "consciousness of abstracting". His system included the promotion of attitudes such as "I don't know; let's see," in order that we may better discover or reflect on its realities as revealed by modern science. Another technique involved becoming inwardly and outwardly quiet, an experience he termed, "silence on the objective levels".

Many devotees and critics of Korzybski reduced his rather complex system to a simple matter of what he said about the verb form "is" of the general verb "to be." His system, however, is based primarily on such terminology as the different "orders of abstraction," and formulations such as "consciousness of abstracting." The contention that Korzybski "opposed" the use of the verb "to be" would be a profound exaggeration.

He thought that "certain uses" of the verb "to be", called the "is of identity" and the "is of predication", were faulty in structure, e.g., a statement such as, "Elizabeth is a fool" (said of a person named "Elizabeth" who has done something that we regard as foolish). In Korzybski's system, one's assessment of Elizabeth belongs to a higher order of abstraction than Elizabeth herself. Korzybski's remedy was to "deny" identity; in this example, to be aware continually that "Elizabeth" is "not" what we "call" her. We find Elizabeth not in the verbal domain, the world of words, but the nonverbal domain (the two, he said, amount to different orders of abstraction). This was expressed by Korzybski's most famous premise, "the map is not the territory". Note that this premise uses the phrase "is not", a form of "to be"; this and many other examples show that he did not intend to abandon "to be" as such. In fact, he said explicitly that there were no structural problems with the verb "to be" when used as an auxiliary verb or when used to state existence or location. It was even acceptable at times to use the faulty forms of the verb "to be," as long as one was aware of their structural limitations.

One day, Korzybski was giving a lecture to a group of students, and he interrupted the lesson suddenly in order to retrieve a packet of biscuits, wrapped in white paper, from his briefcase. He muttered that he just had to eat something, and he asked the students on the seats in the front row if they would also like a biscuit. A few students took a biscuit. "Nice biscuit, don't you think," said Korzybski, while he took a second one. The students were chewing vigorously. Then he tore the white paper from the biscuits, in order to reveal the original packaging. On it was a big picture of a dog's head and the words "Dog Cookies." The students looked at the package, and were shocked. Two of them wanted to vomit, put their hands in front of their mouths, and ran out of the lecture hall to the toilet. "You see," Korzybski remarked, "I have just demonstrated that people don't just eat food, but also words, and that the taste of the former is often outdone by the taste of the latter."

William Burroughs went to a Korzybski workshop in the Autumn of 1939. He was 25 years old, and paid $40. His fellow students—there were 38 in all—included young Samuel I. Hayakawa (later to become a Republican member of the U.S. Senate), Ralph Moriarty deBit (later to become the spiritual teacher Vitvan) and Wendell Johnson (founder of the Monster Study).

Korzybski was well received in numerous disciplines, as evidenced by the positive reactions from leading figures in the sciences and humanities in the 1940s and 1950s.

As reported in the third edition of "Science and Sanity", in World War II the US Army used Korzybski's system to treat battle fatigue in Europe, under the supervision of Dr. Douglas M. Kelley, who went on to become the psychiatrist in charge of the Nazi war criminals at Nuremberg.

Some of the General Semantics tradition was continued by Samuel I. Hayakawa.



Category:1879 births
Category:1950 deaths
Category:People from Warsaw
Category:Clan Abdank
Category:Polish emigrants to the United States
Category:Polish engineers
Category:Polish philosophers
Category:Polish mathematicians
Category:Linguists from Poland
Category:Contemporary philosophers
Category:General semantics
Category:People from Lakeville, ConnecticutAsteroids (video game)

Asteroids is an arcade space shoot 'em up game released in November 1979 by Atari, Inc., and designed by Lyle Rains, Ed Logg, and Dominic Walsh, before being ported in the 1980s to a number of Atari consoles. The player controls a single spaceship in an asteroid field which is periodically traversed by flying saucers. The object of the game is to shoot and destroy the asteroids and saucers, while not colliding with either, or being hit by the saucers' counter-fire. The game becomes harder as the number of asteroids increases.

"Asteroids" was one of the first major hits of the golden age of arcade games; the game sold over 70,000 arcade cabinets and proved both popular with players and influential with developers. It has since been ported to multiple platforms. The game was widely imitated, and it directly influenced "Defender", "Gravitar", and many other video games.

"Asteroids" was conceived during a meeting between Logg and Rains, who decided to use hardware developed by Howard Delman, previously used for "Lunar Lander". Based on an unfinished game titled "Cosmos", and inspired by "Spacewar!", "Computer Space", and "Space Invaders", the physics model, control scheme, and gameplay elements for "Asteroids" were derived from these earlier games and refined through trial and error. The game is rendered on a vector display
The objective of "Asteroids" is to destroy asteroids and saucers. The player controls a triangular ship that can rotate left and right, fire shots straight forward, and thrust forward. Once the ship begins moving in a direction, it will continue in that direction for a time without player intervention unless the player applies thrust in a different direction. The ship eventually comes to a stop when not thrusting. The player can also send the ship into hyperspace, causing it to disappear and reappear in a random location on the screen, at the risk of self-destructing or appearing on top of an asteroid.

Each level starts with a few large asteroids drifting in various directions on the screen. Objects wrap around screen edges – for instance, an asteroid that drifts off the top edge of the screen reappears at the bottom and continues moving in the same direction. As the player shoots asteroids, they break into smaller asteroids that move faster and are more difficult to hit. Smaller asteroids are also worth more points. Two flying saucers appear periodically on the screen; the "big saucer" shoots randomly and poorly, while the "small saucer" fires frequently at the ship. After reaching a score of 40,000, only the small saucer appears. As the player's score increases, the angle range of the shots from the small saucer diminishes until the saucer fires extremely accurately. Once the screen has been cleared of all asteroids and flying saucers, a new set of large asteroids appears, thus starting the next level. The game gets harder as the number of asteroids increases until after the score reaches a range between 40,000 and 60,000. The player starts with 3-5 lives upon game start and gains an extra life per 10,000 points. When the player loses all their lives, the game ends. Machine "turns over" at 99,990 points, which is the maximum high score that can be achieved.

"Asteroids" contains several bugs. The game slows down as the player gains 50-100 lives, due to a programming error in that there is no limit for the permitted number of lives. The player can "lose" the game after more than 250 lives are collected.
"Asteroids" was conceived by Lyle Rains and programmed by Ed Logg with collaborations from other Atari staff. Logg was impressed with the Atari Video Computer System (later called the Atari 2600), and joined Atari's coin-op division and worked on "Dirt Bike", which was never released due to an unsuccessful field test. Paul Mancuso joined the development team as "Asteroids" technician and engineer Howard Delman contributed to the hardware. During a meeting in April 1979, Rains discussed "Planet Grab", a multiplayer arcade game later renamed to "Cosmos". Logg did not know the name of the game, thinking "Computer Space" as "the inspiration for the two-dimensional approach". Rains conceived of "Asteroids" as a mixture of "Computer Space" and "Space Invaders", combining the two-dimensional approach of "Computer Space" with "Space Invaders" addictive gameplay of "completion" and "eliminate all threats". The unfinished game featured a giant, indestructible asteroid, so Rains asked Logg: "Well, why don’t we have a game where you shoot the rocks and blow them up?" In response, Logg described a similar concept where the player selectively shoots at rocks that break into smaller pieces. Both agreed on the concept.

"Asteroids" was implemented on hardware developed by Delman and is a vector game, in which the graphics are composed of lines drawn on a vector monitor. Rains initially wanted the game done in raster graphics, but Logg, experienced in vector graphics, suggested an XY monitor because the high image quality would permit precise aiming. The hardware is chiefly a MOS 6502 executing the game program, and QuadraScan, a high-resolution vector graphics processor developed by Atari and referred to as an "XY display system" and the "Digital Vector Generator (DVG)".

The original design concepts for QuadraScan came out of Cyan Engineering, Atari's off-campus research lab in Grass Valley, California, in 1978. Cyan gave it to Delman, who finished the design and first used it for "Lunar Lander". Logg received Delman's modified board with five buttons, 13 sound effects, and additional RAM, and used it to develop "Asteroids". The size of the board was 4 by 4 inches, and it was "linked up" to a monitor.

Logg modeled the player's ship, the five-button control scheme, and the game physics after "Spacewar!", which he had played as a student at the University of California, Berkeley, but made several changes to improve playability. The ship was programmed into the hardware and rendered by the monitor, and was configured to move with thrust and inertia. The hyperspace button was not placed near Logg's right thumb, which he was dissatisfied with, as he had a problem "tak[ing] his hand off the thrust button". Drawings of asteroids in various shapes were incorporated into the game. Logg copied the idea of a high score table with initials from Exidy's "Star Fire".

The two saucers were formulated to be different from each other. A steadily decreasing timer that shortens intervals between saucer attacks was employed to keep the player from not shooting asteroids and saucers. The minimalist soundtrack features a "heartbeat" sound effect, which quickens as the game progresses. The game did not have a sound chip, so Delman created a hardware circuit for 13 sound effects by hand which was wired onto the board.

A prototype of "Asteroids" was well received by several Atari staff and engineers, who would "wander between labs, passing comment and 
stopping to play as they went". Logg was often asked when he would be leaving by employees eager to play the prototype, so he created a second prototype specifically for staff to play. Atari went to Sacramento, California for testing, setting up prototypes of the game in local arcades to measure its potential success. The company also observed veteran players and younger players during focus group sessions at Atari itself. A group of old players familiar with "Spacewar!" struggled to maintain grip on the thrust button and requested a joystick, whereas younger players accustomed to "Space Invaders" noted they get no break in the game. Logg and other Atari engineers observed proceedings and documented comments in four pages.
"Asteroids" was released for the Atari 2600 and Atari 8-bit family in 1981 and Atari 7800 in 1986. Released in 1981, the 2600 port was the first game to use bank switching, a technique developed by Carl Nielsen's group of engineers that increased available ROM space from 4 KB to 8 KB. Brad Stewart, the programmer tasked to work on the port, used bank switching to complete the game. A port for the Atari 5200, identical to the Atari 8-bit computer version, was in development in 1982, but was not published.

The Atari 7800 version was a launch title and features co-operative play. The asteroids receive colorful textures, and the "heartbeat" sound effect remains intact. 

A technical demo of "Asteroids" was developed by iThink for the Atari Jaguar but it was never released, though a prototype exists in the hands of video game collector Richard Turner, owner of the JustClaws website who demonstrated it during E-JagFest 2000. It's also referred to unofficially as "Asteroids 2000". In 2017, a ROM image of the prototype was released online.

"Asteroids" was immediately successful upon release. It displaced "Space Invaders" by popularity in the United States and became Atari's best selling arcade game of all time, with over 70,000 units sold. Atari earned an estimated $150 million in sales from the game, and arcade operators earned a further $500 million from coin drops. Atari had been in the process of manufacturing another vector game, "Lunar Lander", but demand for "Asteroids" was so high "that several hundred "Asteroids" games were shipped in "Lunar Lander" cabinets". "Asteroids" was so popular that some video arcade operators had to install large boxes to hold the number of coins spent by players.

"Asteroids" received positive reviews from video game critics and has been regarded as Logg's magnum opus. William Cassidy, writing for GameSpy's "Classic Gaming", noticed its innovations, including being one of the first video games to track initials and allow players to enter their initials for appearing in the top 10 high scores, and commented, "the vector graphics fit the futuristic outer space theme very well." In 1996, "Next Generation" listed it as number 39 on their "Top 100 Games of All Time", particularly lauding the control dynamics which require "the constant juggling of speed, positioning, and direction." "Asteroids" was ranked fourth on "Retro Gamer"s list of "Top 25 Arcade Games"; the "Retro Gamer" staff cited its simplicity and the lack of a proper ending as allowances of revisiting the game. In 2012, "Asteroids" was listed on Time's All-TIME 100 greatest video games list. "Entertainment Weekly" named "Asteroids" one of the top ten games for the Atari 2600 in 2013. It was added to the Museum of Modern Art's collection of video games. By contrast, in March 1983 the Atari 8-bit port won sixth place in "Softline"s Dog of the Year awards "for badness in computer games", Atari division, based on reader submissions.

Richard A. Edwards reviewed the 1981 "Asteroids" home cartridge in "The Space Gamer" No. 46. Edwards commented that "This home cartridge is a virtual duplicate of the ever-popular Atari arcade game. [...] If blasting asteroids is the thing you want to do then this is the game, but at this price I can't wholeheartedly recommend it."

Usage of the names of "Saturday Night Live" characters "Mr. Bill" and "Sluggo" to refer to the saucers in an "Esquire" article about the game led to Logg receiving a cease and desist letter from a lawyer with the "Mr. Bill Trademark."

Released in 1981, "Asteroids Deluxe" is the first sequel to "Asteroids". Dave Shepperd edited the code and made enhancements to the game without Logg's involvement. The onscreen objects were tinted blue, and hyperspace was replaced by a shield that depleted if used. The asteroids rotate, and the added "killer satellite" enemy breaks apart into smaller ships when hit that home in on the player's position. The arcade machine's monitor displays vector graphics overlaying a holographic backdrop. The game is much more difficult than the original and enables saucers to shoot across the screen boundary, eliminating a common strategy for high scores in the original game.

It was followed by Owen Rubin's "Space Duel" in 1982, featuring colorful geometric shapes and co-op multiplayer gameplay.

In 1987's "Blasteroids", Ed Rotberg added "power-ups, ship morphing, branching levels, bosses, and the ability to dock your ships in multiplayer for added firepower". "Blasteroids" uses raster graphics instead of vectors.

The game was included as part of the Atari Lynx title "Super Asteroids & Missile Command", and featured in the original "Microsoft Arcade" compilation in 1993, the latter with four other Atari video games: "Missile Command", "Tempest", "Centipede", and "Battlezone".

Activision made an enhanced version of "Asteroids" for PlayStation, Nintendo 64, Microsoft Windows, and the Game Boy Color in 1998. Doug Perry, writing for entertainment and video game journalism website IGN, praised the high-end graphics – with realistic space object models, backgrounds, and special effects – for making "Asteroids" "a pleasure to look at" while being a homage to the original arcade version. The Atari Flashback series of dedicated video game consoles have included both the 2600 and the arcade versions of "Asteroids".

Published by Crave Entertainment on December 14, 1999, "Asteroids Hyper 64" is the Nintendo 64 port of "Asteroids". The game's graphics were upgraded to 3D, with both the ship and asteroids receiving polygon models along static backgrounds, and it was supplemented with weapons and a multiplayer mode. IGN writer Matt Casamassina was pleased that the gameplay was faithful to the original but felt the minor additions and constant "repetition" was not enough to make the port "warrant a $50 purchase". He was disappointed about the lack of music and found the sound effects to be of poor quality.

In 2001, Infogrames released "Atari Anniversary Edition" for the Sega Dreamcast, PlayStation, and PC compatibles. Developed by Digital Eclipse, it included emulated versions of Asteroids and other old Atari games. Jeff Gerstmann of GameSpot criticized the Dreamcast version for its limitations, such as the presentation of vector graphics on a low resolution television set, which obscures the copyright text in "Asteroids". The arcade and Atari 2600 versions of "Asteroids", along with "Asteroids Deluxe", were included in "Atari Anthology" for both Xbox and PlayStation 2.

Released on November 28, 2007, the Xbox Live Arcade port of "Asteroids" has revamped HD graphics along with an added intense "throttle monkey" mode. Both "Asteroids" in its arcade and 2600 versions and "Asteroids Deluxe" were ported to Microsofts "Game Room" download service in 2010. Glu Mobile released a mobile phone port of the game with supplementary features as well as the original arcade version.

"Asteroids" was included on "Atari Greatest Hits Volume 1" for the Nintendo DS. Craig Harris, writing for IGN, noted that the Nintendo DS's small screen can not properly display details of games with vector graphics.

"Asteroids" inspired many direct clones." By December 1981 "BYTE" observed that "If imitation is the sincerest form of flattery, then [Atari's "Asteroids" has] a lot to be proud of ... Its popularity has inspired numerous imitations", including eight for personal computers. Quality Software's "Asteroids in Space" (1980) was one of the best selling games for the Apple II and was voted one of the most popular software titles of 1978-80 by "Softalk" magazine. Others clones include Acornsoft's "Meteors", "Moons of Jupiter" for the VIC-20, "MineStorm" for the Vectrex, and "Apple-Oids" is a 1980 clone for the Apple II, with asteroids in the shape of apples.

The Mattel Intellivision title "Meteor!" , an "Asteroids" clone, was cancelled to avoid a lawsuit, and was reworked as "Astrosmash". The resultant game borrows elements from "Asteroids" and "Space Invaders".

The saucer in the original game design was supposed to take a shot as soon as it appeared. This action was altered so there would be a delay before the saucer shoots. Additionally, the saucers can only aim at the player's ship on-screen, but are not capable of aiming across a screen boundary. In response to both of these behaviors, some players adopted a strategy referred to as "lurking", in which the player keeps the ship on the opposite side of the screen from the saucer when it appears, easily moving across the boundary if necessary. By keeping just one or two rocks in play, the player can shoot across the boundary and quickly destroy saucers to accumulate points indefinitely on a single credit, with little risk of being destroyed. Arcade operators began to complain about losing revenue due to this exploit. In response, Atari issued a patched EPROM to attempt to correct the issue, and due to the impact of this exploit, Atari and other companies changed their development and testing policies to try to prevent future games from having such exploits.

On February 6, 1982, Leo Daniels of Carolina Beach, North Carolina, set a world record score of 40,101,910 points. On November 13 of the same year, 15-year-old Scott Safran of Cherry Hill, New Jersey, set a new record at 41,336,440 points. In 1998, to congratulate Safran on his accomplishment, the Twin Galaxies Intergalactic Scoreboard searched for him for four years until 2002, when it was discovered that he had died in an accident in 1989. In a ceremony in Philadelphia on April 27, 2002, Walter Day of Twin Galaxies presented an award to the surviving members of Safran's family, commemorating his achievement. On April 5, 2010, John McAllister broke Safran's record with a high score of 41,838,740 in a 58-hour Internet livestream.



Category:1979 video games
Category:Arcade games
Category:Atari 2600 games
Category:Atari 7800 games
Category:Atari 8-bit family games
Category:Atari arcade games
Category:Atari Lynx games
Category:Cancelled Atari 5200 games
Category:Cancelled Atari Jaguar games
Category:Ed Logg games
Category:Game Boy Color games
Category:Multidirectional shooters
Category:Multiplayer and single-player video games
Category:Science fiction video games
Category:Xbox 360 games
Category:Xbox 360 Live Arcade games
Category:Vector arcade games
Category:Video games developed in the United StatesAsparagales

Asparagales (asparagoid lilies) is an order of plants in modern classification systems such as the Angiosperm Phylogeny Group (APG) and the Angiosperm Phylogeny Web. The order takes its name from the type family Asparagaceae and is placed in the monocots amongst the lilioid monocots. The order has only recently been recognized in classification systems. It was first put forward by Huber in 1977 and later taken up in the Dahlgren system of 1985 and then the APG in 1998, 2003 and 2009. Before this, many of its families were assigned to the old order Liliales, a very large order containing almost all monocots with colourful tepals and lacking starch in their endosperm. DNA sequence analysis indicated that many of the taxa previously included in Liliales should actually be redistributed over three orders, Liliales, Asparagales and Dioscoreales. The boundaries of the Asparagales and of its families have undergone a series of changes in recent years; future research may lead to further changes and ultimately greater stability. In the APG circumscription, Asparagales is the largest order of monocots with 14 families, 1,122 genera, and about 36,000 species.

The order is clearly circumscribed on the basis of molecular phylogenetics, but is difficult to define morphologically, since its members are structurally diverse. Most species of Asparagales are herbaceous perennials, although some are climbers and some are tree-like. The order also contains many geophytes (bulbs, corms and various kinds of tuber). According to telomere sequence, at least two evolutionary switch-points happened within the order. Basal sequence is formed by TTTAGGG like in majority of higher plants. Basal motif was changed to vertebrate-like TTAGGG and finally the most divergent motif CTCGGTTATGGG appears in "Allium". One of the defining characteristics (synapomorphies) of the order is the presence of phytomelanin, a black pigment present in the seed coat, creating a dark crust. Phytomelanin is found in most families of the Asparagales (although not in Orchidaceae, thought to be a sister to the rest of the group).

The leaves of almost all species form a tight rosette, either at the base of the plant or at the end of the stem, but occasionally along the stem. The flowers are not particularly distinctive, being 'lily type', with six tepals and up to six stamina.

The order is thought to have first diverged from other related monocots some 120–130 million years ago (early in the Cretaceous period), although given the difficulty in classifying the families involved, estimates are likely to be uncertain.

From an economic point of view, the order Asparagales is second in importance within the monocots to the order Poales (which includes grasses and cereals). Species are used as food and flavourings (e.g. onion, garlic, leek, asparagus, vanilla), as cut flowers (e.g. freesia, gladiolus, iris, orchids), and as garden ornamentals (e.g. day lilies, lily of the valley, "Agapanthus

Thus although most species in the order are herbaceous, some no more than 15 cm high, there are a number of climbers ("e.g.", some species of "Asparagus"), as well as several genera forming trees (e.g. "Agave", "Cordyline", "Yucca", "Dracaena", "Aloe" ), which can exceed 10 m in height. Succulent genera occur in several families (e.g. "Aloe").

Almost all species have a tight cluster of leaves (a rosette), either at the base of the plant or at the end of a more-or-less woody stem as with "Yucca". In some cases the leaves are produced along the stem. The flowers are in the main not particularly distinctive, being of a general 'lily type', with six tepals, either free or fused from the base and up to six stamina. They are frequently clustered at the end of the plant stem.

The Asparagales are generally distinguished from the Liliales by the lack of markings on the tepals, the presence of septal nectaries in the ovaries, rather than the bases of the tepals or stamen filaments, and the presence of secondary growth. They are generally geophytes, but with linear leaves, and a lack of fine reticular venation.

The seeds characteristically have the external epidermis either obliterated (in most species bearing fleshy fruit), or if present, have a layer of black carbonaceous phytomelanin in species with dry fruits (nuts). The inner part of the seed coat is generally collapsed, in contrast to Liliales whose seeds have a well developed outer epidermis, lack phytomelanin, and usually display a cellular inner layer.

The orders which have been separated from the old Liliales are difficult to characterize. No single morphological character appears to be diagnostic of the order Asparagales.

As circumscribed within the Angiosperm Phylogeny Group system Asparagales is the largest order within the monocotyledons, with 14 families, 1,122 genera and about 25,000–42,000 species, thus accounting for about 50% of all monocots and 10–15% of the flowering plants (angiosperms). The attribution of botanical authority for the name Asparagales belongs to Johann Heinrich Friedrich Link (1767 – 1851) who coined the word 'Asparaginae' in 1829 for a higher order taxon that included "Asparagus" although Adanson and Jussieau had also done so earlier (see History). Earlier circumscriptions of Asparagales attributed the name to Bromhead (1838), who had been the first to use the term 'Asparagales'.

The type genus, "Asparagus", from which the name of the order is derived, was described by Carl Linnaeus in 1753, with ten species. He placed "Asparagus" within the "Hexandria Monogynia" (six stamens, one carpel) in his sexual classification in the "Species Plantarum". The majority of taxa now considered to constitute Asparagales have historically been placed within the very large and diverse family, Liliaceae. The Liliaceae family was first described by Michel Adanson in 1763, and in his taxonomic scheme he created eight sections within it, including the Asparagi with "Asparagus" and three other genera. The system of organising genera into families is generally credited to Antoine Laurent de Jussieu who formally described both the Liliaceae and the type family of Asparagales, the Asparagaceae, as Lilia and Asparagi, respectively, in 1789. Jussieu established the hierarchical system of taxonomy (phylogeny), placing "Asparagus" and related genera within a division of Monocotyledons, a class (III) of "Stamina Perigynia" and 'order' Asparagi, divided into three subfamilies. The use of the term "Ordo" (order) at that time was closer to what we now understand as Family, rather than Order. In creating his scheme he used a modified form of Linnaeus' sexual classification but using the respective topography of stamens to carpels rather than just their numbers. While De Jussieu's "Stamina Perigynia" also included a number of 'orders' that would eventually form families within the Asparagales such as the Asphodeli (Asphodelaceae), Narcissi (Amaryllidaceae) and Irides (Iridaceae), the remainder are now allocated to other orders. Jussieu's Asparagi soon came to be referred to as "Asparagacées" in the French literature (Latin: Asparagaceae). Meanwhile, the 'Narcissi' had been renamed as the 'Amaryllidées' (Amaryllideae) in 1805, by Jean Henri Jaume Saint-Hilaire, using "Amaryllis" as the type species rather than "Narcissus", and thus has the authority attribution for Amaryllidaceae. In 1810 Brown proposed that a subgroup of Liliaceae be distinguished on the basis of the position of the ovaries and be referred to as Amaryllideae and in 1813 de Candolle described Liliacées Juss. and Amaryllidées Brown as two quite separate families.

The literature on the organisation of genera into families and higher ranks became available in the English language with Samuel Frederick Gray
The circumscription of Asparagales has been a source of difficulty for many botanists from the time of John Lindley (1846), the other important British taxonomist of the early nineteenth century. In his first taxonomic work, "An Introduction to the Natural System of Botany" (1830) he partly followed Jussieu by describing a subclass he called Endogenae, or Monocotyledonous Plants (preserving de Candolle's "Endogenæ phanerogamæ") divided into two tribes, the Petaloidea and Glumaceae. He divided the former, often referred to as petaloid monocots, into 32 orders, including the Liliaceae (defined narrowly), but also most of the families considered to make up the Asparagales today, including the Amaryllideae.

By 1846, in his final scheme Lindley had greatly expanded and refined the treatment of the monocots, introducing both an intermediate ranking (Alliances) and tribes within orders ("i.e." families). Lindley placed the Liliaceae within the Liliales, but saw it as a paraphyletic ("catch-all") family, being all Liliales not included in the other orders, but hoped that the future would reveal some characteristic that would group them better. The order Liliales was very large and had become a used to include almost all monocotyledons with colourful tepals and without starch in their endosperm (the lilioid monocots). The Liliales was difficult to divide into families because morphological characters were not present in patterns that clearly demarcated groups. This kept the Liliaceae separate from the Amaryllidaceae (Narcissales). Of these Liliaceae was divided into eleven tribes (with 133 genera) and Amaryllidaceae into four tribes (with 68 genera), yet both contained many genera that would eventually segregate to each other's contemporary orders (Liliales and Asparagales respectively). The Liliaceae would be reduced to a small 'core' represented by the Tulipae tribe, while large groups such Scilleae and Asparagae would become part of Asparagales either as part of the Amaryllidaceae or as separate families. While of the Amaryllidaceae, the Agaveae would be part of Asparagaceae but the Alstroemeriae would become a family within the Liliales.

The number of known genera (and species) continued to grow and by the time of the next major British classification, that of Bentham and Hooker in 1883 (published in Latin) several of Lindley's other families had been absorbed into the Liliaceae. They used the term 'series' to indicate suprafamilial rank, with seven series of monocotyledons (including Glumaceae), but did not use Lindley's terms for these. However they did place the Liliaceous and Amaryllidaceous genera into separate series. The Liliaceae were placed in series Coronariae, while the Amaryllideae were placed in series Epigynae. The Liliaceae now consisted of twenty tribes (including Tulipeae, Scilleae and Asparageae), and the Amaryllideae of five (including Agaveae and Alstroemerieae). An important addition to the treatment of the Liliaceae was the recognition of the Allieae as a distinct tribe that would eventually find its way to the Asparagales as the Allioideae subfamily of the Amaryllidaceae.

The appearance of Charles Darwin's Origin of Species in 1859 changed the way that taxonomists considered plant classification, incorporating evolutionary information into their schemata. The Darwinian approach led to the concept of phylogeny (tree-like structure) in assembling classification systems, starting with Eichler. Eichler, having established a hierarchical system in which the flowering plants (angiosperms) were divided into monocotyledons and dicotyledons, further divided into former into seven orders. Within the Liliiflorae were seven families, including Liliaceae and Amaryllidaceae. Liliaceae included "Allium" and "Ornithogalum" (modern Allioideae) and "Asparagus".

Engler, in his system developed Eichler's ideas into a much more elaborate scheme which he treated in a number of works including "Die Natürlichen Pflanzenfamilien" (Engler and Prantl 1888) and "Syllabus der Pflanzenfamilien" (1892–1924). In his treatment of Liliiflorae the Liliineae were a suborder which included both Liliaceae and Amaryllidaceae families. The Liliaceae had eight subfamilies and the Amaryllidaceae four. In this rearrangement of Liliaceae, with fewer subdivisions, the core Liliales were represented as subfamily Lilioideae (with Tulipae and Scilleae as tribes), the Asparagae were represented as Asparagoideae and the Allioideae was preserved, representing the alliaceous genera. Allieae, Agapantheae and Gilliesieae were the three tribes within this subfamily. In the Amaryllidacea, there was little change from Bentham and Hooker. A similar approach was adopted by Wettstein the twentieth century the Wettstein system (1901–1935) placed many of the taxa in an order called 'Liliiflorae'. Next Johannes Paulus Lotsy (1911) proposed dividing the Liliiflorae into a number of smaller families including Asparagaceae. Then Herbert Huber (1969, 1977), following Lotsy's example, proposed that the Liliiflorae be split into four groups including the 'Asparagoid' Liliiflorae.
The widely used Cronquist system (1968–1988) used the very broadly defined order Liliales.

These various proposals to separate small groups of genera into more homogeneous families made little impact till that of Dahlgren (1985) incorporating new information including synapomorphy. Dahlgren developed Huber's ideas further and popularised them, with a major deconstruction of existing families into smaller units. They created a new order, calling it Asparagales. This was one of five orders within the superorder Liliiflorae. Where Cronquist saw one family, Dahlgren saw forty distributed over three orders (predominantly Liliales and Asparagales).
Over the 1980s, in the context of a more general review of the classification of angiosperms, the Liliaceae were subjected to more intense scrutiny. By the end of that decade, the Royal Botanic Gardens at Kew, the British Museum of Natural History and the Edinburgh Botanical Gardens formed a committee to examine the possibility of separating the family at least for the organization of their herbaria. That committee finally recommended that 24 new families be created in the place of the original broad Liliaceae, largely by elevating subfamilies to the rank of separate families.

The order Asparagales as currently circumscribed has only recently been recognized in classification systems, through the advent of phylogenetics. The 1990s saw considerable progress in plant phylogeny and phylogenetic theory, enabling a phylogenetic tree to be constructed for all of the flowering plants. The establishment of major new clades necessitated a departure from the older but widely used classifications such as Cronquist and Thorne based largely on morphology rather than genetic data. This complicated discussion about plant evolution and necessitated a major restructuring. "rbc"L gene sequencing and cladistic analysis of monocots had redefined the Liliales in 1995. from four morphological orders "sensu" Dahlgren. The largest clade representing the Liliaceae, all previously included in Liliales, but including both the Calochortaceae and Liliaceae "sensu" Tamura. This redefined family, that became referred to as core Liliales, but corresponded to the emerging circumscription of the Angiosperm Phylogeny Group (1998).

The 2009 revision of the Angiosperm Phylogeny Group system, APG III, places the order in the clade monocots.

From the Dahlgren system of 1985 onwards, studies based mainly on morphology had identified the Asparagales as a distinct group, but had also included groups now located in Liliales, Pandanales and Zingiberales. Research in the 21st century has supported the monophyly of Asparagales, based on morphology, 18S rDNA, and other DNA sequences, although some phylogenetic reconstructions based on molecular data have suggested that Asparagales may be paraphyletic, with Orchidaceae separated from the rest. Within the monocots, Asparagales is the sister group of the commelinid clade.

This cladogram shows the placement of Asparagales within the orders of Lilianae "sensu" Chase & Reveal (monocots) based on molecular phylogenetic evidence. The lilioid monocot orders are bracketed, namely Petrosaviales, Dioscoreales, Pandanales, Liliales and Asparagales. These constitute a paraphyletic assemblage, that is groups with a common ancestor that do not include all direct descendants (in this case commelinids as the sister group to Asparagales); to form a clade, all the groups joined by thick lines would need to be included. While Acorales and Alismatales have been collectively referred to as "alismatid monocots" (basal or early branching monocots), the remaining clades (lilioid and commelinid, that is diverging in succession from the line that leads to the commelinids. Numbers indicate crown group (most recent common ancestor of the sampled species of the clade of interest) divergence times in mya (million years ago).

A phylogenetic tree for the Asparagales, generally to family level, but including groups which were recently and widely treated as families but which are now reduced to subfamily rank, is shown below.

The tree shown above can be divided into a basal paraphyletic group, the 'lower Asparagales (asparagoids)', from Orchidaceae to Asphodelaceae, and a well-supported monophyletic group of 'core Asparagales' (higher asparagoids), comprising the two largest families, Amaryllidaceae "sensu lato" and Asparagaceae "sensu lato".

Two differences between these two groups (although with exceptions) are: the mode of microsporogenesis and the position of the ovary. The 'lower Asparagales' typically have simultaneous microsporogenesis (i.e. cell walls develop only after both meiotic divisions), which appears to be an apomorphy within the monocots, whereas the 'core Asparagales' have reverted to successive microsporogenesis (i.e. cell walls develop after each division). The 'lower Asparagales' typically have an inferior ovary, whereas the 'core Asparagales' have reverted to a superior ovary. A 2002 morphological study by Rudall treated possessing an inferior ovary as a synapomorphy of the Asparagales, stating that reversions to a superior ovary in the 'core Asparagales' could be associated with the presence of nectaries below the ovaries. However, Stevens notes that superior ovaries are distributed among the 'lower Asparagales' in such a way that it is not clear where to place the evolution of different ovary morphologies. The position of the ovary seems a much more flexible character (here and in other angiosperms) than previously thought.

The APG III system when it was published in 2009, greatly expanded the families Xanthorrhoeaceae, Amaryllidaceae, and Asparagaceae. Thirteen of the families of the earlier APG II system were thereby reduced to subfamilies within these three families. The expanded Xanthorrhoeaceae is now called "Asphodelaceae". The APG II families (left) and their equivalent APG III subfamilies (right) are as follows:

Orchidaceae is the largest family of all angiosperms and hence by far the largest in the order. The Dahlgren system recognized three families of orchids, but DNA sequence analysis later showed that these families are polyphyletic and so should be combined. Several studies suggest (with high bootstrap support) that Orchidaceae is the sister of the rest of the Asparagales. Other studies have placed the orchids differently in the phylogenetic tree, generally among the Boryaceae-Hypoxidaceae clade. The position of Orchidaceae shown above seems the best current hypothesis, but cannot be taken as confirmed.

Orchids have simultaneous microsporogenesis and inferior ovaries, two characters that are typical of the 'lower Asparagales'. However, their nectaries are rarely in the septa of the ovaries, and most orchids have dust-like seeds, atypical of the rest of the order. (Some members of Vanilloideae and Cypripedioideae have crustose seeds, probably associated with dispersal by birds and mammals that are attracted by fermenting fleshy fruit releasing fragrant compounds, e.g. vanilla.)

In terms of the number of species, Orchidaceae diversification is remarkable. However, although the other Asparagales may be less rich in species, they are more variable morphologically, including tree-like forms.

The four families excluding Boryaceae form a well-supported clade in studies based on DNA sequence analysis. All four contain relatively few species, and it has been suggested that they be combined into one family under the name Hypoxidaceae "sensu lato". The relationship between Boryaceae (which includes only two genera, "Borya" and "Alania"), and other Asparagales has remained unclear for a long time. The Boryaceae are mycorrhizal, but not in the same way as orchids. Morphological studies have suggested a close relationship between Boryaceae and Blandfordiaceae. There is relatively low support for the position of Boryaceae in the tree shown above.

The relationship shown between Ixioliriaceae and Tecophilaeaceae is still unclear. Some studies have supported a clade of these two families, others have not. The position of Doryanthaceae has also varied, with support for the position shown above, but also support for other positions.

The clade from Iridaceae upwards appears to have stronger support. All have some genetic characteristics in common, having lost Arabidopsis-type telomeres. Iridaceae is distinctive among the Asparagales in the unique structure of the inflorescence (a rhipidium), the combination of an inferior ovary and three stamens, and the common occurrence of unifacial leaves whereas bifacial leaves are the norm in other Asparagales.

Members of the clade from Iridaceae upwards have infra-locular septal nectaries, which Rudall interpreted as a driver towards secondarily superior ovaries.

The next node in the tree (Xanthorrhoeaceae "sensu lato" + the 'core Asparagales') has strong support. 'Anomalous' secondary thickening occurs among this clade, e.g. in "Xanthorrhoea" (family Asphodelaceae) and "Dracaena" (family Asparagaceae "sensu lato"), with species reaching tree-like proportions.

The 'core Asparagales', comprising Amaryllidaceae "sensu lato" and Asparagaceae "sensu lato", are a strongly supported clade, as are clades for each of the families. Relationships within these broadly defined families appear less clear, particularly within the Asparagaceae "sensu lato". Stevens notes that most of its subfamilies are difficult to recognize, and that significantly different divisions have been used in the past, so that the use of a broadly defined family to refer to the entire clade is justified. Thus the relationships among subfamilies shown above, based on APWeb , is somewhat uncertain.

Several studies have attempted to date the evolution of the Asparagales, based on phylogenetic evidence. Earlier studies generally give younger dates than more recent studies, which have been preferred in the table below.

A 2009 study suggests that the Asparagales have the highest diversification rate in the monocots, about the same as the order Poales, although in both orders the rate is little over half that of the eudicot order Lamiales, the clade with the highest rate.

The taxonomic diversity of the monocotyledons is described in detail by Kubitzki. Up-to-date information on the Asparagales can be found on the Angiosperm Phylogeny Website.

The APG III system's family circumscriptions are being used as the basis of the Kew-hosted "World Checklist of Selected Plant Families". With this circumscription, the order consists of 14 families (Dahlgren had 31) with approximately 1120 genera and 26000 species.

Order Asparagales 

The earlier 2003 version, APG II, allowed 'bracketed' families, i.e. families which could either be segregated from more comprehensive families or could be included in them. These are the families given under "including" in the list above. APG III does not allow bracketed families, requiring the use of the more comprehensive family; otherwise the circumscription of the Asparagales is unchanged. A separate paper accompanying the publication of the 2009 APG III system provided subfamilies to accommodate the families which were discontinued. The first APG system of 1998 contained some extra families, included in square brackets in the list above.

Two older systems which use the order Asparagales are the Dahlgren system and the Kubitzki system. The families included in the circumscriptions of the order in these two systems are shown in the first and second columns of the table below. The equivalent family in the modern APG III system (see below) is shown in the third column. Note that although these systems may use the same name for a family, the genera which it includes may be different, so the equivalence between systems is only approximate in some cases.

The Asparagales include many important crop plants and ornamental plants. Crops include Allium, Asparagus and Vanilla, while ornamentals include irises, hyacinths and orchids
Category:Angiosperm orders
Category:Extant Late Cretaceous first appearances

The Alismatales (alismatids) are an order of flowering plants including about 4500 species. Plants assigned to this order are mostly tropical or aquatic. Some grow in fresh water, some in marine habitats.

The Alismatales comprise herbaceous flowering plants of aquatic and marshy habitats, and the only monocots known to have green embryos other than the Amaryllidaceae. They also include the only marine angiosperms growing completely submerged, the seagrasses. The flowers are usually arranged in inflorescences, and the mature seeds lack endosperm.

Both marine and freshwater forms include those with staminate flowers that detach from the parent plant and float to the surface where they become pollinated. In others, pollination occurs underwater, where pollen may form elongated strands, increasing chance of success. Most aquatic species have a totally submerged juvenile phase, and flowers are either floating or emergent. Vegetation may be totally submersed, have floating leaves, or protrude from the water. Collectively, they are commonly known as "water plantain".

The Alismatales contain about 165 genera in 13 families, with a cosmopolitan distribution. Phylogenetically, they are basal monocots, diverging early in evolution relative to the lilioid and commelinid monocot lineages. Together with the Acorales, the Alismatales are referred to informally as the alismatid monocots.

The Cronquist system (1981) places the Alismatales in subclass Alismatidae, class Liliopsida [= monocotyledons] and includes only three families as shown:
Cronquist's subclass Alismatidae conformed fairly closely to the order Alismatales as defined by APG, minus the Araceae.

The Dahlgren system places the Alismatales in the superorder Alismatanae in the subclass Liliidae [= monocotyledons] in the class Magnoliopsida [= angiosperms] with the following families included:

In Tahktajan's classification (1997), the order Alismatales contains only the Alismataceae and Limnocharitaceae, making it equivalent to the Alismataceae as revised in APG-III. Other families included in the Alismatates as currently defined are here distributed among 10 additional orders, all of which are assigned, with the following exception, to the Subclass Alismatidae. Araceae in Tahktajan 1997 is assigned to the Arales and placed in the Subclass Aridae; Tofieldiaceae to the Melanthiales and placed in the Liliidae.

The Angiosperm Phylogeny Group system (APG) of 1998 and APG II (2003) assigned the Alismatales to the monocots, which may be thought of as an unranked clade containing the families listed below. The biggest departure from earlier systems (see below) is the inclusion of family Araceae. By its inclusion, the order has grown enormously in number of species. The family Araceae alone accounts for about a hundred genera, totaling over two thousand species. The rest of the families together contain only about five hundred species, many of which are in very small families.

The APG III system (2009) differs only in that the Limnocharitaceae are combined with the Alismataceae; it was also suggested that the genus "Maundia" (of the Juncaginaceae) could be separated into a monogeneric family, the Maundiaceae, but the authors noted that more study was necessary before the Maundiaceae could be recognized.


In APG IV (2016), it was decided that evidence was sufficient to elevate "Maundia" to family level as the monogeneric Maundiaceae. The authors considered including a number of the smaller orders within the Juncaginaceae, but an online survey of botanists and other users found little support for this "lumping" approach. Consequently, the family structure for APG IV is:


Cladogram showing the orders of monocots (Lilianae "sensu
Category:Angiosperm ordersApiales

The Apiales are an order of flowering plants. The families are those recognized in the APG III system. This is typical of the newer classifications, though there is some slight variation and in particular, the Torriceliaceae may be divided.

Under this definition, well-known members include carrots, celery, parsley, and "Hedera helix" (English ivy).

The order Apiales is placed within the asterid group of eudicots as circumscribed by the APG III system. Within the asterids, Apiales belongs to an unranked group called the campanulids, and within the campanulids, it belongs to a clade known in phylogenetic nomenclature as Apiidae. In 2010, a subclade of Apiidae named Dipsapiidae was defined to consist of the three orders: Apiales, Paracryphiales, and Dipsacales.

Under the Cronquist system, only the Apiaceae and Araliaceae were included here, and the restricted order was placed among the rosids rather than the asterids. The Pittosporaceae were placed within the Rosales, and many of the other forms within the family Cornaceae. "Pennantia" was in the family Icacinaceae. In the classification system of Dahlgren the Apiaceae and Araliaceae families were placed in the order Ariales, in the superorder Araliiflorae (also called Aralianae).

The present understanding of the Apiales is fairly recent and is based upon comparison of DNA sequences by phylogenetic methods. The circumscriptions of some of the families have changed. In 2009, one of the subfamilies of Araliaceae was shown to be polyphyletic.

The largest and obviously closely related families of Apiales are Araliaceae, Myodocarpaceae and
Apiaceae, which resemble each other in the structure of their gynoecia. In this respect however, the Pittosporaceae is notably distinct from them.

Typical syncarpous gynoecia exhibit four vertical zones, determined by the extent of fusion of the carpels. In most plants the synascidiate (i.e. "united bottle-shaped") and symplicate zones are fertile and bear the ovules. Each of the first three families possess mainly bi- or multilocular ovaries in a gynoecium with a long synascidiate, but very short symplicate zone, where the ovules are inserted at their transition, the so-called cross-zone (or "Querzone").

In gynoecia of the Pittosporaceae, the symplicate is much longer than the synascidiate zone, and the ovules are arranged along the first. Members of the latter family consequently have unilocular
Category:Angiosperm orders
Category:Taxa named by Takenoshin NakaiAsterales

Asterales is an order of dicotyledonous flowering plants that includes the large family Asteraceae (or Compositae) known for composite flowers made of florets, and ten families related to the Asteraceae.

The order is a cosmopolite (plants found throughout most of the world including desert and frigid zones), and includes mostly herbaceous species, although a small number of trees (such as the giant Lobelia and the giant Senecio) and shrubs are also present.

Asterales are organisms that seem to have evolved from one common ancestor. Asterales share characteristics on morphological and biochemical levels. Synapomorphies (a character that is shared by two or more groups through evolutionary development) include the presence in the plants of oligosaccharide inulin, a nutrient storage molecule used instead of starch; and unique stamen morphology. The stamens are usually found around the style, either aggregated densely or fused into a tube, probably an adaptation in association with the plunger (brush; or secondary) pollination that is common among the families of the order, wherein pollen is collected and stored on the length of the pistil.

The name and order Asterales is botanically venerable, dating back to at least 1926 in the Hutchinson system of plant taxonomy when it contained only five families, of which only two are retained in the APG III classification. Under the Cronquist system of taxonomic classification of flowering plants, Asteraceae was the only family in the group, but newer systems (such as APG II and APG III) have expanded it to 11. In the classification system of Dahlgren the Asterales were in the superorder Asteriflorae (also called Asteranae).

The order Asterales currently includes 11 families, the largest of which are the Asteraceae, with about 25,000 species, and the Campanulaceae ("bellflowers"), with about 2,000 species. The remaining families count together for less than 1500 species. The two large families are cosmopolitan, with many of their species found in the Northern Hemisphere, and the smaller families are usually confined to Australia and the adjacent areas, or sometimes South America.

Only the Asteraceae have composite flower heads; the other families do not, but share other characteristics such as storage of inulin that define the 11 families as more closely related to each other than to other plant families or orders such as the rosids.

The phylogenetic tree according to APG III for the Campanulid clade is as below.

The core Asterales are Stylidiaceae (six genera), APA clade (Alseuosmiaceae, Phellinaceae and Argophyllaceae, together 7 genera), MGCA clade (Menyanthaceae, Goodeniaceae, Calyceraceae, in total twenty genera), and Asteraceae (about sixteen hundred genera). Other Asterales are Rousseaceae (four genera), Campanulaceae (eighty four genera) and Pentaphragmataceae (one genus).

All Asterales families are represented in the Southern Hemisphere; however, Asteraceae and Campanulaceae are cosmopolitan and Menyanthaceae nearly so.

Although most extant species of Asteraceae are herbaceous, the examination of the basal members in the family suggests that the common ancestor of the family was an arborescent plant, a tree or shrub, perhaps adapted to dry conditions, radiating from South America. Less can be said about the Asterales themselves with certainty, although since several families in Asterales contain trees, the ancestral member is most likely to have been a tree or shrub.

Because all clades are represented in the southern hemisphere but many not in the northern hemisphere, it is natural to conjecture that there is a common southern origin to them. Asterales are angiosperms, flowering plants that appeared about 140 million years ago. The Asterales order probably originated in the Cretaceous (145 – 66 Mya) on the supercontinent Gondwana which broke up from 184 – 80 Mya, forming the area that is now Australia, South America, Africa, India and Antarctica.

Asterales contain about 14% of eudicot diversity. From an analysis of relationships and diversities within the Asterales and with their superorders, estimates of the age of the beginning of the Asterales have been made, which range from 116 Mya to 82Mya. However few fossils have been found, of the Menyanthaceae-Asteraceae clade in the Oligocene, about 29 Mya.

Fossil evidence of the Asterales is rare and belongs to rather recent epochs, so the precise estimation of the order's age is quite difficult. An Oligocene (34 – 23 Mya) pollen is known for Asteraceae and Goodeniaceae, and seeds from Oligocene and Miocene (23 – 5.3 Mya) are known for Menyanthaceae and Campanulaceae respectively.

The Asterales, by dint of being a super-set of the family Asteraceae, include some species grown for food, including the sunflower ("Helianthus annuus"), lettuce ("Lactuca sativa") and chicory ("Cichorium"). Many are also used as spices and traditional medicines.

Asterales are common plants and have many known uses. For example, pyrethrum (derived from Old World members of the genus "Chrysanthemum") is a natural insecticide with minimal environmental impact. Wormwood, derived from a genus that includes the sagebrush, is used as a source of flavoring for absinthe
Category:Angiosperm orders
Asteroids are minor planets, especially of the inner Solar System. Larger asteroids have also been called planetoids. These terms have historically been applied to any astronomical object orbiting the Sun that did not resemble a planet-like disc and was not observed to have characteristics of an active comet such as a tail. As minor planets in the outer Solar System were discovered they were typically found to have volatile-rich surfaces similar to comets. As a result, they were often distinguished from objects found in the main asteroid belt. In this article, the term "asteroid" refers to the minor planets of the inner Solar System including those co-orbital with Jupiter.

There exist millions of asteroids, many thought to be the shattered remnants of planetesimals, bodies within the young Sun's solar nebula that never grew large enough to become planets. The vast majority of known asteroids orbit within the main asteroid belt located between the orbits of Mars and Jupiter, or are co-orbital with Jupiter (the Jupiter trojans). However, other orbital families exist with significant populations, including the near-Earth objects. Individual asteroids are classified by their characteristic spectra, with the majority falling into three main groups: C-type, M-type, and S-type. These were named after and are generally identified with carbon-rich, metallic, and silicate (stony) compositions, respectively. The sizes of asteroids varies greatly; the largest, Ceres, is almost across.

Asteroids are differentiated from comets and meteoroids. In the case of comets, the difference is one of composition: while asteroids are mainly composed of mineral and rock, comets are primarily composed of dust and ice. Furthermore, asteroids formed closer to the sun, preventing the development of cometary ice. The difference between asteroids and meteoroids is mainly one of size: meteoroids have a diameter of one meter or less, whereas asteroids have a diameter of greater than one meter. Finally, meteoroids can be composed of either cometary or asteroidal materials.

Only one asteroid, 4 Vesta, which has a relatively reflective surface, is normally visible to the naked eye, and this only in very dark skies when it is favorably positioned. Rarely, small asteroids passing close to Earth may be visible to the naked eye for a short time. , the Minor Planet Center had data on almost 745,000 objects in the inner and outer Solar System, of which almost 504,000 had enough information to be given numbered designations.

The United Nations declared 30 June as International Asteroid Day to educate the public about asteroids. The date of International Asteroid Day commemorates the anniversary of the Tunguska asteroid impact over Siberia, Russian Federation, on 30 June 1908.

In April 2018, the B612 Foundation reported "It's 100 percent certain we'll be hit [by a devastating asteroid], but we're not 100 percent sure when." Also in 2018, physicist Stephen Hawking,
in his final book "Brief Answers to the Big Questions", considered an asteroid collision to be the biggest threat to the planet. In June 2018, the US National Science and Technology Council warned that America is unprepared for an asteroid impact event, and has developed and released the ""National Near-Earth Object Preparedness Strategy Action Plan"" to better prepare. According to expert testimony in the United States Congress in 2013, NASA

The first asteroid to be discovered, Ceres, was originally considered to be a new planet. This was followed by the discovery of other similar bodies, which, with the equipment of the time, appeared to be points of light, like stars, showing little or no planetary disc, though readily distinguishable from stars due to their apparent motions. This prompted the astronomer Sir William Herschel to propose the term "asteroid", coined in Greek as ἀστεροειδής, or "asteroeidēs", meaning 'star-like, star-shaped', and derived from the Ancient Greek "astēr" 'star, planet'. In the early second half of the nineteenth century, the terms "asteroid" and "planet" (not always qualified as "minor") were still used interchangeably. 

Overview of discovery timeline:

Asteroid discovery methods have dramatically improved over the past two centuries.

In the last years of the 18th century, Baron Franz Xaver von Zach organized a group of 24 astronomers to search the sky for the missing planet predicted at about 2.8 AU from the Sun by the Titius-Bode law, partly because of the discovery, by Sir William Herschel in 1781, of the planet Uranus at the distance predicted by the law. This task required that hand-drawn sky charts be prepared for all stars in the zodiacal
The first object, Ceres, was not discovered by a member of the group, but rather by accident in 1801 by Giuseppe Piazzi, director of the observatory of Palermo in Sicily. He discovered a new star-like object in Taurus and followed the displacement of this object during several nights. Later that year, Carl Friedrich Gauss used these observations to calculate the orbit of this unknown object, which was found to be between the planets Mars and Jupiter. Piazzi named it after Ceres, the Roman goddess of agriculture.

Three other asteroids (2 Pallas, 3 Juno, and 4 Vesta) were discovered over the next few years, with Vesta found in 1807. After eight more years of fruitless searches, most astronomers assumed that there were no more and abandoned any further searches.

However, Karl Ludwig Hencke persisted, and began searching for more asteroids in 1830. Fifteen years later, he found 5 Astraea, the first new asteroid in 38 years. He also found 6 Hebe less than two years later. After this, other astronomers joined in the search and at least one new asteroid was discovered every year after that (except the wartime years 1944 and 1945). Notable asteroid hunters of this early era were J. R. Hind, Annibale de Gasparis, Robert Luther, H. M. S. Goldschmidt, Jean Chacornac, James Ferguson, Norman Robert Pogson, E. W. Tempel, J. C. Watson, C. H. F. Peters, A. Borrelly, J. Palisa, the Henry brothers and Auguste Charlois.

In 1891, Max Wolf pioneered the use of astrophotography to detect asteroids, which appeared as short streaks on long-exposure photographic plates. This dramatically increased the rate of detection compared with earlier visual methods: Wolf alone discovered 248 asteroids, beginning with 323 Brucia, whereas only slightly more than 300 had been discovered up to that point. It was known that there were many more, but most astronomers did not bother with them, calling them "vermin of the skies", a phrase variously attributed to Eduard Suess and Edmund Weiss. Even a century later, only a few thousand asteroids were identified, numbered and named.

Until 1998, asteroids were discovered by a four-step process. First, a region of the sky was photographed by a wide-field telescope, or astrograph. Pairs of photographs were taken, typically one hour apart. Multiple pairs could be taken over a series of days. Second, the two films or plates of the same region were viewed under a stereoscope. Any body in orbit around the Sun would move slightly between the pair of films. Under the stereoscope, the image of the body would seem to float slightly above the background of stars. Third, once a moving body was identified, its location would be measured precisely using a digitizing microscope. The location would be measured relative to known star locations.

These first three steps do not constitute asteroid discovery: the observer has only found an apparition, which gets a provisional designation, made up of the year of discovery, a letter representing the half-month of discovery, and finally a letter and a number indicating the discovery's sequential number (example: ).

The last step of discovery is to send the locations and time of observations to the Minor Planet Center, where computer programs determine whether an apparition ties together earlier apparitions into a single orbit. If so, the object receives a catalogue number and the observer of the first apparition with a calculated orbit is declared the discoverer, and granted the honor of naming the object subject to the approval of the International Astronomical Union

There is increasing interest in identifying asteroids whose orbits cross Earth's, and that could, given enough time, collide with Earth "(see Earth-crosser asteroids)". The three most important groups of near-Earth asteroids are the Apollos, Amors, and Atens. Various asteroid deflection strategies have been proposed, as early as the 1960s.

The near-Earth asteroid 433 Eros had been discovered as long ago as 1898, and the 1930s brought a flurry of similar objects. In order of discovery, these were: 1221 Amor, 1862 Apollo, 2101 Adonis, and finally 69230 Hermes, which approached within 0.005 AU of Earth in 1937. Astronomers began to realize the possibilities of Earth impact.

Two events in later decades increased the alarm: the increasing acceptance of the Alvarez hypothesis that an impact event resulted in the Cretaceous–Paleogene extinction, and the 1994 observation of Comet Shoemaker-Levy 9 crashing into Jupiter. The U.S. military also declassified the information that its military satellites, built to detect nuclear explosions, had detected hundreds of upper-atmosphere impacts by objects ranging from one to ten meters across.

All these considerations helped spur the launch of highly efficient surveys that consist of charge-coupled device (CCD

Traditionally, small bodies orbiting the Sun were classified as comets, asteroids, or meteoroids, with anything smaller than one meter across being called a meteoroid. Beech and Steel's 1995 paper proposed a meteoroid definition including size limits. The term "asteroid", from the Greek word for "star-like", never had a formal definition, with the broader term minor planet being preferred by the International Astronomical Union.

However, following the discovery of asteroids below ten meters in size, Rubin and Grossman's 2010 paper revised the previous definition of meteoroid to objects between 10 µm and 1 meter in size in order to maintain the distinction between asteroids and meteoroids. The smallest asteroids discovered (based on absolute magnitude "H") are with "H" = 33.2 and with "H" = 32.1 both with an estimated size of about 1 meter.

In 2006, the term "small Solar System body" was also introduced to cover both most minor planets and comets. Other languages prefer "planetoid" (Greek for "planet-like"), and this term is occasionally used in English especially for larger minor planets such as the dwarf planets as well as an alternative for asteroids since they are not star-like. The word "planetesimal" has a similar meaning, but refers specifically to the small building blocks of the planets that existed when the Solar System was forming. The term "planetule" was coined by the geologist William Daniel Conybeare to describe minor planets, but is not in common use. The three largest objects in the asteroid belt, Ceres, Pallas, and Vesta, grew to the stage of protoplanets. Ceres is a dwarf planet, the only one in the inner Solar System.

When found, asteroids were seen as a class of objects distinct from comets, and there was no unified term for the two until "small Solar System body" was coined in 2006. The main difference between an asteroid and a comet is that a comet shows a coma due to sublimation of near surface ices by solar radiation. A few objects have ended up being dual-listed because they were first classified as minor planets but later showed evidence of cometary activity. Conversely, some (perhaps all) comets are eventually depleted of their surface volatile ices and become asteroid-like. A further distinction is that comets typically have more eccentric orbits than most asteroids; most "asteroids" with notably eccentric orbits are probably dormant or extinct comets.

For almost two centuries, from the discovery of Ceres in 1801 until the discovery of the first centaur, Chiron in 1977, all known asteroids spent most of their time at or within the orbit of Jupiter, though a few such as Hidalgo ventured far beyond Jupiter for part of their orbit. Those located between the orbits of Mars and Jupiter were known for many years simply as The Asteroids. When astronomers started finding more small bodies that permanently resided further out than Jupiter, now called centaurs, they numbered them among the traditional asteroids, though there was debate over whether they should be considered asteroids or as a new type of object. Then, when the first trans-Neptunian object (other than Pluto), Albion, was discovered in 1992, and especially when large numbers of similar objects started turning up, new terms were invented to sidestep the issue: Kuiper-belt object, trans-Neptunian object, scattered-disc object, and so on. These inhabit the cold outer reaches of the Solar System where ices remain solid and comet-like bodies are not expected to exhibit much cometary activity; if centaurs or trans-Neptunian objects were to venture close to the Sun, their volatile ices would sublimate, and traditional approaches would classify them as comets and not asteroids.

The innermost of these are the Kuiper-belt objects, called "objects" partly to avoid the need to classify them as asteroids or comets. They are thought to be predominantly comet-like in composition, though some may be more akin to asteroids. Furthermore, most do not have the highly eccentric orbits associated with comets, and the ones so far discovered are larger than traditional comet nuclei. (The much more distant Oort cloud is hypothesized to be the main reservoir of dormant comets.) Other recent observations, such as the analysis of the cometary dust collected by the "Stardust" probe, are increasingly blurring the distinction between comets and asteroids, suggesting "a continuum between asteroids and comets" rather than a sharp dividing line.

The minor planets beyond Jupiter's orbit are sometimes also called "asteroids", especially in popular presentations. However, it is becoming increasingly common for the term "asteroid" to be restricted to minor planets of the inner Solar System. Therefore, this article will restrict itself for the most part to the classical asteroids: objects of the asteroid belt, Jupiter trojans, and near-Earth objects.

When the IAU introduced the class small Solar System bodies in 2006 to include most objects previously classified as minor planets and comets, they created the class of dwarf planets for the largest minor planets – those that have enough mass to have become ellipsoidal under their own gravity. According to the IAU, "the term 'minor planet' may still be used, but generally the term 'Small Solar System Body' will be preferred." Currently only the largest object in the asteroid belt, Ceres
It is thought that planetesimals in the asteroid belt evolved much like the rest of the solar nebula until Jupiter neared its current mass, at which point excitation from orbital resonances with Jupiter ejected over 99% of planetesimals in the belt. Simulations and a discontinuity in spin rate and spectral properties suggest that asteroids larger than approximately in diameter accreted during that early era, whereas smaller bodies are fragments from collisions between asteroids during or after the Jovian disruption. Ceres and Vesta grew large enough to melt and differentiate, with heavy metallic elements sinking to the core, leaving rocky minerals in the crust.

In the Nice model, many Kuiper-belt objects are captured in the outer asteroid belt, at distances greater than 2.6 AU. Most were later ejected by Jupiter, but those that remained may be the D-type asteroids
Various dynamical groups of asteroids have been discovered orbiting in the inner Solar System. Their orbits are perturbed by the gravity of other bodies in the Solar System and by the Yarkovsky effect. Significant populations include:

The majority of known asteroids orbit within the asteroid belt between the orbits of Mars and Jupiter, generally in relatively low-eccentricity (i.e. not very elongated) orbits. This belt is now estimated to contain between 1.1 and 1.9 million asteroids larger than in diameter, and millions of smaller ones. These asteroids may be remnants of the protoplanetary disk, and in this region the accretion of planetesimals into planets during the formative period of the Solar System was prevented by large gravitational perturbations by Jupiter.

Trojans are populations that share an orbit with a larger planet or moon, but do not collide with it because they orbit in one of the two Lagrangian points of stability, L4 and L5, which lie 60° ahead of and behind the larger body.

The most significant population of trojans are the Jupiter trojans. Although fewer Jupiter trojans have been discovered (), it is thought that they are as numerous as the asteroids in the asteroid belt. Trojans have been found in the orbits of other planets, including Venus, Earth, Mars, Uranus, and Neptune
Asteroids vary greatly in size, from almost for the largest down to rocks just 1 meter across. The three largest are very much like miniature planets: they are roughly spherical, have at least partly differentiated interiors, and are thought to be surviving protoplanets. The vast majority, however, are much smaller and are irregularly shaped; they are thought to be either surviving planetesimals or fragments of larger bodies.

The dwarf planet Ceres is by far the largest asteroid, with a diameter of . The next largest are 4 Vesta and 2 Pallas, both with diameters of just over . Vesta is the only main-belt asteroid that can, on occasion, be visible to the naked eye. On some rare occasions, a near-Earth asteroid may briefly become visible without technical aid; see 99942 Apophis.

The mass of all the objects of the asteroid belt, lying between the orbits of Mars and Jupiter, is estimated to be about 2.8–, or about 4% of the mass of the Moon. Of this, Ceres comprises , a third of the total. Adding in the next three most massive objects, Vesta (9%), Pallas (7%), and Hygiea (3%), brings this figure up to 51%; whereas the three after that, 511 Davida (1.2%), 704 Interamnia (1.0%), and 52 Europa (0.9%), only add another 3% to the total mass. The number of asteroids then increases rapidly as their individual masses decrease.

The number of asteroids decreases markedly with size. Although this generally follows a power law, there are 'bumps' at and , where more asteroids than expected from a logarithmic distribution
Although their location in the asteroid belt excludes them from planet status, the three largest objects, Ceres, Vesta, and Pallas, are intact protoplanets that share many characteristics common to planets, and are atypical compared to the majority of "potato"-shaped asteroids. The fourth largest asteroid, Hygiea, has an undifferentiated interior, like the majority of asteroids. Between them, the four largest asteroids constitute half the mass of the asteroid belt.

Ceres is the only asteroid with a fully ellipsoidal shape and hence the only one that is a dwarf planet. It has a much higher absolute magnitude than the other asteroids, of around 3.32, and may possess a surface layer of ice. Like the planets, Ceres is differentiated: it has a crust, a mantle and a core. No meteorites from Ceres have been found on Earth.

Vesta, too, has a differentiated interior, though it formed inside the Solar System's frost line, and so is devoid of water; its composition is mainly of basaltic rock such as olivine. Aside from the large crater at its southern pole, Rheasilvia, Vesta also has an ellipsoidal shape. Vesta is the parent body of the Vestian family and other V-type asteroids, and is the source of the HED meteorites, which constitute 5% of all meteorites on Earth.

Pallas is unusual in that, like Uranus, it rotates on its side, with its axis of rotation tilted at high angles to its orbital plane. Its composition is similar to that of Ceres: high in carbon and silicon, and perhaps partially differentiated. Pallas is the parent body of the Palladian family of asteroids.

Hygiea is the largest carbonaceous asteroid and, unlike the other largest asteroids, lies relatively close to the plane of the ecliptic. It is the largest member and presumed parent body of the Hygiean family

Measurements of the rotation rates of large asteroids in the asteroid belt show that there is an upper limit. Very few asteroids with a diameter larger than 100 meters have a rotation period smaller than 2.2 hours. For asteroids rotating faster than approximately this rate, the inertial force at the surface is greater than the gravitational force, so any loose surface material would be flung out. However, a solid object should be able to rotate much more rapidly. This suggests that most asteroids with a diameter over 100 meters are rubble piles

The physical composition of asteroids is varied and in most cases poorly understood. Ceres appears to be composed of a rocky core covered by an icy mantle, where Vesta is thought to have a nickel-iron core, olivine mantle, and basaltic crust. 10 Hygiea, however, which appears to have a uniformly primitive composition of carbonaceous chondrite, is thought to be the largest undifferentiated asteroid. Most of the smaller asteroids are thought to be piles of rubble held together loosely by gravity, though the largest are probably solid. Some asteroids have moons or are co-orbiting binaries: Rubble piles, moons, binaries, and scattered asteroid families are thought to be the results of collisions that disrupted a parent asteroid, or, possibly, a planet.

Asteroids contain traces of amino acids and other organic compounds, and some speculate that asteroid impacts may have seeded the early Earth with the chemicals necessary to initiate life, or may have even brought life itself to Earth "(also see panspermia)". In August 2011, a report, based on NASA studies with meteorites found on Earth, was published suggesting DNA and RNA components (adenine, guanine and related organic molecules) may have been formed on asteroids and comets in outer space
Composition is calculated from three primary sources: albedo, surface spectrum, and density. The last can only be determined accurately by observing the orbits of moons the asteroid might have. So far, every asteroid with moons has turned out to be a rubble pile, a loose conglomeration of rock and metal that may be half empty space by volume. The investigated asteroids are as large as 280 km in diameter, and include 121 Hermione (268×186×183 km), and 87 Sylvia (384×262×232 km). Only half a dozen asteroids are larger than 87 Sylvia, though none of them have moons; however, some smaller asteroids are thought to be more massive, suggesting they may not have been disrupted, and indeed 511 Davida, the same size as Sylvia to within measurement error, is estimated to be two and a half times as massive, though this is highly uncertain. The fact that such large asteroids as Sylvia can be rubble piles, presumably due to disruptive impacts, has important consequences for the formation of the Solar System: Computer simulations of collisions involving solid bodies show them destroying each other as often as merging, but colliding rubble piles are more likely to merge. This means that the cores of the planets could have formed relatively quickly.

On 7 October 2009, the presence of water ice was confirmed on the surface of 24 Themis using NASA’s Infrared Telescope Facility. The surface of the asteroid appears completely covered in ice. As this ice layer is sublimated, it may be getting replenished by a reservoir of ice under the surface. Organic compounds were also detected on the surface. Scientists hypothesize that some of the first water brought to Earth was delivered by asteroid impacts after the collision that produced the Moon. The presence of ice on 24 Themis supports this theory.

In October 2013, water was detected on an extrasolar body for the first time, on an asteroid orbiting the white dwarf GD 61. On 22 January 2014, European Space Agency (ESA) scientists reported the detection, for the first definitive time, of water vapor on Ceres, the largest object in the asteroid belt. The detection was made by using the far-infrared abilities of the Herschel Space Observatory. The finding is unexpected because comets, not asteroids, are typically considered to "sprout jets and plumes". According to one of the scientists, "The lines are becoming more and more blurred between comets and asteroids." In May 2016, significant asteroid data arising from the Wide-field Infrared Survey Explorer and NEOWISE missions have been questioned. Although the early original criticism had not undergone peer review, a more recent peer-reviewed study was subsequently published.

Most asteroids outside the "big four" (Ceres, Pallas, Vesta, and Hygiea) are likely to be broadly similar in appearance, if irregular in shape. 50-km (31-mi) 253 Mathilde is a rubble pile saturated with craters with diameters the size of the asteroid's radius, and Earth-based observations of 300-km (186-mi) 511 Davida, one of the largest asteroids after the big four, reveal a similarly angular profile, suggesting it is also saturated with radius-size craters. Medium-sized asteroids such as Mathilde and 243 Ida that have been observed up close also reveal a deep regolith covering the surface. Of the big four, Pallas and Hygiea are practically unknown. Vesta has compression fractures encircling a radius-size crater at its south pole but is otherwise a spheroid. Ceres seems quite different in the glimpses Hubble has provided, with surface features that are unlikely to be due to simple craters and impact basins, but details will be expanded with the "Dawn spacecraft", which entered Ceres orbit on 6 March 2015.

Asteroids become darker and redder with age due to space weathering
Asteroids are commonly classified according to two criteria: the characteristics of their orbits, and features of their reflectance spectrum.

Many asteroids have been placed in groups and families based on their orbital characteristics. Apart from the broadest divisions, it is customary to name a group of asteroids after the first member of that group to be discovered. Groups are relatively loose dynamical associations, whereas families are tighter and result from the catastrophic break-up of a large parent asteroid sometime in the past. Families are more common and easier to identify within the main asteroid belt, but several small families have been reported among the Jupiter trojans. Main belt families were first recognized by Kiyotsugu Hirayama in 1918 and are often called Hirayama families in his honor.

About 30–35% of the bodies in the asteroid belt belong to dynamical families each thought to have a common origin in a past collision between asteroids. A family has also been associated with the plutoid dwarf planet .

Some asteroids have unusual horseshoe orbits that are co-orbital with Earth or some other planet. Examples are 3753 Cruithne and . The first instance of this type of orbital arrangement was discovered between Saturn's moons Epimetheus and Janus.

Sometimes these horseshoe objects temporarily become quasi-satellites for a few decades or a few hundred years, before returning to their earlier status. Both Earth and Venus are known to have quasi-satellites.

Such objects, if associated with Earth or Venus or even hypothetically Mercury, are a special class of Aten asteroids

In 1975, an asteroid taxonomic system based on color, albedo, and spectral shape was developed by Clark R. Chapman, David Morrison, and Ben Zellner. These properties are thought to correspond to the composition of the asteroid's surface material. The original classification system had three categories: C-types for dark carbonaceous objects (75% of known asteroids), S-types for stony (silicaceous) objects (17% of known asteroids) and U for those that did not fit into either C or S. This classification has since been expanded to include many other asteroid types. The number of types continues to grow as more asteroids are studied.

The two most widely used taxonomies now used are the Tholen classification and SMASS classification. The former was proposed in 1984 by David J. Tholen, and was based on data collected from an eight-color asteroid survey performed in the 1980s. This resulted in 14 asteroid categories. In 2002, the Small Main-Belt Asteroid Spectroscopic Survey resulted in a modified version of the Tholen taxonomy with 24 different types. Both systems have three broad categories of C, S, and X asteroids, where X consists of mostly metallic asteroids, such as the M-type
A newly discovered asteroid is given a provisional designation (such as ) consisting of the year of discovery and an alphanumeric code indicating the half-month of discovery and the sequence within that half-month. Once an asteroid's orbit has been confirmed, it is given a number, and later may also be given a name (e.g. 433 Eros). The formal naming convention uses parentheses around the number (e.g. (433) Eros), but dropping the parentheses is quite common. Informally, it is common to drop the number altogether, or to drop it after the first mention when a name is repeated in running text. In addition, names can be proposed by the asteroid's discoverer, within guidelines established by the International Astronomical Union.

The first asteroids to be discovered were assigned iconic symbols like the ones traditionally used to designate the planets. By 1855 there were two dozen asteroid symbols, which often occurred in multiple variants.

In 1851, after the fifteenth asteroid (Eunomia) had been discovered, Johann Franz Encke made a major change in the upcoming 1854 edition of the "Berliner Astronomisches Jahrbuch" (BAJ, "Berlin Astronomical Yearbook"). He introduced a disk (circle), a traditional symbol for a star, as the generic symbol for an asteroid. The circle was then numbered in order of discovery to indicate a specific asteroid (although he assigned ① to the fifth, Astraea, while continuing to designate the first four only with their existing iconic symbols). The numbered-circle convention was quickly adopted by astronomers, and the next asteroid to be discovered (16 Psyche, in 1852) was the first to be designated in that way at the time of its discovery. However, Psyche was given an iconic symbol as well, as were a few other asteroids discovered over the next few years (see chart above). 20 Massalia was the first asteroid that was not assigned an iconic symbol, and no iconic symbols were created after the 1855 discovery of 37 Fides

Until the age of space travel, objects in the asteroid belt were merely pinpricks of light in even the largest telescopes and their shapes and terrain remained a mystery. The best modern ground-based telescopes and the Earth-orbiting Hubble Space Telescope can resolve a small amount of detail on the surfaces of the largest asteroids, but even these mostly remain little more than fuzzy blobs. Limited information about the shapes and compositions of asteroids can be inferred from their light curves (their variation in brightness as they rotate) and their spectral properties, and asteroid sizes can be estimated by timing the lengths of star occulations (when an asteroid passes directly in front of a star). Radar imaging can yield good information about asteroid shapes and orbital and rotational parameters, especially for near-Earth asteroids. In terms of delta-v and propellant requirements, NEOs are more easily accessible than the Moon.

The first close-up photographs of asteroid-like objects were taken in 1971, when the "Mariner 9" probe imaged Phobos and Deimos, the two small moons of Mars, which are probably captured asteroids. These images revealed the irregular, potato-like shapes of most asteroids, as did later images from the Voyager probes of the small moons of the gas giants.

The first true asteroid to be photographed in close-up was 951 Gaspra in 1991, followed in 1993 by 243 Ida and its moon Dactyl, all of which were imaged by the "Galileo" probe en route to Jupiter.

The first dedicated asteroid probe was "NEAR Shoemaker", which photographed 253 Mathilde in 1997, before entering into orbit around 433 Eros, finally landing on its surface in 2001.

Other asteroids briefly visited by spacecraft en route to other destinations include 9969 Braille (by "Deep Space 1" in 1999), and 5535 Annefrank (by "Stardust" in 2002).

From September to November 2005, the Japanese "Hayabusa" probe studied 25143 Itokawa in detail and was plagued with difficulties, but returned samples of its surface to Earth on 13 June 2010.

The European "Rosetta" probe (launched in 2004) flew by 2867 Šteins in 2008 and 21 Lutetia, the third-largest asteroid visited to date, in 2010.

In September 2007, NASA launched the "Dawn" spacecraft, which orbited 4 Vesta from July 2011 to September 2012, and has been orbiting the dwarf planet 1 Ceres since 2015. 4 Vesta is the second-largest asteroid visited to date.

On 13 December 2012, China's lunar orbiter "Chang'e 2" flew within of the asteroid 4179 Toutatis on an extended mission.

The Japan Aerospace Exploration Agency (JAXA) launched the "Hayabusa2" probe in December 2014, and plans to return samples from 162173 Ryugu in December 2020.

In June 2018, the US National Science and Technology Council warned that America is unprepared for an asteroid impact event
In May 2011, NASA selected the OSIRIS-REx sample return mission to asteroid 101955 Bennu

In early 2013, NASA announced the planning stages of a mission to capture a near-Earth asteroid and move it into lunar orbit where it could possibly be visited by astronauts and later impacted into the Moon. On 19 June 2014, NASA reported that asteroid 2011 MD was a prime candidate for capture by a robotic mission, perhaps in the early 2020s.

It has been suggested that asteroids might be used as a source of materials that may be rare or exhausted on Earth (asteroid mining), or materials for constructing space habitats "(see Colonization of the asteroids)". Materials that are heavy and expensive to launch from Earth may someday be mined from asteroids and used for space manufacturing and construction.

In the U.S. Discovery program the "Psyche" spacecraft proposal to 16 Psyche and "Lucy" spacecraft to Jupiter trojans made it to the semifinalist stage of mission selection.

In January 2017, "Lucy" and "Psyche" mission were both selected as NASA's Discovery Program
Category:Minor planetsAllocution

An allocution, or allocutus, is a formal statement made to the court by the defendant who has been found guilty prior to being sentenced. It is part of the criminal procedure in some jurisdictions using common law.

An allocution allows the defendant to explain why the sentence should be lenient. In plea bargains, an allocution may be required of the defendant. The defendant explicitly admits specifically and in detail the actions and their reasons in exchange for a reduced sentence.

In principle, that removes any doubt as to the exact nature of the defendant's guilt in the matter.

The term "allocution" is used generally only in jurisdictions in the United States, but there are vaguely similar processes in other common law countries. In many other jurisdictions, it is for the defense lawyer to mitigate on his client's behalf, and the defendant rarely has the opportunity to speak.

The right of victims to speak at sentencing is also sometimes referred to as allocution.

In Australia, the term "allocutus" is used by the Clerk of Arraigns or another formal associate of the Court. It is generally phrased as, "Prisoner at the Bar, you have been found Guilty by a jury of your peers of the offense of XYZ. Do you have anything to say as to why the sentence of this Court should not now be passed upon you?" The defense counsel will then make a "plea in mitigation" (also called "submissions on penalty") in an attempt to mitigate the relative seriousness of the offense and heavily refer to and rely upon the defendant's previous good character and good works, if any.

The right to make a plea in mitigation is absolute. If a judge or magistrate refuses to hear such a plea or does not properly consider it, the sentence can be overturned on appeal.

In most of the United States, defendants are allowed the opportunity to allocute before a sentence is passed. Some jurisdictions hold that as an absolute right. In its absence, a sentence but not the conviction may be overturned, resulting in the need for a new sentencing hearing. In the federal system, Federal Rule of Criminal Procedure 32(i)(4) provides that the court must "address the defendant personally in order to permit the defendant to speak or present any information to mitigate the sentence."

The Federal Public Defender recommends that defendants speak in terms of how a lenient sentence will be sufficient but not greater than necessary to comply with the statutory directives set forth in .


Category:Criminal procedure
Category:Evidence law

An affidavit ( ) is a written sworn statement of fact voluntarily made by an "affiant" or "deponent" under an oath or affirmation administered by a person authorized to do so by law. Such statement is witnessed as to the authenticity of the affiant's signature by a taker of oaths, such as a notary public or commissioner of oaths. The name is Medieval Latin for "he/she has declared upon oath". An affidavit is a type of verified statement or showing, or in other words, it contains a verification, meaning it is under oath or penalty of perjury, and this serves as evidence to its veracity and is required for court proceedings.

Affidavits may be written in the first or third person, depending on who drafted the document. If in the first person, the document's component parts are typically as follows:

If an affidavit is notarized or authenticated, it will also include a caption with a venue and title in reference to judicial proceedings. In some cases, an introductory clause, called a "preamble", is added attesting that the affiant personally appeared before the authenticating authority.

On 2 March 2016, the High Court of Australia held that the ACT Uniform Evidence Legislation is neutral in the way sworn evidence and unsworn evidence is treated as being of equal weight.

In Indian law, although an affidavit may be taken as proof of the facts stated therein, the Courts have no jurisdiction to admit evidence by way of affidavit. Affidavit is treated as "evidence" within the meaning of Section 3 of the Evidence Act. However, it was held by the Supreme Court that an affidavit can be used as evidence only if the Court so orders for sufficient reasons, namely, the right of the opposite party to have the deponent produced for cross-examination (Khandesh Spg & Wvg Mills CO. Ltd. Vs Rashtriya Girni Kamgar Sangh, citation 1960 AIR571, 1960 SCR(2) 841). Therefore, an affidavit cannot ordinarily be used as evidence in absence of a specific order of the Court.

In Sri Lanka, under the Oaths Ordinance, with the exception of court marshals, a person may submit an affidavit signed in the presence of a Commissioner for Oaths or a justice of the peace.

Affidavits are made in a similar way as to England and Wales, although "make oath" is sometimes omitted. A declaration may be substituted for an affidavit in most cases for those opposed to swearing oaths. The person making the affidavit is known as the deponent but does not sign the affidavit. The affidavit concludes in the standard format "sworn (declared) before me, [name of commissioner for oaths/solicitor], a commissioner for oaths (solicitor), on the [date] at [location] in the county/city of [county/city], and I know the deponent (declarant)", and it is signed and stamped by the commissioner for oaths.

In American jurisprudence, under the rules for hearsay, admission of an unsupported affidavit as evidence is unusual (especially if the affiant is not available for cross-examination) with regard to material facts which may be dispositive of the matter at bar. Affidavits from persons who are dead or otherwise incapacitated, or who cannot be located or made to appear, may be accepted by the court, but usually only in the presence of corroborating evidence. An affidavit which reflected a better grasp of the facts close in time to the actual events may be used to refresh a witness's recollection. Materials used to refresh recollection are admissible as evidence. If the affiant is a party in the case, the affiant's opponent may be successful in having the affidavit admitted as evidence, as statements by a party-opponent are admissible through an exception to the hearsay rule.

Affidavits are typically included in the response to interrogatories. Requests for admissions under Federal Rule of Civil Procedure 36, however, are not required to be sworn.

Some types of motions will not be accepted by the court unless accompanied by an independent sworn statement or other evidence, in support of the need for the motion. In such a case, a court will accept an affidavit from the filing attorney in support of the motion, as certain assumptions are made, to wit: The affidavit in place of sworn testimony promotes judicial economy. The lawyer is an officer of the court and knows that a false swearing by him, if found out, could be grounds for severe penalty up to and including disbarment. The lawyer if called upon would be able to present independent and more detailed evidence to prove the facts set forth in his affidavit. 

The acceptance of an affidavit by one society does not confirm its acceptance as a legal document in other jurisdictions. Equally, the acceptance that a lawyer is an officer of the court (for swearing the affidavit) is not a given. This matter is addressed by the use of the apostille, a means of certifying the legalization of a document for international use under the terms of the 1961 Hague Convention Abolishing the Requirement of Legalization for Foreign Public Documents. Documents which have been notarized by a notary public, and certain other documents, and then certified with a conformant apostille, are accepted for legal use in all the nations that have signed the Hague Convention. Thus most affidavits now require to be apostilled if used for cross border issues.

There are various occasions or circumstances when a person needs an affidavit for a specific purpose and for that reason there are multiple as listed below:


Category:Evidence law
Category:Legal documents
Category:NotaryAries (constellation)

Aries is one of the constellations of the zodiac. It is located in the northern celestial hemisphere between Pisces to the west and Taurus to the east. The name Aries is Latin for ram (Unicode ♈), representing a ram's horns. It is one of the 48 constellations described by the 2nd century astronomer Ptolemy, and remains one of the 88 modern constellations. It is a mid-sized constellation, ranking 39th overall size, with an area of 441 square degrees (1.1% of the celestial sphere).

Although Aries came to represent specifically the ram whose fleece became the Golden Fleece of Ancient Greek mythology, it has represented a ram since late Babylonian times. Before that, the stars of Aries formed a farmhand. Different cultures have incorporated the stars of Aries into different constellations including twin inspectors in China and a porpoise in the Marshall Islands. Aries is a relatively dim constellation, possessing only four bright stars: Hamal (Alpha Arietis, second magnitude), Sheratan (Beta Arietis, third magnitude), Mesarthim (Gamma Arietis, fourth magnitude), and 41 Arietis (also fourth magnitude). The few deep-sky objects within the constellation are quite faint and include several pairs of interacting galaxies. Several meteor showers appear to radiate from Aries, including the Daytime Arietids and the Epsilon Arietids.

Aries is now recognized as an official constellation, albeit as a specific region of the sky, by the International Astronomical Union. It was originally defined in ancient texts as a specific pattern of stars, and has remained a constellation since ancient times; it now includes the ancient pattern as well as the surrounding stars. In the description of the Babylonian zodiac given in the clay tablets known as the MUL.APIN, the constellation now known as Aries was the final station along the ecliptic. The MUL.APIN was a comprehensive table of the risings and settings of stars, which likely served as an agricultural calendar. Modern-day Aries was known as , "The Agrarian Worker" or "The Hired Man". Although likely compiled in the 12th or 11th century BC, the MUL.APIN reflects a tradition which marks the Pleiades as the vernal equinox, which was the case with some precision at the beginning of the Middle Bronze Age. The earliest identifiable reference to Aries as a distinct constellation comes from the boundary stones that date from 1350 to 1000 BC. On several boundary stones, a zodiacal ram figure is distinct from the other characters present. The shift in identification from the constellation as the Agrarian Worker to the Ram likely occurred in later Babylonian tradition because of its growing association with Dumuzi the Shepherd. By the time the MUL.APIN was created—by 1000 BC—modern Aries was identified with both Dumuzi's ram and a hired laborer. The exact timing of this shift is difficult to determine due to the lack of images of Aries or other ram figures.

In ancient Egyptian astronomy, Aries was associated with the god Amon-Ra, who was depicted as a man with a ram's head and represented fertility and creativity. Because it was the location of the vernal equinox, it was called the "Indicator of the Reborn Sun". During the times of the year when Aries was prominent, priests would process statues of Amon-Ra to temples, a practice that was modified by Persian astronomers
Aries was not fully accepted as a constellation until classical times. In Hellenistic astrology, the constellation of Aries is associated with the golden ram of Greek mythology that rescued Phrixus and Helle on orders from Hermes, taking Phrixus to the land of Colchis. Phrixos and Helle were the son and daughter of King Athamas and his first wife Nephele. The king's second wife, Ino, was jealous and wished to kill his children. To accomplish this, she induced a famine in Boeotia, then falsified a message from the Oracle of Delphi that said Phrixos must be sacrificed to end the famine. Athamas was about to sacrifice his son atop Mount Laphystium when Aries, sent by Nephele, arrived. Helle fell off of Aries's back in flight and drowned in the Dardanelles, also called the Hellespont in her honor. After arriving, Phrixus sacrificed the ram to Zeus and gave the Fleece to Aeëtes of Colchis, who rewarded him with an engagement to his daughter Chalciope. Aeëtes hung its skin in a sacred place where it became known as the Golden Fleece and was guarded by a dragon. In a later myth, this Golden Fleece was stolen by Jason and the Argonauts.

Historically, Aries has been depicted as a crouched, wingless ram with its head turned towards Taurus. Ptolemy asserted in his "Almagest" that Hipparchus depicted Alpha Arietis as the ram's muzzle, though Ptolemy did not include it in his constellation figure. Instead, it was listed as an "unformed star", and denoted as "the star over the head". John Flamsteed, in his "Atlas Coelestis", followed Ptolemy's description by mapping it above the figure's head. Flamsteed followed the general convention of maps by depicting Aries lying down. Astrologically, Aries has been associated with the head and its humors. It was strongly associated with Mars, both the planet and the god. It was considered to govern Western Europe and Syria, and to indicate a strong temper in a person.

The First Point of Aries, the location of the vernal equinox, is named for the constellation. This is because the Sun crossed the celestial equator from south to north in Aries more than two millennia ago. Hipparchus defined it in 130 BC. as a point south of Gamma Arietis. Because of the precession of the equinoxes, the First Point of Aries has since moved into Pisces and will move into Aquarius by around 2600 AD. The Sun now appears in Aries from late April through mid May, though the constellation is still associated with the beginning of spring.

Medieval Muslim astronomers depicted Aries in various ways. Astronomers like al-Sufi saw the constellation as a ram, modeled on the precedent of Ptolemy. However, some Islamic celestial globes depicted Aries as a nondescript four-legged animal with what may be antlers instead of horns. Some early Bedouin observers saw a ram elsewhere in the sky; this constellation featured the Pleiades as the ram's tail. The generally accepted Arabic formation of Aries consisted of thirteen stars in a figure along with five "unformed" stars, four of which were over the animal's hindquarters and one of which was the disputed star over Aries's head. Al-Sufi's depiction differed from both other Arab astronomers' and Flamsteed's, in that his Aries was running and looking behind itself.

The obsolete constellations introduced in Aries (Musca Borealis, Lilium, Vespa, and Apes) have all been composed of the northern stars. Musca Borealis was created from the stars 33 Arietis, 35 Arietis, 39 Arietis, and 41 Arietis. In 1612, Petrus Plancius introduced Apes, a constellation representing a bee. In 1624, the same stars were used by Jakob Bartsch to create a constellation called Vespa, representing a wasp. In 1679 Augustin Royer used these stars for his constellation Lilium, representing the fleur-de-lis. None of these constellation became widely accepted. Johann Hevelius renamed the constellation "Musca" in 1690 in his "Firmamentum Sobiescianum". To differentiate it from Musca, the southern fly, it was later renamed Musca Borealis but it did not gain acceptance and its stars were ultimately officially reabsorbed into Aries.

In 1922, the International Astronomical Union defined its recommended three-letter abbreviation, "Ari". The official boundaries of Aries were defined in 1930 by Eugène Delporte as a polygon of 12 segments. Its right ascension is between 1 46.4 and 3 29.4 and its declination is between 10.36° and 31.22° in the equatorial coordinate system.

In traditional Chinese astronomy, stars from Aries were used in several constellations. The brightest stars—Alpha, Beta, and Gamma Arietis—formed a constellation called "Lou", variously translated as "bond", "lasso", and "sickle", which was associated with the ritual sacrifice of cattle. This name was shared by the 16th lunar mansion, the location of the full moon closest to the autumnal equinox. The lunar mansion represented the area where animals were gathered before sacrifice around that time. This constellation has also been associated with harvest-time as it could represent a woman carrying a basket of food on her head. 35, 39, and 41 Arietis were part of a constellation called "Wei", which represented a fat abdomen and was the namesake of the 17th lunar mansion, which represented granaries. Delta and Zeta Arietis were a part of the constellation "Tianyin", thought to represent the Emperor's hunting partner. "Zuogeng" ("Tso-kang"), a constellation depicting a marsh and pond inspector, was composed of Mu, Nu, Omicron, Pi, and Sigma Arietis. He was accompanied by "Yeou-kang", a constellation depicting an official in charge of pasture distribution.

In a similar system to the Chinese, the first lunar mansion in Hindu astronomy was called "Aswini", after the traditional names for Beta and Gamma Arietis, the Aswins. Because the Hindu new year began with the vernal equinox, the Rig Veda contains over 50 new-year's related hymns to the twins, making them some of the most prominent characters in the work. Aries itself was known as ""Aja"" and ""Mesha"". In Hebrew astronomy Aries was named ""Teli""; it signified either Simeon or Gad, and generally symbolizes the "Lamb of the World". The neighboring Syrians named the constellation "Amru", and the bordering Turks named it "Kuzi". Half a world away, in the Marshall Islands, several stars from Aries were incorporated into a constellation depicting a porpoise, along with stars from Cassiopeia, Andromeda, and Triangulum. Alpha, Beta, and Gamma Arietis formed the head of the porpoise, while stars from Andromeda formed the body and the bright stars of Cassiopeia formed the tail. Other Polynesian peoples recognized Aries as a constellation. The Marquesas islanders called it "Na-pai-ka"; the Māori constellation "Pipiri" may correspond to modern Aries as well. In indigenous Peruvian astronomy, a constellation with most of the same stars as Aries existed. It was called the "Market Moon" and the "Kneeling Terrace", as a reminder for when to hold the annual harvest festival, Ayri Huay

Aries has three prominent stars forming an asterism, designated Alpha, Beta, and Gamma Arietis by Johann Bayer. All three are commonly used for navigation. There is also one other star above the fourth magnitude, 41 Arietis (Bharani). α Arietis, called Hamal, is the brightest star in Aries. Its traditional name is derived from the Arabic word for "lamb" or "head of the ram" ("ras al-hamal"), which references Aries's mythological background. With a spectral class of K2 and a luminosity class of III, it is an orange giant with an apparent visual magnitude of 2.00, which lies 66 light-years from Earth. Hamal has a luminosity of and its absolute magnitude is −0.1.

β Arietis, also known as Sheratan, is a blue-white star with an apparent visual magnitude of 2.64. Its traditional name is derived from ""sharatayn"", the Arabic word for "the two signs", referring to both Beta and Gamma Arietis in their position as heralds of the vernal equinox. The two stars were known to the Bedouin as ""qarna al-hamal"", "horns of the ram". It is 59 light-years from Earth. It has a luminosity of and its absolute magnitude is 2.1. It is a spectroscopic binary star, one in which the companion star is only known through analysis of the spectra. The spectral class of the primary is A5. Hermann Carl Vogel determined that Sheratan was a spectroscopic binary in 1903; its orbit was determined by Hans Ludendorff in 1907. It has since been studied for its eccentric orbit.

γ Arietis, with a common name of Mesarthim, is a binary star with two white-hued components, located in a rich field of magnitude 8–12 stars. Its traditional name has conflicting derivations. It may be derived from a corruption of "al-sharatan", the Arabic word meaning "pair" or a word for "fat ram". However, it may also come from the Sanskrit for "first star of Aries" or the Hebrew for "ministerial servants", both of which are unusual languages of origin for star names. Along with Beta Arietis, it was known to the Bedouin as ""qarna al-hamal"". The primary is of magnitude 4.59 and the secondary is of magnitude 4.68. The system is 164 light-years from Earth. The two components are separated by 7.8 arcseconds, and the system as a whole has an apparent magnitude of 3.9. The primary has a luminosity of and the secondary has a luminosity of ; the primary is an A-type star with an absolute magnitude of 0.2 and the secondary is a B9-type star with an absolute magnitude of 0.4. The angle between the two components is 1°. Mesarthim was discovered to be a double star by Robert Hooke in 1664, one of the earliest such telescopic discoveries. The primary, γ Arietis, is an Alpha² Canum Venaticorum variable star that has a range of 0.02 magnitudes and a period of 2.607 days. It is unusual because of its strong silicon emission lines.

The constellation is home to several double stars, including Epsilon, Lambda, and Pi Arietis. ε Arietis is a binary star with two white components. The primary is of magnitude 5.2 and the secondary is of magnitude 5.5. The system is 290 light-years from Earth. Its overall magnitude is 4.63, and the primary has an absolute magnitude of 1.4. Its spectral class is A2. The two components are separated by 1.5 arcseconds. λ Arietis is a wide double star with a white-hued primary and a yellow-hued secondary. The primary is of magnitude 4.8 and the secondary is of magnitude 7.3. The primary is 129 light-years from Earth. It has an absolute magnitude of 1.7 and a spectral class of F0. The two components are separated by 36 arcseconds at an angle of 50°; the two stars are located 0.5° east of 7 Arietis. π Arietis is a close binary star with a blue-white primary and a white secondary. The primary is of magnitude 5.3 and the secondary is of magnitude 8.5. The primary is 776 light-years from Earth. The primary itself is a wide double star with a separation of 25.2 arcseconds; the tertiary has a magnitude of 10.8. The primary and secondary are separated by 3.2 arcseconds.

Most of the other stars in Aries visible to the naked eye have magnitudes between 3 and 5. δ Ari, called Boteïn, is a star of magnitude 4.35, 170 light-years away. It has an absolute magnitude of −0.1 and a spectral class of K2. ζ Arietis is a star of magnitude 4.89, 263 light-years away. Its spectral class is A0 and its absolute magnitude is 0.0. 14 Arietis is a star of magnitude 4.98, 288 light-years away. Its spectral class is F2 and its absolute magnitude is 0.6. 39 Arietis (Lilii Borea) is a similar star of magnitude 4.51, 172 light-years away. Its spectral class is K1 and its absolute magnitude is 0.0. 35 Arietis is a dim star of magnitude 4.55, 343 light-years away. Its spectral class is B3 and its absolute magnitude is −1.7. 41 Arietis, known both as c Arietis and Nair al Butain, is a brighter star of magnitude 3.63, 165 light-years away. Its spectral class is B8 and it has a luminosity of . Its absolute magnitude is −0.2. 53 Arietis is a runaway star of magnitude 6.09, 815 light-years away. Its spectral class is B2. It was likely ejected from the Orion Nebula approximately five million years ago, possibly due to supernovae. Finally, Teegarden's Star is the closest star to Earth in Aries. It is a brown dwarf of magnitude 15.14 and spectral class M6.5V. With a proper motion of 5.1 arcseconds per year, it is the 24th closest star to Earth overall.

Aries has its share of variable stars, including R and U Arietis, Mira-type variable stars, and T Arietis, a semi-regular variable star. R Arietis is a Mira variable star that ranges in magnitude from a minimum of 13.7 to a maximum of 7.4 with a period of 186.8 days. It is 4,080 light-years away. U Arietis is another Mira variable star that ranges in magnitude from a minimum of 15.2 to a maximum of 7.2 with a period of 371.1 days. T Arietis is a semiregular variable star that ranges in magnitude from a minimum of 11.3 to a maximum of 7.5 with a period of 317 days. It is 1,630 light-years away. One particularly interesting variable in Aries is SX Arietis, a rotating variable star considered to be the prototype of its class, helium variable stars. SX Arietis stars have very prominent emission lines of Helium I and Silicon III. They are normally main-sequence B0p—B9p stars, and their variations are not usually visible to the naked eye. Therefore, they are observed photometrically, usually having periods that fit in the course of one night. Similar to Alpha² Canum Venaticorum variables, SX Arietis stars have periodic changes in their light and magnetic field, which correspond to the periodic rotation; they differ from the Alpha² Canum Venaticorum variables in their higher temperature. There are between 39 and 49 SX Arietis variable stars currently known; ten are noted as being "uncertain" in the General Catalog of Variable Stars
NGC 772 is a spiral galaxy with an integrated magnitude of 10.3, located southeast of β Arietis and 15 arcminutes west of 15 Arietis. It is a relatively bright galaxy and shows obvious nebulosity and ellipticity in an amateur telescope. It is 7.2 by 4.2 arcminutes, meaning that its surface brightness, magnitude 13.6, is significantly lower than its integrated magnitude. NGC 772 is a class SA(s)b galaxy, which means that it is an unbarred spiral galaxy without a ring that possesses a somewhat prominent bulge and spiral arms that are wound somewhat tightly. The main arm, on the northwest side of the galaxy, is home to many star forming regions; this is due to previous gravitational interactions with other galaxies. NGC 772 has a small companion galaxy, NGC 770, that is about 113,000 light-years away from the larger galaxy. The two galaxies together are also classified as Arp 78 in the Arp peculiar galaxy catalog. NGC 772 has a diameter of 240,000 light-years and the system is 114 million light-years from Earth. Another spiral galaxy in Aries is NGC 673, a face-on class SAB(s)c galaxy. It is a weakly barred spiral galaxy with loosely wound arms. It has no ring and a faint bulge and is 2.5 by 1.9 arcminutes. It has two primary arms with fragments located farther from the core. 171,000 light-years in diameter, NGC 673 is 235 million light-years from Earth.

NGC 678 and NGC 680 are a pair of galaxies in Aries that are only about 200,000 light-years apart. Part of the NGC 691 group of galaxies, both are at a distance of approximately 130 million light-years. NGC 678 is an edge-on spiral galaxy that is 4.5 by 0.8 arcminutes. NGC 680, an elliptical galaxy with an asymmetrical boundary, is the brighter of the two at magnitude 12.9; NGC 678 has a magnitude of 13.35. Both galaxies have bright cores, but NGC 678 is the larger galaxy at a diameter of 171,000 light-years; NGC 680 has a diameter of 72,000 light-years. NGC 678 is further distinguished by its prominent dust lane. NGC 691 itself is a spiral galaxy slightly inclined to our line of sight. It has multiple spiral arms and a bright core. Because it is so diffuse, it has a low surface brightness. It has a diameter of 126,000 light-years and is 124 million light-years away. NGC 877 is the brightest member of an 8-galaxy group that also includes NGC 870, NGC 871, and NGC 876, with a magnitude of 12.53. It is 2.4 by 1.8 arcminutes and is 178 million light-years away with a diameter of 124,000 light-years. Its companion is NGC 876, which is about 103,000 light-years from the core of NGC 877. They are interacting gravitationally, as they are connected by a faint stream of gas and dust. Arp 276 is a different pair of interacting galaxies in Aries, consisting of NGC 935 and IC 1801.

NGC 821 is an E6 elliptical galaxy. It is unusual because it has hints of an early spiral structure, which is normally only found in lenticular and spiral galaxies. NGC 821 is 2.6 by 2.0 arcminutes and has a visual magnitude of 11.3. Its diameter is 61,000 light-years and it is 80 million light-years away. Another unusual galaxy in Aries is Segue 2. Segue 2 is a dwarf galaxy that is a satellite galaxy of the Milky Way, recently discovered to be a potential relic of the epoch of reionization.

Aries is home to several meteor showers. The Daytime Arietid meteor shower is one of the strongest meteor showers that occurs during the day, lasting from 22 May to 2 July. It is an annual shower associated with the Marsden group of comets that peaks on 7 June with a maximum zenithal hourly rate of 54 meteors. Its parent body may be the asteroid Icarus. The meteors are sometimes visible before dawn, because the radiant is 32 degrees away from the Sun. They usually appear at a rate of 1–2 per hour as "earthgrazers", meteors that last several seconds and often begin at the horizon. Because most of the Daytime Arietids are not visible to the naked eye, they are observed in the radio spectrum. This is possible because of the ionized gas they leave in their wake. Other meteor showers radiate from Aries during the day; these include the Daytime Epsilon Arietids and the Northern and Southern Daytime May Arietids. The Jodrell Bank Observatory discovered the Daytime Arietids in 1947 when James Hey and G. S. Stewart adapted the World War II-era radar systems for meteor observations.

The Delta Arietids are another meteor shower radiating from Aries. Peaking on 9 December with a low peak rate, the shower lasts from 8 December to 14 January, with the highest rates visible from 8 to 14 December. The average Delta Aquarid meteor is very slow, with an average velocity of per second. However, this shower sometimes produces bright fireballs. This meteor shower has northern and southern components, both of which are likely associated with 1990 HA, a near-Earth asteroid.

The Autumn Arietids also radiate from Aries. The shower lasts from 7 September to 27 October and peaks on 9 October. Its peak rate is low. The Epsilon Arietids appear from 12 to 23 October. Other meteor showers radiating from Aries include the October Delta Arietids, Daytime Epsilon Arietids, Daytime May Arietids, Sigma Arietids, Nu Arietids, and Beta Arietids. The Sigma Arietids, a class IV meteor shower, are visible from 12 to 19 October, with a maximum zenithal hourly rate of less than two meteors per hour on 19 October.

Aries contains several stars with extrasolar planets. HIP 14810, a G5 type star, is orbited by three giant planets (those more than ten times the mass of Earth). HD 12661, like HIP 14810, is a G-type main sequence star, slightly larger than the Sun, with two orbiting planets. One planet is 2.3 times the mass of Jupiter, and the other is 1.57 times the mass of Jupiter. HD 20367 is a G0 type star, approximately the size of the Sun, with one orbiting planet. The planet, discovered in 2002, has a mass 1.07 times that of Jupiter and orbits every 500 days.

Explanatory notes

Citations

Bibliography

Online sources


"SIMBAD
Category:Constellations
Category:Constellations listed by Ptolemy
Category:Northern constellationsAquarius (constellation)

Aquarius is a constellation of the zodiac, situated between Capricornus and Pisces. Its name is Latin , a representation of water. Aquarius is one of the oldest of the recognized constellations along the zodiac (the Sun's apparent path). It was one of the 48 constellations listed by the 2nd century astronomer Ptolemy, and it remains one of the 88 modern constellations. It is found in a region often called the Sea due to its profusion of constellations with watery associations such as Cetus the whale, Pisces the fish, and Eridanus the river.

At apparent magnitude 2.9, Beta Aquarii is the brightest star in the constellation.

Aquarius is identified as "The Great One" in the Babylonian star catalogues and represents the god Ea himself, who is commonly depicted holding an overflowing vase. The Babylonian star-figure appears on entitlement stones and cylinder seals from the second millennium. It contained the winter solstice in the Early Bronze Age. In Old Babylonian astronomy, Ea was the ruler of the southernmost quarter of the Sun's path, the "Way of Ea", corresponding to the period of 45 days on either side of winter solstice. Aquarius was also associated with the destructive floods that the Babylonians regularly experienced, and thus was negatively connoted. In Ancient Egypt astronomy, Aquarius was associated with the annual flood of the Nile; the banks were said to flood when Aquarius put his jar into the river, beginning spring.

In the Greek tradition, the constellation came to be represented simply as a single vase from which a stream poured down to Piscis Austrinus. The name in the Hindu zodiac is likewise "kumbha" "water-pitcher".

In Greek mythology, Aquarius is sometimes associated with Deucalion, the son of Prometheus who built a ship with his wife Pyrrha to survive an imminent flood. They sailed for nine days before washing ashore on Mount Parnassus. Aquarius is also sometimes identified with beautiful Ganymede, a youth in Greek mythology and the son of Trojan king Tros, who was taken to Mount Olympus by Zeus to act as cup-carrier to the gods. Neighboring Aquila represents the eagle, under Zeus' command, that snatched the young boy; some versions of the myth indicate that the eagle was in fact Zeus transformed. An alternative version of the tale recounts Ganymede's kidnapping by the goddess of the dawn, Eos, motivated by her affection for young men; Zeus then stole him from Eos and employed him as cup-bearer. Yet another figure associated with the water bearer is Cecrops I, a king of Athens who sacrificed water instead of wine
In the first century, Ptolemy's "Almagest" established the common Western depiction of Aquarius. His water jar, an asterism itself, consists of Gamma, Pi, Eta, and Zeta Aquarii; it pours water in a stream of more than 20 stars terminating with Fomalhaut, now assigned solely to Piscis Austrinus. The water bearer's head is represented by 5th magnitude 25 Aquarii while his left shoulder is Beta Aquarii; his right shoulder and forearm are represented by Alpha and Gamma Aquarii respectively.

In Chinese astronomy, the stream of water flowing from the Water Jar was depicted as the "Army of Yu-Lin" ("Yu-lin-kiun" or "Yulinjun"). The name "Yu-lin" means "feathers and forests", referring to the numerous light-footed soldiers from the northern reaches of the empire represented by these faint stars. The constellation's stars were the most numerous of any Chinese constellation, numbering 45, the majority of which were located in modern Aquarius. The celestial army was protected by the wall "Leibizhen", which counted Iota, Lambda, Phi, and Sigma Aquarii among its 12 stars. 88, 89, and 98 Aquarii represent "Fou-youe", the axes used as weapons and for hostage executions. Also in Aquarius is "Loui-pi-tchin", the ramparts that stretch from 29 and 27 Piscium and 33 and 30 Aquarii through Phi, Lambda, Sigma, and Iota Aquarii to Delta, Gamma, Kappa, and Epsilon Capricorni.

Near the border with Cetus, the axe "Fuyue" was represented by three stars; its position is disputed and may have instead been located in Sculptor. "Tienliecheng" also has a disputed position; the 13-star castle replete with ramparts may have possessed Nu and Xi Aquarii but may instead have been located south in Piscis Austrinus. The Water Jar asterism was seen to the ancient Chinese as the tomb, "Fenmu". Nearby, the emperors' mausoleum "Xiuliang" stood, demarcated by Kappa Aquarii and three other collinear stars. "Ku" ("crying") and "Qi" ("weeping"), each composed of two stars, were located in the same region.

Three of the Chinese lunar mansions shared their name with constellations. "Nu", also the name for the 10th lunar mansion, was a handmaiden represented by Epsilon, Mu, 3, and 4 Aquarii. The 11th lunar mansion shared its name with the constellation "Xu" ("emptiness"), formed by Beta Aquarii and Alpha Equulei; it represented a bleak place associated with death and funerals. "Wei", the rooftop and 12th lunar mansion, was a V-shaped constellation formed by Alpha Aquarii, Theta Pegasi, and Epsilon Pegasi; it shared its name with two other Chinese constellations, in modern-day Scorpius and Aries

Despite both its prominent position on the zodiac and its large size, Aquarius has no particularly bright stars, its four brightest stars being less than magnitude 2. However, recent research has shown that there are several stars lying within its borders that possess planetary systems.

The two brightest stars, Alpha and Beta Aquarii, are luminous yellow supergiants, of spectral types G0Ib and G2Ib respectively, that were once hot blue-white B-class main sequence stars 5 to 9 times as massive as the Sun. The two are also moving through space perpendicular to the plane of the Milky Way. Just shading Alpha, Beta Aquarii is the brightest star in Aquarius with an apparent magnitude of 2.91. It also has the proper name of Sadalsuud. Having cooled and swollen to around 50 times the Sun's diameter, it is around 2200 times as luminous as the Sun. It is around 6.4 times as massive as the Sun and around 56 million years old. Sadalsuud is 540 ± 20 light-years from Earth. Alpha Aquarii, also known as Sadalmelik, has an apparent magnitude of 2.94. It is 520 ± 20 light-years distant from Earth, and is around 6.5 times as massive as the Sun and 3000 times as luminous. It is 53 million years old.

γ Aquarii, also called Sadachbia, is a white main sequence star of spectral type star of spectral type A0V that is between 158 and 315 million years old and is around two and a half times the Sun's mass, and double its radius. Of magnitude 3.85, it is 164 ± 9 light years away. It has a luminosity of . The name Sadachbia comes from the Arabic for "lucky stars of the tents", "sa'd al-akhbiya".

δ Aquarii, also known as Skat or Scheat is a blue-white A2 spectral type star of magnitude 3.27 and luminosity of .

ε Aquarii, also known as Albali, is a blue-white A1 spectral type star with an apparent magnitude of 3.77, an absolute magnitude of 1.2, and a luminosity of .

ζ Aquarii is an F2 spectral type double star; both stars are white. Overall, it appears to be of magnitude 3.6 and luminosity of . The primary has a magnitude of 4.53 and the secondary a magnitude of 4.31, but both have an absolute magnitude of 0.6. Its orbital period is 760 years; the two components are currently moving farther apart.

θ Aquarii, sometimes called Ancha, is a G8 spectral type star with an apparent magnitude of 4.16 and an absolute magnitude of 1.4.

λ Aquarii, also called Hudoor or Ekchusis, is an M2 spectral type star of magnitude 3.74 and luminosity of .

ξ Aquarii, also called Bunda, is an A7 spectral type star with an apparent magnitude of 4.69 and an absolute magnitude of 2.4.

π Aquarii, also called Seat, is a B0 spectral type star with an apparent magnitude of 4.66 and an absolute magnitude of -4.1.

Twelve exoplanet systems have been found in Aquarius as of 2013. Gliese 876, one of the nearest stars to Earth at a distance of 15 light-years, was the first red dwarf star to be found to possess a planetary system. It is orbited by four planets, including one terrestrial planet 6.6 times the mass of Earth. The planets vary in orbital period from 2 days to 124 days. 91 Aquarii is an orange giant star orbited by one planet, 91 Aquarii b. The planet's mass is 2.9 times the mass of Jupiter, and its orbital period is 182 days. Gliese 849 is a red dwarf star orbited by the first known long-period Jupiter-like planet, Gliese 849 b. The planet's mass is 0.99 times that of Jupiter and its orbital period is 1,852 days.

There are also less-prominent systems in Aquarius. WASP-6, a type G8 star of magnitude 12.4, is host to one exoplanet, WASP-6 b. The star is 307 parsecs from Earth and has a mass of 0.888 solar masses and a radius of 0.87 solar radii. WASP-6 b was discovered in 2008 by the transit method. It orbits its parent star every 3.36 days at a distance of 0.042 astronomical units (AU). It is 0.503 Jupiter masses but has a proportionally larger radius of 1.224 Jupiter radii. HD 206610, a K0 star located 194 parsecs from Earth, is host to one planet, HD 206610 b. The host star is larger than the Sun; more massive at 1.56 solar masses and larger at 6.1 solar radii. The planet was discovered by the radial velocity method in 2010 and has a mass of 2.2 Jupiter masses. It orbits every 610 days at a distance of 1.68 AU. Much closer to its sun is WASP-47 b, which orbits every 4.15 days only 0.052 AU from its sun, yellow dwarf (G9V) WASP-47. WASP-47 is close in size to the Sun, having a radius of 1.15 solar radii and a mass even closer at 1.08 solar masses. WASP-47 b was discovered in 2011 by the transit method, like WASP-6 b. It is slightly larger than Jupiter with a mass of 1.14 Jupiter masses and a radius of 1.15 Jupiter masses.

There are several more single-planet systems in Aquarius. HD 210277, a magnitude 6.63 yellow star located 21.29 parsecs from Earth, is host to one known planet: HD 210277 b. The 1.23 Jupiter mass planet orbits at nearly the same distance as Earth orbits the Sun1.1 AU, though its orbital period is significantly longer at around 442 days. HD 210277 b was discovered earlier than most of the other planets in Aquarius, detected by the radial velocity method in 1998. The star it orbits resembles the Sun beyond their similar spectral class; it has a radius of 1.1 solar radii and a mass of 1.09 solar masses. HD 212771 b, a larger planet at 2.3 Jupiter masses, orbits host star HD 212771 at a distance of 1.22 AU. The star itself, barely below the threshold of naked-eye visibility at magnitude 7.6, is a G8IV (yellow subgiant) star located 131 parsecs from Earth. Though it has a similar mass to the Sun1.15 solar massesit is significantly less dense with its radius of 5 solar radii. Its lone planet was discovered in 2010 by the radial velocity method, like several other exoplanets in the constellation.

As of 2013, there were only two known multiple-planet systems within the bounds of Aquarius: the Gliese 876 and HD 215152 systems. The former is quite prominent; the latter has only two planets and has a host star farther away at 21.5 parsecs. The HD 215152 system consists of the planets HD 215152 b and HD 215152 c orbiting their K0-type, magnitude 8.13 sun. Both discovered in 2011 by the radial velocity method, the two tiny planets orbit very close to their host star. HD 215152 c is the larger at 0.0097 Jupiter masses (still significantly larger than the Earth, which weighs in at 0.00315 Jupiter masses); its smaller sibling is barely smaller at 0.0087 Jupiter masses. The error in the mass measurements (0.0032 and respectively) is large enough to make this discrepancy statistically insignificant. HD 215152 c also orbits further from the star than HD 215152 b, 0.0852 AU compared to 0.0652.

On 23 February 2017, NASA announced that ultracool dwarf star TRAPPIST-1 in Aquarius has seven Earth-like rocky planets

Because of its position away from the galactic plane, the majority of deep-sky objects in Aquarius are galaxies, globular clusters, and planetary nebulae. Aquarius contains three deep sky objects that are in the Messier catalog: the globular clusters Messier 2, Messier 72, and the open cluster Messier 73. Two well-known planetary nebulae are also located in Aquarius: the Saturn Nebula (NGC 7009), to the southeast of μ Aquarii; and the famous Helix Nebula (NGC 7293), southwest of δ Aquarii.

M2, also catalogued as NGC 7089, is a rich globular cluster located approximately 37,000 light-years from Earth. At magnitude 6.5, it is viewable in small-aperture instruments, but a 100 mm aperture telescope is needed to resolve any stars. M72, also catalogued as NGC 6981, is a small 9th magnitude globular cluster located approximately 56,000 light-years from Earth. M73, also catalogued as NGC 6994, is an open cluster with highly disputed status.

Aquarius is also home to several planetary nebulae. NGC 7009, also known as the Saturn Nebula, is an 8th magnitude planetary nebula located 3,000 light-years from Earth. It was given its moniker by the 19th century astronomer Lord Rosse for its resemblance to the planet Saturn in a telescope; it has faint protrusions on either side that resemble Saturn's rings. It appears blue-green in a telescope and has a central star of magnitude 11.3. Compared to the Helix Nebula, another planetary nebula in Aquarius, it is quite small. NGC 7293, also known as the Helix Nebula, is the closest planetary nebula to Earth at a distance of 650 light-years. It covers 0.25 square degrees, making it also the largest planetary nebula as seen from Earth. However, because it is so large, it is only viewable as a very faint object, though it has a fairly high integrated magnitude of 6.0.

One of the visible galaxies in Aquarius is NGC 7727, of particular interest for amateur astronomers who wish to discover or observe supernovae. A spiral galaxy (type S), it has an integrated magnitude of 10.7 and is 3 by 3 arcseconds. NGC 7252 is a tangle of stars resulting from the collision of two large galaxies and is known as the Atoms-for-Peace galaxy because of its resemblance to a cartoon atom.

There are three major meteor showers with radiants in Aquarius: the Eta Aquariids, the Delta Aquariids, and the Iota Aquariids.

The Eta Aquariids are the strongest meteor shower radiating from Aquarius. It peaks between 5 and 6 May with a rate of approximately 35 meteors per hour. Originally discovered by Chinese astronomers in 401, Eta Aquariids can be seen coming from the Water Jar beginning on April 21 and as late as May 12. The parent body of the shower is Halley's Comet, a periodic comet. Fireballs are common shortly after the peak, approximately between May 9 and May 11. The normal meteors appear to have yellow trails.

The Delta Aquariids is a double radiant meteor shower that peaks first on 29 July and second on 6 August. The first radiant is located in the south of the constellation, while the second radiant is located in the northern circlet of Pisces asterism. The southern radiant's peak rate is about 20 meteors per hour, while the northern radiant's peak rate is about 10 meteors per hour.

The Iota Aquariids is a fairly weak meteor shower that peaks on 6 August, with a rate of approximately 8 meteors per hour.

, the Sun appears in the constellation Aquarius from 16 February to 11 March. In tropical astrology, the Sun is considered to be in the sign Aquarius from 20 January to 19 February, and in sidereal astrology, from 15 February to 14 March.

Aquarius is also associated with the Age of Aquarius, a concept popular in 1960s counterculture. Despite this prominence, the Age of Aquarius will not dawn until the year 2597, as an astrological age does not begin until the Sun is in a particular constellation on the vernal equinox
Category:Constellations
Category:Equatorial constellations
Category:Constellations listed by PtolemyAnime

The word "anime" is the Japanese term for "animation", which means all forms of animated media. Outside Japan, "anime" refers specifically to animation from Japan or as a Japanese-disseminated animation style often characterized by colorful graphics, vibrant characters and fantastical themes. The culturally abstract approach to the word's meaning may open up the possibility of anime produced in countries other than Japan. For simplicity, many Westerners strictly view anime as a Japanese animation product. Some scholars suggest defining anime as specifically or quintessentially Japanese may be related to a new form of Orientalism.

The earliest commercial Japanese animation dates to 1917, and Japanese anime production has since continued to increase steadily. The characteristic anime art style emerged in the 1960s with the works of Osamu Tezuka and spread internationally in the late twentieth century, developing a large domestic and international audience. Anime is distributed theatrically, by way of television broadcasts, directly to home media, and over the Internet. It is classified into numerous genres targeting diverse broad and niche audiences.

Anime is a diverse art form with distinctive production methods and techniques that have been adapted over time in response to emergent technologies. It consists of an ideal story-telling mechanism, combining graphic art, characterization, cinematography, and other forms of imaginative and individualistic techniques. The production of anime focuses less on the animation of movement and more on the realism of settings as well as the use of camera effects, including panning, zooming, and angle shots. Being hand-drawn, anime is separated from reality by a crucial gap of fiction that provides an ideal path for escapism that audiences can immerse themselves into with relative ease. Diverse art styles are used and character proportions and features can be quite varied, including characteristically large emotive or realistically sized eyes.

The anime industry consists of over 430 production studios, including major names like Studio Ghibli, Gainax, and Toei Animation. Despite comprising only a fraction of Japan's domestic film market, anime makes up a majority of Japanese DVD sales. It has also seen international success after the rise of English-dubbed programming. This rise in international popularity has resulted in non-Japanese productions using the anime art style. Whether these works are anime-influenced animation or proper anime is a subject for debate amongst fans. Japanese anime accounts for 60% of the world's animated cartoon television shows, as of 2016.

Anime is an art form, specifically animation, that includes all genres found in cinema, but it can be mistakenly classified as a genre. In Japanese, the term "anime" is used as a blanket term to refer to all forms of animation from around the world. In English, "anime" () is more restrictively used to denote a "Japanese-style animated film or television entertainment" or as "a style of animation created in Japan".

The etymology of the word "anime" is disputed. The English term "animation" is written in Japanese "katakana" as ("animēshon", ) and is ("anime") in its shortened form. The pronunciation of "anime" in Japanese differs from pronunciations in other languages such as Standard English (pronunciation: ), which has different vowels and stress with regards to Japanese, where each mora carries equal stress. As with a few other Japanese words such as "saké", "Pokémon", and "Kobo Abé," English-language texts sometimes spell "anime" as "animé" (as in French), with an acute accent over the final "e", to cue the reader to pronounce the letter, not to leave it silent as Standard English orthography may suggest.

Some sources claim that "anime" derives from the French term for animation "dessin animé", but others believe this to be a myth derived from the French popularity of the medium in the late 1970s and 1980s. In English, "anime"—when used as a common noun—normally functions as a mass noun. (For example: "Do you watch anime?" or "How much anime have you collected?") Prior to the widespread use of "anime", the term "Japanimation" was prevalent throughout the 1970s and 1980s. In the mid-1980s, the term "anime" began to supplant "Japanimation". In general, the latter term now only appears in period works where it is used to distinguish and identify Japanese animation.

The word "anime" has also been criticised, e.g. in 1987, when Hayao Miyazaki stated that he despised the truncated word "anime" because to him it represented the desolation of the Japanese animation industry. He equated the desolation with animators lacking motivation and with mass-produced, overly expressionistic products relying upon a fixed iconography of facial expressions and protracted and exaggerated action scenes but lacking depth and sophistication in that they do not attempt to convey emotion or thought.

The first format of anime was theatrical viewing which originally began with commercial productions in 1917. Originally the animated flips were crude and required played musical components before adding sound and vocal components to the production. On July 14, 1958, Nippon Television aired "Mogura no Abanchūru" ("Mole's Adventure"), both the first televised and first color anime to debut. It wasn't until the 1960s when the first televised series were broadcast and it has remained a popular medium since. Works released in a direct to video format are called "original video animation" (OVA) or "original animation video" (OAV); and are typically not released theatrically or televised prior to home media release. The emergence of the Internet has led some animators to distribute works online in a format called "original net anime" (ONA).

The home distribution of anime releases were popularized in the 1980s with the VHS and LaserDisc formats. The VHS NTSC video format used in both Japan and the United States is credited as aiding the rising popularity of anime in the 1990s. The Laser Disc and VHS formats were transcended by the DVD format which offered the unique advantages; including multiple subtitling and dubbing tracks on the same disc. The DVD format also has its drawbacks in the its usage of region coding; adopted by the industry to solve licensing, piracy and export problems and restricted region indicated on the DVD player. The Video CD (VCD) format was popular in Hong Kong and Taiwan, but became only a minor format in the United States that was closely associated with bootleg

Japanese animation began in the early 20th century, when Japanese filmmakers experimented with the animation techniques also pioneered in France, Germany, the United States and Russia. A claim for the earliest Japanese animation is "Katsudō Shashin", an undated and private work by an unknown creator. In 1917, the first professional and publicly displayed works began to appear. Animators such as Ōten Shimokawa and Seitarou Kitayama produced numerous works, with the oldest surviving film being Kouchi's "Namakura Gatana", a two-minute clip of a samurai trying to test a new sword on his target only to suffer defeat. The 1923 Great Kantō earthquake resulted in widespread destruction to Japan's infrastructure and the destruction of Shimokawa's warehouse, destroying most of these early works.

By the 1930s animation was well established in Japan as an alternative format to the live-action industry. It suffered competition from foreign producers and many animators, Noburō Ōfuji and Yasuji Murata, who still worked in cheaper cutout animation rather than cel animation. Other creators, Kenzō Masaoka and Mitsuyo Seo, nonetheless made great strides in animation technique; they benefited from the patronage of the government, which employed animators to produce educational shorts and propaganda. The first talkie anime was "Chikara to Onna no Yo no Naka", produced by Masaoka in 1933. By 1940, numerous anime artists' organizations had risen, including the Shin Mangaha Shudan and Shin Nippon Mangaka. The first feature-length animated film was "Momotaro's Divine Sea Warriors" directed by Seo in 1944 with sponsorship by the Imperial Japanese Navy

The success of The Walt Disney Company's 1937 feature film "Snow White and the Seven Dwarfs" profoundly influenced many Japanese animators. In the 1960s, manga artist and animator Osamu Tezuka adapted and simplified many Disney animation techniques to reduce costs and to limit the number of frames in productions. He intended this as a temporary measure to allow him to produce material on a tight schedule with inexperienced animation staff. "Three Tales", aired in 1960, was the first anime shown on television. The first anime television series was "Otogi Manga Calendar", aired from 1961 to 1964.

The 1970s saw a surge of growth in the popularity of "manga", Japanese comic books and graphic novels, many of which were later animated. The work of Osamu Tezuka drew particular attention: he has been called a "legend" and the "god of manga". His work—and that of other pioneers in the field—inspired characteristics and genres that remain fundamental elements of anime today. The giant robot genre (known as "mecha" outside Japan), for instance, took shape under Tezuka, developed into the Super Robot genre under Go Nagai and others, and was revolutionized at the end of the decade by Yoshiyuki Tomino who developed the Real Robot genre. Robot anime like the "Gundam" and "The Super Dimension Fortress Macross" series became instant classics in the 1980s, and the robot genre of anime is still one of the most common in Japan and worldwide today. In the 1980s, anime became more accepted in the mainstream in Japan (although less than manga), and experienced a boom in production. Following a few successful adaptations of anime in overseas markets in the 1980s, anime gained increased acceptance in those markets in the 1990s and even more at the turn of the 21st century. In 2002, "Spirited Away", a Studio Ghibli production directed by Hayao Miyazaki won the Golden Bear at the Berlin International Film Festival and in 2003 at the 75th Academy Awards it won the Academy Award for Best Animated Feature. 

Anime are often classified by target demographic, including , , and a diverse range of genres targeting an adult audience. Shoujo and shounen anime sometimes contain elements popular with children of both sexes in an attempt to gain crossover appeal. Adult anime may feature a slower pace or greater plot complexity that younger audiences may typically find unappealing, as well as adult themes and situations. A subset of adult anime works featuring pornographic elements are labeled "R18" in Japan, and are internationally known as "hentai" (originating from ). By contrast, some anime subgenres incorporate "ecchi", sexual themes or undertones without depictions of sexual intercourse, as typified in the comedic or harem genres; due to its popularity among adolescent and adult anime enthusiasts, the inclusion of such elements is considered a form of fan service. Some genres explore homosexual romances, such as "yaoi" (male homosexuality) and "yuri" (female homosexuality). While often used in a pornographic context, the terms can also be used broadly in a wider context to describe or focus on the themes or the development of the relationships themselves.

Anime's genre classification differs from other types of animation and does not lend itself to simple classification. Gilles Poitras compared the labeling "Gundam 0080" and its complex depiction of war as a "giant robot" anime akin to simply labeling "War and Peace" a "war novel". Science fiction is a major anime genre and includes important historical works like Tezuka's "Astro Boy" and Yokoyama's "Tetsujin 28-go". A major subgenre of science fiction is mecha, with the "Gundam" metaseries being iconic. The diverse fantasy genre includes works based on Asian and Western traditions and folklore; examples include the Japanese feudal fairytale "InuYasha", and the depiction of Scandinavian goddesses who move to Japan to maintain a computer called Yggdrasil in "Ah! My Goddess". Genre crossing in anime is also prevalent, such as the blend of fantasy and comedy in "Dragon Half", and the incorporation of slapstick humor in the crime anime film "Castle of Cagliostro". Other subgenres found in anime include magical girl, harem, sports, martial arts, literary adaptations, medievalism

Anime differs greatly from other forms of animation by its diverse art styles, methods of animation, its production, and its process. Visually, anime is a diverse art form that contains a wide variety of art styles, differing from one creator, artist, and studio. While no one art style predominates anime as a whole, they do share some similar attributes in terms of animation technique and character design.

Anime follows the typical production of animation, including storyboarding, voice acting, character design, and cel production ("Shirobako", itself a series, highlights many of the aspects involved in anime production). Since the 1990s, animators have increasingly used computer animation to improve the efficiency of the production process. Artists like Noburō Ōfuji pioneered the earliest anime works, which were experimental and consisted of images drawn on blackboards, stop motion animation of paper cutouts, and silhouette animation. Cel animation grew in popularity until it came to dominate the medium. In the 21st century, the use of other animation techniques is mostly limited to independent short films, including the stop motion puppet animation work produced by Tadahito Mochinaga, Kihachirō Kawamoto and Tomoyasu Murata. Computers were integrated into the animation process in the 1990s, with works such as "Ghost in the Shell" and "Princess Mononoke" mixing cel animation with computer-generated images. Fuji Film, a major cel production company, announced it would stop cel production, producing an industry panic to procure cel imports and hastening the switch to digital processes.

Prior to the digital era, anime was produced with traditional animation methods using a pose to pose approach. The majority of mainstream anime uses fewer expressive key frames and more in-between animation.

Japanese animation studios were pioneers of many limited animation techniques, and have given anime a distinct set of conventions. Unlike Disney animation, where the emphasis is on the movement, anime emphasizes the art quality and let limited animation techniques make up for the lack of time spent on movement. Such techniques are often used not only to meet deadlines but also as artistic devices. Anime scenes place emphasis on achieving three-dimensional views, and backgrounds are instrumental in creating the atmosphere of the work. The backgrounds are not always invented and are occasionally based on real locations, as exemplified in "Howl's Moving Castle" and "The Melancholy of Haruhi Suzumiya". Oppliger stated that anime is one of the rare mediums where putting together an all-star cast usually comes out looking "tremendously impressive".

The cinematic effects of anime differentiates itself from the stage plays found in American animation. Anime is cinematically shot as if by camera, including panning, zooming, distance and angle shots to more complex dynamic shots that would be difficult to produce in reality. In anime, the animation is produced before the voice acting, contrary to American animation which does the voice acting first; this can cause lip sync errors in the Japanese version.

Body proportions of human anime characters tend to accurately reflect the proportions of the human body in reality. The height of the head is considered by the artist as the base unit of proportion. Head heights can vary, but most anime characters are about seven to eight heads tall. Anime artists occasionally make deliberate modifications to body proportions to produce super deformed characters that feature a disproportionately small body compared to the head; many super deformed characters are two to four heads tall. Some anime works like "Crayon Shin-chan" completely disregard these proportions, in such a way that they resemble cariacatured Western cartoons.

A common anime character design convention is exaggerated eye size. The animation of characters with large eyes in anime can be traced back to Osamu Tezuka, who was deeply influenced by such early animation characters as Betty Boop, who was drawn with disproportionately large eyes. Tezuka is a central figure in anime and manga history, whose iconic art style and character designs allowed for the entire range of human emotions to be depicted solely through the eyes. The artist adds variable color shading to the eyes and particularly to the cornea to give them greater depth. Generally, a mixture of a light shade, the tone color, and a dark shade is used. Cultural anthropologist Matt Thorn argues that Japanese animators and audiences do not perceive such stylized eyes as inherently more or less foreign. However, not all anime have large eyes. For example, the works of Hayao Miyazaki

Hair in anime is often unnaturally lively and colorful or uniquely styled. The movement of hair in anime is exaggerated and "hair action" is used to emphasize the action and emotions of characters for added visual effect. Poitras traces hairstyle color to cover illustrations on manga, where eye-catching artwork and colorful tones are attractive for children's manga. Despite being produced for a domestic market, anime features characters whose race or nationality is not always defined, and this is often a deliberate decision, such as in the "Pokémon" animated series.

Anime and manga artists often draw from a common canon of iconic facial expression illustrations to denote particular moods and thoughts. These techniques are often different in form than their counterparts in Western animation, and they include a fixed iconography that is used as shorthand for certain emotions and moods. For example, a male character may develop a nosebleed when aroused. A variety of visual symbols are employed, including sweat drops to depict nervousness, visible blushing for embarrassment, or glowing eyes for an intense glare.

The opening and credits sequences of most anime television episodes are accompanied by Japanese pop or rock

The animation industry consists of more than 430 production companies with some of the major studios including Toei Animation, Gainax, Madhouse, Gonzo, Sunrise, Bones, TMS Entertainment, Nippon Animation, P.A.Works, Studio Pierrot and Studio Ghibli. Many of the studios are organized into a trade association, The Association of Japanese Animations. There is also a labor union for workers in the industry, the Japanese Animation Creators Association. Studios will often work together to produce more complex and costly projects, as done with Studio Ghibli's "Spirited Away". An anime episode can cost between US$100,000 and US$300,000 to produce. In 2001, animation accounted for 7% of the Japanese film market, above the 4.6% market share for live-action works. The popularity and success of anime is seen through the profitability of the DVD market, contributing nearly 70% of total sales. According to a 2016 article on Nikkei Asian Review, Japanese television stations have bought over worth of anime from production companies "over the past few years", compared with under from overseas. There has been a rise in sales of shows to television stations in Japan, caused by late night anime with adults as the target demographic. This type of anime is less popular outside Japan, being considered "more of a niche product". "Spirited Away" (2001) is the all-time highest-grossing film in Japan. It was also the highest-grossing anime film worldwide until it was overtaken by Makoto Shinkai's 2016 film "Your Name". Anime films represent a large part of the highest-grossing Japanese films yearly in Japan, with 6 out of the top 10 in 2014, in 2015 and also in 2016.

Anime has to be licensed by companies in other countries in order to be legally released. While anime has been licensed by its Japanese owners for use outside Japan since at least the 1960s, the practice became well-established in the United States in the late 1970s to early 1980s, when such TV series as "Gatchaman" and "Captain Harlock" were licensed from their Japanese parent companies for distribution in the US market. The trend towards American distribution of anime continued into the 1980s with the licensing of titles such as "Voltron" and the 'creation' of new series such as "Robotech" through use of source material from several original series.

In the early 1990s, several companies began to experiment with the licensing of less children-oriented material. Some, such as A.D. Vision, and Central Park Media and its imprints, achieved fairly substantial commercial success and went on to become major players in the now very lucrative American anime market. Others, such as AnimEigo, achieved limited success. Many companies created directly by Japanese parent companies did not do as well, most releasing only one or two titles before completing their American operations.

Licenses are expensive, often hundreds of thousands of dollars for one series and tens of thousands for one movie. The prices vary widely; for example, "Jinki: Extend" cost only $91,000 to license while "Kurau Phantom Memory" cost $960,000. Simulcast Internet streaming rights can be cheaper, with prices around $1,000-$2,000 an episode, but can also be more expensive, with some series costing more than per episode.

The anime market for the United States was worth approximately $2.74 billion in 2009. Dubbed animation began airing in the United States in 2000 on networks like The WB and Cartoon Network's Adult Swim. In 2005, this resulted in five of the top ten anime titles having previously aired on Cartoon Network. As a part of localization, some editing of cultural references may occur to better follow the references of the non-Japanese culture. The cost of English localization averages US$10,000 per episode.

The industry has been subject to both praise and condemnation for fansubs, the addition of unlicensed and unauthorized subtitled translations of anime series or films. Fansubs, which were originally distributed on VHS bootlegged cassettes in the 1980s, have been freely available and disseminated online since the 1990s. Since this practice raises concerns for copyright and piracy issues, fansubbers tend to adhere to an unwritten moral code to destroy or no longer distribute an anime once an official translated or subtitled version becomes licensed. They also try to encourage viewers to buy an official copy of the release once it comes out in English, although fansubs typically continue to circulate through file sharing networks. Even so, the laid back regulations of the Japanese animation industry tends to overlook these issues, allowing it to grow underground and thus increasing the popularity until there is a demand for official high quality releases for animation companies. This has led to an increase in global popularity with Japanese animations, reaching $40 million in sales in 2004.

Legal international availability of anime on the Internet has changed in recent years, with simulcasts of series available on websites like Crunchyroll.

Japan External Trade Organization (JETRO) valued the domestic anime market in Japan at (), including from licensed products, in 2005. JETRO reported sales of overseas anime exports in 2004 to be (). JETRO valued the anime market in the United States at (), including in home video sales and over from licensed products, in 2005. JETRO projected in 2005 that the worldwide anime market, including sales of licensed products, would grow to (). The anime market in China was valued at in 2017, and is projected to reach by 2020.

The anime industry has several annual awards which honor the year's best works. Major annual awards in Japan include the Ōfuji Noburō Award, the Mainichi Film Award for Best Animation Film, the Animation Kobe Awards, the Japan Media Arts Festival animation awards, the Tokyo Anime Award and the Japan Academy Prize for Animation of the Year. In the United States, anime films compete in the ICv2.com Anime Awards There were also the American Anime Awards, which were designed to recognize excellence in anime titles nominated by the industry, and were held only once in 2006. Anime productions have also been nominated and won awards not exclusively for anime, like the Academy Award for Best Animated Feature or the Golden Bear.

Anime has become commercially profitable in Western countries, as demonstrated by early commercially successful Western adaptations of anime, such as "Astro Boy" and "Speed Racer". Early American adaptions in the 1960s made Japan expand into the continental European market, first with productions aimed at European and Japanese children, such as "Heidi", "Vicky the Viking" and "Barbapapa", which aired in various countries. Particularly Italy, Spain and France grew an interest into Japan's output, due to its cheap selling price and productive output. In fact, Italy imported the most anime outside of Japan. These mass imports influenced anime popularity in South American, Arabic and German markets.

The beginning of 1980 saw the introduction of Japanese anime series into the American culture. In the 1990s, Japanese animation slowly gained popularity in America. Media companies such as Viz and Mixx began publishing and releasing animation into the American market. The 1988 film "Akira" is largely credited with popularizing anime in the Western world during the early 1990s, before anime was further popularized by television shows such "Pokémon" and "Dragon Ball" in the late 1990s. The growth of the Internet later provided Western audiences an easy way to access Japanese content. This is especially the case with net services such as Netflix and Crunchyroll. As a direct result, various interests surrounding Japan has increased.

Anime clubs gave rise to anime conventions in the 1990s with the "anime boom", a period marked by increased popularity of anime. These conventions are dedicated to anime and manga and include elements like cosplay contests and industry talk panels. Cosplay, a portmanteau for "costume play", is not unique to anime and has become popular in contests and masquerades at anime conventions. Japanese culture and words have entered English usage through the popularity of the medium, including "otaku", an unflattering Japanese term commonly used in English to denote a fan of anime and manga. Another word that has arisen describing fans in the United States is "wapanese" meaning White individuals who desire to be Japanese, or later known as "weeaboo" for individuals who demonstrate a strong interest in Japanese anime subculture, which is a term that originated from abusive content posted on the popular bulletin board website 4chan.org. Anime enthusiasts have produced fan fiction and fan art, including computer wallpaper and anime music videos.

As of the 2010s, many anime fans use online communities and databases such as MyAnimeList to discuss anime and track their progress watching respective series.

One of the key points that made anime different from a handful of the Western cartoons is the potential for visceral content. Once the expectation that the aspects of visual intrigue or animation being just for children is put aside, the audience can realize that themes involving violence, suffering, sexuality, pain, and death can all be storytelling elements utilized in anime as much as other types of media. However, as anime itself became increasingly popular, its styling has been inevitably the subject of both satire and serious creative productions. "South Park"s "Chinpokomon" and "Good Times with Weapons" episodes, Adult Swim's "Perfect Hair Forever", and Nickelodeon's "Kappa Mikey" are examples of satirical depictions of Japanese culture and anime. Some works have sparked debate for blurring the lines between satire and serious "anime style" productions, such as the American anime style production "Avatar: The Last Airbender". These anime styled works have become defined as anime-influenced animation, in an attempt to classify all anime styled works of non-Japanese origin. Some creators of these works cite anime as a source of inspiration and like the French production team for "Ōban Star-Racers" moved to Tokyo to collaborate with a Japanese production team. When anime is defined as a "style" rather than as a national product it leaves open the possibility of anime being produced in other countries. A U.A.E.-Filipino produced TV series called "Torkaizer" is dubbed as the "Middle East's First Anime Show", and is currently in production, which is currently looking for funding. The web-based series "RWBY" is produced using an anime art style and has been declared to be anime. In addition, the series will be released in Japan, under the label of "anime" per the Japanese definition of the term and referenced as an "American-made anime". Netflix declared the company's intention to produce anime. In doing so, the company is offering a more accessible channel for distribution to Western markets. Defining anime as style has been contentious amongst fans, with John Oppliger stating, "The insistence on referring to original American art as Japanese "anime" or "manga" robs the work of its cultural identity."

A number of anime media franchises have gained considerable global popularity, and are among the world's highest-grossing media franchises. "Pokémon" in particular is the highest-grossing media franchise of all time, bigger than "Star Wars" and "Marvel Cinematic Universe". Other anime media franchises among the world's top 10 highest-grossing media franchises include "Hello Kitty" and "Dragon Ball", while the top 20 also includes "Fist of the North Star", "Yu-Gi-Oh", "Gundam" and "Evangelion
Category:1917 introductions
Category:Anime and manga terminology
Category:Articles including recorded pronunciations
Category:Japanese inventionsAnkara

Ankara (; ), historically known as Ancyra and Angora, is the capital of Turkey. With a population of 4,587,558 in the urban center and 5,150,072 in its province , it is Turkey's second largest city after Istanbul (the former imperial capital), having outranked İzmir in the 20th century.

On 23 April 1920 the Grand National Assembly of Turkey was established in Ankara, which became the headquarters of Atatürk and the Turkish National Movement during the Turkish War of Independence. Ankara became the new Turkish capital upon the establishment of the Republic on 29 October 1923, succeeding in this role the former Turkish capital Istanbul (Constantinople) following the fall of the Ottoman Empire. The government is a prominent employer, but Ankara is also an important commercial and industrial city, located at the center of Turkey's road and railway networks. The city gave its name to the Angora wool shorn from Angora rabbits, the long-haired Angora goat (the source of mohair), and the Angora cat. The area is also known for its pears, honey and muscat grapes. Although situated in one of the driest places of Turkey and surrounded mostly by steppe vegetation except for the forested areas on the southern periphery, Ankara can be considered a green city in terms of green areas per inhabitant, at per head.

Ankara is a very old city with various Hittite, Phrygian, Hellenistic, Roman, Byzantine, and Ottoman archaeological sites. The historical center of town is a rocky hill rising over the left bank of the Ankara Çayı, a tributary of the Sakarya River, the classical Sangarius. The hill remains crowned by the ruins of the old citadel. Although few of its outworks have survived, there are well-preserved examples of Roman and Ottoman architecture throughout the city, the most remarkable being the 20  Temple of Augustus and Rome that boasts the Monumentum Ancyranum, the inscription recording the "Res Gestae Divi Augusti".

The orthography of the name Ankara has varied over the ages. It has been identified with the Hittite cult center "Ankuwaš", although this remains a matter of debate. In classical antiquity and during the medieval period, the city was known as "Ánkyra" (,  "anchor") in Greek and "Ancyra" in Latin; the Galatian Celtic name was probably a similar variant. Following its annexation by the Seljuk Turks in 1073, the city became known in many European languages as "Angora"; it was also known in Ottoman Turkish as "Engürü". The form "Angora" is preserved in the names of breeds of many different kinds of animals, and in the names of several locations in the US (see Angora).

Ankara has a hot-summer Mediterranean climate (Köppen "Csa") which closely borders a hot summer Mediterranean continental climate (Köppen "Dsa"). Under the Trewartha climate classification, Ankara has a middle latitude steppe climate ("BSk"). Due to its elevation and inland location, Ankara has cold, somewhat snowy winters and hot, dry summers. Rainfall occurs mostly during the spring and autumn. Ankara lies in USDA Hardiness zone

Ankara had a population of 75,000 in 1927. In 2013, Ankara Province had a population of 5,045,083.

When Ankara became the capital of the Republic of Turkey in 1923, it was designated as a planned city for 500,000 future inhabitants. During the 1920s, 1930s and 1940s, the city grew in a planned and orderly pace. However, from the 1950s onward, the city grew much faster than envisioned, because unemployment and poverty forced people to migrate from the countryside into the city in order to seek a better standard of living. As a result, many illegal houses called gecekondu were built around the city, causing the unplanned and uncontrolled urban landscape of Ankara, as not enough planned housing could be built fast enough. Although precariously built, the vast majority of them have electricity, running water and modern household amenities.

Nevertheless, many of these gecekondus have been replaced by huge public housing projects in the form of tower blocks such as Elvankent, Eryaman and Güzelkent

The region's history can be traced back to the Bronze Age Hattic civilization, which was succeeded in the 2nd millennium BC by the Hittites, in the 10th century BC by the Phrygians, and later by the Lydians, Persians, Greeks, Galatians, Romans, Byzantines, and Turks (the Seljuk Sultanate of Rûm, the Ottoman Empire and finally republican Turkey).

The oldest settlements in and around the city center of Ankara belonged to the Hattic civilization which existed during the Bronze Age and was gradually absorbed c. 2000–1700 BC by the Indo-European Hittites. The city grew significantly in size and importance under the Phrygians starting around 1000 BC, and experienced a large expansion following the mass migration from Gordion, (the capital of Phrygia), after an earthquake which severely damaged that city around that time. In Phrygian tradition, King Midas was venerated as the founder of Ancyra, but Pausanias mentions that the city was actually far older, which accords with present archaeological knowledge.

Phrygian rule was succeeded first by Lydian and later by Persian rule, though the strongly Phrygian character of the peasantry remained, as evidenced by the gravestones of the much later Roman period. Persian sovereignty lasted until the Persians' defeat at the hands of Alexander the Great who conquered the city in 333 BC. Alexander came from Gordion to Ankara and stayed in the city for a short period. After his death at Babylon in 323 BC and the subsequent division of his empire among his generals, Ankara and its environs fell into the share of Antigonus.

Another important expansion took place under the Greeks of Pontos who came there around 300 BC and developed the city as a trading center for the commerce of goods between the Black Sea ports and Crimea to the north; Assyria, Cyprus, and Lebanon to the south; and Georgia, Armenia and Persia to the east. By that time the city also took its name Ἄγκυρα ("Ánkyra", meaning "anchor" in Greek

In 278 BC, the city, along with the rest of central Anatolia, was occupied by a Celtic group, the Galatians, who were the first to make Ankara one of their main tribal centers, the headquarters of the Tectosages tribe. Other centers were Pessinos, today's "Balhisar", for the Trocmi tribe, and Tavium, to the east of Ankara, for the "Tolstibogii" tribe. The city was then known as "Ancyra". The Celtic element was probably relatively small in numbers; a warrior aristocracy which ruled over Phrygian-speaking peasants. However, the Celtic language continued to be spoken in Galatia for many centuries. At the end of the 4th century, St. Jerome, a native of Dalmatia, observed that the language spoken around Ankara was very similar to that being spoken in the northwest of the Roman world near Trier

The city was subsequently passed under the control of the Roman Empire. In 25 BC, Emperor Augustus raised it to the status of a "polis" and made it the capital city of the Roman province of Galatia. Ankara is famous for the "Monumentum Ancyranum" ("Temple of Augustus and Rome") which contains the official record of the "Acts of Augustus", known as the "Res Gestae Divi Augusti", an inscription cut in marble on the walls of this temple. The ruins of Ancyra still furnish today valuable bas-reliefs, inscriptions and other architectural fragments. Two other Galatian tribal centers, Tavium near Yozgat, and Pessinus

An estimated 200,000 people lived in Ancyra in good times during the Roman Empire, a far greater number than was to be the case from after the fall of the Roman Empire until the early 20th century. A small river, the Ankara Çayı, ran through the center of the Roman town. It has now been covered and diverted, but it formed the northern boundary of the old town during the Roman, Byzantine and Ottoman periods. Çankaya, the rim of the majestic hill to the south of the present city center, stood well outside the Roman city, but may have been a summer resort. In the 19th century, the remains of at least one Roman villa or large house were still standing not far from where the Çankaya Presidential Residence stands today. To the west, the Roman city extended until the area of the Gençlik Park and Railway Station, while on the southern side of the hill, it may have extended downwards as far as the site presently occupied by Hacettepe University. It was thus a sizeable city by any standards and much larger than the Roman towns of Gaul or Britannia.

Ancyra's importance rested on the fact that it was the junction point where the roads in northern Anatolia running north–south and east–west intersected, giving it major strategic importance for Rome's eastern frontier. The great imperial road running east passed through Ankara and a succession of emperors and their armies came this way. They were not the only ones to use the Roman highway network, which was equally convenient for invaders. In the second half of the 3rd century, Ancyra was invaded in rapid succession by the Goths coming from the west (who rode far into the heart of Cappadocia, taking slaves and pillaging) and later by the Arabs. For about a decade, the town was one of the western outposts of one of Palmyrean empress Zenobia in the Syrian Desert, who took advantage of a period of weakness and disorder in the Roman Empire to set up a short-lived state of her own.

The town was reincorporated into the Roman Empire under Emperor Aurelian in 272. The tetrarchy, a system of multiple (up to four) emperors introduced by Diocletian (284–305), seems to have engaged in a substantial programme of rebuilding and of road construction from Ankara westwards to Germe and Dorylaeum (now Eskişehir).

In its heyday, Roman Ankara was a large market and trading center but it also functioned as a major administrative capital, where a high official ruled from the city's Praetorium, a large administrative palace or office. During the 3rd century, life in Ancyra, as in other Anatolian towns, seems to have become somewhat militarized in response to the invasions and instability of the town.

The city is well known during the 4th century as a centre of Christian activity (see also below), due to frequent imperial visits, and through the letters of the pagan scholar Libanius. Bishop Marcellus of Ancyra and Basil of Ancyra were active in the theological controversies of their day, and the city was the site of no less than three church synods in 314, 358 and 375, the latter two in favour of Arianism. The city was visited by Emperor Constans I (r. 337–350) in 347 and 350, Julian (r. 361–363) during his Persian campaign in 362, and Julian's successor Jovian (r. 363–364) in winter 363/364 (he entered his consulship while in the city). After Jovian's death soon after, Valentinian I (r. 364–375) was acclaimed emperor at Ancyra, and in the next year his brother Valens (r. 364–378) used Ancyra as his base against the usurper Procopius. When the province of Galatia was divided sometime in 396/99, Ancyra remained the civil capital of Galatia I, as well as its ecclesiastical centre (metropolitan see). Emperor Arcadius (r. 395–408) frequently used the city as his summer residence, and some information about the ecclesiastical affairs of the city during the early 5th century is found in the works of Palladius of Galatia and Nilus of Galatia.

In 479, the rebel Marcian attacked the city, without being able to capture it. In 610/11, Comentiolus, brother of Emperor Phocas (r. 602–610), launched his own unsuccessful rebellion in the city against Heraclius (r. 610–641). Ten years later, in 620 or more likely 622, it was captured by the Sassanid Persians during the Byzantine–Sassanid War of 602–628. Although the city returned to Byzantine hands after the end of the war, the Persian presence left traces in the city's archaeology, and likely began the process of its transformation from a late antique city to a medieval fortified settlement.

In 654, the city was captured for the first time by the Arabs of the Rashidun Caliphate, under Muawiyah, the future founder of the Umayyad Caliphate. At about the same time, the themes were established in Anatolia, and Ancyra became capital of the Opsician Theme, which was the largest and most important theme until it was split up under Emperor Constantine V (r. 741–775); Ancyra then became the capital of the new Bucellarian Theme. The city was attacked without success by Abbasid forces in 776 and in 798/99. In 805, Emperor Nikephoros I (r. 802–811) strengthened its fortifications, a fact which probably saved it from sack during the large-scale invasion of Anatolia by Caliph Harun al-Rashid in the next year. Arab sources report that Harun and his successor al-Ma'mun (r. 813–833) took the city, but this information is later invention. In 838, however, during the Amorium campaign, the armies of Caliph al-Mu'tasim (r. 833–842) converged and met at the city; abandoned by its inhabitants, Ancara was razed to the ground, before the Arab armies went on to besiege and destroy Amorium. In 859, Emperor Michael III (r. 842–867) came to the city during a campaign against the Arabs, and ordered its fortifications restored. In 872, the city was menaced, but not taken, by the Paulicians under Chrysocheir. The last Arab raid to reach the city was undertaken in 931, by the Abbasid governor of Tarsus, Thamal al-Dulafi

After the Battle of Manzikert in 1071, the Seljuk Turks overran much of Anatolia. By 1073, the Turkish settlers had reached the vicinity of Ancyra, and the city was captured shortly after, at the latest by the time of the rebellion of Nikephoros Melissenos in 1081. In 1101, when the Crusade under Raymond IV of Toulouse arrived, the city had been under Danishmend control for some time. The Crusaders captured the city, and handed it over to the Byzantine emperor Alexios I Komnenos (r. 1081–1118). Byzantine rule did not last long, and the city was captured by the Seljuk Sultanate of Rum at some unknown point; in 1127, it returned to Danishmend control until 1143, when the Seljuks of Rum retook it.

After the Battle of Köse Dağ in 1243, in which the Mongols defeated the Seljuks, most of Anatolia became part of the dominion of the Mongols. Taking advantage of Seljuk decline, a semi-religious cast of craftsmen and trade people named "Ahiler" chose Ankara as their independent city-state in 1290. Orhan I, the second Bey of the Ottoman Empire, captured the city in 1356. Timur defeated Bayezid I at the Battle of Ankara in 1402 and took the city, but in 1403 Ankara was again under Ottoman control.

The Levant Company maintained a factory in the town from 1639 to 1768. In the 19th century, its population was estimated at 20,000 to 60,000. It was sacked by Egyptians under Ibrahim Pasha in 1832. Prior to World War I, the town had a British consulate

Following the Ottoman defeat at World War I, the Ottoman capital Constantinople (modern Istanbul) and much of Anatolia were occupied by the Allies, who planned to share these lands between Armenia, France, Greece, Italy and the United Kingdom, leaving for the Turks the core piece of land in central Anatolia. In response, the leader of the Turkish nationalist movement, Mustafa Kemal Atatürk, established the headquarters of his resistance movement in Ankara in 1920. After the Turkish War of Independence was won and the Treaty of Sèvres was superseded by the Treaty of Lausanne (1923), the Turkish nationalists replaced the Ottoman Empire with the Republic of Turkey on 29 October 1923. A few days earlier, Ankara had officially replaced Constantinople as the new Turkish capital city, on 13 October 1923.

After Ankara became the capital of the newly founded Republic of Turkey, new development divided the city into an old section, called "Ulus", and a new section, called "Yenişehir". Ancient buildings reflecting Roman, Byzantine, and Ottoman history and narrow winding streets mark the old section. The new section, now centered on Kızılay Square, has the trappings of a more modern city: wide streets, hotels, theaters, shopping malls, and high-rises. Government offices and foreign embassies are also located in the new section. Ankara has experienced a phenomenal growth since it was made Turkey's capital in 1923, when it was "a small town of no importance". In 1924, the year after the government had moved there, Ankara had about 35,000 residents. By 1927 there were 44,553 residents and by 1950 the population had grown to 286,781. Ankara continued to grow rapidly during the latter half of the 20th century and eventually outranked Izmir as Turkey's second largest city, after Istanbul. Ankara's urban population reached 4,587,558 in 2014, while the population of Ankara Province reached 5,150,072 in 2015.

Early Christian martyrs of Ancyra, about whom little is known, included Proklos and Hilarios who were natives of the otherwise unknown nearby village of Kallippi, and suffered repression under the emperor Trajan
As in other Roman towns, the reign of Diocletian marked the culmination of the persecution of the Christians. In 303, Ancyra was one of the towns where the co-Emperors Diocletian and his deputy Galerius launched their anti-Christian persecution. In Ancyra, their first target was the 38-year-old Bishop of the town, whose name was Clement. Clement's life describes how he was taken to Rome, then sent back, and forced to undergo many interrogations and hardship before he, and his brother, and various companions were put to death. The remains of the church of St. Clement can be found today in a building just off Işıklar Caddesi in the Ulus district. Quite possibly this marks the site where Clement was originally buried. Four years later, a doctor of the town named Plato and his brother Antiochus also became celebrated martyrs under Galerius. Theodotus of Ancyra is also venerated as a saint.

However, the persecution proved unsuccessful and in 314 Ancyra was the center of an important council of the early church; its 25 disciplinary canons constitute one of the most important documents in the early history of the administration of the Sacrament of Penance. The synod also considered ecclesiastical policy for the reconstruction of the Christian Church after the persecutions, and in particular the treatment of "lapsi"—Christians who had given in to forced paganism (sacrifices) to avoid martyrdom

Though paganism was probably tottering in Ancyra in Clement's day, it may still have been the majority religion. Twenty years later, Christianity and monotheism had taken its place. Ancyra quickly turned into a Christian city, with a life dominated by monks and priests and theological disputes. The town council or senate gave way to the bishop as the main local figurehead. During the middle of the 4th century, Ancyra was involved in the complex theological disputes over the nature of Christ, and a form of Arianism seems to have originated there.

In 362–363, the Emperor Julian passed through Ancyra on his way to an ill-fated campaign against the Persians, and according to Christian sources, engaged in a persecution of various holy men. The stone base for a statue, with an inscription describing Julian as "Lord of the whole world from the British Ocean to the barbarian nations", can still be seen, built into the eastern side of the inner circuit of the walls of Ankara Castle. The Column of Julian which was erected in honor of the emperor's visit to the city in 362 still stands today. In 375, Arian bishops met at Ancyra and deposed several bishops, among them St. Gregory of Nyssa.

In the late 4th century, Ancyra became something of an imperial holiday resort. After Constantinople became the East Roman capital, emperors in the 4th and 5th centuries would retire from the humid summer weather on the Bosporus to the drier mountain atmosphere of Ancyra. Theodosius II (408–450) kept his court in Ancyra in the summers. Laws issued in Ancyra testify to the time they spent there.

The Metropolis of Ancyra continued to be a residential see of the Eastern Orthodox Church until the 20th century, with about 40,000 faithful, mostly Turkish-speaking, but that situation ended as a result of the 1923 Convention Concerning the Exchange of Greek and Turkish Populations. The earlier Armenian Genocide put an end to the residential eparchy of Ancyra of the Armenian Catholic Church, which had been established in 1850. It is also a titular metropolis of the Ecumenical Patriarchate of Constantinople.
Both the Ancient Byzantine Metropolitan archbishopric and the 'modern' Armenian eparchy are now listed by the Catholic Church as titular sees, with separate apostolic successions.

In 1735 an Armenian Catholic diocese was established (Curiate Italian: "Ancira degli Ameni"). Having fallen into disuse, it was restored on 30 April 1850.

The Armenian Genocide brought an effective end to the residential diocese, which was only formally suppressed in 1972 and instantly transformed into an Armenian Catholic titular bishopric. The titular see has had a single occupant:

No later than 1696, the Catholic Church also established a Latin Rite titular archbishopric of Ancyra. The last incumbent died in 1976.

The Saint Clement Church is the only structure survived from the Byzantine era in Ankara. 
The church is believed to have been built between the 4th and 9th centuries.
At the time of the Ottoman Sultan Murad II, a mosque and madrasah

The city has exported mohair (from the Angora goat) and Angora wool (from the Angora rabbit) internationally for centuries. In the 19th century, the city also exported substantial amounts of goat and cat skins, gum, wax, honey, berries, and madder root. It was connected to Istanbul by railway before the First World War, continuing to export mohair, wool, berries, and grain.

The Central Anatolia Region is one of the primary locations of grape and wine production in Turkey, and Ankara is particularly famous for its Kalecik Karası and Muscat grapes; and its Kavaklıdere wine, which is produced in the Kavaklıdere neighbourhood within the Çankaya district of the city. Ankara is also famous for its pears. Another renowned natural product of Ankara is its indigenous type of honey ("Ankara Balı") which is known for its light color and is mostly produced by the Atatürk Forest Farm and Zoo in the Gazi district, and by other facilities in the Elmadağ, Çubuk and Beypazarı districts.

Ankara is the center of the state-owned and private Turkish defence and aerospace companies, where the industrial plants and headquarters of the Turkish Aerospace Industries, MKE, ASELSAN, Havelsan, Roketsan, FNSS, Nurol Makina, and numerous other firms are located. Exports to foreign countries from these defence and aerospace firms have steadily increased in the past decades. The IDEF in Ankara is one of the largest international expositions of the global arms industry. A number of the global automotive companies also have production facilities in Ankara, such as the German bus and truck manufacturer MAN SE. Ankara hosts the OSTIM Industrial Zone, Turkey's largest industrial park.

A large percentage of the complicated employment in Ankara is provided by the state institutions; such as the ministries, undersecretariats, and other administrative bodies of the Turkish government. There are also many foreign citizens working as diplomats or clerks in the embassies

The "Electricity, Gas, Bus General Directorate" (EGO) operates the Ankara Metro and other forms of public transportation. Ankara is currently served by a suburban rail named Ankaray (A1) and three subway lines (M1, M2, M3) of the Ankara Metro with about 300,000 total daily commuters, while an additional subway line (M4) is currently under construction. A long gondola lift with four stations connects the district of Şentepe to the Yenimahalle metro station.

The Ankara Central Station is a major rail hub in Turkey. The Turkish State Railways operates passenger train service from Ankara to other major cities, such as: Istanbul, Eskişehir, Balıkesir, Kütahya, İzmir, Kayseri, Adana, Kars, Elâzığ, Malatya, Diyarbakır, Karabük, Zonguldak and Sivas. Commuter rail also runs between the stations of Sincan and Kayaş. On 13 March 2009, the new Yüksek Hızlı Tren (YHT) high-speed rail service began operation between Ankara and Eskişehir. On 23 August 2011, another YHT high-speed line commercially started its service between Ankara and Konya. On 25 July 2014, the Ankara–Istanbul high-speed line of YHT entered service.

Esenboğa International Airport, located in the north-east of the city, is Ankara's main airport.

The average amount of time people spend commuting on public transit in Ankara on a weekday is 71 minutes. 17% of public transit passengers, ride for more than two hours every day. The average amount of time people wait at a stop or station for public transit is sixteen minutes, while 28% of users wait for over twenty minutes on average every day. The average distance people usually ride in a single trip with public transit is , while 27% travel for over in a single direction.

Ankara is politically a triple battleground between the ruling conservative Justice and Development Party (AKP), the opposition Kemalist centre-left Republican People's Party (CHP) and the nationalist far-right Nationalist Movement Party (MHP). The province of Ankara is divided into 25 districts. The CHP's key and almost only political stronghold in Ankara lies within the central area of Çankaya, which is the city's most populous district. While the CHP has always gained between 60 and 70% of the vote in Çankaya since 2002, political support elsewhere throughout Ankara is minimal. The high population within Çankaya, as well as Yenimahalle to an extent, has allowed the CHP to take overall second place behind the AKP in both local and general elections, with the MHP a close third, despite the fact that the MHP is politically stronger than the CHP in almost every other district. Overall, the AKP enjoys the most support throughout the city. The electorate of Ankara thus tend to vote in favour of the political right, far more so than the other main cities of Istanbul and İzmir. In retrospect, the 2013–14 protests against the AKP government were particularly strong in Ankara, proving to be fatal on multiple occasions.
Melih Gökçek has been the Metropolitan Mayor of Ankara since 1994 as a politician from the Welfare Party. He later joined the Virtue Party and then the AKP. Initially elected in the 1994 local elections, he was re-elected in 1999, 2004 and 2009. In the 2014 local election, Gökçek stood for a fifth term. The MHP metropolitan mayoral candidate for the 2009 local elections, conservative politician Mansur Yavaş, stood as the CHP candidate against Gökçek. In a heavily controversial election, Gökçek was declared the winner by just 1% ahead of Yavaş amid allegations of systematic electoral fraud. With the Supreme Electoral Council and courts rejecting Yavaş's appeals, he has declared intention to take the irregularities to the European Court of Human Rights. Although Gökçek was inaugurated for a fifth term, most election observers believe that Yavaş was the winner of the election.

Gökçek is resigned on 28 October 2017, replaced by former mayor of Sincan, Mustafa Tuna.

The city suffered from a series of terrorist attacks in 2015 and 2016, most notably on 10 October 2015; 17 February 2016; 13 March 2016; and 15 July 2016

The foundations of the Ankara castle and citadel were laid by the Galatians on a prominent lava outcrop (), and the rest was completed by the Romans. The Byzantines and Seljuks further made restorations and additions. The area around and inside the citadel, being the oldest part of Ankara, contains many fine examples of traditional architecture. There are also recreational areas to relax. Many restored traditional Turkish houses inside the citadel area have found new life as restaurants, serving local cuisine.

The citadel was depicted in various Turkish banknotes during 1927–1952 and 1983–1989.

The remains, the stage, and the backstage of the Roman theatre can be seen outside the castle. Roman statues that were found here are exhibited in the Museum of Anatolian Civilizations. The seating area is still under excavation.

The Augusteum, now known as the Temple of Augustus and Rome, was built 25  20  following the conquest of Central Anatolia by the Roman Empire. Ancyra then formed the capital of the new province of Galatia. After the death of Augustus in  14, a copy of the text of the "Res Gestae Divi Augusti" (the "Monumentum Ancyranum") was inscribed on the interior of the temple's ' in Latin and a Greek translation on an exterior wall of the '. The temple on the ancient acropolis of Ancyra was enlarged in the 2nd century and converted into a church in the 5th century. It is located in the Ulus quarter of the city. It was subsequently publicized by the Austrian ambassador Ogier Ghiselin de Busbecq in the 16th century.

The Roman Baths of Ankara have all the typical features of a classical Roman bath complex: a "frigidarium" (cold room), a "tepidarium" (warm room) and a "caldarium" (hot room). The baths were built during the reign of the Roman emperor Caracalla in the early 3rd century to honor Asclepios, the God of Medicine. Today, only the basement and first floors remain. It is situated in the Ulus quarter.

The Roman Road of Ankara or "Cardo Maximus" was found in 1995 by Turkish archaeologist Cevdet Bayburtluoğlu. It is long and wide. Many ancient artifacts were discovered during the excavations along the road and most of them are currently displayed at the Museum of Anatolian Civilizations.

The Column of Julian or Julianus, now in the Ulus district, was erected in honor of the Roman emperor Julian the Apostate
Kocatepe Mosque is the largest mosque in the city. Located in the Kocatepe quarter, it was constructed between 1967 and 1987 in classical Ottoman style with four minarets. Its size and prominent location have made it a landmark for the city.

Ahmet Hamdi Akseki Mosque is located near the Presidency of Religious Affairs on the Eskişehir Road. Built in the Turkish neoclassical style, it is one of the largest new mosques in the city, completed and opened in 2013. It can accommodate 6 thousand people during general prayers, and up to 30 thousand people during funeral prayers. The mosque was decorated with Anatolian Seljuk style
This mosque, in the Ulus quarter next to the Temple of Augustus, was built in the early 15th century in Seljuk style by an unknown architect. It was subsequently restored by architect Mimar Sinan in the 16th century, with Kütahya tiles being added in the 18th century. The mosque was built in honor of Hacı Bayram-ı Veli, whose tomb is next to the mosque, two years before his death (1427–28). The usable space inside this mosque is on the first floor and on the second floor.

It was founded in the Ulus quarter near the Ankara Citadel and was constructed by the Ahi fraternity during the late 14th and early 15th centuries. The finely carved walnut mimber (pulpit) is of particular interest.

The Alâeddin Mosque is the oldest mosque in Ankara. It has a carved walnut mimber, the inscription on which records that the mosque was completed in early AH 574 (which corresponds to the summer of 1178 AD) and was built by the Seljuk prince Muhiddin Mesud Şah (d. 1204), the Bey of Ankara, who was the son of the Anatolian Seljuk sultan Kılıç Arslan II (reigned 1156–1192.)

The " Victory Monument" (Turkish: "Zafer Anıtı") was crafted by Austrian sculptor Heinrich Krippel in 1925 and was erected in 1927 at Ulus Square. The monument is made of marble and bronze and features an equestrian statue of Mustafa Kemal Atatürk, who wears a Republic era modern military uniform, with the rank Field Marshal.

Located at Zafer Square (Turkish: "Zafer Meydanı"), the marble and bronze statue was crafted by the renowned Italian sculptor Pietro Canonica in 1927 and depicts a standing Atatürk who wears a Republic era modern military uniform, with the rank Field Marshal.

This monument, located in Güven Park near Kızılay Square, was erected in 1935 and bears Atatürk's advice to his people: "Turk! Be proud, work hard, and believe in yourself."

The monument was depicted on the reverse of the Turkish 5 lira banknote of 1937–1952 and of the 1000 lira banknotes of 1939–1946.

Erected in 1978 at Sıhhiye Square, this impressive monument symbolizes the Hatti Sun Disc (which was later adopted by the Hittites
Suluhan is a historical Inn in Ankara. It is also called the "Hasanpaşa Han". It is about southeast of Ulus Square and situated in the Hacıdoğan neighbourhood. According to the "vakfiye" (inscription) of the building, the Ottoman era "han" was commissioned by Hasan Pasha, a regional beylerbey, and was constructed between 1508 and 1511, during the final years of the reign of Sultan Bayezid II.
There are 102 rooms (now shops) which face the two yards. In each room there is a window, a niche and a chimney.

Çengelhan Rahmi Koç Museum is a museum of industrial technology situated in Çengel Han, an Ottoman era Inn which was completed in 1523, during the early years of the reign of Sultan Suleiman the Magnificent
Foreign visitors to Ankara usually like to visit the old shops in "Çıkrıkçılar Yokuşu" (Weavers' Road) near Ulus, where myriad things ranging from traditional fabrics, hand-woven carpets and leather products can be found at bargain prices. "Bakırcılar Çarşısı" (Bazaar of Coppersmiths) is particularly popular, and many interesting items, not just of copper, can be found here like jewelry, carpets, costumes, antiques and embroidery. Up the hill to the castle gate, there are many shops selling a huge and fresh collection of spices, dried fruits, nuts, and other produce.

Modern shopping areas are mostly found in Kızılay, or on Tunalı Hilmi Avenue, including the modern mall of Karum (named after the ancient Assyrian merchant colonies called "Kârum" that were established in central Anatolia at the beginning of the 2nd millennium BC) which is located towards the end of the Avenue; and in Çankaya, the quarter with the highest elevation in the city. Atakule Tower next to Atrium Mall in Çankaya has views over Ankara and also has a revolving restaurant at the top. The symbol of the Armada Shopping Mall is an anchor, and there's a large anchor monument at its entrance, as a reference to the ancient Greek name of the city, Ἄγκυρα (Ánkyra), which means anchor. Likewise, the anchor monument is also related with the Spanish name of the mall, Armada, which means naval fleet.

As Ankara started expanding westward in the 1970s, several modern, suburbia-style developments and mini-cities began to rise along the western highway, also known as the Eskişehir Road. The "Armada","CEPA" and "Kentpark" malls on the highway, the "Galleria", "Arcadium" and "Gordion" in Ümitköy, and a huge mall, "Real" in Bilkent Center, offer North American and European style shopping opportunities (these places can be reached through the Eskişehir Highway.) There is also the newly expanded "ANKAmall" at the outskirts, on the Istanbul Highway, which houses most of the well-known international brands. This mall is the largest throughout the Ankara region. In 2014 a few more shopping malls were open in Ankara. They are "Next Level" and "Taurus" on the Boulevard of Mevlana (also known as Konya

Turkish State Opera and Ballet, the national directorate of opera and ballet companies of Turkey, has its headquarters in Ankara, and serves the city with three venues:


Ankara is host to five classical music orchestras:

There are four concert halls in the city:

The city has been host to several well-established, annual theatre, music, film festivals:


Ankara also has a number of concert venues such as "Eskiyeni", "IF Performance Hall", "Jolly Joker", "Kite", "Nefes Bar", "Noxus Pub", "Passage Pub" and "Route", which host the live performances and events of popular musicians.

The Turkish State Theatres also has its head office in Ankara and runs the following stages in the city:

In addition, the city is served by several private theatre companies, among which Ankara Sanat Tiyatrosu
The Museum of Anatolian Civilizations ("Anadolu Medeniyetleri Müzesi") is situated at the entrance of the Ankara Castle. It is an old 15th century bedesten (covered bazaar) that has been restored and now houses a collection of Paleolithic, Neolithic, Hatti, Hittite, Phrygian, Urartian and Roman works as well as a major section dedicated to Lydian treasures.

Anıtkabir is located on an imposing hill, which forms the "Anıttepe" quarter of the city, where the mausoleum of Mustafa Kemal Atatürk, founder of the Republic of Turkey, stands. Completed in 1953, it is an impressive fusion of ancient and modern architectural styles. An adjacent museum houses a wax statue of Atatürk, his writings, letters and personal items, as well as an exhibition of photographs recording important moments in his life and during the establishment of the Republic. Anıtkabir is open every day, while the adjacent museum is open every day except Mondays.

Ankara Ethnography Museum ("Etnoğrafya Müzesi") is located opposite to the Ankara Opera House on Talat Paşa Boulevard, in the Ulus district. There is a fine collection of folkloric items, as well as artifacts from the Seljuk and Ottoman periods. In front of the museum building, there is a marble and bronze equestrian statue of Mustafa Kemal Atatürk (who wears a Republic era modern military uniform, with the rank Field Marshal) which was crafted in 1927 by the renowned Italian sculptor Pietro Canonica

The State Art and Sculpture Museum ("Resim-Heykel Müzesi") which opened to the public in 1980 is close to the Ethnography Museum and houses a rich collection of Turkish art from the late 19th century to the present day. There are also galleries which host guest exhibitions.

Cer Modern is the modern-arts museum of Ankara, inaugurated on 1 April 2010. It is situated in the renovated building of the historic TCDD Cer Atölyeleri, formerly a workshop of the Turkish State Railways. The museum incorporates the largest exhibition hall in Turkey. The museum holds periodic exhibitions of modern and contemporary art as well as hosting other contemporary arts events.

The War of Independence Museum ("Kurtuluş Savaşı Müzesi") is located on Ulus Square. It was originally the first Parliament building (TBMM) of the Republic of Turkey. The War of Independence was planned and directed here as recorded in various photographs and items presently on exhibition. In another display, wax figures of former presidents of the Republic of Turkey are on exhibit.

The Mehmet Akif Literature Museum Library is an important literary museum and archive opened in 2011 and dedicated to Mehmet Akif Ersoy (1873–1936), the poet of the Turkish National Anthem.

The TCDD Open Air Steam Locomotive Museum is an open-air museum which traces the history of steam locomotives.

Ankara Aviation Museum ("Hava Kuvvetleri Müzesi Komutanlığı") is located near the Istanbul Road in Etimesgut. The museum opened to the public in September 1998. It is home to various missiles, avionics, aviation materials and aircraft that have served in the Turkish Air Force (e.g. combat aircraft such as the F-86 Sabre, F-100 Super Sabre, F-102 Delta Dagger, F-104 Starfighter, F-5 Freedom Fighter, F-4 Phantom; and cargo planes such as the Transall C-160.) Also a Hungarian MiG-21, a Pakistani MiG-19, and a Bulgarian MiG-17 are on display at the museum.

The METU Science and Technology Museum ("ODTÜ Bilim ve Teknoloji Müzesi") is located inside the Middle East Technical University
As with all other cities of Turkey, football is the most popular sport in Ankara. The city has one football club currently competing in the Turkish Super League: Ankaragücü, founded in 1910, is the oldest club in Ankara and is associated with Ankara's military arsenal manufacturing company MKE. They were the Turkish Cup winners in 1972 and 1981. Gençlerbirliği, founded in 1923, currently play in the TFF First League and are known as the "Ankara Gale" or the "Poppies" because of their colors: red and black. They were the Turkish Cup winners in 1987 and 2001. Gençlerbirliği's B team, Hacettepe S.K. (formerly known as Gençlerbirliği OFTAŞ) played in the Turkish Super League but currently plays in the TFF Second League. A fourth team, Büyükşehir Belediye Ankaraspor, played in the Turkish Super League until 2010, when they were expelled. The club was reconstituted in 2014 as Osmanlıspor and currently play in the TFF First League at the Osmanlı Stadyumu in the Sincan district of Yenikent, outside the city center.

Ankara has a large number of minor teams, playing at regional levels. In the TFF Second League: Bugsaşspor in Sincan, Ankara Demirspor in Çankaya, Etimesgut Belediyespor in Etimesgut, Keçiörengücü in Keçiören; in the TFF Third League: Ankara Adliyespor in Keçiören; Altındağ Belediyespor in Altındağ; in the Amateur League: Turanspor in Etimesgut, Türk Telekomspor owned by the phone company in Yenimahalle, Çubukspor in Çubuk, and Bağlumspor in Keçiören.

In the Turkish Basketball League, Ankara is represented by Türk Telekom, whose home is the Ankara Arena, and CASA TED Kolejliler, whose home is the TOBB Sports Hall.

Halkbank Ankara is currently the leading domestic powerhouse in Men's Volleyball, having won many championships and cups in the Turkish Men's Volleyball League and even the CEV Cup in 2013.

Ankara Buz Pateni Sarayı is where the ice skating and ice hockey competitions take place in the city.

There are many popular spots for skateboarding which is active in the city since the 1980s. Skaters in Ankara usually meet in the park near the Grand National Assembly of Turkey.

The 2012-built THF Sport Hall hosts the Handball Super League and Women's Handball Super League

Ankara has many parks and open spaces mainly established in the early years of the Republic and well maintained and expanded thereafter. The most important of these parks are: Gençlik Parkı (houses an amusement park with a large pond for rowing), the Botanical garden, Seğmenler Park, Anayasa Park, Kuğulu Park (famous for the swans received as a gift from the Chinese government), Abdi İpekçi Park, Esertepe Parkı, Güven Park (see above for the monument), Kurtuluş Park (has an ice-skating rink), Altınpark (also a prominent exposition/fair area), Harikalar Diyarı (claimed to be Biggest Park of Europe inside city borders) and Göksu Park.

Gençlik Park was depicted on the reverse of the Turkish 100 lira banknotes of 1952–1976.

Atatürk Forest Farm and Zoo ("Atatürk Orman Çiftliği") is an expansive recreational farming area which houses a zoo, several small agricultural farms, greenhouses, restaurants, a dairy farm and a brewery. It is a pleasant place to spend a day with family, be it for having picnics, hiking, biking or simply enjoying good food and nature. There is also an exact replica of the house where Atatürk was born in 1881, in Thessaloniki, Greece. Visitors to the "Çiftlik" (farm) as it is affectionately called by Ankarans, can sample such famous products of the farm such as old-fashioned beer and ice cream, fresh dairy products

Ankara is home to a world-famous domestic cat breed – the Turkish Angora, called "Ankara kedisi" (Ankara cat) in Turkish. Turkish Angoras are one of the ancient, naturally occurring cat breeds, having originated in Ankara and its surrounding region in central Anatolia.

They mostly have a white, silky, medium to long length coat, no undercoat and a fine bone structure. There seems to be a connection between the Angora Cats and Persians, and the Turkish Angora is also a distant cousin of the Turkish Van. Although they are known for their shimmery white coat, currently there are more than twenty varieties including black, blue and reddish fur. They come in tabby and tabby-white, along with smoke varieties, and are in every color other than pointed, lavender, and cinnamon (all of which would indicate breeding to an outcross.)

Eyes may be blue, green, or amber, or even one blue and one amber or green. The W gene which is responsible for the white coat and blue eye is closely related to the hearing ability, and the presence of a blue eye can indicate that the cat is deaf to the side the blue eye is located. However, a great many blue and odd-eyed

The Angora rabbit () is a variety of domestic rabbit bred for its long, soft hair. The Angora is one of the oldest types of domestic rabbit, originating in Ankara and its surrounding region in central Anatolia, along with the Angora cat and Angora goat. The rabbits were popular pets with French royalty in the mid-18th century, and spread to other parts of Europe by the end of the century. They first appeared in the United States in the early 20th century. They are bred largely for their long Angora wool, which may be removed by shearing, combing, or plucking

The Angora goat () is a breed of domestic goat that originated in Ankara and its surrounding region in central Anatolia.

This breed was first mentioned in the time of Moses, roughly in 1500 BC. The first Angora goats were brought to Europe by Charles V, Holy Roman Emperor, about 1554, but, like later imports, were not very successful. Angora goats were first introduced in the United States in 1849 by Dr. James P. Davis. Seven adult goats were a gift from Sultan Abdülmecid I in appreciation for his services and advice on the raising of cotton.

The fleece taken from an Angora goat is called mohair. A single goat produces between of hair per year. Angoras are shorn twice a year, unlike sheep, which are shorn only once. Angoras have high nutritional requirements due to their rapid hair growth. A poor quality diet will curtail mohair development. The United States, Turkey, and South Africa are the top producers of mohair.

For a long period of time, Angora goats were bred for their white coat. In 1998, the Colored Angora Goat Breeders Association was set up to promote breeding of colored Angoras. Today, Angora goats produce white, black (deep black to greys and silver), red (the color fades significantly as the goat gets older), and brownish fiber.

Angora goats were depicted on the reverse of the Turkish 50 lira banknotes of 1938–1952.

Ankara is twinned
Category:Capitals in Asia
Category:Capitals in Europe
Category:Populated places in Ankara ProvinceArabic

Arabic () ' or () ' or ) is a Central Semitic language that first emerged in Iron Age northwestern Arabia and is now the of the Arab world. It is named after the Arabs, a term initially used to describe peoples living in the area bounded by Mesopotamia in the east and the Anti-Lebanon mountains in the west, in northwestern Arabia, and in the Sinai Peninsula. Arabic is classified as a macrolanguage comprising 30 modern varieties, including its standard form, Modern Standard Arabic, which is derived from Classical Arabic.

As the modern written language, Modern Standard Arabic is widely taught in schools and universities, and is used to varying degrees in workplaces, government, and the media. The two formal varieties are grouped together as Literary Arabic (""), which is the official language of 26 states, and the liturgical language of Islam. Modern Standard Arabic largely follows the grammatical standards of Classical Arabic, and uses much of the same vocabulary. However, it has discarded some grammatical constructions and vocabulary that no longer have any counterpart in the spoken varieties, and has adopted certain new constructions and vocabulary from the spoken varieties. Much of the new vocabulary is used to denote concepts that have arisen in the post-classical era, especially in modern times. Due to its grounding in Classical Arabic, Modern Standard Arabic is removed over a millennium from everyday speech, which is construed as a multitude of dialects of this language. These dialects and Modern Standard Arabic are described by some scholars as not mutually comprehensible. The former are usually acquired in families, while the latter is taught in formal education settings. However, there have been studies reporting some degree of comprehension of stories told in the standard variety among preschool-aged children. The relation between Modern Standard Arabic and these dialects is sometimes compared to that of Latin and vernaculars (or today's French, Czech or German) in medieval and early modern Europe. This view though does not take into account the widespread use of Modern Standard Arabic as a medium of audiovisual communication in today's mass media—a function Latin has never performed.

During the Middle Ages, Literary Arabic was a major vehicle of culture in Europe, especially in science, mathematics and philosophy. As a result, many European languages have also borrowed many words from it. Arabic influence, mainly in vocabulary, is seen in European languages, mainly Spanish and to a lesser extent Portuguese, and Catalan, owing to both the proximity of Christian European and Muslim Arab civilizations and 800 years of Arabic culture and language in the Iberian Peninsula, referred to in Arabic as "". Sicilian has about 500 Arabic words as result of Sicily being progressively conquered by Arabs from North Africa, from the mid-9th to mid-10th centuries. Many of these words relate to agriculture and related activities. Balkan languages, including Greek and Bulgarian, have also acquired a significant number of Arabic words through contact with Ottoman Turkish.

Arabic has influenced many languages around the globe throughout its history. Some of the most influenced languages are Persian, Turkish, Spanish, Urdu, Kashmiri, Kurdish, Bosnian, Kazakh, Bengali, Hindi, Malay, Maldivian, Indonesian, Pashto, Punjabi, Tagalog, Sindhi, and Hausa, and some languages in parts of Africa. Conversely, Arabic has borrowed words from other languages, including Greek and Persian in medieval times, and contemporary European languages such as English and French in modern times.

Classical Arabic is the liturgical language of 1.8 billion Muslims, and Modern Standard Arabic is one of six official languages of the United Nations. All varieties of Arabic combined are spoken by perhaps as many as 422 million speakers (native and non-native) in the Arab world, making it the fifth most spoken language in the world. Arabic is written with the Arabic alphabet, which is an abjad script and is written from right to left, although the spoken varieties are sometimes written in ASCII Latin from left to right with no standardized orthography.

Arabic is a Central Semitic language, closely related to the Northwest Semitic languages (Aramaic, Hebrew, Ugaritic, and Phoenician), the Ancient South Arabian languages, and various other Semitic languages of Arabia such as Dadanitic. The Semitic languages changed a great deal between Proto-Semitic and the establishment of the Central Semitic languages, particularly in grammar. Innovations of the Central Semitic languages—all maintained in Arabic—include:
There are several features which Classical Arabic, the modern Arabic varieties, as well as the Safaitic and Hismaic inscriptions share which are unattested in any other Central Semitic language variety, including the Dadanitic and Taymanitic languages of the northern Hejaz. These features are evidence of common descent from a hypothetical ancestor, Proto-Arabic
Arabia boasted a wide variety of Semitic languages in antiquity. In the southwest, various Central Semitic languages both belonging to and outside of the Ancient South Arabian family (e.g. Southern Thamudic) were spoken. It is also believed that the ancestors of the Modern South Arabian languages (non-Central Semitic languages) were also spoken in southern Arabia at this time. To the north, in the oases of northern Hejaz, Dadanitic and Taymanitic held some prestige as inscriptional languages. In Najd and parts of western Arabia, a language known to scholars as Thamudic C is attested. In eastern Arabia, inscriptions in a script derived from ASA attest to a language known as Hasaitic. Finally, on the northwestern frontier of Arabia, various languages known to scholars as Thamudic B, Thamudic D, Safaitic, and Hismaic are attested. The last two share important isoglosses with later forms of Arabic, leading scholars to theorize that Safaitic and Hismaic are in fact early forms of Arabic and that they should be considered Old Arabic.

Beginning in the 1st century CE, fragments of Northern Old Arabic are attested in the Nabataean script across northern Arabia. By the 4th century CE, the Nabataean Aramaic writing system had come to express varieties of Arabic other than that of the Nabataeans.

In late pre-Islamic times, a transdialectal and transcommunal variety of Arabic emerged in the Hejaz which continued living its parallel life after literary Arabic had been institutionally standardized in the 2nd and 3rd century of the Hijra, most strongly in Judeo-Christian texts, keeping alive ancient features eliminated from the "learned" tradition (Classical Arabic). This variety and both its classicizing and "lay" iterations have been termed Middle Arabic in the past, but they are thought to continue an Old Higazi register. It is clear that the orthography of the Qur'an was not developed for the standardized form of Classical Arabic; rather, it shows the attempt on the part of writers to record an archaic form of Old Higazi.

In the late 6th century AD, a relatively uniform intertribal "poetic koine" distinct from the spoken vernaculars developed based on the Bedouin dialects of Najd, probably in connection with the court of al-Ḥīra. During the first Islamic century, the majority of Arabic poets and Arabic-writing persons spoke Arabic as their mother tongue. Their texts, although mainly preserved in far later manuscripts, contain traces of non-standardized Classical Arabic elements in morphology and syntax. The standardization of Classical Arabic reached completion around the end of the 8th century. The first comprehensive description of the "ʿarabiyya" "Arabic", Sībawayhi's "al"-"Kitāb", is based first of all upon a corpus of poetic texts, in addition to Qur'an usage and Bedouin informants whom he considered to be reliable speakers of the "ʿarabiyya". By the 8th century, knowledge of Classical Arabic had become an essential prerequisite for rising into the higher classes throughout the Islamic world.

Charles Ferguson's koine theory (Ferguson 1959) claims that the modern Arabic dialects collectively descend from a single military koine that sprang up during the Islamic conquests; this view has been challenged in recent times. Ahmad al-Jallad proposes that there were at least two considerably distinct types of Arabic on the eve of the conquests: Northern and Central (Al-Jallad 2009). The modern dialects emerged from a new contact situation produced following the conquests. Instead of the emergence of a single or multiple koines, the dialects contain several sedimentary layers of borrowed and areal features, which they absorbed at different points in their linguistic histories.
According to Veersteegh and Bickerton, colloquial Arabic dialects arose from pidginized Arabic formed from contact between Arabs and conquered peoples. Pidginization and subsequent creolization among Arabs and arabized

"Arabic" usually designates one of three main variants: Classical Arabic, Modern Standard Arabic and "colloquial" or "dialectal" Arabic. Classical Arabic is the language found in the Quran, used from the period of Pre-Islamic Arabia to that of the Abbasid Caliphate. Theoretically, Classical Arabic is considered normative, according to the syntactic and grammatical norms laid down by classical grammarians (such as Sibawayh) and the vocabulary defined in classical dictionaries (such as the Lisān al-ʻArab). In practice, however, modern authors almost never write in pure Classical Arabic, instead using a literary language with its own grammatical norms and vocabulary, commonly known as Modern Standard Arabic (MSA).

MSA is the variety used in most current, printed Arabic publications, spoken by some of the Arabic media across North Africa and the Middle East, and understood by most educated Arabic speakers. "Literary Arabic" and "Standard Arabic" ( ") are less strictly defined terms that may refer to Modern Standard Arabic or Classical Arabic.

Some of the differences between Classical Arabic (CA) and Modern Standard Arabic (MSA) are as follows:

MSA uses much Classical vocabulary (e.g., ' 'to go') that is not present in the spoken varieties, but deletes Classical words that sound obsolete in MSA. In addition, MSA has borrowed or coined a large number of terms for concepts that did not exist in Quranic times, and MSA continues to evolve. Some words have been borrowed from other languages—notice that transliteration mainly indicates spelling and not real pronunciation (e.g., ' 'film' or " 'democracy').

However, the current preference is to avoid direct borrowings, preferring to either use loan translations (e.g., ' 'branch', also used for the branch of a company or organization; ' 'wing', is also used for the wing of an airplane, building, air force, etc.), or to coin new words using forms within existing roots ( ' 'apoptosis', using the root "m/w/t" 'death' put into the Xth form, or ' 'university', based on ' 'to gather, unite'; ' 'republic', based on ' 'multitude'). An earlier tendency was to redefine an older word although this has fallen into disuse (e.g., ' 'telephone' < 'invisible caller (in Sufism)'; "" 'newspaper' < 'palm-leaf stalk').

"Colloquial" or "dialectal" Arabic refers to the many national or regional varieties which constitute the everyday spoken language and evolved from Classical Arabic. Colloquial Arabic has many regional variants; geographically distant varieties usually differ enough to be mutually unintelligible, and some linguists consider them distinct languages. The varieties are typically unwritten. They are often used in informal spoken media, such as soap operas and talk shows, as well as occasionally in certain forms of written media such as poetry and printed advertising.

The only variety of modern Arabic to have acquired official language status is Maltese, which is spoken in (predominantly Catholic) Malta and written with the Latin script. It is descended from Classical Arabic through Siculo-Arabic, but is not mutually intelligible with any other variety of Arabic. Most linguists list it as a separate language rather than as a dialect of Arabic.

Even during Muhammad's lifetime, there were dialects of spoken Arabic. Muhammad spoke in the dialect of Mecca, in the western Arabian peninsula, and it was in this dialect that the Quran was written down. However, the dialects of the eastern Arabian peninsula were considered the most prestigious at the time, so the language of the Quran was ultimately converted to follow the eastern phonology. It is this phonology that underlies the modern pronunciation of Classical Arabic. The phonological differences between these two dialects account for some of the complexities of Arabic writing, most notably the writing of the glottal stop or "hamzah" (which was preserved in the eastern dialects but lost in western speech) and the use of ' (representing a sound preserved in the western dialects but merged with ' in eastern speech).

The sociolinguistic situation of Arabic in modern times provides a prime example of the linguistic phenomenon of diglossia, which is the normal use of two separate varieties of the same language, usually in different social situations. In the case of Arabic, educated Arabs of any nationality can be assumed to speak both their school-taught Standard Arabic as well as their native, mutually unintelligible "dialects"; these dialects linguistically constitute separate languages which may have dialects of their own. When educated Arabs of different dialects engage in conversation (for example, a Moroccan speaking with a Lebanese), many speakers code-switch back and forth between the dialectal and standard varieties of the language, sometimes even within the same sentence. Arabic speakers often improve their familiarity with other dialects via music or film.

The issue of whether Arabic is one language or many languages is politically charged, in the same way it is for the varieties of Chinese, Hindi and Urdu, Serbian and Croatian, Scots and English, etc. In contrast to speakers of Hindi and Urdu who claim they cannot understand each other even when they can, speakers of the varieties of Arabic will claim they can all understand each other even when they cannot. The issue of diglossia between spoken and written language is a significant complicating factor: A single written form, significantly different from any of the spoken varieties learned natively, unites a number of sometimes divergent spoken forms. For political reasons, Arabs mostly assert that they all speak a single language, despite significant issues of mutual incomprehensibility among differing spoken versions.

From a linguistic standpoint, it is often said that the various spoken varieties of Arabic differ among each other collectively about as much as the Romance languages. This is an apt comparison in a number of ways. The period of divergence from a single spoken form is similar—perhaps 1500 years for Arabic, 2000 years for the Romance languages. Also, while it is comprehensible to people from the Maghreb, a linguistically innovative variety such as Moroccan Arabic is essentially incomprehensible to Arabs from the Mashriq, much as French is incomprehensible to Spanish or Italian speakers but relatively easily learned by them. This suggests that the spoken varieties may linguistically be considered separate languages.

The influence of Arabic has been most important in Islamic countries, because it is the language of the Islamic sacred book, the Quran. Arabic is also an important source of vocabulary for languages such as Amharic, Baluchi, Bengali, Berber, Bosnian, Chaldean, Chechen, Croatian, Dagestani, English, German, Gujarati, Hausa, Hindi, Kazakh, Kurdish, Kutchi, Kyrgyz, Malay (Malaysian and Indonesian), Pashto, Persian, Punjabi, Rohingya, Romance languages (French, Catalan, Italian, Portuguese, Sicilian, Spanish, etc.) Saraiki, Sindhi, Somali, Sylheti, Swahili, Tagalog, Tigrinya, Turkish, Turkmen, Urdu, Uyghur, Uzbek, Visayan and Wolof, as well as other languages in countries where these languages are spoken. France has recently been emphasizing the learning and usage of Arabic in their classroom(s)/school(s).

In addition, English has many Arabic loanwords, some directly, but most via other Mediterranean languages. Examples of such words include admiral, adobe, alchemy, alcohol, algebra, algorithm, alkaline, almanac, amber, arsenal, assassin, candy, carat, cipher, coffee, cotton, ghoul, hazard, jar, kismet, lemon, loofah, magazine, mattress, sherbet, sofa, sumac, tariff, and zenith. Other languages such as Maltese and Kinubi derive ultimately from Arabic, rather than merely borrowing vocabulary or grammatical rules.

Terms borrowed range from religious terminology (like Berber "taẓallit", "prayer", from "salat" ( "")), academic terms (like Uyghur "mentiq", "logic"), and economic items (like English "coffee") to placeholders (like Spanish "fulano", "so-and-so"), everyday terms (like Hindustani "lekin", "but", or Spanish "taza" and French "tasse", meaning "cup"), and expressions (like Catalan "a betzef", "galore, in quantity"). Most Berber varieties (such as Kabyle), along with Swahili, borrow some numbers from Arabic. Most Islamic religious terms are direct borrowings from Arabic, such as ("salat"), "prayer", and ("imam"), "prayer leader."

In languages not directly in contact with the Arab world, Arabic loanwords are often transferred indirectly via other languages rather than being transferred directly from Arabic. For example, most Arabic loanwords in Hindustani and Turkish entered through Persian though Persian is an Indo-Iranian language. Older Arabic loanwords in Hausa were borrowed from Kanuri.

Arabic words also made their way into several West African languages as Islam spread across the Sahara. Variants of Arabic words such as "kitāb" ("book") have spread to the languages of African groups who had no direct contact with Arab traders.

Since throughout the Islamic world, Arabic occupied a position similar to that of Latin in Europe, many of the Arabic concepts in the fields of science, philosophy, commerce, etc. were coined from Arabic roots by non-native Arabic speakers, notably by Aramaic and Persian translators, and then found their way into other languages. This process of using Arabic roots, especially in Kurdish and Persian, to translate foreign concepts continued through to the 18th and 19th centuries, when swaths of Arab-inhabited lands were under Ottoman rule.

The most important sources of borrowings into (pre-Islamic) Arabic are from the related (Semitic) languages Aramaic, which used to be the principal, international language of communication throughout the ancient Near and Middle East, Ethiopic, and to a lesser degree Hebrew (mainly religious concepts). In addition, many cultural, religious and political terms have entered Arabic from Iranian languages, notably Middle Persian, Parthian, and (Classical) Persian, and Hellenistic Greek ("kīmiyāʼ" has as origin the Greek "khymia", meaning in that language the melting of metals; see Roger Dachez, "Histoire de la Médecine de l'Antiquité au XXe siècle", Tallandier, 2008, p. 251), "alembic" (distiller) from "ambix" (cup), "almanac" (climate) from "almenichiakon" (calendar). (For the origin of the last three borrowed words, see Alfred-Louis de Prémare, "Foundations of Islam", Seuil, L'Univers Historique, 2002.) Some Arabic borrowings from Semitic or Persian languages are, as presented in De Prémare's above-cited book:

There have been many instances of national movements to convert Arabic script into Latin script or to Romanize the language. Currently, the only language derived from Classical Arabic to use Latin script is Maltese.

The Beirut newspaper "La Syrie" pushed for the change from Arabic script to Latin letters in 1922. The major head of this movement was Louis Massignon, a French Orientalist, who brought his concern before the Arabic Language Academy in Damascus in 1928. Massignon's attempt at Romanization failed as the Academy and population viewed the proposal as an attempt from the Western world to take over their country. Sa'id Afghani, a member of the Academy, mentioned that the movement to Romanize the script was a Zionist plan to dominate Lebanon.

After the period of colonialism in Egypt, Egyptians were looking for a way to reclaim and re-emphasize Egyptian culture. As a result, some Egyptians pushed for an Egyptianization of the Arabic language in which the formal Arabic and the colloquial Arabic would be combined into one language and the Latin alphabet would be used. There was also the idea of finding a way to use Hieroglyphics instead of the Latin alphabet, but this was seen as too complicated to use. A scholar, Salama Musa agreed with the idea of applying a Latin alphabet to Arabic, as he believed that would allow Egypt to have a closer relationship with the West. He also believed that Latin script was key to the success of Egypt as it would allow for more advances in science and technology. This change in alphabet, he believed, would solve the problems inherent with Arabic, such as a lack of written vowels and difficulties writing foreign words that made it difficult for non-native speakers to learn. Ahmad Lutfi As Sayid and Muhammad Azmi, two Egyptian intellectuals, agreed with Musa and supported the push for Romanization. The idea that Romanization was necessary for modernization and growth in Egypt continued with Abd Al-Aziz Fahmi in 1944. He was the chairman for the Writing and Grammar Committee for the Arabic Language Academy of Cairo. However, this effort failed as the Egyptian people felt a strong cultural tie to the Arabic alphabet. In particular, the older Egyptian generations believed that the Arabic alphabet had strong connections to Arab values and history, due to the long history of the Arabic alphabet (Shrivtiel, 189) in Muslim societies.

The Quran introduced a new way of writing to the world. People began studying and applying the unique styles they learned from the Quran to not only their own writing, but also their culture. Writers studied the unique structure and format of the Quran in order to identify and apply the figurative devices and their impact on the reader.

The Quran inspired musicality in poetry through the internal rhythm of the verses. The arrangement of words, how certain sounds create harmony, and the agreement of rhymes create the sense of rhythm within each verse. At times, the chapters of the Quran only have the rhythm in common.

The repetition in the Quran introduced the true power and impact repetition can have in poetry. The repetition of certain words and phrases made them appear more firm and explicit in the Quran. The Quran uses constant metaphors of blindness and deafness to imply unbelief. Metaphors were not a new concept to poetry, however the strength of extended metaphors was. The explicit imagery in the Quran inspired many poets to include and focus on the feature in their own work. The poet ibn al Mu'tazz wrote a book regarding the figures of speech inspired by his study of the Quran. Poets such as badr Shakir al sayyab expresses his political opinion in his work through imagery inspired by the forms of more harsher imagery used in the Quran.
The Quran uses figurative devices in order to express the meaning in the most beautiful form possible. The study of the pauses in the Quran as well as other rhetoric allow it to be approached in a multiple ways.

Although the Quran is known for its fluency and harmony, the structure can be best described as chaotic. The suras also known as chapters of the Quran are not placed in chronological order. The only constant in their structure is that the longest are placed first and shorter ones follow. The topics discussed in the chapter often have no relation to each other and only share their sense of rhyme. The Quran introduces to poetry the idea of abandoning order and scattering narratives throughout the text. Harmony is also present in the sound of the Quran. The elongations and accents present in the Quran create a harmonious flow within the writing. Unique sound of the Quran recited, due to the accents, create a deeper level of understanding through a deeper emotional connection.

The Quran is written in a language that is simple and understandable by people. The simplicity of the writing inspired later poets to write in a more clear and clear-cut style. The words of the Quran, although unchanged, are to this day understandable and frequently used in both formal and informal Arabic. The simplicity of the language makes memorizing and reciting the Quran a slightly easier task.

The writer al-Khattabi explains how culture is a required element to create a sense of art in work as well as understand it. He believes that fluency and harmony the Quran possess are not the only elements that make it beautiful and create a bond between the reader and the text.
While a lot of poetry was deemed comparable to the Quran in that it is equal to or better than the composition of the Quran, a debate rose that such statements are not possible because humans are incapable of composing work comparable to the Quran.
Because the structure of the Quran made it difficult for a clear timeline to be seen, Hadith were the main source of chronological order. The Hadith were passed down from generation to generation and this tradition became a large resource for understanding the context. Poetry after the Quran began possessing this element of tradition by including ambiguity and background information to be required to understand the meaning.

After the Quran came down to the people, the tradition of memorizing the verses became present. It is believed that the greater the amount of the Quran memorized, the greater the faith. As technology improved over time, hearing recitations of Quran became more available as well as more tools to help memorize the verses.
The tradition of Love Poetry served as a symbolic representation of a Muslim's desire for a closer contact with their Lord.

While the influence of the Quran on Arabic poetry is explained and defended by numerous writers, some writers such as Al- Baqillani believe that poetry and the Quran are in no conceivable way related due to the uniqueness of the Quran. Poetry's imperfections prove his points that they cannot be compared with the fluency the Quran holds.

Classical Arabic is the language of poetry and literature (including news); it is also mainly the language of the Quran. Classical Arabic is closely associated with the religion of Islam because the Quran was written in it. Most of the world's Muslims do not speak Classical Arabic as their native language, but many can read the Quranic script and recite the Quran. Among non-Arab Muslims, translations of the Quran are most often accompanied by the original text. At present, Modern Standard Arabic (MSA) is also used in modernized versions of literary forms of the Quran.

Some Muslims present a monogenesis of languages and claim that the Arabic language was the language revealed by God for the benefit of mankind and the original language as a prototype system of symbolic communication, based upon its system of triconsonantal roots, spoken by man from which all other languages were derived, having first been corrupted. Judaism has a similar account with the Tower of Babel
"Colloquial Arabic" is a collective term for the spoken dialects of Arabic used throughout the Arab world, which differ radically from the literary language. The main dialectal division is between the varieties within and outside of the Arabian peninsula, followed by that between sedentary varieties and the much more conservative Bedouin varieties. All of the varieties outside of the Arabian peninsula (which include the large majority of speakers) have a large number of features in common with each other that are not found in Classical Arabic. This has led researchers to postulate the existence of a prestige koine dialect in the one or two centuries immediately following the Arab conquest, whose features eventually spread to all of the newly conquered areas. (These features are present to varying degrees inside the Arabian peninsula. Generally, the Arabian peninsula varieties have much more diversity than the non-peninsula varieties, but have been understudied.)

Within the non-peninsula varieties, the largest difference is between the non-Egyptian North African dialects (especially Moroccan Arabic) and the others. Moroccan Arabic in particular is hardly comprehensible to Arabic speakers east of Libya (although the converse is not true, in part due to the popularity of Egyptian films and other media).

One factor in the differentiation of the dialects is influence from the languages previously spoken in the areas, which have typically provided a significant number of new words and have sometimes also influenced pronunciation or word order; however, a much more significant factor for most dialects is, as among Romance languages, retention (or change of meaning) of different classical forms. Thus Iraqi "aku", Levantine "fīh" and North African "kayən" all mean 'there is', and all come from Classical Arabic forms ("yakūn", "fīhi", "kā'in" respectively), but now sound very different.

Transcription is a broad IPA transcription, so minor differences were ignored for easier comparison. Also, the pronunciation of Modern Standard Arabic differs significantly from region to region.

According to Charles A. Ferguson, the following are some of the characteristic features of the koiné that underlies all of the modern dialects outside the Arabian peninsula. Although many other features are common to most or all of these varieties, Ferguson believes that these features in particular are unlikely to have evolved independently more than once or twice and together suggest the existence of the koine:


Of the 29 Proto-Semitic consonants, only one has been lost: , which merged with . But the consonant is still found in many colloquial Arabic dialects. Various other consonants have changed their sound too, but have remained distinct. An original lenited to , and – consistently attested in pre-Islamic Greek transcription of Arabic languages – became palatalized to or by the time of the Quran and , , or after early Muslim conquests and in MSA (see Arabic phonology#Local variations for more detail). An original voiceless alveolar lateral fricative became . Its emphatic counterpart was considered by Arabs to be the most unusual sound in Arabic (Hence the Classical Arabic's appellation ' or "language of the '"); for most modern dialects, it has become an emphatic stop with loss of the laterality or with complete loss of any pharyngealization or velarization, . (The classical "" pronunciation of pharyngealization still occurs in the Mehri language and the similar sound without velarization, , exists in other Modern South Arabian languages.)

Other changes may also have happened. Classical Arabic pronunciation is not thoroughly recorded and different reconstructions of the sound system of Proto-Semitic propose different phonetic values. One example is the emphatic consonants, which are pharyngealized in modern pronunciations but may have been velarized in the eighth century and glottalized in Proto-Semitic.

Reduction of and between vowels occurs in a number of circumstances and is responsible for much of the complexity of third-weak ("defective") verbs. Early Akkadian transcriptions of Arabic names shows that this reduction had not yet occurred as of the early part of the 1st millennium BC.

The Classical Arabic language as recorded was a poetic koine that reflected a consciously archaizing dialect, chosen based on the tribes of the western part of the Arabian Peninsula, who spoke the most conservative variants of Arabic. Even at the time of Muhammed and before, other dialects existed with many more changes, including the loss of most glottal stops, the loss of case endings, the reduction of the diphthongs and into monophthongs , etc. Most of these changes are present in most or all modern varieties of Arabic.

An interesting feature of the writing system of the Quran (and hence of Classical Arabic) is that it contains certain features of Muhammad's native dialect of Mecca, corrected through diacritics into the forms of standard Classical Arabic. Among these features visible under the corrections are the loss of the glottal stop and a differing development of the reduction of certain final sequences containing : Evidently, final became as in the Classical language, but final became a different sound, possibly (rather than again in the Classical language). This is the apparent source of the "alif maqṣūrah" 'restricted alif' where a final is reconstructed: a letter that would normally indicate or some similar high-vowel sound, but is taken in this context to be a logical variant of "alif" and represent the sound .

Although Classical Arabic was a unitary language and is now used in Quran, its pronunciation varies somewhat from country to country and from region to region within a country. It is influenced by colloquial dialects.

The "colloquial" spoken dialects of Arabic are learned at home and constitute the native languages of Arabic speakers. "Formal" Literary Arabic (usually specifically Modern Standard Arabic) is learned at school; although many speakers have a native-like command of the language, it is technically not the native language of any speakers. Both varieties can be both written and spoken, although the colloquial varieties are rarely written down and the formal variety is spoken mostly in formal circumstances, e.g., in radio and TV broadcasts, formal lectures, parliamentary discussions and to some extent between speakers of different colloquial dialects. Even when the literary language is spoken, however, it is normally only spoken in its pure form when reading a prepared text out loud and communication between speakers of different colloquial dialects. When speaking extemporaneously (i.e. making up the language on the spot, as in a normal discussion among people), speakers tend to deviate somewhat from the strict literary language in the direction of the colloquial varieties. In fact, there is a continuous range of "in-between" spoken varieties: from nearly pure Modern Standard Arabic (MSA), to a form that still uses MSA grammar and vocabulary but with significant colloquial influence, to a form of the colloquial language that imports a number of words and grammatical constructions in MSA, to a form that is close to pure colloquial but with the "rough edges" (the most noticeably "vulgar" or non-Classical aspects) smoothed out, to pure colloquial. The particular variant (or "register") used depends on the social class and education level of the speakers involved and the level of formality of the speech situation. Often it will vary within a single encounter, e.g., moving from nearly pure MSA to a more mixed language in the process of a radio interview, as the interviewee becomes more comfortable with the interviewer. This type of variation is characteristic of the diglossia
Although Modern Standard Arabic (MSA) is a unitary language, its pronunciation varies somewhat from country to country and from region to region within a country. The variation in individual "accents" of MSA speakers tends to mirror corresponding variations in the colloquial speech of the speakers in question, but with the distinguishing characteristics moderated somewhat. Note that it is important in descriptions of "Arabic" phonology to distinguish between pronunciation of a given colloquial (spoken) dialect and the pronunciation of MSA by these same speakers. Although they are related, they are not the same. For example, the phoneme that derives from Classical Arabic has many different pronunciations in the modern spoken varieties, e.g., including the proposed original . Speakers whose native variety has either or will use the same pronunciation when speaking MSA. Even speakers from Cairo, whose native Egyptian Arabic has , normally use when speaking MSA. The of Persian Gulf speakers is the only variant pronunciation which isn't found in MSA; is used instead, but may use [j] in MSA for comfortable pronunciation. Another reason of different pronunciations is influence of colloquial dialects. The differentiation of pronunciation of colloquial dialects is the influence from other languages previously spoken and some still presently spoken in the regions, such as Coptic in Egypt, Berber, Punic or Phoenician in North Africa, Himyaritic, Modern South Arabian and Old South Arabian in Yemen and Oman, Aramaic and Canaanite languages (including Phoenician) in the Levant and Mesopotamia.

Another example: Many colloquial varieties are known for a type of vowel harmony in which the presence of an "emphatic consonant" triggers backed allophones of nearby vowels (especially of the low vowels , which are backed to in these circumstances and very often fronted to in all other circumstances). In many spoken varieties, the backed or "emphatic" vowel allophones spread a fair distance in both directions from the triggering consonant; in some varieties (most notably Egyptian Arabic), the "emphatic" allophones spread throughout the entire word, usually including prefixes and suffixes, even at a distance of several syllables from the triggering consonant. Speakers of colloquial varieties with this vowel harmony tend to introduce it into their MSA pronunciation as well, but usually with a lesser degree of spreading than in the colloquial varieties. (For example, speakers of colloquial varieties with extremely long-distance harmony may allow a moderate, but not extreme, amount of spreading of the harmonic allophones in their MSA speech, while speakers of colloquial varieties with moderate-distance harmony may only harmonize immediately adjacent vowels in MSA.)

Modern Standard Arabic has six pure vowels (while most modern dialects have eight pure vowels which includes the long vowels ), with short and corresponding long vowels . There are also two diphthongs: and .

The pronunciation of the vowels differs from speaker to speaker, in a way that tends to reflect the pronunciation of the corresponding colloquial variety. Nonetheless, there are some common trends. Most noticeable is the differing pronunciation of and , which tend towards fronted , or in most situations, but a back in the neighborhood of emphatic consonants. Some accents and dialects, such as those of the Hejaz region, have an open or a central in all situations. The vowel varies towards too. Listen to the final vowel in the recording of " at the beginning of this article, for example. The point is, Arabic has only three short vowel phonemes, so those phonemes can have a very wide range of allophones. The vowels and are often affected somewhat in emphatic neighborhoods as well, with generally more back or centralized allophones, but the differences are less great than for the low vowels. The pronunciation of short and tends towards and , respectively, in many dialects.

The definition of both "emphatic" and "neighborhood" vary in ways that reflect (to some extent) corresponding variations in the spoken dialects. Generally, the consonants triggering "emphatic" allophones are the pharyngealized consonants ; ; and , if not followed immediately by . Frequently, the fricatives also trigger emphatic allophones; occasionally also the pharyngeal consonants (the former more than the latter). Many dialects have multiple emphatic allophones of each vowel, depending on the particular nearby consonants. In most MSA accents, emphatic coloring of vowels is limited to vowels immediately adjacent to a triggering consonant, although in some it spreads a bit farther: e.g., ' 'time'; ' 'homeland'; " 'downtown' (sometimes or similar).

In a non-emphatic environment, the vowel in the diphthong tends to be fronted even more than elsewhere, often pronounced or : hence ' 'sword' but ' 'summer'. However, in accents with no emphatic allophones of (e.g., in the Hejaz), the pronunciation or occurs in all situations.

The phoneme is represented by the Arabic letter ' () and has many standard pronunciations. is characteristic of north Algeria, Iraq, also in most of the Arabian peninsula but with an allophonic in some positions; occurs in most of the Levant and most North Africa; and is used in most of Egypt and some regions in Yemen and Oman. Generally this corresponds with the pronunciation in the colloquial dialects. In some regions in Sudan and Yemen, as well as in some Sudanese and Yemeni dialects, it may be either or , representing the original pronunciation of Classical Arabic. Foreign words containing may be transcribed with , , , , , or , mainly depending on the regional spoken variety of Arabic or the commonly diacriticized Arabic letter. Note also that in northern Egypt, where the Arabic letter ' () is normally pronounced , a separate phoneme , which may be transcribed with , occurs in a small number of mostly non-Arabic loanwords, e.g., 'jacket'.

In many varieties, () are actually epiglottal (despite what is reported in many earlier works).

The emphatic consonant was actually pronounced , or possibly —either way, a highly unusual sound. The medieval Arabs actually termed their language " 'the language of the Ḍād' (the name of the letter used for this sound), since they thought the sound was unique to their language. (In fact, it also exists in a few other minority Semitic languages, e.g., Mehri.)

Arabic has consonants traditionally termed "emphatic" (), which exhibit simultaneous pharyngealization as well as varying degrees of velarization , so they may be written with the "Velarized or pharyngealized" diacritic () as: . This simultaneous articulation is described as "Retracted Tongue Root" by phonologists. In some transcription systems, emphasis is shown by capitalizing the letter, for example, is written ; in others the letter is underlined or has a dot below it, for example, .

Vowels and consonants can be phonologically short or long. Long (geminate) consonants are normally written doubled in Latin transcription (i.e. bb, dd, etc.), reflecting the presence of the Arabic diacritic mark ', which indicates doubled consonants. In actual pronunciation, doubled consonants are held twice as long as short consonants. This consonant lengthening is phonemically contrastive: ' 'he accepted' vs. " 'he kissed'.

Arabic has two kinds of syllables: open syllables (CV) and (CVV)—and closed syllables (CVC), (CVVC) and (CVCC). The syllable types with two morae (units of time), i.e. CVC and CVV, are termed "heavy syllables", while those with three morae, i.e. CVVC and CVCC, are "superheavy syllables". Superheavy syllables in Classical Arabic occur in only two places: at the end of the sentence (due to pausal pronunciation) and in words such as ' 'hot', ' 'stuff, substance', ' 'they disputed with each other', where a long ' occurs before two identical consonants (a former short vowel between the consonants has been lost). (In less formal pronunciations of Modern Standard Arabic, superheavy syllables are common at the end of words or before clitic suffixes such as "" 'us, our', due to the deletion of final short vowels.)

In surface pronunciation, every vowel must be preceded by a consonant (which may include the glottal stop ). There are no cases of hiatus within a word (where two vowels occur next to each other, without an intervening consonant). Some words do have an underlying vowel at the beginning, such as the definite article "al-" or words such as ' 'he bought', ' 'meeting'. When actually pronounced, one of three things happens:

Word stress is not phonemically contrastive in Standard Arabic. It bears a strong relationship to vowel length. The basic rules for Modern Standard Arabic are:

Examples:' 'book', ' 'writer', ' 'desk', ' 'desks', ' 'library' (but ' 'library' in short pronunciation), ' (Modern Standard Arabic) 'they wrote' = ' (dialect), ' (Modern Standard Arabic) 'they wrote it' = ' (dialect), ' (Modern Standard Arabic) 'they (dual, fem) wrote', ' (Modern Standard Arabic) 'I wrote' = ' (short form or dialect). Doubled consonants count as two consonants: ' 'magazine', "" "place".

These rules may result in differently stressed syllables when final case endings are pronounced, vs. the normal situation where they are not pronounced, as in the above example of ' 'library' in full pronunciation, but ' 'library' in short pronunciation.

The restriction on final long vowels does not apply to the spoken dialects, where original final long vowels have been shortened and secondary final long vowels have arisen from loss of original final "-hu/hi".

Some dialects have different stress rules. In the Cairo (Egyptian Arabic) dialect a heavy syllable may not carry stress more than two syllables from the end of a word, hence ' 'school', ' 'Cairo'. This also affects the way that Modern Standard Arabic is pronounced in Egypt. In the Arabic of Sanaa, stress is often retracted: ' 'two houses', ' 'their table', ' 'desks', ' 'sometimes', "" 'their school'. (In this dialect, only syllables with long vowels or diphthongs are considered heavy; in a two-syllable word, the final syllable can be stressed only if the preceding syllable is light; and in longer words, the final syllable cannot be stressed.)

The final short vowels (e.g., the case endings "-a -i -u" and mood endings "-u -a") are often not pronounced in this language, despite forming part of the formal paradigm of nouns and verbs. The following levels of pronunciation exist:

This is the most formal level actually used in speech. All endings are pronounced as written, except at the end of an utterance, where the following changes occur:

This is a formal level of pronunciation sometimes seen. It is somewhat like pronouncing all words as if they were in pausal position (with influence from the colloquial varieties). The following changes occur:

This is the pronunciation used by speakers of Modern Standard Arabic in extemporaneous speech, i.e. when producing new sentences rather than simply reading a prepared text. It is similar to formal short pronunciation except that the rules for dropping final vowels apply "even" when a clitic suffix is added. Basically, short-vowel case and mood endings are never pronounced and certain other changes occur that echo the corresponding colloquial pronunciations. Specifically:

As mentioned above, many spoken dialects have a process of "emphasis spreading", where the "emphasis" (pharyngealization) of emphatic consonants spreads forward and back through adjacent syllables, pharyngealizing all nearby consonants and triggering the back allophone in all nearby low vowels. The extent of emphasis spreading varies. For example, in Moroccan Arabic, it spreads as far as the first full vowel (i.e. sound derived from a long vowel or diphthong) on either side; in many Levantine dialects, it spreads indefinitely, but is blocked by any or ; while in Egyptian Arabic, it usually spreads throughout the entire word, including prefixes and suffixes. In Moroccan Arabic, also have emphatic allophones and , respectively.

Unstressed short vowels, especially , are deleted in many contexts. Many sporadic examples of short vowel change have occurred (especially → and interchange ↔). Most Levantine dialects merge short /i u/ into in most contexts (all except directly before a single final consonant). In Moroccan Arabic, on the other hand, short triggers labialization of nearby consonants (especially velar consonants and uvular consonants), and then short /a i u/ all merge into , which is deleted in many contexts. (The labialization plus is sometimes interpreted as an underlying phoneme .) This essentially causes the wholesale loss of the short-long vowel distinction, with the original long vowels remaining as half-long , phonemically , which are used to represent "both" short and long vowels in borrowings from Literary Arabic.

Most spoken dialects have monophthongized original to in most circumstances, including adjacent to emphatic consonants, while keeping them as the original diphthongs in others e.g. . In most of the Moroccan, Algerian and Tunisian (except Sahil and Southeastern) Arabic dialects, they have subsequently merged into original .

In some dialects, there may be more or fewer phonemes than those listed in the chart above. For example, non-Arabic is used in the Maghrebi dialects as well in the written language mostly for foreign names. Semitic became extremely early on in Arabic before it was written down; a few modern Arabic dialects, such as Iraqi (influenced by Persian and Kurdish) distinguish between and . The Iraqi Arabic also uses sounds , and uses Persian adding letters, e.g.: "" – "a plum"; " – "a truffle" and so on.

Early in the expansion of Arabic, the separate emphatic phonemes and coalesced into a single phoneme . Many dialects (such as Egyptian, Levantine, and much of the Maghreb) subsequently lost fricatives, converting into . Most dialects borrow "learned" words from the Standard language using the same pronunciation as for inherited words, but some dialects without interdental fricatives (particularly in Egypt and the Levant) render original in borrowed words as .

Another key distinguishing mark of Arabic dialects is how they render the original velar and uvular plosives , (Proto-Semitic ), and :

Pharyngealization of the emphatic consonants tends to weaken in many of the spoken varieties, and to spread from emphatic consonants to nearby sounds. In addition, the "emphatic" allophone automatically triggers pharyngealization of adjacent sounds in many dialects. As a result, it may difficult or impossible to determine whether a given coronal consonant is phonemically emphatic or not, especially in dialects with long-distance emphasis spreading. (A notable exception is the sounds vs. in Moroccan Arabic, because the former is pronounced as an affricate

As in other Semitic languages, Arabic has a complex and unusual morphology (i.e. method of constructing words from a basic root). Arabic has a nonconcatenative "root-and-pattern" morphology: A root consists of a set of bare consonants (usually three), which are fitted into a discontinuous pattern to form words. For example, the word for 'I wrote' is constructed by combining the root ' 'write' with the pattern ' 'I Xed' to form ' 'I wrote'. Other verbs meaning 'I Xed' will typically have the same pattern but with different consonants, e.g. ' 'I read', ' 'I ate', ' 'I went', although other patterns are possible (e.g. ' 'I drank', ' 'I said', ' 'I spoke', where the subpattern used to signal the past tense may change but the suffix ' is always used).

From a single root , numerous words can be formed by applying different patterns:

Nouns in Literary Arabic have three grammatical cases (nominative, accusative, and genitive [also used when the noun is governed by a preposition]); three numbers (singular, dual and plural); two genders (masculine and feminine); and three "states" (indefinite, definite, and construct). The cases of singular nouns (other than those that end in long ā) are indicated by suffixed short vowels (/-u/ for nominative, /-a/ for accusative, /-i/ for genitive).

The feminine singular is often marked by /-at/, which is reduced to /-ah/ or /-a/ before a pause. Plural is indicated either through endings (the sound plural) or internal modification (the broken plural). Definite nouns include all proper nouns, all nouns in "construct state" and all nouns which are prefixed by the definite article /al-/. Indefinite singular nouns (other than those that end in long ā) add a final /-n/ to the case-marking vowels, giving /-un/, /-an/ or /-in/ (which is also referred to as nunation or tanwīn).

Adjectives in Literary Arabic are marked for case, number, gender and state, as for nouns. However, the plural of all non-human nouns is always combined with a singular feminine adjective, which takes the /-ah/ or /-at/ suffix.

Pronouns in Literary Arabic are marked for person, number and gender. There are two varieties, independent pronouns and enclitics. Enclitic pronouns are attached to the end of a verb, noun or preposition and indicate verbal and prepositional objects or possession of nouns. The first-person singular pronoun has a different enclitic form used for verbs (/-ni/) and for nouns or prepositions (/-ī/ after consonants, /-ya/ after vowels).

Nouns, verbs, pronouns and adjectives agree with each other in all respects. However, non-human plural nouns are grammatically considered to be feminine singular. Furthermore, a verb in a verb-initial sentence is marked as singular regardless of its semantic number when the subject of the verb is explicitly mentioned as a noun. Numerals between three and ten show "chiasmic" agreement, in that grammatically masculine numerals have feminine marking and vice versa.

Verbs in Literary Arabic are marked for person (first, second, or third), gender, and number. They are conjugated in two major paradigms (past and non-past); two voices (active and passive); and six moods (indicative, imperative, subjunctive, jussive, shorter energetic and longer energetic), the fifth and sixth moods, the energetics, exist only in Classical Arabic but not in MSA. There are also two participles (active and passive) and a verbal noun, but no infinitive.

The past and non-past paradigms are sometimes also termed perfective and imperfective, indicating the fact that they actually represent a combination of tense and aspect. The moods other than the indicative occur only in the non-past, and the future tense is signaled by prefixing ' or ' onto the non-past. The past and non-past differ in the form of the stem (e.g., past ' vs. non-past '), and also use completely different sets of affixes for indicating person, number and gender: In the past, the person, number and gender are fused into a single suffixal morpheme, while in the non-past, a combination of prefixes (primarily encoding person) and suffixes (primarily encoding gender and number) are used. The passive voice uses the same person/number/gender affixes but changes the vowels of the stem.

The following shows a paradigm of a regular Arabic verb, "" 'to write'. Note that in Modern Standard, the energetic mood (in either long or short form, which have the same meaning) is almost never used.

Like other Semitic languages, and unlike most other languages, Arabic makes much more use of nonconcatenative morphology (applying a large number of templates applied roots) to derive words than adding prefixes or suffixes to words.

For verbs, a given root can occur in many different derived verb stems (of which there are about fifteen), each with one or more characteristic meanings and each with its own templates for the past and non-past stems, active and passive participles, and verbal noun. These are referred to by Western scholars as "Form I", "Form II", and so on through "Form XV" (although Forms XI to XV are rare). These stems encode grammatical functions such as the causative, intensive and reflexive. Stems sharing the same root consonants represent separate verbs, albeit often semantically related, and each is the basis for its own conjugational paradigm. As a result, these derived stems are part of the system of derivational morphology, not part of the inflectional system.

Examples of the different verbs formed from the root ' 'write' (using ' 'red' for Form IX, which is limited to colors and physical defects):
Form II is sometimes used to create transitive denominative verbs (verbs built from nouns); Form V is the equivalent used for intransitive denominatives.

The associated participles and verbal nouns of a verb are the primary means of forming new lexical nouns in Arabic. This is similar to the process by which, for example, the English gerund
The Arabic alphabet derives from the Aramaic through Nabatean, to which it bears a loose resemblance like that of Coptic or Cyrillic scripts to Greek script. Traditionally, there were several differences between the Western (North African) and Middle Eastern versions of the alphabet—in particular, the "faʼ" had a dot underneath and "qaf" a single dot above in the Maghreb, and the order of the letters was slightly different (at least when they were used as numerals).

However, the old Maghrebi variant has been abandoned except for calligraphic purposes in the Maghreb itself, and remains in use mainly in the Quranic schools (zaouias) of West Africa. Arabic, like all other Semitic languages (except for the Latin-written Maltese, and the languages with the Ge'ez script), is written from right to left. There are several styles of script, notably naskh, which is used in print and by computers, and ruqʻah, which is commonly used in handwriting.

After Khalil ibn Ahmad al Farahidi finally fixed the Arabic script around 786, many styles were developed, both for the writing down of the Quran and other books, and for inscriptions on monuments as decoration.

Arabic calligraphy has not fallen out of use as calligraphy has in the Western world, and is still considered by Arabs as a major art form; calligraphers are held in great esteem. Being cursive by nature, unlike the Latin script, Arabic script is used to write down a verse of the Quran, a hadith, or simply a proverb. The composition is often abstract, but sometimes the writing is shaped into an actual form such as that of an animal. One of the current masters of the genre is Hassan Massoudy.

In modern times the intrinsically calligraphic nature of the written Arabic form is haunted by the thought that a typographic approach to the language, necessary for digitized unification, will not always accurately maintain meanings conveyed through calligraphy.

There are a number of different standards for the romanization of Arabic, i.e. methods of accurately and efficiently representing Arabic with the Latin script. There are various conflicting motivations involved, which leads to multiple systems. Some are interested in transliteration, i.e. representing the "spelling" of Arabic, while others focus on transcription, i.e. representing the "pronunciation" of Arabic. (They differ in that, for example, the same letter is used to represent both a consonant, as in "you" or "yet", and a vowel, as in "me" or "eat".) Some systems, e.g. for scholarly use, are intended to accurately and unambiguously represent the phonemes of Arabic, generally making the phonetics more explicit than the original word in the Arabic script. These systems are heavily reliant on diacritical marks such as "š" for the sound equivalently written "sh" in English. Other systems (e.g. the Bahá'í orthography) are intended to help readers who are neither Arabic speakers nor linguists with intuitive pronunciation of Arabic names and phrases. These less "scientific" systems tend to avoid diacritics and use digraphs (like "sh" and "kh"). These are usually simpler to read, but sacrifice the definiteness of the scientific systems, and may lead to ambiguities, e.g. whether to interpret "sh" as a single sound, as in "gash", or a combination of two sounds, as in "gashouse". The ALA-LC romanization solves this problem by separating the two sounds with a prime symbol ( ′ ); e.g., "as′hal" 'easier'.

During the last few decades and especially since the 1990s, Western-invented text communication technologies have become prevalent in the Arab world, such as personal computers, the World Wide Web, email, bulletin board systems, IRC, instant messaging and mobile phone text messaging. Most of these technologies originally had the ability to communicate using the Latin script only, and some of them still do not have the Arabic script as an optional feature. As a result, Arabic speaking users communicated in these technologies by transliterating the Arabic text using the Latin script, sometimes known as IM Arabic.

To handle those Arabic letters that cannot be accurately represented using the Latin script, numerals and other characters were appropriated. For example, the numeral "3" may be used to represent the Arabic letter . There is no universal name for this type of transliteration, but some have named it Arabic Chat Alphabet. Other systems of transliteration exist, such as using dots or capitalization to represent the "emphatic" counterparts of certain consonants. For instance, using capitalization, the letter , may be represented by d. Its emphatic counterpart, , may be written as D.

In most of present-day North Africa, the Western Arabic numerals (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) are used. However, in Egypt and Arabic-speaking countries to the east of it, the Eastern Arabic numerals ( – – – – – – – – – ) are in use. When representing a number in Arabic, the lowest-valued position is placed on the right, so the order of positions is the same as in left-to-right scripts. Sequences of digits such as telephone numbers are read from left to right, but numbers are spoken in the traditional Arabic fashion, with units and tens reversed from the modern English usage. For example, 24 is said "four and twenty" just like in the German language ("vierundzwanzig") and Classical Hebrew, and 1975 is said "a thousand and nine-hundred and five and seventy" or, more eloquently, "a thousand and nine-hundred five seventy"

Academy of the Arabic Language is the name of a number of language-regulation bodies formed in the Arab League. The most active are in Damascus and Cairo. They review language development, monitor new words and approve inclusion of new words into their published standard dictionaries. They also publish old and historical Arabic manuscripts.

Arabic has been taught worldwide in many elementary and secondary schools, especially Muslim schools. Universities around the world have classes that teach Arabic as part of their foreign languages, Middle Eastern studies, and religious studies courses. Arabic language schools exist to assist students to learn Arabic outside the academic world. There are many Arabic language schools in the Arab world and other Muslim countries. Because the Quran is written in Arabic and all Islamic terms are in Arabic, millions of Muslims (both Arab and non-Arab) study the language. Software and books with tapes are also important part of Arabic learning, as many of Arabic learners may live in places where there are no academic or Arabic language school classes available. Radio series of Arabic language classes are also provided from some radio stations. A number of websites on the Internet
With the sole example of Medieval linguist Abu Hayyan al-Gharnati – who, while a scholar of the Arabic language, was not ethnically Arab – Medieval scholars of the Arabic language made no efforts at studying comparative linguistics, considering all other languages inferior.

In modern times, the educated upper classes in the Arab world have taken a nearly opposite view. Yasir Suleiman wrote in 2011 that "studying and knowing English or French in most of the Middle East and North Africa have become a badge of sophistication and modernity and ... feigning, or asserting, weakness or lack of facility in Arabic is sometimes paraded as a sign of status, class, and perversely, even education through a mélange of code-switching practises." Arab-American professor Franck Salamah went as far as to declare Arabic a dead language conveying dead ideas, blaming its stagnation for Arab intellectual stagnation and lamenting that great writers in Arabic are judged by their command of the language and not the merit of the ideas they express with it.



Category:Languages attested from the 9th century BC
Category:Central Semitic languages
Category:Fusional languages
Category:Languages of Algeria
Category:Languages of Bahrain
Category:Languages of Cameroon
Category:Languages of Chad
Category:Languages of the Comoros
Category:Languages of Djibouti
Category:Languages of Eritrea
Category:Languages of Gibraltar
Category:Languages of Israel
Category:Languages of Iran
Category:Languages of Iraq
Category:Languages of Jordan
Category:Languages of Kuwait
Category:Languages of Lebanon
Category:Languages of Libya
Category:Languages of Mali
Category:Languages of Mauritania
Category:Languages of Morocco
Category:Languages of Niger
Category:Languages of Oman
Category:Languages of the State of Palestine
Category:Languages of Qatar
Category:Languages of Saudi Arabia
Category:Languages of Senegal
Category:Languages of South Sudan
Category:Languages of Sicily
Category:Languages of Somalia
Category:Languages of Sudan
Category:Languages of Syria
Category:Languages of the United Arab Emirates
Category:Languages of Tunisia
Category:Languages of Yemen
Category:Requests for audio pronunciation (Arabic)
Category:Stress-timed languages
Category:Subject–verb–object languages
Category:Verb–subject–object languagesAlfred Hitchcock

Sir Alfred Joseph Hitchcock (13 August 1899 – 29 April 1980) was an English film director and producer, widely regarded as one of the most influential filmmakers in the history of cinema. Known as "the Master of Suspense", he directed over 50 feature films in a career spanning six decades, becoming as well known as any of his actors thanks to his many interviews, his cameo roles in most of his films, and his hosting and producing of the television anthology "Alfred Hitchcock Presents" (1955–1965).

Born in Leytonstone, Essex, Hitchcock entered the film industry in 1919 as a title card designer after training as a technical clerk and copy writer for a telegraph-cable company. He made his directorial debut with the silent film "The Pleasure Garden" (1925). His first successful film, "The Lodger: A Story of the London Fog" (1927), helped to shape the thriller genre, while his 1929 film, "Blackmail". Two of his 1930s thrillers, "The 39 Steps" (1935) and "The Lady Vanishes" (1938), are ranked among the greatest British films of the 20th century.

By 1939 Hitchcock was a filmmaker of international importance, and film producer David O. Selznick persuaded him to move to Hollywood. A string of successful films followed, including "Rebecca" (1940), "Foreign Correspondent" (1940), "Shadow of a Doubt" (1943), and "The Paradine Case" (1947); "Rebecca" was nominated for 11 Oscars and won the Academy Award for Best Picture. His 53 films have grossed over US$223.3 million worldwide and garnered a total of 46 Oscar nominations and six wins.

The "Hitchcockian" style includes the use of camera movement to mimic a person's gaze, thereby turning viewers into voyeurs, and framing shots to maximise anxiety and fear. The film critic Robin Wood wrote that the meaning of a Hitchcock film "is there in the method, in the progression from shot to shot. A Hitchcock film is an organism, with the whole implied in every detail and every detail related to the whole." By 1960 Hitchcock had directed four films often ranked among the greatest of all time: "Rear Window" (1954), "Vertigo" (1958), "North by Northwest" (1959), and "Psycho" (1960). In 2012 "Vertigo" replaced Orson Welles's "Citizen Kane" (1941) as the British Film Institute's greatest film ever made. By 2018 eight of his films had been selected for preservation in the United States National Film Registry, including his personal favourite, "Shadow of a Doubt" (1943). He received the AFI Life Achievement Award in 1979 and was knighted

Hitchcock was born in the flat above his parents' leased grocer's shop at 517 High Road, Leytonstone, on the outskirts of east London (then part of Essex), the youngest of three children: William (born 1890), Ellen Kathleen ("Nellie") (1892), and Alfred Joseph (1899). His parents, Emma Jane Hitchcock, née Whelan (1863–1942), and William Hitchcock (1862–1914), were both Roman Catholics, with partial roots in Ireland; William was a greengrocer as his father had been. There was a large extended family, including Uncle John Hitchcock with his five-bedroom Victorian house on Campion Road, Putney, complete with maid, cook, chauffeur and gardener. Every summer John rented a seaside house for the family in Cliftonville, Kent. Hitchcock said that he first became class-conscious there, noticing the differences between tourists and locals.

Describing himself as a well-behaved boy—his father called him his "little lamb without a spot"—Hitchcock said he could not remember ever having had a playmate. One of his favourite stories for interviewers was about his father sending him to the local police station with a note when he was five; the policeman looked at the note and locked him in a cell for a few minutes, saying, "This is what we do to naughty boys." The experience left him, he said, with a lifelong fear of policemen; in 1973 he told Tom Snyder that he was "scared stiff of anything ... to do with the law" and wouldn't even drive a car in case he got a parking ticket.

When he was six, the family moved to Limehouse and leased two stores at 130 and 175 Salmon Lane, which they ran as a fish-and-chips shop and fishmongers' respectively; they lived above the former. It seems that Hitchcock was seven when he attended his first school, the Howrah House Convent in Poplar, which he entered in 1907. According to Patrick McGilligan, he stayed at Howrah House for at most two years. He also attended a convent school, the Wode Street School "for the daughters of gentlemen and little boys", run by the Faithful Companions of Jesus; briefly attended a primary school near his home; and was for a very short time, when he was nine, a boarder at Salesian College in Battersea family moved again when he was 11, this time to Stepney, and on 5 October 1910 Hitchcock was sent to St Ignatius College in Stamford Hill, Tottenham (now in the London Borough of Haringey), a Jesuit grammar school with a reputation for discipline. The priests used a hard rubber cane on the boys, always at the end of the day, so the boys had to sit through classes anticipating the punishment once they knew they'd been written up for it. He said it was here that he developed his sense of fear. The school register lists his year of birth as 1900 rather than 1899; Spoto writes that it seems he was deliberately enrolled as a 10-year-old, perhaps because he was a year behind with his schooling. While biographer Gene Adair reports that Hitchcock was "an average, or slightly above-average, pupil", Hitchcock said he was "usually among the four or five at the top of the class"; at the end of his first year, his work in Latin, English, French and religious education was noted. His favourite subject was geography, and he became interested in maps, and railway and bus timetables; according to Taylor, he could recite all the stops on the Orient Express. He told Peter Bogdanovich: "The Jesuits taught me organization, control and, to some degree, analysis."

Hitchcock told his parents that he wanted to be an engineer, and on 25 July 1913, he left St Ignatius and enrolled in night classes at the London County Council School of Engineering and Navigation in Poplar. In a book-length interview in 1962, he told François Truffaut that he had studied "mechanics, electricity, acoustics, and navigation". Then on 12 December 1914 his father, who had been suffering from emphysema and kidney disease, died at the age of 52. To support himself and his mother—his older siblings had left home by then—Hitchcock took a job, for 15 shillings a week (£ in 2017), as a technical clerk at the Henley Telegraph and Cable Company in Blomfield Street near London Wall. He kept up his night classes, this time in art history, painting, economics, and political science. His older brother ran the family shops, while he and his mother continued to live in Salmon Lane.

Hitchcock was too young to enlist when the First World War broke out in July 1914, and when he reached the required age of 18 in 1917, he received a C3 classification ("free from serious organic disease, able to stand service conditions in garrisons at home ... only suitable for sedentary work"). He joined a cadet regiment of the Royal Engineers and took part in theoretical briefings, weekend drills, and exercises. John Russell Taylor wrote that, in one session of practical exercises in Hyde Park, Hitchcock was required to wear puttees. He could never master wrapping them around his legs, and they repeatedly fell down around his ankles.

After the war, Hitchcock began dabbling in creative writing. In June 1919 he became a founding editor and business manager of Henley's in-house publication, "The Henley Telegraph" (sixpence a copy), to which he submitted several short stories. Henley's promoted him to the advertising department, where he wrote copy and drew graphics for advertisements for electric cable. He apparently loved the job and would stay late at the office to examine the proofs; he told Truffaut that this was his "first step toward cinema". He enjoyed watching films, especially American cinema, and from the age of 16 read the trade papers; he watched Charlie Chaplin, D. W. Griffith and Buster Keaton, and particularly liked Fritz Lang's "Der müde Tod
While still at Henley's, he read in a trade paper that Famous Players-Lasky, the production arm of Paramount Pictures, was opening a studio in London. They were planning to film "The Sorrows of Satan" by Marie Corelli, so he produced some drawings for the title cards and sent his work to the studio. They hired him, and in 1919 he began working for Islington Studios in Poole Street, Hoxton, as a title-card designer. Donald Spoto writes that most of the staff were Americans with strict job specifications, but the English workers were encouraged to try their hand at anything, which meant that Hitchcock gained experience as a co-writer, art director and production manager on at least 18 silent films. "The Times" wrote in February 1922 about the studio's "special art title department under the supervision of Mr. A. J. Hitchcock". His work there included "Number 13" (1922), also known as "Mrs. Peabody", cancelled because of financial problems—the few finished scenes are lost—and "Always Tell Your Wife" (1923), which he and Seymour Hicks
When Paramount pulled out of London in 1922, Hitchcock was hired as an assistant director by a new firm run in the same location by Michael Balcon, later known as Gainsborough Pictures. Hitchcock worked on "Woman to Woman" (1923) with the director Graham Cutts, designing the set, writing the script and producing. He said: "It was the first film that I had really got my hands onto." The editor and "script girl" on "Woman to Woman" was Alma Reville, his future wife. He also worked as an assistant to Cutts on "The White Shadow" (1924), "The Passionate Adventure" (1924), "The Blackguard" (1925), and "The Prude's Fall" (1925). "The Blackguard" was produced at the Babelsberg Studios in Potsdam, where Hitchcock watched part of the making of F. W. Murnau's film "The Last Laugh" (1924). He was impressed with Murnau's work and later used many of his techniques for the set design in his own productions.

In the summer of 1925, Balcon asked Hitchcock to direct "The Pleasure Garden" (1925), starring Virginia Valli, a co-production of Gainsborough and the German firm Emelka at the Geiselgasteig studio near Munich. Reville, by then Hitchcock's fiancée, was assistant director-editor. Although the film was a commercial flop, Balcon liked Hitchcock's work; a "Daily Express" headline called him, "Young man with a master mind". Balcon asked him to direct a second film in Munich, "The Mountain Eagle" (1926), released in the United States as "Fear o' God". The film is lost; Hitchcock called it "a very bad movie".

Hitchcock's luck changed with his first thriller, "The Lodger: A Story of the London Fog" (1927), about the hunt for a serial killer who, wearing a black cloak and carrying a black bag, is murdering young blonde women in London, and only on Tuesdays. A landlady suspects that her lodger is the killer, but he turns out to be innocent. To convey that footsteps were being heard from an upper floor, Hitchcock had a glass floor made so that the audience could see the lodger pacing up and down in his room above the landlady. Hitchcock had wanted the leading man to be guilty, or for the film at least to end ambiguously, but the star was Ivor Novello, a matinée idol, and the "star system" meant that Novello could not be the villain. Hitchcock told Truffaut: "You have to clearly spell it out in big letters: 'He is innocent.'" (He had the same problem years later with Cary Grant in "Suspicion" (1941).)

Released in January 1927, "The Lodger" was a commercial and critical success in the UK. Hitchcock told Truffaut that the film was the first of his to be influenced by the Expressionist techniques he had witnessed in Germany: "In truth, you might almost say that "The Lodger" was my first picture." He made his first cameo appearances in the film, purely because an extra body was needed, sitting in a newsroom and later standing in a crowd as the leading man is arrested.

On 2 December 1926, Hitchcock and Alma Reville (1899–1982) married at the Brompton Oratory in South Kensington. The couple honeymooned in Paris, Lake Como and St. Moritz, before returning to London to live in a leased flat on the top two floors of 153 Cromwell Road, Kensington. Reville, who was born just hours after Hitchcock, converted from Protestantism to Catholicism, apparently at the insistence of Hitchcock's mother; she was baptized on 31 May 1927 and confirmed at Westminster Cathedral by Cardinal Francis Bourne on 5 June.

In 1928, when they learned that she was pregnant, the Hitchcocks purchased "Winter's Grace", a Tudor farmhouse set in 11 acres on Stroud Lane, Shamley Green, Surrey, for £2,500. Their daughter and only child, Patricia Alma Hitchcock, was born on 7 July that year. Reville became her husband's closest collaborator; Charles Champlin

Hitchcock began work on his tenth film, "Blackmail" (1929), when its production company, British International Pictures (BIP), converted its Elstree studios"; it followed the first American sound feature film, "The Jazz Singer" (1927). "Blackmail" began the Hitchcock tradition of using famous landmarks as a backdrop for suspense sequences, with the climax taking place on the dome of the British Museum. It also features one of his longest cameo appearances, which shows him being bothered by a small boy as he reads a book on the London Underground. In the PBS series "The Men Who Made The Movies", Hitchcock explained how he used early sound recording as a special element of the film, stressing the word "knife" in a conversation with the woman suspected of murder. During this period, Hitchcock directed segments for a BIP revue, "Elstree Calling" (1930), and directed a short film, "An Elastic Affair" (1930), featuring two "Film Weekly" scholarship winners. "An Elastic Affair" is one of the lost films.

In 1933 Hitchcock was once again working for Michael Balcon at Gaumont British. His first film for the company, "The Man Who Knew Too Much" (1934), was a success; his second, "The 39 Steps" (1935), was acclaimed in the UK and made Hitchcock a star in the US. It also established the quintessential English "Hitchcock blonde" (Madeleine Carroll) as the template for his succession of ice-cold, elegant leading ladies. Screenwriter Robert Towne remarked, "It's not much of an exaggeration to say that all contemporary escapist entertainment begins with "The 39 Steps"". This film was one of the first to introduce the "MacGuffin" plot device, a term coined by the English screenwriter Angus MacPhail

Hitchcock released two spy thrillers in 1936. "Sabotage" was loosely based on Joseph Conrad's novel, "The Secret Agent" (1907), about a woman who discovers that her husband is a terrorist, and "Secret Agent", based on two stories in "Ashenden: Or the British Agent" (1928) by W. Somerset Maugham.

At this time, Hitchcock also became notorious for pranks against the cast and crew. These jokes ranged from simple and innocent to crazy and maniacal. For instance, he hosted a dinner party where he dyed all the food blue because, as he claimed, there weren't enough blue foods. He also had a horse delivered to the dressing room of his friend, actor Sir Gerald du Maurier.

Hitchcock's next major success was "The Lady Vanishes" (1938), "one of the greatest train movies from the genre's golden era", according to Philip French, in which Miss Froy (May Whitty), a British spy posing as a governess, disappears on a train journey through the fictional European country of Bandrika. The film saw Hitchcock receive the 1939 New York Film Critics Circle Award for Best Director, the only time he won an award for his direction. Benjamin Crisler, the "New York Times" film critic, wrote in June 1938: "Three unique and valuable institutions the British have that we in America have not: Magna Carta, the Tower Bridge and Alfred Hitchcock, the greatest director of screen melodramas in the world."

David O. Selznick signed Hitchcock to a seven-year contract beginning in March 1939, and the Hitchcocks moved to Hollywood. In June that year "Life" magazine called him the "greatest master of melodrama in screen history". The working arrangements with Selznick were less than ideal. Selznick suffered from constant financial problems, and Hitchcock was often unhappy about Selznick's creative control over his films. In a later interview, Hitchcock said: "[Selznick] was the Big Producer. ... Producer was king. The most flattering thing Mr. Selznick ever said about me—and it shows you the amount of control—he said I was the 'only director' he'd 'trust with a film'." At the same time, Selznick complained about Hitchcock's "goddamn jigsaw cutting", which meant that the producer had to follow Hitchcock's vision of the finished product.

Selznick lent Hitchcock to the larger studios more often than producing Hitchcock's films himself. Selznick made only a few films each year, as did fellow independent producer Samuel Goldwyn

The Selznick picture "Rebecca" (1940) was Hitchcock's first American film, set in a Hollywood version of England's Cornwall and based on a novel by English novelist Daphne du Maurier. The film stars Laurence Olivier and Joan Fontaine. The story concerns a naïve (and unnamed) young woman who marries a widowed aristocrat. She goes to live in his huge English country house, and struggles with the lingering reputation of his elegant and worldly first wife Rebecca, who died under mysterious circumstances. The film won Best Picture at the 13th Academy Awards; the statuette was given to Selznick, as the film's producer. Hitchcock was nominated for Best Director, his first of five such nominations.

Hitchcock's second American film was the thriller "Foreign Correspondent" (1940), set in Europe, based on Vincent Sheean's book "Personal History" (1935) and produced by Walter Wanger. It was nominated for Best Picture that year. Hitchcock felt uneasy living and working in Hollywood while his country was at war; his concern resulted in a film that overtly supported the British war effort. Filmed in the first year of the Second World War, it was inspired by the rapidly changing events in Europe, as covered by an American newspaper reporter played by Joel McCrea. Mixing footage of European scenes with scenes filmed on a Hollywood backlot, the film avoided direct references to Nazism, Nazi Germany, and Germans to comply with Hollywood's Motion Picture Production Code censorship at the time.

In September 1940 the Hitchcocks bought the Cornwall Ranch near Scotts Valley, California, in the Santa Cruz Mountains. Their primary residence was an English-style home in Bel Air, purchased in 1942. Hitchcock's films were diverse during this period, ranging from the romantic comedy "Mr. & Mrs. Smith" (1941) to the bleak film noir "Shadow of a Doubt
"Suspicion" (1941) marked Hitchcock's first film as a producer and director. It is set in England; Hitchcock used the north coast of Santa Cruz for the English coastline sequence. The film is the first of four projects on which Cary Grant worked with Hitchcock, and it is one of the rare occasions that Grant was cast in a sinister role. Grant plays Johnnie Aysgarth, an English con man whose actions raise suspicion and anxiety in his shy young English wife, Lina McLaidlaw (Joan Fontaine). In one scene Hitchcock placed a light inside a glass of milk, perhaps poisoned, that Grant is bringing to his wife; the light makes sure that the audience's attention is on the glass. Grant's character is a killer in the book on which the film was based, "Before the Fact" by Francis Iles, but the studio felt that Grant's image would be tarnished by that. Hitchcock therefore settled for an ambiguous finale, although, as he told François Truffaut, he would have preferred to end with the wife's murder. Fontaine won Best Actress for her performance.

"Saboteur" (1942) is the first of two films that Hitchcock made for Universal during the decade. Hitchcock was forced by Universal Studios to use Universal contract player Robert Cummings and Priscilla Lane, a freelancer who signed a one-picture deal with Universal, both known for their work in comedies and light dramas. Breaking with Hollywood conventions of the time, Hitchcock did extensive location filming, especially in New York City, and depicted a confrontation between a suspected saboteur (Cummings) and a real saboteur (Norman Lloyd) atop the Statue of Liberty. He also directed "Have You Heard?" (1942), a photographic dramatisation for "Life" magazine of the dangers of rumours during wartime. In 1943 he wrote a mystery story for "Look" magazine, "The Murder of Monty Woolley

"Shadow of a Doubt" (1943) was Hitchcock's personal favourite and the second of the early Universal films. Charlotte "Charlie" Newton (Teresa Wright) suspects her beloved uncle Charlie Oakley (Joseph Cotten) of being a serial killer. Hitchcock again filmed extensively on location, this time in the Northern California city of Santa Rosa.

Working at 20th Century Fox, Hitchcock adapted a script of John Steinbeck's, which recorded the experiences of the survivors of a German U-boat attack in the film "Lifeboat" (1944). The action sequences were shot in a small boat in the studio water tank. The locale posed problems for Hitchcock's traditional cameo appearance. That was solved by having Hitchcock's image appear in a newspaper that William Bendix is reading in the boat, showing the director in a before-and-after advertisement for "Reduco-Obesity Slayer". He told Truffaut in 1962:

Hitchcock's typical dinner before the weight loss had been a roast chicken, boiled ham, potatoes, bread, vegetables, relishes, salad, dessert, a bottle of wine and some brandy. To lose weight, he stopped drinking, drank black coffee for breakfast and lunch, and ate steak and salad for dinner, but it was hard to maintain; Spoto writes that his weight fluctuated considerably over the next 40 years. At the end of 1943, despite the weight loss, the Occidental Insurance Company of Los Angeles refused him life insurance.

Hitchcock returned to the UK for an extended visit in late 1943 and early 1944. While there he made two short propaganda films, "Bon Voyage" (1944) and "Aventure Malgache" (1944), for the Ministry of Information. In June and July 1945 Hitchcock served as "treatment advisor" on a Holocaust documentary that used Allied Forces footage of the liberation of Nazi concentration camps. The film was assembled in London and produced by Sidney Bernstein of the Ministry of Information, who brought Hitchcock (a friend of his) on board. It was originally intended to be broadcast to the Germans, but the British government deemed it too traumatic to be shown to a shocked post-war population. Instead, it was transferred in 1952 from the British War Office film vaults to London's Imperial War Museum and remained unreleased until 1985, when an edited version was broadcast as an episode of PBS "Frontline", under the title the Imperial War Museum had given it: "Memory of the Camps". The full-length version of the film, "German Concentration Camps Factual Survey
Hitchcock worked for David Selznick again when he directed "Spellbound" (1945), which explores psychoanalysis and features a dream sequence designed by Salvador Dalí. The dream sequence as it appears in the film is ten minutes shorter than was originally envisioned; Selznick edited it to make it "play" more effectively. Gregory Peck plays amnesiac Dr. Anthony Edwardes under the treatment of analyst Dr. Peterson (Ingrid Bergman), who falls in love with him while trying to unlock his repressed past. Two point-of-view shots were achieved by building a large wooden hand (which would appear to belong to the character whose point of view the camera took) and out-sized props for it to hold: a bucket-sized glass of milk and a large wooden gun. For added novelty and impact, the climactic gunshot was hand-coloured red on some copies of the black-and-white film. The original musical score by Miklós Rózsa makes use of the theremin, and some of it was later adapted by the composer into Rozsa's Piano Concerto Op. 31 (1967) for piano and orchestra.

"Notorious" (1946) followed "Spellbound".
Hitchcock told François Truffaut that Selznick had sold him, Ingrid Bergman, Cary Grant, and the screenplay by Ben Hecht, to RKO Radio Pictures as a "package" for $500,000 () because of cost overruns on Selznick's "Duel in the Sun" (1946). "Notorious" stars Bergman and Grant, both Hitchcock regulars, and features a plot about Nazis, uranium and South America. His prescient use of uranium as a plot device led to him being briefly placed under surveillance by the Federal Bureau of Investigation. According to McGilligan, in or around March 1945 Hitchcock and Ben Hecht consulted Robert Millikan of the California Institute of Technology about the development of a uranium bomb. Selznick complained that the notion was "science fiction", only to be confronted by the news of the detonation of two atomic bombs on Hiroshima and Nagasaki

Hitchcock formed an independent production company, Transatlantic Pictures, with his friend Sidney Bernstein. He made two films with Transatlantic, one of which was his first colour film. With "Rope" (1948), Hitchcock experimented with marshalling suspense in a confined environment, as he had done earlier with "Lifeboat" (1944). The film appears to have been shot in a single take, but it was actually shot in 10 takes ranging from 4- to 10 minutes each; a 10-minute length of film was the most that a camera's film magazine could hold at the time. Some transitions between reels were hidden by having a dark object fill the entire screen for a moment. Hitchcock used those points to hide the cut, and began the next take with the camera in the same place. The film features James Stewart in the leading role, and was the first of four films that Stewart made with Hitchcock. It was inspired by the Leopold and Loeb case of the 1920s. The film was not well received.

"Under Capricorn" (1949), set in 19th-century Australia, also uses the short-lived technique of long takes, but to a more limited extent. He again used Technicolor in this production, then returned to black-and-white films for several years. Transatlantic Pictures became inactive after these two unsuccessful films. Hitchcock filmed "Stage Fright" (1950) at studios in Elstree, England, where he had worked during his British International Pictures contract many years before. He matched one of Warner Bros.' most popular stars, Jane Wyman, with the expatriate German actor Marlene Dietrich and used several prominent British actors, including Michael Wilding, Richard Todd and Alastair Sim. This was Hitchcock's first proper production for Warner Bros., which had distributed "Rope" and "Under Capricorn", because Transatlantic Pictures was experiencing financial difficulties.

His film "Strangers on a Train" (1951) was based on the novel of the same name by Patricia Highsmith. Hitchcock combined many elements from his preceding films. He approached Dashiell Hammett to write the dialogue, but Raymond Chandler took over, then left over disagreements with the director. In the film, two men casually meet, one of whom speculates on a foolproof method to murder; he suggests that two people, each wishing to do away with someone, should each perform the other's murder. Farley Granger's role was as the innocent victim of the scheme, while Robert Walker, previously known for "boy-next-door" roles, played the villain. "I Confess" (1953) was set in Quebec with Montgomery Clift
"I Confess" was followed by three colour films starring Grace Kelly: "Dial M for Murder" (1954), "Rear Window" (1954), and "To Catch a Thief" (1955). In "Dial M for Murder", Ray Milland plays the villain who tries to murder his unfaithful wife (Kelly) for her money. She kills the hired assassin in self-defence, so Milland manipulates the evidence to make it look like murder. Her lover, Mark Halliday (Robert Cummings), and Police Inspector Hubbard (John Williams) save her from execution. Hitchcock experimented with 3D cinematography for "Dial M".

Hitchcock moved to Paramount Pictures and filmed "Rear Window" (1954), starring James Stewart and Kelly again, as well as Thelma Ritter and Raymond Burr. Stewart's character is a photographer (based on Robert Capa) who must temporarily use a wheelchair. Out of boredom, he begins observing his neighbours across the courtyard, then becomes convinced that one of them (Raymond Burr) has murdered his wife. Stewart eventually manages to convince his policeman buddy (Wendell Corey

From 1955 to 1965, Hitchcock was the host of the television series "Alfred Hitchcock Presents". With his droll delivery, gallows humour and iconic image, the series made Hitchcock a celebrity. The title-sequence of the show pictured a minimalist caricature of his profile (he drew it himself; it is composed of only nine strokes), which his real silhouette then filled. The series theme tune was "Funeral March of a Marionette" by the French composer Charles Gounod (1818–1893).

His introductions always included some sort of wry humour, such as the description of a recent multi-person execution hampered by having only one electric chair, while two are shown with a sign "Two chairs—no waiting!" He directed 18 episodes of the series, which aired from 1955 to 1965. It became "The Alfred Hitchcock Hour" in 1962, and NBC broadcast the final episode on 10 May 1965. In the 1980s, a new version of "Alfred Hitchcock Presents" was produced for television, making use of Hitchcock's original introductions in a colourised

In 1955 Hitchcock became a United States citizen. The same year, his third Grace Kelly film, "To Catch a Thief", was released; it is set in the French Riviera, and pairs Kelly with Cary Grant. Grant plays retired thief John Robie, who becomes the prime suspect for a spate of robberies in the Riviera. A thrill-seeking American heiress played by Kelly surmises his true identity and tries to seduce him. "Despite the obvious age disparity between Grant and Kelly and a lightweight plot, the witty script (loaded with double entendres) and the good-natured acting proved a commercial success." It was Hitchcock's last film with Kelly. She married Prince Rainier of Monaco in 1956, and ended her film career. Hitchcock then remade his own 1934 film "The Man Who Knew Too Much" in 1956. This time, the film starred James Stewart and Doris Day, who sang the theme song "Que Sera, Sera", which won the Oscar for Best Original Song and became a big hit for her. They play a couple whose son is kidnapped to prevent them from interfering with an assassination. As in the 1934 film, the climax takes place at the Royal Albert Hall, London.

"The Wrong Man" (1957), Hitchcock's final film for Warner Bros., is a low-key black-and-white production based on a real-life case of mistaken identity reported in "Life" magazine in 1953. This was the only film of Hitchcock to star Henry Fonda, playing a Stork Club musician mistaken for a liquor store thief, who is arrested and tried for robbery while his wife (Vera Miles

Hitchcock's next film, "Vertigo" (1958) again starred James Stewart, this time with Kim Novak and Barbara Bel Geddes. He had wanted Vera Miles to play the lead, but she was pregnant. He told Oriana Fallaci: "I was offering her a big part, the chance to become a beautiful sophisticated blonde, a real actress. We'd have spent a heap of dollars on it, and she has the bad taste to get pregnant. I hate pregnant women, because then they have children."

In the film, James Stewart plays Scottie, a former police investigator suffering from acrophobia, who develops an obsession with a woman he has been hired to shadow (Kim Novak). Scottie's obsession leads to tragedy, and this time Hitchcock does not opt for a happy ending. Some critics, including Donald Spoto and Roger Ebert, agree that "Vertigo" is the director's most personal and revealing film, dealing with the "Pygmalion"-like obsessions of a man who crafts a woman into the woman he desires. "Vertigo" explores more frankly and at greater length his interest in the relation between sex and death than any other work in his filmography.

"Vertigo" contains a camera technique developed by Irmin Roberts, commonly referred to as a dolly zoom, that has been copied many times by filmmakers. The film premiered at the San Sebastián International Film Festival, where Hitchcock won a Silver Seashell. "Vertigo" is considered a classic, but it attracted some negative reviews and poor box-office receipts at the time, and it was the last collaboration between Stewart and Hitchcock. In the 2002 "Sight & Sound" polls, it ranked just behind "Citizen Kane" (1941); ten years later, in the same magazine, critics chose it as the best film ever made.

Hitchcock followed "Vertigo" with three more successful films, which are also recognised as among his best: "North by Northwest" (1959), "Psycho" (1960) and "The Birds" (1963). In "North by Northwest", Cary Grant portrays Roger Thornhill, a Madison Avenue advertising executive who is mistaken for a government secret agent. He is hotly pursued across the United States by enemy agents, including (it appears) Eve Kendall (Eva Marie Saint). Thornhill at first believes Kendall is helping him, then that she is an enemy agent; he eventually learns that she is working undercover for the CIA. During its opening two-week run at Radio City Music Hall, the film grossed $404,056 (), setting a record in that theatre's non-holiday gross. "Time
"Psycho" (1960) is arguably Hitchcock's best-known film. Based on Robert Bloch's novel "Psycho" (1959), which was inspired by the case of Ed Gein, the film was produced on a constrained budget of $800,000 () and shot in black-and-white on a spare set using crew members from "Alfred Hitchcock Presents". The unprecedented violence of the shower scene, the early death of the heroine, and the innocent lives extinguished by a disturbed murderer became the hallmarks of a new horror-film genre. The public loved the film, with lines stretching outside cinemas as people had to wait for the next showing. It broke box-office records in the United Kingdom, France, South America, the United States and Canada and was a moderate success in Australia for a brief period.

The film was the most profitable of Hitchcock's career; he personally earned well in excess of $15 million (equivalent to $ million in ). He subsequently swapped his rights to "Psycho" and his TV anthology for 150,000 shares of MCA, making him the third largest shareholder and his own boss at Universal, in theory at least, although that did not stop them from interfering with him. Following the first film, "Psycho" became an American horror franchise: "Psycho II", "Psycho III", "Bates Motel", "Psycho IV: The Beginning", and a colour 1998 remake of the original.

On 13 August 1962, Hitchcock's 63rd birthday, the French director François Truffaut
The film scholar Peter William Evans writes that "The Birds" (1963) and "Marnie" (1964) are regarded as "undisputed masterpieces". Hitchcock had intended to film "Marnie" first, and in March 1962 it was announced that Grace Kelly, Princess Grace of Monaco since 1956, would come out of retirement to star in it. When Kelly asked Hitchcock to postpone "Marnie" until 1963 or 1964, he recruited Evan Hunter, author of "The Blackboard Jungle" (1954), to develop a screenplay based on a Daphne du Maurier short story, "The Birds" (1952), which Hitchcock had republished in his "My Favorites in Suspense" (1959). He hired Tippi Hedren to play the lead role. It was her first role; she had been a model in New York when Hitchcock saw her, in October 1961, in an NBC television ad for Sego, a diet drink: "I signed her because she is a classic beauty. Movies don't have them any more. Grace Kelly was the last." He insisted, without explanation, that her first name be written in single quotation marks: 'Tippi'.

In "The Birds", Melanie Daniels, a young socialite, meets lawyer Mitch Brenner (Rod Taylor) in a bird shop; Jessica Tandy plays his possessive mother. Hedren visits him in Bodega Bay (where "The Birds" was filmed) carrying a pair of lovebirds as a gift. Suddenly waves of birds start gathering, watching, and attacking. The question: "What do the birds want?" is left unanswered. Hitchcock made the film with equipment from the Revue Studio, which made "Alfred Hitchcock Presents". He said it was his most technically challenging film yet, using a combination of trained and mechanical birds against a backdrop of wild ones. Every shot was sketched in advance.

An HBO/BBC television film, "The Girl" (2012), depicted Hedren's experiences on set; she said that Hitchcock became obsessed with her and sexually harassed her. He reportedly isolated her from the rest of the crew, had her followed, whispered obscenities to her, had her handwriting analysed, and had a ramp built from his private office directly into her trailer. Diane Baker

In June 1962, Grace Kelly announced that she had decided against appearing in "Marnie" (1964). Hedren had signed an exclusive seven-year, $500-a-week contract with him in October 1961, and he decided to cast her in the lead role opposite Sean Connery. In 2016, describing Hedren's performance as "one of the greatest in the history of cinema", Richard Brody

No longer speaking to her because she had rebuffed him, Hitchcock apparently referred to Hedren throughout as "the girl" rather than by name. He told Robert Burks, the cinematographer, that the camera had to be placed as close as possible to Hedren when he filmed her face. Evan Hunter, the screenwriter of "The Birds" who was writing "Marnie" too, explained to Hitchcock that, if Mark loved Marnie, he would comfort her, not rape her. Hitchcock reportedly replied: "Evan, when he sticks it in her, I want that camera right on her face!" When Hunter submitted two versions of the script, one without the rape scene, Hitchcock replaced him with Jay Presson Allen.

Failing health reduced Hitchcock's output during the last two decades of his life. Biographer Stephen Rebello claimed Universal "forced" two movies on him, "Torn Curtain" (1966) and "Topaz" (1969). Both were spy thrillers with Cold War-related themes. "Torn Curtain", with Paul Newman and Julie Andrews, precipitated the bitter end of the 12-year collaboration between Hitchcock and composer Bernard Herrmann. Hitchcock was unhappy with Herrmann's score and replaced him with John Addison, Jay Livingston and Ray Evans. "Topaz" (1967), based on a Leon Uris

Hitchcock returned to Britain to make his penultimate film, "Frenzy" (1972), based on the novel "Goodbye Piccadilly, Farewell Leicester Square" (1966). After two espionage films, the plot marked a return to the murder-thriller genre. Richard Blaney (Jon Finch), a volatile barman with a history of explosive anger, becomes the prime suspect in the investigation into the "Necktie Murders", which are actually committed by his friend Bob Rusk (Barry Foster). This time, Hitchcock makes the victim and villain kindreds, rather than opposites as in "Strangers on a Train".

In "Frenzy", Hitchcock allowed nudity for the first time. Two scenes show naked women, one of whom is being raped and strangled; Spoto called the latter "one of the most repellent examples of a detailed murder in the history of film". Both actors, Barbara Leigh-Hunt and Anna Massey, refused to do the scenes, so models were used instead. Biographers have noted that Hitchcock had always pushed the limits of film censorship, often managing to fool Joseph Breen, the longtime head of Hollywood's Motion Picture Production Code. Many times Hitchcock slipped in subtle hints of improprieties forbidden by censorship until the mid-1960s. Yet McGilligan wrote that Breen and others often realised that Hitchcock was inserting such things and were actually amused, as well as alarmed by Hitchcock's "inescapable inferences".

"Family Plot" (1976) was Hitchcock's last film. It relates the escapades of "Madam" Blanche Tyler, played by Barbara Harris, a fraudulent spiritualist, and her taxi-driver lover Bruce Dern, making a living from her phony powers. While "Family Plot" was based on the Victor Canning novel "The Rainbird Pattern" (1972), the novel's tone is more sinister. Screenwriter Ernest Lehman originally wrote the film with a dark tone but was pushed to a lighter, more comical tone by Hitchcock.

Toward the end of his life, Hitchcock was working on the script for a spy thriller, "The Short Night", collaborating with James Costigan, Ernest Lehman and David Freeman. Despite preliminary work, it was never filmed. Hitchcock's health was declining and he was worried about his wife, who had suffered a stroke. The screenplay was eventually published in Freeman's book "The Last Days of Alfred Hitchcock" (1999).

Having refused a CBE in 1962, Hitchcock was appointed a Knight Commander of the Most Excellent Order of the British Empire (KBE) in the 1980 New Year Honours. He was too ill to travel to London—he had a pacemaker and was being given cortisone injections for his arthritis—so on 3 January 1980 the British consul general presented him with the papers at Universal Studios. Asked by a reporter after the ceremony why it had taken the Queen so long, Hitchcock quipped, "I suppose it was a matter of carelessness." Cary Grant, Janet Leigh, and others attended a luncheon afterwards.

His last public appearance was on 16 March 1980, when he introduced the next year's winner of the American Film Institute award. He died of kidney failure the following month, on 29 April, in his Bel Air home. Donald Spoto, one of Hitchcock's biographers, wrote that Hitchcock had declined to see a priest, but according to Jesuit priest Mark Henninger, he and another priest, Tom Sullivan, celebrated Mass at the filmmaker's home, and Sullivan heard his confession
Hitchcock returned several times to cinematic devices such as the audience as voyeur, suspense, the wrong man or woman, and the "MacGuffin," a plot device essential to the characters but irrelevant to the audience. Thus, the MacGuffin was always hazily described (in "North by Northwest", Leo G. Carroll describes James Mason as an "importer-exporter").

Hitchcock appears briefly in most of his own films. For example, he is seen struggling to get a double bass onto a train ("Strangers on a Train"), walking dogs out of a pet shop ("The Birds"), fixing a neighbour's clock ("Rear Window"), as a shadow ("Family Plot"), sitting at a table in a photograph ("Dial M for Murder"), and riding a bus ("North by Northwest").

Hitchcock's portrayal of women has been the subject of much scholarly debate. Bidisha wrote in "The Guardian" in 2010: "There's the vamp, the tramp, the snitch, the witch, the slink, the double-crosser and, best of all, the demon mommy. Don't worry, they all get punished in the end." In a widely cited essay in 1975, Laura Mulvey introduced the idea of the male gaze; the view of the spectator in Hitchcock's films, she argued, is that of the heterosexual male protagonist. "The female characters in his films reflected the same qualities over and over again", Roger Ebert
The victims in "The Lodger" are all blondes. In "The 39 Steps" (1935), Madeleine Carroll is put in handcuffs. Ingrid Bergman, whom Hitchcock directed three times ("Spellbound" (1945), "Notorious" (1946), and "Under Capricorn" (1949)), is dark blonde. In "Rear Window" (1954), Lisa (Grace Kelly) risks her life by breaking into Lars Thorwald's apartment. In "To Catch a Thief" (1955), Francie (Grace Kelly again) offers to help a man she believes is a burglar. In "Vertigo" (1958) and "North by Northwest" (1959) respectively, Kim Novak and Eva Marie Saint play the blonde heroines. In "Psycho" (1960), Janet Leigh's character steals $40,000 () and is murdered by Norman Bates, a reclusive psychopath. Tippi Hedren, a blonde, appears to be the focus of the attacks in "The Birds" (1963). In "Marnie" (1964), the title character, again played by Hedren, is a thief. In "Topaz", French actresses Dany Robin as Stafford's wife and Claude Jade as Stafford's daughter are blonde heroines, the mistress was played by brunette Karin Dor. Hitchcock's last blonde heroine was Barbara Harris as a phony psychic turned amateur sleuth in "Family Plot" (1976), his final film. In the same film, the diamond smuggler played by Karen Black wears a long blonde wig in several scenes.

His films often feature characters struggling in their relationships with their mothers, such as Norman Bates in "Psycho". In "North by Northwest" (1959), Roger Thornhill (Cary Grant) is an innocent man ridiculed by his mother for insisting that shadowy, murderous men are after him. In "The Birds" (1963), the Rod Taylor character, an innocent man, finds his world under attack by vicious birds, and struggles to free himself from a clinging mother (Jessica Tandy). The killer in "Frenzy" (1972) has a loathing of women but idolises his mother. The villain Bruno in "Strangers on a Train" hates his father, but has an incredibly close relationship with his mother (played by Marion Lorne). Sebastian (Claude Rains) in "Notorious" has a clearly conflicting relationship with his mother, who is (rightly) suspicious of his new bride, Alicia Huberman (Ingrid Bergman).

Hitchcock became known for having remarked that "actors are cattle." During the filming of "Mr. & Mrs. Smith" (1941), Carole Lombard brought three cows onto the set wearing the name tags of Lombard, Robert Montgomery, and Gene Raymond, the stars of the film, to surprise him.

Hitchcock believed that actors should concentrate on their performances and leave work on script and character to the directors and screenwriters. He told Bryan Forbes in 1967: "I remember discussing with a method actor how he was taught and so forth. He said, 'We're taught using improvisation. We are given an idea and then we are turned loose to develop in any way we want to.' I said 'That's not acting. That's writing.'" Walter Slezak said that Hitchcock knew the mechanics of acting better than anyone he knew.

Critics observed that, despite his reputation as a man who disliked actors, actors who worked with him often gave brilliant performances. He used the same actors in many of his films; Cary Grant worked with Hitchcock four times, and Ingrid Bergman three. James Mason said that Hitchcock regarded actors as "animated props". For Hitchcock, the actors were part of the film's setting. He told François Truffaut: "The chief requisite for an actor is the ability to do nothing well, which is by no means as easy as it sounds. He should be willing to be utilised and wholly integrated into the picture by the director and the camera. He must allow the camera to determine the proper emphasis and the most effective dramatic highlights."

Hitchcock planned his scripts in detail with his writers. In "Writing with Hitchcock" (2001), Steven DeRosa noted that Hitchcock supervised them through every draft, asking that they tell the story visually. He told Roger Ebert in 1969:

Hitchcock's films were extensively storyboarded to the finest detail. He was reported to have never even bothered looking through the viewfinder
This view of Hitchcock as a director who relied more on pre-production than on the actual production itself has been challenged by Bill Krohn, the American correspondent of French film magazine "Cahiers du cinéma", in his book "Hitchcock at Work". After investigating script revisions, notes to other production personnel written by or to Hitchcock, and other production material, Krohn observed that Hitchcock's work often deviated from how the screenplay was written or how the film was originally envisioned. He noted that the myth of storyboards in relation to Hitchcock, often regurgitated by generations of commentators on his films, was to a great degree perpetuated by Hitchcock himself or the publicity arm of the studios. For example, the celebrated crop-spraying sequence of "North by Northwest" was not storyboarded at all. After the scene was filmed, the publicity department asked Hitchcock to make storyboards to promote the film, and Hitchcock in turn hired an artist to match the scenes in detail.

Even when storyboards were made, scenes that were shot differed from them significantly. Krohn's analysis of the production of Hitchcock classics like "Notorious" reveals that Hitchcock was flexible enough to change a film's conception during its production. Another example Krohn notes is the American remake of "The Man Who Knew Too Much," whose shooting schedule commenced without a finished script and moreover went over schedule, something that, as Krohn notes, was not an uncommon occurrence on many of Hitchcock's films, including "Strangers on a Train" and "Topaz
Krohn's work also sheds light on Hitchcock's practice of generally shooting in chronological order, which he notes sent many films over budget and over schedule and, more importantly, differed from the standard operating procedure of Hollywood in the Studio System Era. Equally important is Hitchcock's tendency to shoot alternative takes of scenes. This differed from coverage in that the films were not necessarily shot from varying angles so as to give the editor options to shape the film how he/she chooses (often under the producer's aegis). Rather they represented Hitchcock's tendency to give himself options in the editing room, where he would provide advice to his editors after viewing a rough cut of the work. According to Krohn, this and a great deal of other information revealed through his research of Hitchcock's personal papers, script revisions and the like refute the notion of Hitchcock as a director who was always in control of his films, whose vision of his films did not change during production, which Krohn notes has remained the central long-standing myth of Alfred Hitchcock. Both his fastidiousness and attention to detail also found their way into each film poster for his films. Hitchcock preferred to work with the best talent of his day—film poster designers such as Bill Gold and Saul Bass
Hitchcock was inducted into the Hollywood Walk of Fame on 8 February 1960 with two stars: one for television and a second for his motion pictures. In 1978 John Russell Taylor described him as "the most universally recognizable person in the world" and "a straightforward middle-class Englishman who just happened to be an artistic genius". In 2002 "MovieMaker
He won two Golden Globes, eight Laurel Awards, and five lifetime achievement awards, including the first BAFTA Academy Fellowship Award and, in 1979, an AFI Life Achievement Award. He was nominated five times for an Academy Award for Best Director. "Rebecca", nominated for 11 Oscars, won the Academy Award for Best Picture of 1940; another Hitchcock film, "Foreign Correspondent", was also nominated that year. By 2018 eight of his films had been selected for preservation by the United States National Film Registry: "Rebecca" (1940), "Shadow of a Doubt" (1943), "Notorious" (1946), "Rear Window" (1954), "Vertigo" (1958), "North by Northwest" (1959), "Psycho" (1960), and "The Birds" (1963).

In 2012 Hitchcock was selected by artist Sir Peter Blake, author of the Beatles' "Sgt. Pepper's Lonely Hearts Club Band" album cover, to appear in a new version of the cover, along with other British cultural figures, and he was featured that year in a BBC Radio 4 series, "The New Elizabethans", as someone "whose actions during the reign of Elizabeth II have had a significant impact on lives in these islands and given the age its character". In June 2013 nine restored versions of Hitchcock's early silent films, including "The Pleasure Garden" (1925), were shown at the Brooklyn Academy of Music's Harvey Theatre; known as "The Hitchcock 9", the travelling tribute was organised by the British Film Institute.

The Alfred Hitchcock Collection is housed at the Academy Film Archive
Category:1899 births
Category:1980 deaths
Category:20th-century English people
Category:Articles containing video clips
Category:BAFTA fellows
Category:Cecil B. DeMille Award Golden Globe winners
Category:Deaths from kidney failure
Category:Directors Guild of America Award winners
Category:Edgar Award winners
Category:English emigrants to the United States
Category:English film directors
Category:English film producers
Category:English people of Irish descent
Category:English Roman Catholics
Category:English television directors
Category:English-language film directors
Category:Film directors from London
Category:Film directors from Los Angeles
Category:Film producers from London
Category:German-language film directors
Category:Horror film directors
Category:Knights Commander of the Order of the British Empire
Category:People educated at St Ignatius' College, Enfield
Category:People from Bel Air, Los Angeles
Category:People from Leytonstone
Category:People with acquired American citizenship
Category:Recipients of the Irving G. Thalberg Memorial Award
Category:Silent film directors
Category:AFI Life Achievement Award recipientsAnaconda

Anacondas are a group of large snakes of the genus "Eunectes". They are found in tropical South America. Four species are currently recognized.

Although the name applies to a group of snakes, it is often used to refer only to one species in particular, the common or green anaconda ("Eunectes murinus") which is the largest snake in the world by weight, and the second longest.

The South American names "anacauchoa" and "anacaona" were suggested in an account by Peter Martyr d'Anghiera but the idea of a South American origin was questioned by Henry Walter Bates who, in his travels in South America, failed to find any similar name in use. The word anaconda is derived from the name of a snake from Ceylon (Sri Lanka) that John Ray described in Latin in his "Synopsis Methodica Animalium" (1693) as "serpens indicus bubalinus anacandaia zeylonibus, ides bubalorum aliorumque jumentorum membra conterens". Ray used a catalogue of snakes from the Leyden museum supplied by Dr. Tancred Robinson, but the description of its habit was based on Andreas Cleyer who in 1684 described a gigantic snake that crushed large animals by coiling around their bodies and crushing their bones. Henry Yule in his Hobson-Jobson notes that the word became more popular due to a piece of fiction published in 1768 in the Scots Magazine by a certain R. Edwin. Edwin described a 'tiger' being crushed to death by an anaconda, when there actually never were any tigers in Sri Lanka. Yule and Frank Wall noted that the snake was in fact a python and suggested a Tamil origin "anai-kondra" meaning elephant killer. A Sinhalese origin was also suggested by Donald Ferguson who pointed out that the word "Henakandaya" ("hena" lightning/large and "kanda" stem/trunk) was used in Sri Lanka for the small whip snake ("Ahaetulla pulverulenta



Category:Boidae
Category:Boinae by common nameAltaic languages

Altaic () is a hypothetical language family of central Eurasia and Siberia first proposed in the 18th century, but whose existence is widely discredited among comparative linguists. The Turkic, Mongolic and Tungusic groups are invariably included in the family; some authors added Koreanic and the Japonic languages. The latter expanded grouping came to be known as "Macro-Altaic", leading to the designation of the smaller former grouping as "Micro-Altaic" by retronymy. Most proponents of Altaic continue to support the inclusion of Korean. These languages are spoken in a wide arc stretching from Eastern Europe through Anatolia and eastern Caucasus through North Asia and Central Asia to the Korean Peninsula and Japanese archipelago in East Asia. The group is named after the Altai mountain range in the center of Asia.

The hypothesis of common origin for some or all of these languages—that is, the theory that they form a language family—was widespread before the 1960s, but has almost no supporters among specialists today. Opponents of the Altaic hypothesis maintain that the similarities are due to areal interaction between the language groups concerned. The inclusion of Korean and Japanese has also been criticized and disputed by other linguists. As for Turkic, Tungusic, and Mongolic, if they were related genetically

The idea that the Turkic, Mongolic, and Tungusic languages are closely related was allegedly first published in 1730 by Philip Johan von Strahlenberg, a Swedish officer who traveled in the eastern Russian Empire while a prisoner of war after the Great Northern War. However, as has been pointed out by Alexis Manaster Ramer and Paul Sidwell (1997), von Strahlenberg actually opposed the idea of a closer relationship among the languages that later became known as "Altaic". Von Strahlenberg's classification was the first attempt to classify a large number of languages, some of which are Altaic.

The term "Altaic", as applied to a language family, was introduced in 1844 by Matthias Castrén, a Finnish philologist who made contributions to the study of the Uralic languages. As originally formulated by Castrén, Altaic included not only Turkic, Mongolian, and Manchu-Tungus (=Tungusic), but also Finno-Ugric and Samoyed.

The original Altaic family came to be known as the Ural–Altaic. In the "Ural–Altaic" nomenclature, Finno-Ugric and Samoyedic are "Uralic", whereas Turkic, Mongolic, and Tungusic are "Altaic", as are Korean and Japanese if they are included at all.

For much of the 19th and the early 20th centuries, the theory of a common Ural–Altaic family was widespread, based on such shared features as vowel harmony and agglutination. However, while the Ural–Altaic hypothesis can still be found in encyclopedias, atlases, and similar general references, it has generally been abandoned by linguists. For instance, it was characterized by Sergei Starostin as "an idea now completely discarded".

In 1857, the Austrian scholar Anton Boller suggested adding Japanese to the Ural–Altaic family. In the 1920s, G.J. Ramstedt and E.D. Polivanov advocated the inclusion of Korean. However, Ramstedt's three-volume, "Einführung in die altaische Sprachwissenschaft" ('Introduction to Altaic Linguistics'), published in 1952–1966, rejected the Ural–Altaic hypothesis and again included Korean in Altaic, an inclusion followed by most leading Altaicists to date. The first volume of his work, "Lautlehre" ('Phonology'), contained the first comprehensive attempt to identify regular correspondences among the sound systems within the Altaic language families.

In 1960, Nicholas Poppe published what was in effect a heavily revised version of Ramstedt's volume on phonology that has since set the standard in Altaic studies. Poppe considered the issue of the relationship of Korean to Turkic-Mongolic-Tungusic not settled. In his view, there were three possibilities: (1) Korean did not belong with the other three genealogically, but had been influenced by an Altaic substratum; (2) Korean was related to the other three at the same level they were related to each other; (3) Korean had split off from the other three before they underwent a series of characteristic changes.

Micro-Altaic includes about 66 living languages, to which Macro-Altaic would add Korean, Japanese and the Ryukyuan languages, for a total of about 74 (depending on what is considered a language and what is considered a dialect). (The numbers do not include earlier states of languages, such as Middle Mongol, Old Korean or Old Japanese.)

Roy Andrew Miller's 1971 book "Japanese and the Other Altaic Languages" convinced most Altaicists that Japanese also belonged to Altaic. Since then, the standard set of languages included in Macro-Altaic has been Turkic, Mongolic, Tungusic, Korean, and Japanese.

An alternative classification, though one with much less currency among Altaicists, was proposed by John C. Street (1962), according to which Turkic-Mongolic-Tungusic forms one grouping and Korean-Japanese-Ainu another, the two being linked in a common family that Street designated as "North Asiatic". The same schema was adopted by James Patrie (1982) in the context of an attempt to classify the Ainu language. The Turkic-Mongolic-Tungusic and Korean-Japanese-Ainu groupings were also posited by Joseph Greenberg (2000–2002); however, he treated them as independent members of a larger family, which he termed Eurasiatic.

Anti-Altaicists Gerard Clauson (1956), Gerhard Doerfer (1963), and Alexander Shcherbak argued that the words and features shared by Turkic, Mongolic, and Tungusic languages were for the most part borrowings and that the rest could be attributed to chance resemblances. They noted that there was little vocabulary shared by Turkic and Tungusic languages, though more shared with Mongolic languages. They reasoned that, if all three families had a common ancestor, we should expect losses to happen at random and not only at the geographical margins of the family; and that the observed pattern is consistent with borrowing. Furthermore, they argued that many of the typological features of the supposed Altaic languages, such as agglutinative morphology and subject–object–verb (SOV) word order, usually simultaneously occur in languages. In sum, the idea was that Turkic, Mongolic, and Tungusic languages form a "Sprachbund"—the result of convergence through intensive borrowing and long contact among speakers of languages that are not necessarily closely related.

Doubt was also raised about the affinities of Korean and Japanese; in particular, some authors tried to connect Japanese to the Austronesian languages.

Starostin's (1991) lexicostatistical research claimed that the proposed Altaic groups shared about 15–20% of potential cognates within a 110-word Swadesh-Yakhontov list (e.g. Turkic–Mongolic 20%, Turkic–Tungusic 18%, Turkic–Korean 17%, Mongolic–Tungusic 22%, Mongolic–Korean 16%, Tungusic–Korean 21%). Altogether, Starostin concluded that the Altaic grouping was substantiated, though "older than most other language families in Eurasia, such as Indo-European or Finno-Ugric, and this is the reason why the modern Altaic languages preserve few common elements".

Unger (1990) advocates a family consisting of Tungusic, Korean, and Japonic languages but not Turkic or Mongolic; and Doerfer (1988) rejects all the genetic claims over these major groups. In 2003, Claus Schönig published a critical overview of the history of the Altaic hypothesis up to that time. He concluded:

In 2003, "An Etymological Dictionary of the Altaic Languages" was published by Starostin, Dybo, and Mudrak. It contains 2,800 proposed cognate sets, a set of sound laws based on those proposed sets, and a number of grammatical correspondences, as well as a few important changes to the reconstruction of Proto-Altaic. For example, although most of today's Altaic languages have vowel harmony, Proto-Altaic as reconstructed by Starostin "et al." lacked it; instead, various vowel assimilations between the first and second syllables of words occurred in Turkic, Mongolic, Tungusic, Korean, and Japonic. It tries hard to distinguish loans between Turkic and Mongolic and between Mongolic and Tungusic from cognates; and it suggests words that occur in Turkic and Tungusic but not in Mongolic. All other combinations between the five branches also occur in the book. It lists 144 items of shared basic vocabulary (most of them already present in Starostin 1991), including words for such items as 'eye', 'ear', 'neck', 'bone', 'blood', 'water', 'stone', 'sun', and 'two'. This work has not changed the minds of any of the principal authors in the field, however. The debate continues unabated – e.g. S. Georg 2004, A. Vovin 2005, S. Georg 2005 (anti-Altaic); S. Starostin 2005, V. Blažek 2006, M. Robbeets 2007, A. Dybo and G. Starostin 2008 (pro-Altaic).

According to Roy Andrew Miller (1996: 98–99), the Clauson–Doerfer critique of Altaic relies exclusively on lexicon, whereas the fundamental evidence for Altaic comprises verbal morphology. Lars Johanson (2010: 15–17) suggests that a resolution of the Altaic dispute may yet come from the examination of verbal morphology and calls for a muting of the polemic: "The dark age of "pro" and "contra" slogans, unfair polemics, and humiliations is not yet completely over and done with, but there seems to be some hope for a more constructive discussion" (ib. 17).

A 2015 analysis using the Automated Similarity Judgment Program resulted in the Japonic languages being grouped with the Ainu and Austroasiatic languages, but showing no connection to Turkic and Mongolic. However, similarities between Ainu and Japonic are also due to extensive past contact. Analytic grammatical constructions acquired or transformed in Ainu were likely due to contact with Japanese and the Japonic languages, which had heavy influence on the Ainu languages with a large number of loanwords borrowed into the Ainu languages, and to a smaller extent, vice versa.

The Ainu languages shows the least connection with Altaic. No genealogical relationship between Ainu and any other language family has been demonstrated, despite numerous attempts. Thus, it is a language isolate. Ainu is sometimes grouped with the Paleosiberian languages, but this is only a geographic blanket term for several unrelated language families that were present in Siberia before the advances of Turkic and Tungusic languages there.

The earliest known texts in a Turkic language are the Orkhon inscriptions, 720–735 AD. They were deciphered in 1893 by the Danish linguist Vilhelm Thomsen in a scholarly race with his rival, the German–Russian linguist Wilhelm Radloff. However, Radloff was the first to publish the inscriptions.

The first Tungusic language to be attested is Jurchen, the language of the ancestors of the Manchus. A writing system for it was devised in 1119 AD and an inscription using this system is known from 1185 (see List of Jurchen inscriptions).

The earliest Mongolic language of which we have written evidence is known as Middle Mongol. It is first attested by an inscription dated to 1224 or 1225 AD and by the "Secret History of the Mongols", written in 1228 (see Mongolic languages). The earliest Para-Mongolic text is the Memorial for Yelü Yanning, written in the Khitan Large Script and dated to 986 AD.

Japanese is first attested in the form of names contained in a few short inscriptions in Classical Chinese from the 5th century AD, such as found on the Inariyama Sword. The first substantial text in Japanese, however, is the Kojiki, which dates from 712 AD. It is followed by the Nihon shoki, completed in 720, and that by the Man'yōshū, which dates from c. 771–785, but includes material that is from about 400 years earlier.

The most important text for the study of early Korean is the Hyangga, a collection of 25 poems, of which some go back to the Three Kingdoms period (57 BC–668 AD), but are preserved in an orthography that only goes back to the 9th century AD. Korean is copiously attested from the mid-15th century on in the phonetically precise Hangul system of writing.

The prehistory of the peoples speaking these languages is largely unknown. Whereas for certain other language families, such as the speakers of Indo-European, Uralic, and Austronesian, it is possible to frame substantial hypotheses, in the case of the proposed Altaic family much remains to be done.
Some scholars bear in mind a possible Uralic and Altaic homeland in the Central Asian steppes.

According to Juha Janhunen, the ancestral languages of Turkic, Mongolic, Tungusic, Korean, and Japanese were spoken in a relatively small area comprising present-day North Korea, Southern Manchuria, and Southeastern Mongolia. However Janhunen (1992) is skeptical about an affiliation of Japanese to Altaic, while András Róna-Tas remarked that a relationship between Altaic and Japanese, if it ever existed, must be more remote than the relationship of any two of the Indo-European languages. Ramsey stated that "the genetic relationship between Korean and Japanese, if it in fact exists, is probably more complex and distant than we can imagine on the basis of our present state of knowledge".

Supporters of the Altaic hypothesis formerly set the date of the Proto-Altaic language at around 4000 BC, but today at around 5000 BC or 6000 BC. This would make Altaic a language family about as old as Indo-European (4000 to 7,000 BC according to several hypotheses) but considerably younger than Afroasiatic (c. 10,000 BC or 11,000 to 16,000 BC according to different sources).

"Note: This list is limited to linguists who have worked specifically on the Altaic problem since the publication of the first volume of Ramstedt's "Einführung" in 1952. The dates given are those of works concerning Altaic. For Altaicists, the version of Altaic they favor is given at the end of the entry, if other than the prevailing one of Turkic–Mongolic–Tungusic–Korean–Japanese."




Based on the proposed correspondences listed below, the following phoneme inventory has been reconstructed for the hypothetical Proto):

 This phoneme only occurred at the beginnings of words.<br>

It is not clear whether , , were monophthongs as shown here (presumably ) or diphthongs (); the evidence is equivocal. In any case, however, they only occurred in the first (and sometimes only) syllable of any word.

Every vowel occurred in long and short versions which were different phonemes in the first syllable. Starostin et al. (2003) treat length together with pitch as a prosodic feature.

As reconstructed by Starostin et al. (2003), Proto-Altaic was a pitch accent or tone language; at least the first and probably every syllable could have a high or a low pitch.

If a Proto(-Macro)-Altaic language really existed, it should be possible to reconstruct regular sound correspondences between that protolanguage and its descendants; such correspondences would make it possible to distinguish cognates from loanwords.

When a Proto-Altaic phoneme developed differently depending on its position in a word (beginning, interior, or end), the special case (or all cases) is marked with a hyphen; for example, Proto-Altaic disappears (marked "0") or becomes at the beginning of a Turkic word and becomes elsewhere in a Turkic word.

Only single consonants are considered here. In the middle of words, clusters of two consonants were allowed in Proto-Altaic as reconstructed by Starostin et al. (2003); the correspondence table of these clusters spans almost seven pages in their book (83–89), and most clusters are only found in one or a few of the reconstructed roots.

Vowel harmony is pervasive in the languages attributed to Altaic: most Turkic and Mongolic as well as some Tungusic languages have it, Korean is arguably in the process of losing its traces, and it is controversially hypothesized for Old Japanese. (Vowel harmony is also typical of the neighboring Uralic languages and was often counted among the arguments for the Ural–Altaic hypotheses.) Nevertheless, Starostin et al. (2003) reconstruct Proto-Altaic as lacking vowel harmony. Instead, according to them, vowel harmony originated in each daughter branch as assimilation of the vowel in the first syllable to the vowel in the second syllable (which was usually modified or lost later). "The situation therefore is very close, e.g. to Germanic [see Germanic umlaut] or to the Nakh languages in the Eastern Caucasus, where the quality of non-initial vowels can now only be recovered on the basis of umlaut processes in the first syllable." (Starostin et al. 2003:91) The table below is taken from Starostin et al. (2003):

Length and pitch in the first syllable evolved as follows according to Starostin et al. (2003), with the caveat that it is not clear which pitch was high and which was low in Proto-Altaic (Starostin et al. 2003:135). For simplicity of input and display every syllable is symbolized as "a" here:

¹ "Proto-Mongolian has lost all traces of the original prosody except for voicing *p > *b in syllables with original high pitch" (Starostin et al. 2003:135).<br>
² "[...] several secondary metatonic processes happened [...] in Korean, basically in the verb subsystem: all verbs have a strong tendency towards low pitch on the first syllable." (Starostin et al. 2003:135)

Starostin et al. (2003) have reconstructed the following correspondences between the case and number suffixes (or clitics) of the (Macro-)Altaic languages (taken from Blažek, 2006):

/V/ symbolizes an uncertain vowel. Suffixes reconstructed for Proto-Turkic, Proto-Mongolic, Proto-Korean, or Proto-Japonic, but not attested in Old Turkic, Classical Mongolian, Middle Korean, or Old Japanese are marked with asterisks.

This correspondences, however, have been harshly criticized for several reasons: There are significant gaps resulting in the absence of etymologies for certain initial segments: an impossible situation in the case of a genetic relationship; lack of common paradigmatic morphology; in many cases, there are ghosts, invented or polished meanings; and word-list linguistics rules supreme, as there are few if any references to texts or philology.

There are also many reconstructions proved to be totally false. For instance, regarding Korean, Starostin et al. state that Middle Korean genitive is /nʲ/, while it actually was /s/ in its honorific form, and /ój/ or /uj/ as neutral forms.

In addition, some "cognates" are visibly forced, like the comparison between Turkish instrumental and Japanese locative /ni/. A locative postposition expresses an absolutely different meaning to that of an instrumental, so it is evident that both of them are not related whatsoever. The same applies for Japanese /ga/ and Proto Tungusic /ga/. The first of those particles expresses genitive case, while the second is the partitive case, which bear no resemblance of meaning at all either. Therefore, those two are not cognates. A different kind of issue is that of the Old Turkish genitive /Xŋ/ (where "X" stands for any phoneme) and Old Japanese genitive /no/. Although they share the same consonant, the fact that the former is a vowel plus a consonant, and the second is a fixed set of the consonant /n/ plus vowel /o/ makes the fact that those two are cognates extremely unlikely.

The table below is taken (with slight modifications) from Blažek (2006) and transcribed into IPA.

As above, forms not attested in Classical Mongolian or Middle Korean but reconstructed for their ancestors are marked with an asterisk, and /V/ represents an uncertain vowel.

There are, however, several problems with this proposed list. Aside from the huge amount of non-attested, free reconstructions, some mistakes on the research carried out by altaicists must be pointed out. The first of them is that Old Japanese for the first person pronoun ("I", in English) was neither /ba/ or /a/. It was /ware/ (和禮), and sometimes it was abbreviated to /wa/ (吾). Also, it is not a Sino-Japanese word, but a native Japanese term. In addition, the second person pronoun was not /si/, but either /imasi/ (汝), or /namu/ (奈牟), which sometimes was shortened to /na/. Its plural was /namu tachi/ (奈牟多知).

The following table is a brief selection of further proposed cognates in basic vocabulary across the Altaic family (from Starostin et al. [2003]). Their reconstructions and equivalences are not accepted by the mainstream linguists and therefore remain very controversial.

In the Indo-European family, the numerals are remarkably stable. This is a rather exceptional case; especially words for higher numbers are often borrowed wholesale. (Perhaps the most famous cases are Japanese and Korean, which have two complete sets of numerals each – one native, one Chinese
Category:Agglutinative languages
Category:Central Asia
Category:Proposed language families
Category:Requests for audio pronunciationAustrian German

Austrian German (), Austrian Standard German, Standard Austrian German (), or Austrian High German (), is the variety of Standard German written and spoken in Austria. It has the highest sociolinguistic prestige locally, as it is the variation used in the media and for other formal situations. In less formal situations, Austrians tend to use forms closer to or identical with the Bavarian and Alemannic dialects, traditionally spoken – but rarely written – in Austria.

Austrian German has its beginning in the mid-18th century, when empress Maria Theresa and her son Joseph II introduced compulsory schooling (in 1774) and several reforms of administration in their multilingual Habsburg empire. At the time, the written standard was "Oberdeutsche Schreibsprache", which was highly influenced by the Bavarian and Alemannic dialects of Austria. Another option was to create a new standard based on the Southern German dialects, as proposed by the linguist Johann Siegmund Popowitsch. Instead they decided for pragmatic reasons to adopt the already standardized Chancellery language of Saxony ("Sächsische Kanzleisprache" or "Meißner Kanzleideutsch"), which was based on the administrative language of the non-Austrian area of Meißen and Dresden. 
Thus Standard Austrian German has the same geographic origin as the Standard German of Germany ("Bundesdeutsches Hochdeutsch", also "Deutschländisches Deutsch") and Swiss High German ("Schweizer Hochdeutsch", not to be confused with the Alemannic Swiss German dialects).

The process of introducing the new written standard was led by Joseph von Sonnenfels.
Since 1951 the standardized form of Austrian German for official texts and schools has been defined by the "Austrian Dictionary" (""), published under the authority of the Austrian Federal Ministry of Education, Arts and Culture.

As German is a pluricentric language, Austrian German is one among several varieties of Standard German. Much like the relationship between British English and American English, the German varieties differ in minor respects (e.g., spelling, word usage and grammar) but are recognizably equivalent and largely mutually intelligible.

The official Austrian dictionary, "das Österreichische Wörterbuch", prescribes grammatical and spelling rules defining the official language. Austrian delegates participated in the international working group that drafted the German spelling reform of 1996—several conferences leading up to the reform were hosted in Vienna at the invitation of the Austrian federal government—and adopted it as a signatory, along with Germany, Switzerland, and Liechtenstein, of an international memorandum of understanding (Wiener Absichtserklärung) signed in Vienna in 1996. 
The "sharp s
Because of the German language's pluricentric nature, German dialects in Austria should not be confused with the variety of Standard German spoken by most Austrians, which is distinct from that of Germany or Switzerland. Distinctions in vocabulary persist, for example, in culinary terms, where communication with Germans is frequently difficult, and administrative and legal language, which is due to Austria's exclusion from the development of a German nation-state in the late 19th century and its manifold particular traditions. A comprehensive collection of Austrian-German legal, administrative and economic terms is offered in "Markhardt, Heidemarie: Wörterbuch der österreichischen Rechts-, Wirtschafts- und Verwaltungsterminologie" (Peter Lang, 2006).

The former standard, used for about 300 years or more in speech in refined language, was the ', a sociolect spoken by the imperial Habsburg family and the nobility of Austria-Hungary. It differed from other dialects in vocabulary and pronunciation; it appears to have been spoken with a slight degree of nasality. This was not a standard in a modern technical sense, as it was just the social standard of upper-class speech.

For many years, Austria had a special form of the language for official government documents. This form is known as "", or "Austrian chancellery language". It is a very traditional form of the language, probably derived from medieval deeds and documents, and has a very complicated structure and vocabulary generally reserved for such documents. For most speakers (even native speakers), this form of the language is generally difficult to understand, as it contains many highly specialised terms for diplomatic, internal, official, and military matters. There are no regional variations, because this special written form has mainly been used by a government that has now for centuries been based in Vienna.

' is now used less and less, thanks to various administrative reforms that reduced the number of traditional civil servants ('). As a result, Standard German is replacing it in government and administrative texts.

When Austria became a member of the European Union, 23 food-related terms were listed in its accession agreement as having the same legal status as the equivalent terms used in Germany. Austrian German is the only variety of a pluricentric language recognized under international law or EU primary law.

In Austria, as in the German-speaking parts of Switzerland and in southern Germany, verbs that express a state tend to use "" as the auxiliary verb in the perfect, as well as verbs of movement. Verbs which fall into this category include "sitzen" (to sit), "liegen" (to lie) and, in parts of Carinthia, "schlafen" (to sleep). Therefore, the perfect of these verbs would be "ich bin gesessen", "ich bin gelegen" and "ich bin geschlafen" respectively (note: "ich bin geschlafen" is a rarely used form, more commonly "ich habe geschlafen" is used).

In Germany, the words "stehen" (to stand) and "gestehen" (to confess) are identical in the present perfect: "habe gestanden". The Austrian variant avoids this potential ambiguity ("bin gestanden" from "stehen", "to stand"; and "habe gestanden" from "gestehen", "to confess", e.g. ""der Verbrecher ist vor dem Richter gestanden und hat gestanden"").

In addition, the preterite (simple past) is very rarely used in Austria, especially in the spoken language, with the exception of some modal verbs (i.e. "ich sollte", "ich wollte").

There are many official terms that differ in Austrian German from their usage in most parts of Germany. Words primarily used in Austria are "Jänner" (January) rather than "Januar", "Feber" (February) rather than "Februar", "heuer" (this year) rather than "dieses Jahr", "Stiege" (stairs) instead of "Treppe", "Rauchfang" (chimney) instead of "Schornstein", many administrative, legal and political terms, and many food terms, including the following:

There are, however, some false friends between the two regional varieties:


In addition to the standard variety, in everyday life most Austrians speak one of a number of Upper German dialects.

While strong forms of the various dialects are not fully mutually intelligible to northern Germans, communication is much easier in Bavaria, especially rural areas, where the Bavarian dialect still predominates as the mother tongue. The Central Austro-Bavarian dialects are more intelligible to speakers of Standard German than the Southern Austro-Bavarian dialects of Tyrol.

Viennese, the Austro-Bavarian dialect of Vienna, is seen for many in Germany as quintessentially Austrian. The people of Graz, the capital of Styria, speak yet another dialect which is not very Styrian and more easily understood by people from other parts of Austria than other Styrian dialects, for example from western Styria.

Simple words in the various dialects are very similar, but pronunciation is distinct for each and, after listening to a few spoken words, it may be possible for an Austrian to realise which dialect is being spoken. However, in regard to the dialects of the deeper valleys of the Tirol, other Tyroleans are often unable to understand them. Speakers from the different states of Austria can easily be distinguished from each other by their particular accents (probably more so than Bavarians), those of Carinthia, Styria, Vienna, Upper Austria, and the Tyrol being very characteristic. Speakers from those regions, even those speaking Standard German, can usually be easily identified by their accent, even by an untrained listener.

Several of the dialects have been influenced by contact with non-Germanic linguistic groups, such as the dialect of Carinthia, where in the past many speakers were bilingual with Slovene, and the dialect of Vienna, which has been influenced by immigration during the Austro-Hungarian period, particularly from what is today the Czech Republic. The German dialects of South Tyrol have been influenced by local Romance languages, particularly noticeable with the many loanwords from Italian and Ladin.

The geographic borderlines between the different accents (isoglosses) coincide strongly with the borders of the states and also with the border with Bavaria, with Bavarians having a markedly different rhythm of speech in spite of the linguistic similarities.




Category:German dialects
Category:National varieties of German
Category:Bavarian language

In mathematics, the axiom of choice, or AC, is an axiom of set theory equivalent to the statement that "the Cartesian product of a collection of non-empty sets is non-empty". Informally put, the axiom of choice says that given any collection of bins, each containing at least one object, it is possible to make a selection of exactly one object from each bin, even if the collection is infinite. Formally, it states that for every indexed family formula_1 of nonempty sets there exists an indexed family formula_2 of elements such that formula_3 for every formula_4. The axiom of choice was formulated in 1904 by Ernst Zermelo in order to formalize his proof of the well-ordering theorem.

In many cases, such a selection can be made without invoking the axiom of choice; this is in particular the case if the number of sets is finite, or if a selection rule is available – some distinguishing property that happens to hold for exactly one element in each set. An illustrative example is sets picked from the natural numbers. From such sets, one may always select the smallest number, e.g. in <nowiki></nowiki> the smallest elements are {4, 10, 1}. In this case, "select the smallest number" is a choice function. Even if infinitely many sets were collected from the natural numbers, it will always be possible to choose the smallest element from each set to produce a set. That is, the choice function provides the set of chosen elements. However, no choice function is known for the collection of all non-empty subsets of the real numbers (if there are non-constructible reals). In that case, the axiom of choice must be invoked. 

Bertrand Russell coined an analogy: for any (even infinite) collection of pairs of shoes, one can pick out the left shoe from each pair to obtain an appropriate selection; this makes it possible to directly define a choice function. For an "infinite" collection of pairs of socks (assumed to have no distinguishing features), there is no obvious way to make a function that selects one sock from each pair, without invoking the axiom of choice.

Although originally controversial, the axiom of choice is now used without reservation by most mathematicians, and it is included in the standard form of axiomatic set theory, Zermelo–Fraenkel set theory with the axiom of choice (ZFC). One motivation for this use is that a number of generally accepted mathematical results, such as Tychonoff's theorem, require the axiom of choice for their proofs. Contemporary set theorists also study axioms that are not compatible with the axiom of choice, such as the axiom of determinacy. The axiom of choice is avoided in some varieties of constructive mathematics, although there are varieties of constructive mathematics in which the axiom of choice is embraced.

A choice function is a function "f", defined on a collection "X" of nonempty sets, such that for every set "A" in "X", "f"("A") is an element of "A". With this concept, the axiom can be stated:
Formally, this may be expressed as follows:

Thus, the negation of the axiom of choice states that there exists a collection of nonempty sets that has no choice function.

Each choice function on a collection "X" of nonempty sets is an element of the Cartesian product of the sets in "X". This is not the most general situation of a Cartesian product of a family of sets, where a given set can occur more than once as a factor; however, one can focus on elements of such a product that select the same element every time a given set appears as factor, and such elements correspond to an element of the Cartesian product of all "distinct" sets in the family. The axiom of choice asserts the existence of such elements; it is therefore equivalent to:

In this article and other discussions of the Axiom of Choice the following abbreviations are common:

There are many other equivalent statements of the axiom of choice. These are equivalent in the sense that, in the presence of other basic axioms of set theory, they imply the axiom of choice and are implied by it.

One variation avoids the use of choice functions by, in effect, replacing each choice function with its range.
This guarantees for any partition of a set "X" the existence of a subset "C" of "X" containing exactly one element from each part of the partition.

Another equivalent axiom only considers collections "X" that are essentially powersets of other sets:
Authors who use this formulation often speak of the "choice function on A", but be advised that this is a slightly different notion of choice function. Its domain is the powerset of "A" (with the empty set removed), and so makes sense for any set "A", whereas with the definition used elsewhere in this article, the domain of a choice function on a "collection of sets" is that collection, and so only makes sense for sets of sets. With this alternate notion of choice function, the axiom of choice can be compactly stated as
which is equivalent to
The negation of the axiom can thus be expressed as:

The statement of the axiom of choice does not specify whether the collection of nonempty sets is finite or infinite, and thus implies that every finite collection of nonempty sets has a choice function. However, that particular case is a theorem of the Zermelo–Fraenkel set theory without the axiom of choice (ZF); it is easily proved by mathematical induction. In the even simpler case of a collection of "one" set, a choice function just corresponds to an element, so this instance of the axiom of choice says that every nonempty set has an element; this holds trivially. The axiom of choice can be seen as asserting the generalization of this property, already evident for finite collections, to arbitrary collections.

Until the late 19th century, the axiom of choice was often used implicitly, although it had not yet been formally stated. For example, after having established that the set "X" contains only non-empty sets, a mathematician might have said "let "F(s)" be one of the members of "s" for all "s" in "X"." In general, it is impossible to prove that "F" exists without the axiom of choice, but this seems to have gone unnoticed until Zermelo.

Not every situation requires the axiom of choice. For finite sets "X", the axiom of choice follows from the other axioms of set theory. In that case it is equivalent to saying that if we have several (a finite number of) boxes, each containing at least one item, then we can choose exactly one item from each box. Clearly we can do this: We start at the first box, choose an item; go to the second box, choose an item; and so on. The number of boxes is finite, so eventually our choice procedure comes to an end. The result is an explicit choice function: a function that takes the first box to the first element we chose, the second box to the second element we chose, and so on. (A formal proof for all finite sets would use the principle of mathematical induction to prove "for every natural number "k", every family of "k" nonempty sets has a choice function.") This method cannot, however, be used to show that every countable family of nonempty sets has a choice function, as is asserted by the axiom of countable choice. If the method is applied to an infinite sequence ("X" : "i"∈ω) of nonempty sets, a function is obtained at each finite stage, but there is no stage at which a choice function for the entire family is constructed, and no "limiting" choice function can be constructed, in general, in ZF without the axiom of choice.

The nature of the individual nonempty sets in the collection may make it possible to avoid the axiom of choice even for certain infinite collections. For example, suppose that each member of the collection "X" is a nonempty subset of the natural numbers. Every such subset has a smallest element, so to specify our choice function we can simply say that it maps each set to the least element of that set. This gives us a definite choice of an element from each set, and makes it unnecessary to apply the axiom of choice.

The difficulty appears when there is no natural choice of elements from each set. If we cannot make explicit choices, how do we know that our set exists? For example, suppose that "X" is the set of all non-empty subsets of the real numbers. First we might try to proceed as if "X" were finite. If we try to choose an element from each set, then, because "X" is infinite, our choice procedure will never come to an end, and consequently, we shall never be able to produce a choice function for all of "X". Next we might try specifying the least element from each set. But some subsets of the real numbers do not have least elements. For example, the open interval (0,1) does not have a least element: if "x" is in (0,1), then so is "x"/2, and "x"/2 is always strictly smaller than "x". So this attempt also fails.

Additionally, consider for instance the unit circle "S", and the action on "S" by a group "G" consisting of all rational rotations. Namely, these are rotations by angles which are rational multiples of "π". Here "G" is countable while "S" is uncountable. Hence "S" breaks up into uncountably many orbits under "G". Using the axiom of choice, we could pick a single point from each orbit, obtaining an uncountable subset "X" of "S" with the property that all of its translates by G are disjoint from "X". The set of those translates partitions the circle into a countable collection of disjoint sets, which are all pairwise congruent. Since "X" is not measurable for any rotation-invariant countably additive finite measure on "S", finding an algorithm to select a point in each orbit requires the axiom of choice. See non-measurable set for more details.

The reason that we are able to choose least elements from subsets of the natural numbers is the fact that the natural numbers are well-ordered: every nonempty subset of the natural numbers has a unique least element under the natural ordering. One might say, "Even though the usual ordering of the real numbers does not work, it may be possible to find a different ordering of the real numbers which is a well-ordering. Then our choice function can choose the least element of every set under our unusual ordering." The problem then becomes that of constructing a well-ordering, which turns out to require the axiom of choice for its existence; every set can be well-ordered if and only if the axiom of choice holds.

A proof requiring the axiom of choice may establish the existence of an object without explicitly defining the object in the language of set theory. For example, while the axiom of choice implies that there is a well-ordering of the real numbers, there are models of set theory with the axiom of choice in which no well-ordering of the reals is definable. Similarly, although a subset of the real numbers that is not Lebesgue measurable can be proved to exist using the axiom of choice, it is consistent that no such set is definable.

The axiom of choice proves the existence of these intangibles (objects that are proved to exist, but which cannot be explicitly constructed), which may conflict with some philosophical principles. Because there is no canonical well-ordering of all sets, a construction that relies on a well-ordering may not produce a canonical result, even if a canonical result is desired (as is often the case in category theory). This has been used as an argument against the use of the axiom of choice.

Another argument against the axiom of choice is that it implies the existence of objects that may seem counterintuitive. One example is the Banach–Tarski paradox which says that it is possible to decompose the 3-dimensional solid unit ball into finitely many pieces and, using only rotations and translations, reassemble the pieces into two solid balls each with the same volume as the original. The pieces in this decomposition, constructed using the axiom of choice, are non-measurable sets.

Despite these seemingly paradoxical facts, most mathematicians accept the axiom of choice as a valid principle for proving new results in mathematics. The debate is interesting enough, however, that it is considered of note when a theorem in ZFC (ZF plus AC) is logically equivalent (with just the ZF axioms) to the axiom of choice, and mathematicians look for results that require the axiom of choice to be false, though this type of deduction is less common than the type which requires the axiom of choice to be true.

It is possible to prove many theorems using neither the axiom of choice nor its negation; such statements will be true in any model of ZF, regardless of the truth or falsity of the axiom of choice in that particular model. The restriction to ZF renders any claim that relies on either the axiom of choice or its negation unprovable. For example, the Banach–Tarski paradox is neither provable nor disprovable from ZF alone: it is impossible to construct the required decomposition of the unit ball in ZF, but also impossible to prove there is no such decomposition. Similarly, all the statements listed below which require choice or some weaker version thereof for their proof are unprovable in ZF, but since each is provable in ZF plus the axiom of choice, there are models of ZF in which each statement is true. Statements such as the Banach–Tarski paradox can be rephrased as conditional statements, for example, "If AC holds, then the decomposition in the Banach–Tarski paradox exists." Such conditional statements are provable in ZF when the original statements are provable from ZF and the axiom of choice.

As discussed above, in ZFC, the axiom of choice is able to provide "nonconstructive proofs" in which the existence of an object is proved although no explicit example is constructed. ZFC, however, is still formalized in classical logic. The axiom of choice has also been thoroughly studied in the context of constructive mathematics, where non-classical logic is employed. The status of the axiom of choice varies between different varieties of constructive mathematics.

In Martin-Löf type theory and higher-order Heyting arithmetic, the appropriate statement of the axiom of choice is (depending on approach) included as an axiom or provable as a theorem. Errett Bishop argued that the axiom of choice was constructively acceptable, saying

In constructive set theory, however, Diaconescu's theorem shows that the axiom of choice implies the law of excluded middle (unlike in Martin-Löf type theory, where it does not). Thus the axiom of choice is not generally available in constructive set theory. A cause for this difference is that the axiom of choice in type theory does not have the extensionality properties that the axiom of choice in constructive set theory does.

Some results in constructive set theory use the axiom of countable choice or the axiom of dependent choice, which do not imply the law of the excluded middle in constructive set theory. Although the axiom of countable choice in particular is commonly used in constructive mathematics, its use has also been questioned.

In 1938, Kurt Gödel showed that the "negation" of the axiom of choice is not a theorem of ZF by constructing an inner model (the constructible universe) which satisfies ZFC and thus showing that ZFC is consistent if ZF itself is consistent. In 1963, Paul Cohen employed the technique of forcing, developed for this purpose, to show that: assuming ZF is consistent, the axiom of choice itself is not a theorem of ZF by constructing a much more complex model which satisfies ZF¬C (ZF with the negation of AC added as axiom) and thus showing that ZF¬C is consistent. Together these results establish that the axiom of choice is logically independent of ZF. The assumption that ZF is consistent is harmless because adding another axiom to an already inconsistent system cannot make the situation worse. Because of independence, the decision whether to use the axiom of choice (or its negation) in a proof cannot be made by appeal to other axioms of set theory. The decision must be made on other grounds.

One argument given in favor of using the axiom of choice is that it is convenient to use it because it allows one to prove some simplifying propositions that otherwise could not be proved. Many theorems which are provable using choice are of an elegant general character: every ideal in a ring is contained in a maximal ideal, every vector space has a basis, and every product of compact spaces is compact. Without the axiom of choice, these theorems may not hold for mathematical objects of large cardinality.

The proof of the independence result also shows that a wide class of mathematical statements, including all statements that can be phrased in the language of Peano arithmetic, are provable in ZF if and only if they are provable in ZFC. Statements in this class include the statement that P = NP, the Riemann hypothesis, and many other unsolved mathematical problems. When one attempts to solve problems in this class, it makes no difference whether ZF or ZFC is employed if the only question is the existence of a proof. It is possible, however, that there is a shorter proof of a theorem from ZFC than from ZF.

The axiom of choice is not the only significant statement which is independent of ZF. For example, the generalized continuum hypothesis (GCH) is not only independent of ZF, but also independent of ZFC. However, ZF plus GCH implies AC, making GCH a strictly stronger claim than AC, even though they are both independent of ZF.

The axiom of constructibility and the generalized continuum hypothesis each imply the axiom of choice and so are strictly stronger than it. In class theories such as Von Neumann–Bernays–Gödel set theory and Morse–Kelley set theory, there is an axiom called the axiom of global choice that is stronger than the axiom of choice for sets because it also applies to proper classes. The axiom of global choice follows from the axiom of limitation of size.

There are important statements that, assuming the axioms of ZF but neither AC nor ¬AC, are equivalent to the axiom of choice. The most important among them are Zorn's lemma and the well-ordering theorem. In fact, Zermelo initially introduced the axiom of choice in order to formalize his proof of the well-ordering theorem.


There are several results in category theory which invoke the axiom of choice for their proof. These results might be weaker than, equivalent to, or stronger than the axiom of choice, depending on the strength of the technical foundations. For example, if one defines categories in terms of sets, that is, as sets of objects and morphisms (usually called a small category), or even locally small categories, whose hom-objects are sets, then there is no category of all sets, and so it is difficult for a category-theoretic formulation to apply to all sets. On the other hand, other foundational descriptions of category theory are considerably stronger, and an identical category-theoretic statement of choice may be stronger than the standard formulation, à la class theory, mentioned above.

Examples of category-theoretic statements which require choice include:

There are several weaker statements that are not equivalent to the axiom of choice, but are closely related. One example is the axiom of dependent choice (DC). A still weaker example is the axiom of countable choice (AC or CC), which states that a choice function exists for any countable set of nonempty sets. These axioms are sufficient for many proofs in elementary mathematical analysis, and are consistent with some principles, such as the Lebesgue measurability of all sets of reals, that are disprovable from the full axiom of choice.

Other choice axioms weaker than axiom of choice include the Boolean prime ideal theorem and the axiom of uniformization. The former is equivalent in ZF to the existence of an ultrafilter containing each given filter, proved by Tarski in 1930.

One of the most interesting aspects of the axiom of choice is the large number of places in mathematics that it shows up. Here are some statements that require the axiom of choice in the sense that they are not provable from ZF but are provable from ZFC (ZF plus AC). Equivalently, these statements are true in all models of ZFC but false in some models of ZF.


There are several historically important set-theoretic statements implied by AC whose equivalence to AC is open. The partition principle, which was formulated before AC itself, was cited by Zermelo as a justification for believing AC. In 1906 Russell declared PP to be equivalent, but whether the Partition Principle implies AC is still the oldest open problem in set theory, and the equivalences of the other statements are similarly hard old open problems. In every "known" model of ZF where choice fails, these statements fail too, but it is unknown if they can hold without choice.


Now, consider stronger forms of the negation of AC. For example, if we abbreviate by BP the claim that every set of real numbers has the property of Baire, then BP is stronger than ¬AC, which asserts the nonexistence of any choice function on perhaps only a single set of nonempty sets. Note that strengthened negations may be compatible with weakened forms of AC. For example, ZF + DC + BP is consistent, if ZF is.

It is also consistent with ZF + DC that every set of reals is Lebesgue measurable; however, this consistency result, due to Robert M. Solovay, cannot be proved in ZFC itself, but requires a mild large cardinal assumption (the existence of an inaccessible cardinal). The much stronger axiom of determinacy, or AD, implies that every set of reals is Lebesgue measurable, has the property of Baire, and has the perfect set property (all three of these results are refuted by AC itself). ZF + DC + AD is consistent provided that a sufficiently strong large cardinal axiom is consistent (the existence of infinitely many Woodin cardinals).

Quine's system of axiomatic set theory, "New Foundations" (NF), takes its name from the title (“New Foundations for Mathematical Logic”) of the 1937 article which introduced it. In the NF axiomatic system, the axiom of choice can be disproved.

There are models of Zermelo-Fraenkel set theory in which the axiom of choice is false. We shall abbreviate "Zermelo-Fraenkel set theory plus the negation of the axiom of choice" by ZF¬C. For certain models of ZF¬C, it is possible to prove the negation of some standard facts.
Note that any model of ZF¬C is also a model of ZF, so for each of the following statements, there exists a model of ZF in which that statement is true. For each of the following statements, there is some model of ZF¬C where it is true:


For proofs, see .


In type theory, a different kind of statement is known as the axiom of choice. This form begins with two types, σ and τ, and a relation "R" between objects of type σ and objects of type τ. The axiom of choice states that if for each "x" of type σ there exists a "y" of type τ such that "R"("x","y"), then there is a function "f" from objects of type σ to objects of type τ such that "R"("x","f"("x")) holds for all "x" of type σ:
Unlike in set theory, the axiom of choice in type theory is typically stated as an axiom scheme, in which "R" varies over all formulas or over all formulas of a particular logical form.

This is a joke: although the three are all mathematically equivalent, many mathematicians find the axiom of choice to be intuitive, the well-ordering principle to be counterintuitive, and Zorn's lemma to be too complex for any intuition.

The observation here is that one can define a function to select from an infinite number of pairs of shoes by stating for example, to choose a left shoe. Without the axiom of choice, one cannot assert that such a function exists for pairs of socks, because left and right socks are (presumably) indistinguishable.
Polish-American mathematician Jan Mycielski relates this anecdote in a 2006 article in the Notices of the AMS.
This quote comes from the famous April Fools' Day article in the "computer recreations" column of the "Scientific American
Attila (; fl. c. 406–453), frequently called Attila the Hun, was the ruler of the Huns from 434 until his death in March 453. He was also the leader of a tribal empire consisting of Huns, Ostrogoths, and Alans among others, in Central and Eastern Europe.

During his reign, he was one of the most feared enemies of the Western and Eastern Roman Empires. He crossed the Danube twice and plundered the Balkans, but was unable to take Constantinople. His unsuccessful campaign in Persia was followed in 441 by an invasion of the Eastern Roman (Byzantine) Empire, the success of which emboldened Attila to invade the West. He also attempted to conquer Roman Gaul (modern France), crossing the Rhine in 451 and marching as far as Aurelianum (Orléans) before being defeated at the Battle of the Catalaunian Plains.

He subsequently invaded Italy, devastating the northern provinces, but was unable to take Rome. He planned for further campaigns against the Romans, but died in 453. After Attila's death, his close adviser, Ardaric of the Gepids, led a Germanic revolt against Hunnic rule, after which the Hunnic Empire quickly collapsed
There is no surviving first-hand account of Attila's appearance, but there is a possible second-hand source provided by Jordanes, who cites a description given by Priscus.

Some scholars have suggested that this description is typically East Asian, because it has all the combined features that fit the physical type of people from Eastern Asia, and Attila's ancestors may have come from there. Other historians also believed that the same descriptions were also evident on some Scythian

Many scholars have argued that Attila derives from East Germanic origin; "Attila" is formed from the Gothic or Gepidic noun "atta", "father", by means of the diminutive suffix "-ila", meaning "little father". The Gothic etymology was first proposed by Jacob and Wilhelm Grimm in the early 19th century. Maenchen-Helfen notes that this derivation of the name "offers neither phonetic nor semantic difficulties", and Gerhard Doerfer notes that the name is simply correct Gothic. The name has sometimes been interpreted as a Germanization of a name of Hunnic origin.

Other scholars have argued for a Turkic origin of the name. Omeljan Pritsak considered "Ἀττίλα" (Attíla) a composite title-name which derived from Turkic *"es" (great, old), and *"t il" (sea, ocean), and the suffix /a/. The stressed back syllabic "til" assimilated the front member "es", so it became *"as". It is a nominative, in form of "attíl-" (< *"etsíl" < *"es tíl") with the meaning "the oceanic, universal ruler". J.J. Mikkola connected it with Turkic "āt" (name, fame). As another Turkic possibility, H. Althof (1902) considered it was related to Turkish "atli" (horseman, cavalier), or Turkish "at" (horse) and "dil" (tongue). Maenchen-Helfen argues that Pritsak's derivation is "ingenious but for many reasons unacceptable", while dismissing Mikkola's as "too farfetched to be taken seriously". M. Snædal similarly notes that none of these proposals has achieved wide acceptance. Criticizing the proposals of finding Turkic or other etymologies for Attila, Doerfer notes that King George VI of England had a name of Greek origin, and Süleyman the Magnificent had a name of Arabic origin, yet that does not make them Greeks or Arabs: it is therefore plausible that Attila would have a name not of Hunnic origin. Historian Hyun Jin Kim, however, has argued that the Turkic etymology is "more probable".

M. Snædal, in a paper that rejects the Germanic derivation but notes the problems with the existing proposed Turkic etymologies, argues that Attila's name could have originated from Turkic-Mongolian "at, adyy/agta" (gelding, warhorse) and Turkish "atli" (horseman, cavalier), meaning "possessor of geldings, provider of warhorses".

The historiography of Attila is faced with a major challenge, in that the only complete sources are written in Greek and Latin by the enemies of the Huns. Attila's contemporaries left many testimonials of his life, but only fragments of these remain. Priscus was a Byzantine diplomat and historian who wrote in Greek, and he was both a witness to and an actor in the story of Attila, as a member of the embassy of Theodosius II at the Hunnic court in 449. He was obviously biased by his political position, but his writing is a major source for information on the life of Attila, and he is the only person known to have recorded a physical description of him. He wrote a history of the late Roman Empire in eight books covering the period from 430 to 476.

Today we have only fragments of Priscus' work, but it was cited extensively by 6th-century historians Procopius and Jordanes, especially in Jordanes' "The Origin and Deeds of the Goths". It contains numerous references to Priscus's history, and it is also an important source of information about the Hunnic empire and its neighbors. He describes the legacy of Attila and the Hunnic people for a century after Attila's death. Marcellinus Comes, a chancellor of Justinian during the same era, also describes the relations between the Huns and the Eastern Roman Empire.

Numerous ecclesiastical writings contain useful but scattered information, sometimes difficult to authenticate or distorted by years of hand-copying between the 6th and 17th centuries. The Hungarian writers of the 12th century wished to portray the Huns in a positive light as their glorious ancestors, and so repressed certain historical elements and added their own legends.

The literature and knowledge of the Huns themselves was transmitted orally, by means of epics and chanted poems that were handed down from generation to generation. Indirectly, fragments of this oral history have reached us via the literature of the Scandinavians and Germans, neighbors of the Huns who wrote between the 9th and 13th centuries. Attila is a major character in many Medieval epics, such as the Nibelungenlied, as well as various Eddas and sagas.

Archaeological
The Huns were a group of Eurasian nomads, appearing from east of the Volga, who migrated further into Western Europe c. 370 and built up an enormous empire there. Their main military techniques were mounted archery and javelin throwing. They were in the process of developing settlements before their arrival in Western Europe, yet the Huns were a society of pastoral warriors whose primary form of nourishment was meat and milk, products of their herds.

The origin and language of the Huns has been the subject of debate for centuries. According to some theories, their leaders at least may have spoken a Turkic language, perhaps closest to the modern Chuvash language. One scholar suggests a relationship to Yeniseian. According to the "Encyclopedia of European Peoples", "the Huns, especially those who migrated to the west, may have been a combination of central Asian Turkic, Mongolic, and Ugric stocks".

Attila's father Mundzuk was the brother of kings Octar and Ruga, who reigned jointly over the Hunnic empire in the early fifth century. This form of diarchy was recurrent with the Huns, but historians are unsure whether it was institutionalized, merely customary, or an occasional occurrence. His family was from a noble lineage, but it is uncertain whether they constituted a royal dynasty. Attila's birthdate is debated; journalist Éric Deschodt and writer Herman Schreiber have proposed a date of 395. However, historian Iaroslav Lebedynsky and archaeologist Katalin Escher prefer an estimate between the 390s and the first decade of the fifth century. Several historians have proposed 406 as the date.

Attila grew up in a rapidly changing world. His people were nomads who had only recently arrived in Europe. They crossed the Volga river during the 370s and annexed the territory of the Alans, then attacked the Gothic kingdom between the Carpathian mountains and the Danube. They were a very mobile people, whose mounted archers had acquired a reputation for invincibility, and the Germanic tribes seemed unable to withstand them. Vast populations fleeing the Huns moved from Germania into the Roman Empire in the west and south, and along the banks of the Rhine and Danube. In 376, the Goths crossed the Danube, initially submitting to the Romans but soon rebelling against Emperor Valens, whom they killed in the Battle of Adrianople in 378. Large numbers of Vandals, Alans, Suebi, and Burgundians crossed the Rhine and invaded Roman Gaul on December 31, 406 to escape the Huns. The Roman Empire had been split in half since 395 and was ruled by two distinct governments, one based in Ravenna in the West, and the other in Constantinople in the East. The Roman Emperors, both East and West, were generally from the Theodosian family in Attila's lifetime (despite several power struggles).

The Huns dominated a vast territory with nebulous borders determined by the will of a constellation of ethnically varied peoples. Some were assimilated to Hunnic nationality, whereas many retained their own identities and rulers but acknowledged the suzerainty of the king of the Huns. The Huns were also the indirect source of many of the Romans' problems, driving various Germanic tribes into Roman territory, yet relations between the two empires were cordial: the Romans used the Huns as mercenaries against the Germans and even in their civil wars. Thus, the usurper Joannes was able to recruit thousands of Huns for his army against Valentinian III in 424. It was Aëtius, later Patrician of the West, who managed this operation. They exchanged ambassadors and hostages, the alliance lasting from 401 to 450 and permitting the Romans numerous military victories. The Huns considered the Romans to be paying them tribute, whereas the Romans preferred to view this as payment for services rendered. The Huns had become a great power by the time that Attila came of age during the reign of his uncle Ruga, to the point that Nestorius
The death of Rugila (also known as Rua or Ruga) in 434 left the sons of his brother Mundzuk, Attila and Bleda, in control of the united Hun tribes. At the time of the two brothers' accession, the Hun tribes were bargaining with Eastern Roman Emperor Theodosius II who had taken refuge within the Eastern Roman Empire, possibly Hunnic nobles who disagreed with the brothers' assumption of leadership.

The following year, Attila and Bleda met with the imperial legation at Margus (Požarevac), all seated on horseback in the Hunnic manner, and negotiated an advantageous treaty. The Romans agreed to return the fugitives, to double their previous tribute of 350 Roman pounds (c. 115 kg) of gold, to open their markets to Hunnish traders, and to pay a ransom of eight "solidi" for each Roman taken prisoner by the Huns. The Huns, satisfied with the treaty, decamped from the Roman Empire and returned to their home in the Great Hungarian Plain, perhaps to consolidate and strengthen their empire. Theodosius used this opportunity to strengthen the walls of Constantinople, building the city's first sea wall, and to build up his border defenses along the Danube.

The Huns remained out of Roman sight for the next few years while they invaded the Sassanid Empire. They were defeated in Armenia by the Sassanids, abandoned their invasion, and turned their attentions back to Europe. In 440, they reappeared in force on the borders of the Roman Empire, attacking the merchants at the market on the north bank of the Danube that had been established by the treaty.

Crossing the Danube, they laid waste to the cities of Illyricum and forts on the river, including (according to Priscus) Viminacium, a city of Moesia. Their advance began at Margus, where they demanded that the Romans turn over a bishop who had retained property that Attila regarded as his. While the Romans discussed the bishop's fate, he slipped away secretly to the Huns and betrayed the city to them.

While the Huns attacked city-states along the Danube, the Vandals (led by Geiseric) captured the Western Roman province of Africa and its capital of Carthage. Carthage was the richest province of the Western Empire and a main source of food for Rome. The Sassanid Shah Yazdegerd II invaded Armenia in 441.

The Romans stripped the Balkan area of forces, sending them to Sicily in order to mount an expedition against the Vandals in Africa. This left Attila and Bleda a clear path through Illyricum into the Balkans, which they invaded in 441. The Hunnish army sacked Margus and Viminacium, and then took Singidunum (Belgrade) and Sirmium. During 442, Theodosius recalled his troops from Sicily and ordered a large issue of new coins to finance operations against the Huns. He believed that he could defeat the Huns and refused the Hunnish kings' demands.

Attila responded with a campaign in 443. The Huns were equipped with new military weapons as they advanced along the Danube, such as battering rams and rolling siege towers, and they overran the military centers of Ratiara and successfully besieged Naissus (Niš).

Advancing along the Nišava River, the Huns next took Serdica (Sofia), Philippopolis (Plovdiv), and Arcadiopolis (Lüleburgaz). They encountered and destroyed a Roman army outside Constantinople but were stopped by the double walls of the Eastern capital. They defeated a second army near Callipolis (Gelibolu).

Theodosius, stripped of his armed forces, admitted defeat, sending the "Magister militum per Orientem" Anatolius
In 447, Attila again rode south into the Eastern Roman Empire through Moesia. The Roman army, under Gothic "magister militum" Arnegisclus, met him in the Battle of the Utus and was defeated, though not without inflicting heavy losses. The Huns were left unopposed and rampaged through the Balkans as far as Thermopylae.

Constantinople itself was saved by the Isaurian troops of "magister militum per Orientem" Zeno and protected by the intervention of prefect Constantinus
In 450, Attila proclaimed his intent to attack the Visigoth kingdom of Toulouse by making an alliance with Emperor Valentinian III. He had previously been on good terms with the Western Roman Empire and its influential general Flavius Aëtius. Aëtius had spent a brief exile among the Huns in 433, and the troops that Attila provided against the Goths and Bagaudae had helped earn him the largely honorary title of "magister militum" in the west. The gifts and diplomatic efforts of Geiseric, who opposed and feared the Visigoths, may also have influenced Attila's plans.

However, Valentinian's sister was Honoria, who had sent the Hunnish king a plea for help—and her engagement ring—in order to escape her forced betrothal to a Roman senator in the spring of 450. Honoria may not have intended a proposal of marriage, but Attila chose to interpret her message as such. He accepted, asking for half of the western Empire as dowry.

When Valentinian discovered the plan, only the influence of his mother Galla Placidia convinced him to exile Honoria, rather than killing her. He also wrote to Attila, strenuously denying the legitimacy of the supposed marriage proposal. Attila sent an emissary to Ravenna to proclaim that Honoria was innocent, that the proposal had been legitimate, and that he would come to claim what was rightfully his.

Attila interfered in a succession struggle after the death of a Frankish ruler. Attila supported the elder son, while Aëtius supported the younger. (The location and identity of these kings is not known and subject to conjecture.) Attila gathered his vassals—Gepids, Ostrogoths, Rugians, Scirians, Heruls, Thuringians, Alans, Burgundians, among others–and began his march west. In 451, he arrived in Belgica with an army exaggerated by Jordanes to half a million strong.

On April 7, he captured Metz. Other cities attacked can be determined by the hagiographic "vitae" written to commemorate their bishops: Nicasius was slaughtered before the altar of his church in Rheims; Servatus is alleged to have saved Tongeren with his prayers, as Saint Genevieve is said to have saved Paris. Lupus, bishop of Troyes, is also credited with saving his city by meeting Attila in person.

Aëtius moved to oppose Attila, gathering troops from among the Franks, the Burgundians, and the Celts. A mission by Avitus and Attila's continued westward advance convinced the Visigoth king Theodoric I (Theodorid) to ally with the Romans. The combined armies reached Orléans ahead of Attila, thus checking and turning back the Hunnish advance. Aëtius gave chase and caught the Huns at a place usually assumed to be near Catalaunum (modern Châlons-en-Champagne). Attila decided to fight the Romans on plains where he could use his cavalry.

The two armies clashed in the Battle of the Catalaunian Plains
Attila returned in 452 to renew his marriage claim with Honoria, invading and ravaging Italy along the way. Communities became established in what would later become Venice as a result of these attacks when the residents fled to small islands in the Venetian Lagoon. His army sacked numerous cities and razed Aquileia so completely that it was afterwards hard to recognize its original site. Aëtius lacked the strength to offer battle, but managed to harass and slow Attila's advance with only a shadow force. Attila finally halted at the River Po. By this point, disease and starvation may have taken hold in Attila's camp, thus hindering his war efforts and potentially contributing to the cessation of invasion.

Emperor Valentinian III sent three envoys, the high civilian officers Gennadius Avienus and Trigetius, as well as the Bishop of Rome Leo I, who met Attila at Mincio in the vicinity of Mantua and obtained from him the promise that he would withdraw from Italy and negotiate peace with the Emperor. Prosper of Aquitaine gives a short description of the historic meeting, but gives all the credit to Leo for the successful negotiation. Priscus reports that superstitious fear of the fate of Alaric gave him pause—as Alaric died shortly after sacking Rome in 410.

Italy had suffered from a terrible famine in 451 and her crops were faring little better in 452. Attila's devastating invasion of the plains of northern Italy this year did not improve the harvest. To advance on Rome would have required supplies which were not available in Italy, and taking the city would not have improved Attila's supply situation. Therefore, it was more profitable for Attila to conclude peace and retreat to his homeland.

Furthermore, an East Roman force had crossed the Danube under the command of another officer also named Aetius—who had participated in the Council of Chalcedon the previous year—and proceeded to defeat the Huns who had been left behind by Attila to safeguard their home territories. Attila, hence, faced heavy human and natural pressures to retire "from Italy without ever setting foot south of the Po". As Hydatius
Marcian was the successor of Theodosius, and he had ceased paying tribute to the Huns in late 450 while Attila was occupied in the west. Multiple invasions by the Huns and others had left the Balkans with little to plunder.
After Attila left Italy and returned to his palace across the Danube, he planned to strike at Constantinople again and reclaim the tribute which Marcian had stopped. However, he died in the early months of 453.

The conventional account from Priscus says that Attila was at a feast celebrating his latest marriage, this time to the beautiful young Ildico (the name suggests Gothic or Ostrogoth origins). In the midst of the revels, however, he suffered a severe nosebleed and choked to death in a stupor. An alternative theory is that he succumbed to internal bleeding after heavy drinking, possibly a condition called esophageal varices, where dilated veins in the lower part of the esophagus rupture leading to death by hemorrhage.

Another account of his death was first recorded 80 years after the events by Roman chronicler Marcellinus Comes. It reports that "Attila, King of the Huns and ravager of the provinces of Europe, was pierced by the hand and blade of his wife". Most scholars reject these accounts as no more than hearsay, preferring instead the account given by Attila's contemporary Priscus. Priscus' version, however, has recently come under renewed scrutiny by Michael A. Babcock. Based on detailed philological analysis, Babcock concludes that the account of natural death given by Priscus was an ecclesiastical "cover story", and that Emperor Marcian (who ruled the Eastern Roman Empire from 450 to 457) was the political force behind Attila's death. Jordanes recounts:

Attila's sons Ellac, Dengizich and Ernak, ""in their rash eagerness to rule they all alike destroyed his empire"". They "were clamoring that the nations should be divided among them equally and that warlike kings with their peoples should be apportioned to them by lot like a family estate". Against the treatment as "slaves of the basest condition" a Germanic alliance led by the Gepid ruler Ardaric (who was noted for great loyalty to Attila) revolted and fought with the Huns in Pannonia in the Battle of Nedao 454 AD. Attila's eldest son Ellac was killed in that battle. Attila's sons "regarding the Goths as deserters from their rule, came against them as though they were seeking fugitive slaves", attacked Ostrogothic co-ruler Valamir (who also fought alongside Ardaric and Attila at the Catalaunian Plains), but were repelled, and some group of Huns moved to Scythia (probably those of Ernak). His brother Dengizich attempted a renewed invasion across the Danube in 468 AD, but was defeated at the Battle of Bassianae by the Ostrogoths. Dengizich was killed by Roman-Gothic general Anagast the following year, after which the Hunnic dominion ended.

Attila's many children and relatives are known by name and some even by deeds, but soon valid genealogical sources all but dried up, and there seems to be no verifiable way to trace Attila's descendants. This has not stopped many genealogists from attempting to reconstruct a valid line of descent for various medieval rulers. One of the most credible claims has been that of the "Nominalia of the Bulgarian khans" for mythological Avitohol and Irnik from the Dulo clan of the Bulgars
Attila himself is said to have claimed the titles "Descendant of the Great Nimrod", and "King of the Huns, the Goths, the Danes, and the Medes"—the last two peoples being mentioned to show the extent of his control over subject nations even on the peripheries of his domain.

Jordanes embellished the report of Priscus, reporting that Attila had possessed the "Holy War Sword of the Scythians", which was given to him by Mars and made him a "prince of the entire world".

By the end of the 12th century the royal court of Hungary proclaimed their descent from Attila. Lampert of Hersfeld's contemporary chronicles report that shortly before the year 1071, the Sword of Attila had been presented to Otto of Nordheim by the exiled queen of Hungary, Anastasia of Kiev. This sword, a cavalry sabre now in the Kunsthistorisches Museum in Vienna, appears to be the work of Hungarian goldsmiths of the ninth or tenth century.

An anonymous chronicler of the medieval period represented the meeting of Pope Leo and Atilla as attended also by Saint Peter and Saint Paul, "a miraculous tale calculated to meet the taste of the time" This apotheosis was later portrayed artistically by the Renaissance artist Raphael and sculptor Algardi, whom eighteenth-century historian Edward Gibbon praised for establishing "one of the noblest legends of ecclesiastical tradition".

According to a version of this narrative related in the Chronicon Pictum, a mediaeval Hungarian chronicle, the Pope promised Attila that if he left Rome in peace, one of his successors would receive a holy crown (which has been understood as referring to the Holy Crown of Hungary).

Some histories and chronicles describe him as a great and noble king, and he plays major roles in three Norse sagas: "Atlakviða", "Volsunga saga", and "Atlamál". The "Polish Chronicle" represents Attila's name as "Aquila".

Frutolf of Michelsberg and Otto of Freising pointed out that some songs as "vulgar fables" made Theoderic the Great, Attila and Ermanaric contemporaries, when any reader of Jordanes knew that this was not the case. This refers to the so-called historical poems about Dietrich von Bern (Theoderic), in which Etzel (Attila) is Dietrich's refuge in exile from his wicked uncle Ermenrich (Ermanaric). Etzel is most prominent in the poems "Dietrichs Flucht" and "Die Rabenschlacht". Etzel also appears as Kriemhild's second noble husband in the "Nibelungenlied", in which Kriemhild causes the destruction of both the Hunnish kingdom and that of her Burgundian relatives.

In 1812, Ludwig van Beethoven conceived the idea of writing an opera about Attila and approached August von Kotzebue to write the libretto. It was, however, never written. In 1846, Giuseppe Verdi wrote the opera Attila_(opera), loosely based on episodes in Attila's invasion of Italy.

In World War I, Allied propaganda referred to Germans as the "Huns", based on a 1900 speech by Emperor Wilhelm II praising Attila the Hun's military prowess, according to Jawaharlal Nehru's "Glimpses of World History". "Der Spiegel" commented on November 6, 1948, that the Sword of Attila was hanging menacingly over Austria.

American writer Cecelia Holland wrote "The Death of Attila" (1973), a historical novel in which Attila appears as a powerful background figure whose life and death deeply impact the protagonists, a young Hunnic warrior and a Germanic one.

The name has many variants in several languages: Atli and Atle in Old Norse; Etzel in Middle High German (Nibelungenlied); Ætla in Old English; Attila, Atilla, and Etele in Hungarian (Attila is the most popular); Attila, Atilla, Atilay, or Atila in Turkish; and Adil and Edil in Kazakh or Adil ("same/similar") or Edil ("to use") in Mongolian.

In modern Hungary and in Turkey, "Attila" and its Turkish variation "Atilla" are commonly used as a male first name. In Hungary, several public places are named after Attila; for instance, in Budapest there are 10 Attila Streets, one of which is an important street behind the Buda Castle. When the Turkish Armed Forces invaded Cyprus in 1974, the operations were named after Attila ("The Attila Plan").

The 1954 Universal International film "Sign of the Pagan" starred Jack Palance
Category:406 births
Category:453 deaths
Category:5th-century monarchs in Europe
Category:5th-century Hunnic rulers
Category:Huns
Category:Germanic rulers
Category:Deaths from choking
Category:Nimrod
Category:Hunnic rulers