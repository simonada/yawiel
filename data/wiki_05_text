

The Aegean Sea ( or ; "Aigaío Pélagos" ; ) is an elongated embayment of the Mediterranean Sea located between the Greek and Anatolian peninsulas i.e. between the mainlands of Greece and Turkey. In the north, the Aegean is connected to the Marmara Sea and Black Sea by the Dardanelles and Bosphorus. The Aegean Islands are within the sea and some bound it on its southern periphery, including Crete and Rhodes.

The sea was traditionally known as "the Archipelago" (in Ancient Greek, , meaning "chief sea"), but in English the meaning of Archipelago has changed to refer to the Aegean Islands and, generally, to any island group.

In ancient times, there were various explanations for the name "Aegean". It was said to have been named after the Greek town of Aegae; after Aegea, a queen of the Amazons who died in the sea; Aigaion, the "sea goat", another name of Briareus, one of the archaic Hecatonchires; or, especially among the Athenians, Aegeus, the father of Theseus, who drowned himself in the sea when he thought his son had died.

A possible etymology is a derivation from the Greek word  – ' = ""waves"" (Hesychius of Alexandria; metaphorical use of (') "goat"), hence "wavy sea", cf. also (' = ' (waves) + "" (sea)), hence meaning "sea-shore".

The Venetians, who ruled many Greek islands in the High and Late Middle Ages, popularized the name "Archipelago" (Greek for "main sea" or "chief sea"), a name that held on in many European countries until the early modern period.

In some South Slavic languages the Aegean is often called "White Sea" (/ in Serbo-Croatian and Macedonian; "" in Bulgarian).

The Aegean Sea covers about in area, and measures about longitudinally and latitudinally. The sea's maximum depth is , east of Crete. The Aegean Islands are found within its waters, with the following islands delimiting the sea on the south (generally from west to east): Kythera, Antikythera, Crete, Kasos, Karpathos and Rhodes.

The Aegean Islands, which almost all belong to Greece, can be divided into seven groups:

The word "archipelago" was originally applied specifically to the Aegean Sea and its islands. Many of the Aegean Islands, or chains of islands, are actually extensions of the mountains on the mainland. One chain extends across the sea to Chios, another extends across Euboea to Samos, and a third extends across the Peloponnese and Crete to Rhodes, dividing the Aegean from the Mediterranean.

The bays and gulfs of the Aegean beginning at the South and moving clockwise include on Crete, the Mirabello, Almyros, Souda and Chania bays or gulfs, on the mainland the Myrtoan Sea to the west with the Argolic Gulf, the Saronic Gulf northwestward, the Petalies Gulf which connects with the South Euboic Sea, the Pagasetic Gulf which connects with the North Euboic Sea, the Thermian Gulf northwestward, the Chalkidiki Peninsula including the Cassandra and the Singitic Gulfs, northward the Strymonian Gulf and the Gulf of Kavala and the rest are in Turkey; Saros Gulf, Edremit Gulf, Dikili Gulf, Gulf of Çandarlı, Gulf of İzmir, Gulf of Kuşadası, Gulf of Gökova, Güllük Gulf.

The International Hydrographic Organization defines the limits of the Aegean Sea as follows:

"On the South." A line running from Cape Aspro (28°16′E) in Asia Minor, to Cum Burnù (Capo della Sabbia) the Northeast extreme of the Island of Rhodes, through the island to Cape Prasonisi, the Southwest point thereof, on to Vrontos Point (35°33′N) in Skarpanto <nowiki>[</nowiki>Karpathos<nowiki>]</nowiki>, through this island to Castello Point, the South extreme thereof, across to Cape Plaka (East extremity of Crete), through Crete to Agria Grabusa, the Northwest extreme thereof, thence to Cape Apolitares in Antikithera Island, through the island to Psira Rock (off the Northwest point) and across to Cape Trakhili in Kithera Island, through Kithera to the Northwest point (Cape Karavugia) and thence to Cape Santa Maria () in the Morea.
<br><br>"In the Dardanelles." A line joining Kum Kale (26°11′E) and Cape Helles
Aegean surface water circulates in a counterclockwise gyre, with hypersaline Mediterranean water moving northward along the west coast of Turkey, before being displaced by less dense Black Sea outflow. The dense Mediterranean water sinks below the Black Sea inflow to a depth of , then flows through the Dardanelles Strait and into the Sea of Marmara at velocities of . The Black Sea outflow moves westward along the northern Aegean Sea, then flows southwards along the east coast of Greece.

The physical oceanography of the Aegean Sea is controlled mainly by the regional climate, the fresh water discharge from major rivers draining southeastern Europe, and the seasonal variations in the Black Sea surface water outflow through the Dardanelles Strait
The current coastline dates back to about 4000 BC. Before that time, at the peak of the last ice age (about 18,000 years ago) sea levels everywhere were 130 metres lower, and there were large well-watered coastal plains instead of much of the northern Aegean. When they were first occupied, the present-day islands including Milos with its important obsidian production were probably still connected to the mainland. The present coastal arrangement appeared around 9,000 years ago, with post-ice age sea levels continuing to rise for another 3,000 years after that.

The subsequent Bronze Age civilizations of Greece and the Aegean Sea have given rise to the general term "Aegean civilization". In ancient times, the sea was the birthplace of two ancient civilizations – the Minoans of Crete and the Myceneans of the Peloponnese.

Later arose the city-states of Athens and Sparta among many others that constituted the Athenian Empire and Hellenic Civilization. Plato described the Greeks living round the Aegean "like frogs around a pond". The Aegean Sea was later invaded by the Persians and the Romans, and inhabited by the Eastern Romans (Byzantine-Greeks), the Bulgarians, the Venetians, the Genoese, the Seljuq Turks, and the Ottomans. The Aegean was the site of the original democracies, and its seaways were the means of contact among several diverse civilizations of the Eastern Mediterranean.

Many of the islands in the Aegean have safe harbours and bays. In ancient times, navigation through the sea was easier than travelling across the rough terrain of the Greek mainland (and to some extent the coastal areas of Anatolia). Many of the islands are volcanic, and marble and iron are mined on other islands. The larger islands have some fertile valleys and plains.

Of the main islands in the Aegean Sea, two belong to Turkey – Bozcaada (Tenedos) and Gökçeada (Imbros); the rest belong to Greece. Between the two countries, there are political disputes over several aspects of political control over the Aegean space, including the size of territorial waters, air control and the delimitation of economic rights to the continental shelf
Category:Seas of Greece
Category:Seas of Turkey
Category:Marginal seas of the Mediterranean
Category:European seas
Category:Seas of Asia
Category:Landforms of Çanakkale Province
Category:Landforms of Muğla Province
Category:Landforms of Izmir Province
Category:Landforms of Balıkesir Province
Category:Landforms of Edirne Province
Category:Landforms of Aydın ProvinceA Clockwork Orange (novel)

A Clockwork Orange is a dystopian satirical black comedy novel by English writer Anthony Burgess, published in 1962. It is set in a near-future English society that has a youth subculture of extreme violence. The teenage protagonist, Alex, narrates his violent exploits, and his experiences with state authorities intent on reforming him. The book is partially written in a Russian-influenced argot called "Nadsat" written in just three weeks.

In 2005, "A Clockwork Orange" was included on "Time" magazine's list of the 100 best English-language novels written since 1923, and it was named by Modern Library and its readers as one of the 100 best English-language novels of the 20th century. The original manuscript of the book has been located at McMaster University's William Ready Division of Archives and Research Collections in Hamilton, Ontario, Canada since the institution purchased the documents in 1971.

Alex is a 15-year-old living in near-future dystopian England who leads his gang on a night of opportunistic, random "ultra-violence". Alex's friends ("droogs" in the novel's Anglo-Russian slang, 'Nadsat') are Dim, a slow-witted bruiser who is the gang's muscle; Georgie, an ambitious second-in-command; and Pete, who mostly plays along as the droogs indulge their taste for ultra-violence. Characterised as a sociopath and hardened juvenile delinquent, Alex also displays intelligence, quick wit, and a predilection for classical music; he is particularly fond of Beethoven, referred to as "Lovely Ludwig Van".

The novella begins with the droogs sitting in their favourite hangout, the Korova Milk Bar, and drinking "milk-plus" — a beverage consisting of milk laced with the customer's drug of choice — to prepare for a night of mayhem. They assault a scholar walking home from the public library; rob a store, leaving the owner and his wife bloodied and unconscious; beat up a beggar; then scuffle with a rival gang. Joyriding through the countryside in a stolen car, they break into an isolated cottage and terrorise the young couple living there, beating the husband and raping his wife. In a metafictional touch, the husband is a writer working on a manuscript called ""A Clockwork Orange"", and Alex contemptuously reads out a paragraph that states the novel's main theme before shredding the manuscript. Back at the Korova, Alex strikes Dim for his crude response to a woman's singing of an operatic passage, and strains within the gang become apparent. At home in his parents' futuristic flat, Alex plays classical music at top volume, which he describes as giving him orgasmic bliss before falling asleep.

Alex coyly feigns illness to his parents to stay out of school the next day. Following an unexpected visit from P.R. Deltoid, his "post-corrective adviser", Alex visits a record store, where he meets two pre-teen girls. He invites them back to the flat, where he drugs and rapes them. The next morning, Alex finds his droogs in a mutinous mood, waiting downstairs in the torn-up and graffitied lobby. Georgie challenges Alex for leadership of the gang, demanding that they pull a "man-sized" job. Alex quells the rebellion by slashing Dim's hand and fighting with Georgie. Then, in a show of generosity, he takes them to a bar, where Alex insists on following through on Georgie's idea to burgle the home of a wealthy elderly woman. Alex breaks in and knocks the woman unconscious; but, when he opens the door to let the others in, Dim strikes him in payback for the earlier fight. The gang abandons Alex on the front step to be arrested by the police; while in custody, he learns that the woman has died from her injuries.

Alex is convicted of murder and sentenced to 14 years in prison. (His parents visit one day to inform him that Georgie has been killed in a botched robbery). Two years into his term, he has obtained a job in one of the prison chapels, playing religious music on the stereo to accompany the Sunday religious services. The chaplain mistakes Alex's Bible studies for stirrings of faith; in reality, Alex is only reading Scripture for the violent passages. After his fellow cellmates blame him for beating a troublesome cellmate to death, he is chosen to undergo an experimental behaviour modification treatment called the Ludovico Technique in exchange for having the remainder of his sentence commuted. The technique is a form of aversion therapy, in which Alex is injected with nausea-inducing drugs while watching graphically violent films, eventually conditioning him to become severely ill at the mere thought of violence. As an unintended consequence, the soundtrack to one of the films, Beethoven's Fifth Symphony, renders Alex unable to enjoy his beloved classical music as before.

The effectiveness of the technique is demonstrated to a group of VIPs, who watch as Alex collapses before a bully and abases himself before a scantily clad young woman whose presence has aroused his predatory sexual inclinations. Although the prison chaplain accuses the state of stripping Alex of free will, the government officials on the scene are pleased with the results and Alex is released from prison.

Alex returns to his parents' flat, only to find that they are letting his room to a lodger. Now homeless, he wanders the streets and enters a public library, hoping to learn of a painless method for committing suicide. The old scholar whom Alex had assaulted in Part 1 finds him and beats him, with the help of several friends. Two policemen come to Alex's rescue, but they turn out to be Dim and Billyboy, a former rival gang leader. They take Alex outside of town, brutalise him, and abandon him there. Alex collapses at the door of an isolated cottage, realising too late that it is the one he and his droogs invaded in Part 1. The writer, F. Alexander, still lives here, but his wife has since died of injuries she sustained in the gang rape. He does not recognise Alex but gives him shelter and questions him about the conditioning he has undergone. Alexander and his colleagues, all highly critical of the government, plan to use Alex as a symbol of state brutality and thus prevent the incumbent government from being re-elected. Alex inadvertently reveals that he was the ringleader of the home invasion; he is removed from the cottage and locked in an upper-story bedroom as a relentless barrage of classical music plays over speakers. He attempts suicide by leaping from the window.

Alex wakes up in a hospital, where he is courted by government officials anxious to counter the bad publicity created by his suicide attempt. Placed in a mental institution, Alex is offered a well-paying job if he agrees to side with the government. A round of tests reveals that his old violent impulses have returned, indicating that the hospital doctors have undone the effects of his conditioning. As photographers snap pictures, Alex daydreams of orgiastic violence and reflects, "I was cured all right."

In the final chapter, Alex finds himself halfheartedly preparing for yet another night of crime with a new gang (Lenn, Rick, Bully). After a chance encounter with Pete, who has reformed and married, Alex finds himself taking less and less pleasure in acts of senseless violence. He begins contemplating giving up crime himself to become a productive member of society and start a family of his own, while reflecting on the notion that his own children could possibly end up being just as destructive as he has been, if not more so.

The book has three parts, each with seven chapters. Burgess has stated that the total of 21 chapters was an intentional nod to the age of 21 being recognised as a milestone in human maturation. The 21st chapter was omitted from the editions published in the United States prior to 1986. In the introduction to the updated American text (these newer editions include the missing 21st chapter), Burgess explains that when he first brought the book to an American publisher, he was told that U.S. audiences would never go for the final chapter, in which Alex sees the error of his ways, decides he has lost all energy for and thrill from violence and resolves to turn his life around (a moment of metanoia).

At the American publisher's insistence, Burgess allowed their editors to cut the redeeming final chapter from the U.S. version, so that the tale would end on a darker note, with Alex succumbing to his violent, reckless nature—an ending which the publisher insisted would be "more realistic" and appealing to a US audience. The film adaptation, directed by Stanley Kubrick, is based on the American edition of the book (which Burgess considered to be "badly flawed"). Kubrick called Chapter 21 "an extra chapter" and claimed that he had not read the original version until he had virtually finished the screenplay, and that he had never given serious consideration to using it. In Kubrick's opinion—as in the opinion of other readers, including the original American editor—the final chapter was unconvincing and inconsistent with the book.


"A Clockwork Orange" was written in Hove, then a senescent seaside town. Burgess had arrived back in Britain after his stint abroad to see that much had changed. A youth culture had grown, including coffee bars, pop music and teenage gangs. England was gripped by fears over juvenile delinquency. Burgess claimed that the novel's inspiration was his first wife Lynne's beating by a gang of drunk American servicemen stationed in England during World War II. She subsequently miscarried. In its investigation of free will, the book's target is ostensibly the concept of behaviourism, pioneered by such figures as B. F. Skinner.

Burgess later stated that he wrote the book in three weeks.

Burgess has offered several clarifications about the meaning and origin of its title:


This title alludes to the protagonist's negative emotional responses to feelings of evil which prevent the exercise of his free will subsequent to the administration of the Ludovico Technique. To induce this conditioning, Alex is forced to watch scenes of violence on a screen that are systematically paired with negative physical stimulation. The negative physical stimulation takes the form of nausea and "feelings of terror," which are caused by an emetic medicine administered just before the presentation of the films.

The book, narrated by Alex, contains many words in a slang argot which Burgess invented for the book, called Nadsat. It is a mix of modified Slavic words, rhyming slang and derived Russian (like "baboochka"). For instance, these terms have the following meanings in Nadsat: "droog" = friend; "korova" = cow; "gulliver" ("golova") = head; "malchick" or "malchickiwick" = boy; "soomka" = sack or bag; "Bog" = God; "khorosho" ("horrorshow") = good; "prestoopnick" = criminal; "rooka" ("rooker") = hand; "cal" = crap; "veck" ("chelloveck") = man or guy; "litso" = face; "malenky" = little; and so on. Some words Burgess invented himself or just adapted from pre-existing languages. Compare Polari.

One of Alex's doctors explains the language to a colleague as "odd bits of old rhyming slang; a bit of gypsy talk, too. But most of the roots are Slav propaganda. Subliminal penetration." Some words are not derived from anything, but merely easy to guess, e.g. "in-out, in-out" or "the old in-out" means sexual intercourse. "Cutter", however, means "money", because "cutter" rhymes with "bread-and-butter"; this is rhyming slang, which is intended to be impenetrable to outsiders (especially eavesdropping policemen). Additionally, slang like "appypolly loggy" ("apology") seems to derive from school boy slang. This reflects Alex's age of 15.

In the first edition of the book, no key was provided, and the reader was left to interpret the meaning from the context. In his appendix to the restored edition, Burgess explained that the slang would keep the book from seeming dated, and served to muffle "the raw response of pornography" from the acts of violence.

The term "ultraviolence", referring to excessive or unjustified violence, was coined by Burgess in the book, which includes the phrase "do the ultra-violent". The term's association with aesthetic violence has led to its use in the media.

In 1976, "A Clockwork Orange" was removed from an Aurora, Colorado high school because of "objectionable language". A year later in 1977 it was removed from high school classrooms in Westport, Massachusetts over similar concerns with "objectionable" language. In 1982, it was removed from two Anniston, Alabama libraries, later to be reinstated on a restricted basis. Also, in 1973 a bookseller was arrested for selling the novel. The charges were later dropped. However, each of these instances came after the release of Stanley Kubrick's popular 1971 film adaptation of "A Clockwork Orange", itself the subject of much controversy.

"The Sunday Telegraph" review was positive, and described the book as "entertaining ... even profound".

"The Sunday Times" review was negative, and described the book as "a very ordinary, brutal and psychologically shallow story".

"The Times

Burgess dismissed "A Clockwork Orange" as "too didactic to be artistic". He claimed that the violent content of the novel "nauseated" him.

In 1985, Burgess published "Flame into Being: The Life and Work of D. H. Lawrence" and while discussing "Lady Chatterley's Lover" in his biography, Burgess compared that novel's notoriety with "A Clockwork Orange": "We all suffer from the popular desire to make the known notorious. The book I am best known for, or only known for, is a novel I am prepared to repudiate: written a quarter of a century ago, a "jeu d'esprit" knocked off for money in three weeks, it became known as the raw material for a film which seemed to glorify sex and violence. The film made it easy for readers of the book to misunderstand what it was about, and the misunderstanding will pursue me until I die. I should not have written the book because of this danger of misinterpretation, and the same may be said of Lawrence and "Lady Chatterley's Lover"."


"A Clockwork Orange" was chosen by "Time" magazine as one of the 100 best English-language books from 1923 to 2005.

The best known adaptation of the novella to other forms is the 1971 film "A Clockwork Orange" by Stanley Kubrick, starring Malcolm McDowell as Alex.

A 1965 film by Andy Warhol entitled "Vinyl" was an adaptation of Burgess's novel.

In 1987 Burgess published a stage play titled "A Clockwork Orange: A Play with Music". The play includes songs, written by Burgess, which are inspired by Beethoven and Nadsat slang.

In 1988, a German adaptation of "A Clockwork Orange" at the intimate theatre of Bad Godesberg featured a musical score by the German punk rock band Die Toten Hosen which, combined with orchestral clips of Beethoven's Ninth Symphony and "other dirty melodies" (so stated by the subtitle), was released on the album "Ein kleines bisschen Horrorschau". The track "Hier kommt Alex
In February 1990, another musical version was produced at the Barbican Theatre in London by the Royal Shakespeare Company. Titled "A Clockwork Orange: 2004", it received mostly negative reviews, with John Peter of "The Sunday Times" of London calling it "only an intellectual "Rocky Horror Show"", and John Gross of "The Sunday Telegraph" calling it "a clockwork lemon". Even Burgess himself, who wrote the script based on his novel, was disappointed. According to "The Evening Standard", he called the score, written by Bono and The Edge of the rock group U2, "neo-wallpaper." Burgess had originally worked alongside the director of the production, Ron Daniels, and envisioned a musical score that was entirely classical. Unhappy with the decision to abandon that score, he heavily criticised the band's experimental mix of hip hop, liturgical and gothic music. Lise Hand of "The Irish Independent" reported The Edge as saying that Burgess's original conception was "a score written by a novelist rather than a songwriter". Calling it "meaningless glitz", Jane Edwardes of "20/20 Magazine" said that watching this production was "like being invited to an expensive French Restaurant – and being served with a Big Mac."

In 1994, Chicago's Steppenwolf Theater put on a production of "A Clockwork Orange" directed by Terry Kinney. The American premiere of novelist Anthony Burgess's own adaptation of his "A Clockwork Orange" starred K. Todd Freeman as Alex. In 2001, UNI Theatre (Mississauga, Ontario) presented the Canadian premiere of the play under the direction of Terry Costa.

In 2002, Godlight Theatre Company presented the New York Premiere adaptation of "A Clockwork Orange" at Manhattan Theatre Source. The production went on to play at the SoHo Playhouse (2002), Ensemble Studio Theatre (2004), 59E59 Theaters (2005) and the Edinburgh Festival Fringe (2005). While at Edinburgh, the production received rave reviews from the press while playing to sold-out audiences. The production was directed by Godlight's Artistic Director, Joe Tantalo.

In 2003, Los Angeles director Brad Mays and the ARK Theatre Company staged a multi-media adaptation of "A Clockwork Orange", which was named "Pick Of The Week" by the "LA Weekly" and nominated for three of the 2004 LA Weekly Theater Awards: Direction, Revival Production (of a 20th-century work), and Leading Female Performance. Vanessa Claire Smith won Best Actress for her gender-bending portrayal of Alex, the music-loving teenage sociopath
Category:1962 British novels
Category:1962 science fiction novels
Category:Mind control in fiction
Category:Books written in fictional dialects
Category:British novellas
Category:British novels adapted into films
Category:British philosophical novels
Category:British science fiction novels
Category:Dystopian novels
Category:Fiction with unreliable narrators
Category:Novels about music
Category:Novels by Anthony Burgess
Category:Novels set in England
Category:Obscenity controversies in literature
Category:Prometheus Award-winning works
Category:Rape in fiction
Category:Heinemann (publisher) books
Category:English-language novels
Category:Novels set in London
Category:Metafictional novels
Category:Novels about sociopathyAmsterdam

Amsterdam (, ; ) is the capital city and most populous municipality of the Netherlands. Its status as the capital is mandated by the Constitution of the Netherlands, although it is not the seat of the government, which is The Hague. Amsterdam has a population of 846,948 within the city proper, 1,347,224 in the urban area and 2,410,960 in the metropolitan area. The city is located in the province of North Holland in the west of the country but is not its capital, which is Haarlem. The Amsterdam metropolitan area comprises much of the northern part of the Randstad, one of the larger conurbations in Europe, which has a population of approximately 8.1 million.

Amsterdam's name derives from "Amstelredamme", indicative of the city's origin around a dam in the river Amstel. Originating as a small fishing village in the late 12th century, Amsterdam became one of the most important ports in the world during the Dutch Golden Age (17th century), as a result of its innovative developments in trade. During that time, the city was the leading centre for finance and trade. In the 19th and 20th centuries the city expanded, and many new neighbourhoods and suburbs were planned and built. The 17th-century canals of Amsterdam and the 19–20th century Defence Line of Amsterdam are on the UNESCO World Heritage List. Since the annexation of the municipality of Sloten in 1921 by the municipality of Amsterdam, the oldest historic part of the city lies in Sloten, dating to the 9th century.

As the commercial capital of the Netherlands and one of the top financial centres in Europe, Amsterdam is considered an alpha- world city by the Globalization and World Cities (GaWC) study group. The city is also the cultural capital of the Netherlands. Many large Dutch institutions have their headquarters there, including Philips, AkzoNobel, TomTom and ING. Also, many of the world's largest companies are based in Amsterdam or established their European headquarters in the city, such as leading technology companies Uber, Netflix and Tesla. In 2012, Amsterdam was ranked the second best city to live in by the Economist Intelligence Unit (EIU) and 12th globally on quality of living for environment and infrastructure by Mercer. The city was ranked 4th place globally as top tech hub in the Savills Tech Cities 2019 report (2nd in Europe), and 3rd in innovation by Australian innovation agency 2thinknow in their Innovation Cities Index 2009. The Port of Amsterdam to this day remains the second in the country, and the fifth largest seaport in Europe. Famous Amsterdam residents include the diarist Anne Frank, artists Rembrandt van Rijn and Vincent van Gogh, and philosopher Baruch Spinoza.

The Amsterdam Stock Exchange, the oldest stock exchange in the world, is located in the city centre. Amsterdam's main attractions include its historic canals, the Rijksmuseum, the Van Gogh Museum, the Stedelijk Museum, Hermitage Amsterdam, the Anne Frank House, the Scheepvaartmuseum, the Amsterdam Museum, the Heineken Experience, the Royal Palace of Amsterdam, Natura Artis Magistra, Hortus Botanicus Amsterdam, NEMO, the red-light district and many cannabis coffee shops. They draw more than 5 million international visitors annually. The city is also well known for its nightlife and festival activity; several of its nightclubs (Melkweg, Paradiso) are among the world's most famous. It is also one of the world's most multicultural cities, with at least 177 nationalities represented.

After the floods of 1170 and 1173, locals near the river Amstel built a bridge over the river and a dam across it, giving its name to the village: "Aemstelredamme". The earliest recorded use of that name is in a document dated 27 October 1275, which exempted inhabitants of the village from paying bridge tolls to Count Floris V. This allowed the inhabitants of the village of Aemstelredamme to travel freely through the County of Holland
Amsterdam is much younger than Dutch cities such as Nijmegen, Rotterdam, and Utrecht. In October 2008, historical geographer Chris de Bont suggested that the land around Amsterdam was being reclaimed as early as the late 10th century. This does not necessarily mean that there was already a settlement then, since reclamation of land may not have been for farming—it may have been for peat, for use as fuel.

Amsterdam was granted city rights in either 1300 or 1306. From the 14th century on, Amsterdam flourished, largely from trade with the Hanseatic League. In 1345, an alleged Eucharistic miracle in the Kalverstraat rendered the city an important place of pilgrimage until the adoption of the Protestant faith. The Miracle devotion went underground but was kept alive. In the 19th century, especially after the jubilee of 1845, the devotion was revitalized and became an important national point of reference for Dutch Catholics. The "Stille Omgang"—a silent walk or procession
In the 16th century, the Dutch rebelled against Philip II of Spain and his successors. The main reasons for the uprising were the imposition of new taxes, the tenth penny, and the religious persecution of Protestants by the newly introduced Inquisition. The revolt escalated into the Eighty Years' War, which ultimately led to Dutch independence. Strongly pushed by Dutch Revolt leader William the Silent, the Dutch Republic became known for its relative religious tolerance. Jews from the Iberian Peninsula, Huguenots from France, prosperous merchants and printers from Flanders, and economic and religious refugees from the Spanish-controlled parts of the Low Countries found safety in Amsterdam. The influx of Flemish printers and the city's intellectual tolerance made Amsterdam a centre for the European free press

The 17th century is considered Amsterdam's "Golden Age", during which it became the wealthiest city in the western world. Ships sailed from Amsterdam to the Baltic Sea, North America, and Africa, as well as present-day Indonesia, India, Sri Lanka, and Brazil, forming the basis of a worldwide trading network. Amsterdam's merchants had the largest share in both the Dutch East India Company and the Dutch West India Company. These companies acquired overseas possessions that later became Dutch colonies.
Amsterdam was Europe's most important point for the shipment of goods and was the leading Financial centre of the western world. In 1602, the Amsterdam office of the international trading Dutch East India Company became the world's first stock exchange by trading in its own shares. The Bank of Amsterdam started operations in 1609, acting as a full service bank for Dutch merchant bankers and as a reserve bank.

Amsterdam's prosperity declined during the 18th and early 19th centuries. The wars of the Dutch Republic with England and France took their toll on Amsterdam. During the Napoleonic Wars, Amsterdam's significance reached its lowest point, with Holland being absorbed into the French Empire. However, the later establishment of the United Kingdom of the Netherlands
The end of the 19th century is sometimes called Amsterdam's second Golden Age. New museums, a railway station, and the Concertgebouw were built; in this same time, the Industrial Revolution reached the city. The Amsterdam–Rhine Canal was dug to give Amsterdam a direct connection to the Rhine, and the North Sea Canal was dug to give the port a shorter connection to the North Sea. Both projects dramatically improved commerce with the rest of Europe and the world. In 1906, Joseph Conrad
Shortly before the First World War, the city started to expand again, and new suburbs were built. Even though the Netherlands remained neutral in this war, Amsterdam suffered a food shortage, and heating fuel became scarce. The shortages sparked riots in which several people were killed. These riots are known as the "Aardappeloproer" (Potato rebellion). People started looting stores and warehouses in order to get supplies, mainly food.

On 1 January 1921, after a flood in 1916, the depleted municipalities of Durgerdam, Holysloot, Zunderdorp and Schellingwoude, all lying north of Amsterdam, were, at their own request, annexed to the city. Between the wars, the city continued to expand, most notably to the west of the Jordaan district in the Frederik Hendrikbuurt and surrounding neighbourhoods.

Nazi Germany invaded the Netherlands on 10 May 1940 and took control of the country. Some Amsterdam citizens sheltered Jews, thereby exposing themselves and their families to a high risk of being imprisoned or sent to concentration camps. More than 100,000 Dutch Jews were deported to Nazi concentration camps, of whom some 60,000 lived in Amsterdam. In response, the Dutch Communist Party organised the February strike attended by 300,000 people to protest against the raids. Perhaps the most famous deportee was the young Jewish girl Anne Frank, who died in the Bergen-Belsen concentration camp. At the end of the Second World War, communication with the rest of the country broke down, and food and fuel became scarce. Many citizens travelled to the countryside to forage. Dogs, cats, raw sugar beets, and Tulip
Many new suburbs, such as Osdorp, Slotervaart, Slotermeer and Geuzenveld, were built in the years after the Second World War.
These suburbs contained many public parks and wide open spaces, and the new buildings provided improved housing conditions with larger and brighter rooms, gardens, and balconies. Because of the war and other events of the 20th century, almost the entire city centre had fallen into disrepair. As society was changing, politicians and other influential figures made plans to redesign large parts of it. There was an increasing demand for office buildings, and also for new roads, as the automobile became available to most people. A metro started operating in 1977 between the new suburb of Bijlmer and the centre of Amsterdam. Further plans were to build a new highway above the metro to connect Amsterdam Centraal and city centre with other parts of the city.

The required large-scale demolitions began in Amsterdam's former Jewish neighbourhood. Smaller streets, such as the Jodenbreestraat, were widened and almost all of their houses were demolished. At the peak of the demolition, the "Nieuwmarktrellen" (Nieuwmarkt Riots) broke out; the rioters expressed their fury about the demolition caused by the restructuring of the city.

As a result, the demolition was stopped and the highway was never built; only the metro was completed. Only a few streets remained widened. The new city hall was built on the almost completely demolished Waterlooplein. Meanwhile, large private organisations, such as "Stadsherstel Amsterdam", were founded with the aim of restoring the entire city centre. Although the success of this struggle is visible today, efforts for further restoration are still ongoing. The entire city centre has reattained its former splendour and, as a whole, is now a protected area. Many of its buildings have become monuments, and in July 2010 the Grachtengordel (the three concentric canals: Herengracht, Keizersgracht, and Prinsengracht) was added to the UNESCO World Heritage List
In the early years of the 21st century, the Amsterdam city centre has attracted large numbers of tourists: between 2012 and 2015, the annual number of visitors rose from 10 million to 17 million. Real estate prices have surged, and local shops are making way for tourist-oriented ones, making the centre unaffordable for the city's inhabitants. These developments have evoked comparisons with Venice, a city thought to be overwhelmed by the tourist influx.

Construction of a metro line connecting the part of the city north of the river (or lake) IJ to the centre was started in 2003. The project is controversial because its cost had exceeded its budget by a factor three by 2008, because of fears of damage to buildings in the centre, and because construction had to be halted and restarted multiple times.

Since 2014, renewed focus has been given to urban regeneration and renewal, especially in areas directly bordering the city centre, such as Frederik Hendrikbuurt. This urban renewal and expansion of the traditional centre of the city—with the construction on artificial islands of the new eastern IJburg neighbourhood—is part of the Structural Vision Amsterdam 2040 initiative.

Amsterdam is located in the Western Netherlands, in the province of North Holland, although it is not its capital which is Haarlem. The river Amstel ends in the city centre and connects to a large number of canals that eventually terminate in the IJ. Amsterdam is about below sea level. The surrounding land is flat as it is formed of large polders. A man-made forest, Amsterdamse Bos, is in the southwest. Amsterdam is connected to the North Sea through the long North Sea Canal.

Amsterdam is intensely urbanised, as is the Amsterdam metropolitan area surrounding the city. Comprising of land, the city proper has 4,457 inhabitants per km and 2,275 houses per km. Parks and nature reserves
Amsterdam has more than of canals, most of which are navigable by boat. The city's three main canals are the Prinsengracht, Herengracht, and Keizersgracht.

In the Middle Ages, Amsterdam was surrounded by a moat, called the Singel, which now forms the innermost ring in the city, and makes the city centre a horseshoe shape. The city is also served by a seaport. It has been compared with Venice
Amsterdam has an oceanic climate (Köppen climate classification "Cfb") strongly influenced by its proximity to the North Sea to the west, with prevailing westerly winds. Both winters and summers are considered mild, although winters can get quite cold, while summers are quite warm occasionally.

Amsterdam, as well as most of the North Holland province, lies in USDA Hardiness zone 8b. Frosts mainly occur during spells of easterly or northeasterly winds from the inner European continent. Even then, because Amsterdam is surrounded on three sides by large bodies of water, as well as having a significant heat-island effect, nights rarely fall below , while it could easily be in Hilversum, southeast.

Summers are moderately warm with a number of hot days every month. The average daily high in August is , and or higher is only measured on average on 2.5 days, placing Amsterdam in AHS Heat Zone 2. The record extremes range from to .
Days with more than of precipitation are common, on average 133 days per year.

Amsterdam's average annual precipitation is , more than what is measured at Amsterdam Schiphol Airport. A large part of this precipitation falls as light rain or brief showers. Cloudy and damp days are common during the cooler months of October through March.

In 1300, Amsterdam's population was around 1,000 people. While many towns in Holland experienced population decline during the 15th and 16th centuries, Amsterdam's population grew, mainly due to the rise of the profitable Baltic maritime trade after the Burgundian victory in the Dutch–Hanseatic War. Still, the population of Amsterdam was only modest compared to the towns and cities of Flanders and Brabant, which comprised the most urbanised area of the Low Countries.

This changed when, during the Dutch Revolt, many people from the Southern Netherlands fled to the North, especially after Antwerp fell to Spanish forces in 1585. Jewish people from Spain, Portugal and Eastern Europe similarly settled in Amsterdam, as did Germans and Scandinavians. In thirty years, Amsterdam's population more than doubled from 1585 to 1610. By 1600, its population was around 50,000. During the 1660s, Amsterdam's population reached 200,000. The city's growth levelled off and the population stabilised around 240,000 for most of the 18th century.

In 1750, Amsterdam was the fourth largest city in western Europe, behind London (676,000), Paris (560,000) and Naples (324,000). This was all the more remarkable as Amsterdam was neither the capital city nor the seat of government of the Dutch Republic, which itself was a much smaller state than England, France or the Ottoman Empire. In contrast to those other metropolises, Amsterdam was also surrounded by large towns such as Leiden (about 67,000), Rotterdam (45,000), Haarlem (38,000), and Utrecht (30,000).

The city's population declined in the early 19th century, dipping under 200,000 in 1820. By the second half of the 19th century, industrialisation spurred renewed growth. Amsterdam's population hit an all-time high of 872,000 in 1959, before declining in the following decades due to government-sponsored suburbanisation to so-called "groeikernen" (growth centres) such as Purmerend and Almere. Between 1970 and 1980, Amsterdam experienced its sharp population decline, peaking at a net loss of 25,000 people in 1973. By 1985 the city had only 675,570 residents. This was soon followed by reurbanisation and gentrification, leading to renewed population growth in the 2010s. Also in the 2010s, much of Amsterdam's population growth was due to immigration to the city. Amsterdam's population is expected to top its previous high in 2019, reaching 873,000.

In the 16th and 17th century non-Dutch immigrants to Amsterdam were mostly Huguenots, Flemings, Sephardi Jews and Westphalians. Huguenots came after the Edict of Fontainebleau in 1685, while the Flemish Protestants came during the Eighty Years' War. The Westphalians came to Amsterdam mostly for economic reasons – their influx continued through the 18th and 19th centuries. Before the Second World War, 10% of the city population was Jewish. Just twenty per cent of them survived the Shoah.

The first mass immigration in the 20th century were by people from Indonesia, who came to Amsterdam after the independence of the Dutch East Indies in the 1940s and 1950s. In the 1960s guest workers from Turkey, Morocco, Italy and Spain emigrated to Amsterdam. After the independence of Suriname in 1975, a large wave of Surinamese settled in Amsterdam, mostly in the Bijlmer area. Other immigrants, including refugees asylum seekers and illegal immigrants, came from Europe, America, Asia, and Africa. In the 1970s and 1980s, many 'old' Amsterdammers moved to 'new' cities like Almere and Purmerend, prompted by the third planological bill of the Dutch government. This bill promoted suburbanisation and arranged for new developments in so-called "groeikernen", literally "cores of growth". Young professionals and artists moved into neighbourhoods de Pijp and the Jordaan abandoned by these Amsterdammers. The non-Western immigrants settled mostly in the social housing projects in Amsterdam-West and the Bijlmer. Today, people of non-Western origin make up approximately one-third of the population of Amsterdam, and more than 50% of the city'
s children. Ethnic Dutch (as defined by the Dutch census) now make up a minority of the total population, although by far the largest one. Only one in three inhabitants under 15 is an "autochtoon", or a person who has two parents of Dutch origin. Segregation along ethnic lines is clearly visible, with people of non-Western origin, considered a separate group by Statistics Netherlands, concentrating in specific neighbourhoods especially in Nieuw-West, Zeeburg, Bijlmer and in certain areas of Amsterdam-Noord.

In 2000, Christians formed the largest religious group in the city (17% of the population). The next largest religion was Islam (14%), most of whose followers were Sunni.

In 1578, the largely Roman Catholic city of Amsterdam joined the revolt against Spanish rule, late in comparison to other major northern Dutch cities. Roman Catholic priests were driven out of the city. Following the Dutch takeover, all churches were converted to Protestant worship. Calvinism was declared the main religion, and although Catholicism was not forbidden and priests allowed to serve, the Catholic hierarchy was prohibited. This led to the establishment of "schuilkerken", covert religious buildings that were hidden in pre-existing buildings. Catholics, some Jewish and dissenting Protestants worshiped in such buildings. A large influx of foreigners of many religions came to 17th-century Amsterdam, in particular Sefardic Jews from Spain and Portugal, Huguenots from France, Lutherans, Mennonites, and Protestants from across the Netherlands. This led to the establishment of many non-Dutch-speaking churches. In 1603, the Jewish received permission to practice their religion. In 1639, the first synagogue was consecrated. The Jews came to call the town Jerusalem of the West.

As they became established in the city, other Christian denominations used converted Catholic chapels to conduct their own services. The oldest English-language church congregation in the world outside the United Kingdom is found at the Begijnhof. Regular services there are still offered in English under the auspices of the Church of Scotland. Being Calvinists, the Huguenots soon integrated into the Dutch Reformed Church, though often retaining their own congregations. Some, commonly referred by the moniker 'Walloon', are recognisable today as they offer occasional services in French.

In the second half of the 17th century, Amsterdam experienced an influx of Ashkenazim, Jews from Central and Eastern Europe. Jews often fled the pogroms in those areas. The first Ashkenazi who arrived in Amsterdam were refugees from the Chmielnicki Uprising in Poland and the Thirty Years' War. They not only founded their own synagogues, but had a strong influence on the 'Amsterdam dialect' adding a large Yiddish local vocabulary.

Despite an absence of an official Jewish ghetto, most Jews preferred to live in the eastern part of the old medieval heart of the city. The main street of this Jewish neighbourhood was the "Jodenbreestraat". The neighbourhood comprised the "Waterlooplein" and the Nieuwmarkt
Catholic churches in Amsterdam have been constructed since the restoration of the episcopal hierarchy in 1853. One of the principal architects behind the city's Catholic churches, Cuypers, was also responsible for the Amsterdam Central station and the Rijksmuseum.

In 1924, the Roman Catholic Church of the Netherlands hosted the International Eucharistic Congress in Amsterdam, and numerous Catholic prelates visited the city, where festivities were held in churches and stadiums. Catholic processions on the public streets, however, were still forbidden under law at the time. Only in the 20th century was Amsterdam's relation to Catholicism normalised, but despite its far larger population size, the episcopal see of the city was placed in the provincial town of Haarlem.

In recent times, religious demographics in Amsterdam have been changed by immigration from former colonies. Hinduism has been introduced from the Hindu diaspora from Suriname and several distinct branches of Islam have been brought from various parts of the world. Islam is now the largest non-Christian religion in Amsterdam. The large community of Ghanaian immigrants have established African churches, often in parking garages in the Bijlmer area.

Amsterdam experienced an influx of religions and cultures after the Second World War. With 180 different nationalities, Amsterdam is home to one of the widest varieties of nationalities of any city in the world. The proportion of the population of immigrant origin in the city proper is about 50% and 88% of the population are Dutch citizens.

Amsterdam has been one of the municipalities in the Netherlands which provided immigrants with extensive and free Dutch-language
Amsterdam fans out south from the Amsterdam Centraal railway station and Damrak, the main street off the station. The oldest area of the town is known as De Wallen (English: "The Quays"). It lies to the east of Damrak and contains the city's famous red light district. To the south of De Wallen is the old Jewish quarter of Waterlooplein.

The medieval and colonial age canals of Amsterdam, known as "grachten", embraces the heart of the city where homes have interesting gables. Beyond the Grachtengordel are the former working class areas of Jordaan and de Pijp. The Museumplein with the city's major museums, the Vondelpark, a 19th-century park named after the Dutch writer Joost van den Vondel, and the Plantage neighbourhood, with the zoo, are also located outside the Grachtengordel.

Several parts of the city and the surrounding urban area are polders. This can be recognised by the suffix "-meer" which means "lake", as in Aalsmeer, Bijlmermeer, Haarlemmermeer, and Watergraafsmeer
The Amsterdam canal system is the result of conscious city planning. In the early 17th century, when immigration was at a peak, a comprehensive plan was developed that was based on four concentric half-circles of canals with their ends emerging at the IJ bay. Known as the Grachtengordel, three of the canals were mostly for residential development: the Herengracht (where "Heren" refers to "Heren Regeerders van de stad Amsterdam" (ruling lords of Amsterdam), and "gracht" means canal, so the name can be roughly translated as "Canal of the Lords"), Keizersgracht (Emperor's Canal), and Prinsengracht (Prince's Canal). The fourth and outermost canal is the Singelgracht, which is often not mentioned on maps, because it is a collective name for all canals in the outer ring. The Singelgracht should not be confused with the oldest and most inner canal Singel.

The canals served for defence, water management and transport. The defences took the form of a moat and earthen dikes, with gates at transit points, but otherwise no masonry superstructures. The original plans have been lost, so historians, such as Ed Taverne, need to speculate on the original intentions: it is thought that the considerations of the layout were purely practical and defensive rather than ornamental.

Construction started in 1613 and proceeded from west to east, across the breadth of the layout, like a gigantic windshield wiper as the historian Geert Mak calls it – and not from the centre outwards, as a popular myth has it. The canal construction in the southern sector was completed by 1656. Subsequently, the construction of residential buildings proceeded slowly. The eastern part of the concentric canal plan, covering the area between the Amstel river and the IJ bay, has never been implemented. In the following centuries, the land was used for parks, senior citizens' homes, theatres, other public facilities, and waterways without much planning. Over the years, several canals have been filled in, becoming streets or squares, such as the Nieuwezijds Voorburgwal and the Spui
After the development of Amsterdam's canals in the 17th century, the city did not grow beyond its borders for two centuries. During the 19th century, Samuel Sarphati devised a plan based on the grandeur of Paris and London at that time. The plan envisaged the construction of new houses, public buildings and streets just outside the Grachtengordel. The main aim of the plan, however, was to improve public health. Although the plan did not expand the city, it did produce some of the largest public buildings to date, like the "Paleis voor Volksvlijt".

Following Sarphati, civil engineers Jacobus van Niftrik and Jan Kalff designed an entire ring of 19th-century neighbourhoods surrounding the city's centre, with the city preserving the ownership of all land outside the 17th-century limit, thus firmly controlling development. Most of these neighbourhoods became home to the working class.

In response to overcrowding, two plans were designed at the beginning of the 20th century which were very different from anything Amsterdam had ever seen before: "Plan Zuid", designed by the architect Berlage, and "West". These plans involved the development of new neighbourhoods consisting of "housing blocks" for all social classes.

After the Second World War, large new neighbourhoods were built in the western, southeastern, and northern parts of the city. These new neighbourhoods were built to relieve the city's shortage of living space and give people affordable houses with modern conveniences. The neighbourhoods consisted mainly of large housing blocks situated among green spaces, connected to wide roads, making the neighbourhoods easily accessible by motor car
Amsterdam has a rich architectural history. The oldest building in Amsterdam is the Oude Kerk (English: Old Church), at the heart of the Wallen, consecrated in 1306. The oldest wooden building is "Het Houten Huys" at the Begijnhof. It was constructed around 1425 and is one of only two existing wooden buildings. It is also one of the few examples of Gothic architecture in Amsterdam. The oldest stone building of the Netherlands, The Moriaan is build in 's-Hertogenbosch.

In the 16th century, wooden buildings were razed and replaced with brick ones. During this period, many buildings were constructed in the architectural style of the Renaissance. Buildings of this period are very recognisable with their stepped gable façades, which is the common Dutch Renaissance style. Amsterdam quickly developed its own Renaissance architecture. These buildings were built according to the principles of the architect Hendrick de Keyser. One of the most striking buildings designed by Hendrick de Keyer is the Westerkerk. In the 17th century baroque architecture became very popular, as it was elsewhere in Europe. This roughly coincided with Amsterdam's Golden Age. The leading architects of this style in Amsterdam were Jacob van Campen, Philips Vingboons and Daniel Stalpaert
Philip Vingboons designed splendid merchants' houses throughout the city. A famous building in baroque style in Amsterdam is the Royal Palace on Dam Square. Throughout the 18th century, Amsterdam was heavily influenced by French culture. This is reflected in the architecture of that period. Around 1815, architects broke with the baroque style and started building in different neo-styles. Most Gothic style buildings date from that era and are therefore said to be built in a neo-gothic style. At the end of the 19th century, the Jugendstil or Art Nouveau style became popular and many new buildings were constructed in this architectural style. Since Amsterdam expanded rapidly during this period, new buildings adjacent to the city centre were also built in this style. The houses in the vicinity of the Museum Square in Amsterdam Oud-Zuid are an example of Jugendstil. The last style that was popular in Amsterdam before the modern era was Art Deco. Amsterdam had its own version of the style, which was called the Amsterdamse School. Whole districts were built this style, such as the "Rivierenbuurt". A notable feature of the façades of buildings designed in Amsterdamse School is that they are highly decorated and ornate, with oddly shaped windows and doors.

The old city centre is the focal point of all the architectural styles before the end of the 19th century.
Jugendstil and Georgian are mostly found outside the city's centre in the neighbourhoods built in the early
20th century, although there are also some striking examples of these styles in the city centre.
Most historic buildings in the city centre and nearby are houses, such as the famous merchants' houses lining the canals.

[[File:Amsterdam map indicating parks - 01.png|thumb|

Amsterdam has many parks, open spaces, and squares throughout the city. The [[Vondelpark]], the largest park in the city, is located in the [[Amsterdam Oud-Zuid|Oud-Zuid]] neighbourhood and is named after the 17th-century Amsterdam author [[Joost van den Vondel]]. Yearly, the park has around 10 million visitors. In the park is an open-air theatre, a playground and several [[horeca]] facilities. In the [[Amsterdam-Zuid|Zuid]] borough, is the [[Beatrixpark]], named after [[Beatrix of the Netherlands|Queen Beatrix]]. Between Amsterdam and [[Amstelveen]] is the [[Amsterdamse Bos]] ("Amsterdam Forest"), the largest recreational area in Amsterdam. Annually, almost 4.5 million people visit the park, which has a size of 1.000 hectares and is approximately three times the size of [[Central Park]]. The [[Amstelpark]] in the [[Amsterdam-Zuid|Zuid]] borough houses the Rieker windmill, which dates to 1636. Other parks include the [[Sarphatipark]] in the [[De Pijp]] neighbourhood, the [[Oosterpark (Amsterdam)|Oosterpark]] in the [[Amsterdam-Oost|Oost]] borough and the [[Westerpark (park)|Westerpark]] in the [[Westerpark (neighbourhood)|Westerpark]] neighbourhood. The city has three beaches: Nemo Beach, Citybeach "Het stenen hoofd" (Silodam) and Blijburg, all located in the Centrum borough.

The city has many open squares ("plein" in Dutch). The namesake of the city as the site of the original dam, [[Dam Square]], is the main city square and has the [[Royal Palace of Amsterdam|Royal Palace]] and [[National Monument (Amsterdam)|National Monument]]. [[Museumplein]] hosts various museums, including the [[Rijksmuseum]], [[Van Gogh Museum]], and [[Stedelijk Museum Amsterdam|Stedelijk Museum]]. Other squares include [[Rembrandtplein]], [[Muntplein, Amsterdam|Muntplein]], [[Nieuwmarkt]], [[Leidseplein]], [[Spui (Amsterdam)|Spui]], and [[Waterlooplein]]. Also, near to Amsterdam is the [[Nekkeveld estate]] conservation project.

[[File:20151120 BeursvanBerlage 002-6972.jpg|thumb|left|250px|The [[Amsterdam Stock Exchange]], the oldest stock exchange in the world.]]
[[File:Zuidas pano.jpg|thumb|left|250px|The [[Zuidas]], the city's main business district.]]
Amsterdam is the financial and business capital of the Netherlands.
Amsterdam is ranked fifth best of European cities in which to locate an [[international business]], surpassed by [[London]], [[Paris]], [[Frankfurt]] and [[Barcelona]]. Many large corporations and banks have their headquarters in Amsterdam, including [[AkzoNobel]], [[Heineken International]], [[ING Group]], [[ABN AMRO]], [[TomTom]], [[Delta Lloyd Group]], [[Booking.com]] and [[Philips]]. [[KPMG]] International's global headquarters is located in nearby Amstelveen, where many non-Dutch companies have settled as well, because surrounding communities allow full land ownership, contrary to Amsterdam's land-lease system.

Though many small offices are still located on the old canals, companies are increasingly relocating outside the city centre. The [[Zuidas]] (English: South Axis) has become the new financial and legal hub. The five largest law firms of the Netherlands, a number of Dutch subsidiaries of large consulting firms like [[Boston Consulting Group]] and [[Accenture]], and the [[World Trade Center (Amsterdam)|World Trade Center Amsterdam]] are also located in Zuidas.

There are three other smaller financial districts in Amsterdam. The first is the area surrounding [[Amsterdam Sloterdijk railway station]], where several newspapers like "[[De Telegraaf]]" have their offices.

Also, [[Deloitte]], the [[Gemeentelijk Vervoerbedrijf]] (municipal public transport company) and the Dutch tax offices ("Belastingdienst") are located there. The second [[Central business district|Financial District]] is the area surrounding the [[Johan Cruyff Arena]]. The third is the area surrounding [[Amsterdam Amstel railway station]]. The [[List of tallest buildings and structures in the world|tallest building]] in Amsterdam, the [[Rembrandt Tower]], is situated there, as is the headquarters of [[Philips]].

The [[Port of Amsterdam]] is the fourth largest port in Europe, the 38th largest port in the world and the second largest port in the Netherlands by metric tons of cargo. In 2014 the Port of Amsterdam had a cargo throughput of 97,4 million tons of cargo, which was mostly [[bulk cargo]].
Amsterdam has the biggest cruise port in the Netherlands with more than 150 cruise ships every year.
In 2019 the new lock in IJmuiden will open; the port will then be able to grow to 125 million tonnes in capacity.

The [[Amsterdam Stock Exchange]] (AEX), now part of [[Euronext]], is the world's oldest stock exchange and is one of Europe's largest bourses. It is near [[Dam Square]] in the city centre.

Together with [[Eindhoven]] ([[BrabantStad#Brainport|Brainport]]) and [[Rotterdam]] ([[Port of Rotterdam|Seaport]]), Amsterdam (Airport) forms the foundation of the Dutch economy.

[[File:Wim Sonneveld tour boat, Rederij Lovers, Amsterdam-9218.jpg|thumb|Boats give tours of the city, such as this one in front of the [[EYE Film Institute Netherlands]].]]
[[File:Brug 97 in de Spiegelgracht over de Lijnbaansgracht foto 1.jpg|thumb|Spiegelgracht]]
Amsterdam is one of the most popular tourist destinations in Europe, receiving more than 4.63 million international visitors annually, this is excluding the 16 million day trippers visiting the city every year. The number of visitors has been growing steadily over the past decade. This can be attributed to an increasing number of European visitors. Two-thirds of the hotels are located in the city's centre. Hotels with 4 or 5 stars contribute 42% of the total beds available and 41% of the overnight stays in Amsterdam. The room occupation rate was 78% in 2006, up from 70% in 2005. The majority of tourists (74%) originate from Europe. The largest group of non-European visitors come from the United States, accounting for 14% of the total. Certain years have a theme in Amsterdam to attract extra tourists. For example, the year 2006 was designated "Rembrandt 400", to celebrate the 400th birthday of [[Rembrandt|Rembrandt van Rijn]]. Some hotels offer special arrangements or activities during these years. The average number of guests per year staying at the four campsites around the city range from 12,000 to 65,000.

[[File:Red-light district of Amsterdam by day. 2012.JPG|thumb|left|[[De Wallen]], Amsterdam's [[Red-light district]], offers activities such as legal [[Prostitution in the Netherlands|prostitution]] and a number of [[coffee shops]] that sell [[Cannabis (drug)|cannabis]]. It is one of the main tourist attractions.]]
De Wallen, also known as Walletjes or Rosse Buurt, is a designated area for [[Prostitution in the Netherlands|legalised prostitution]] and is Amsterdam's largest and most well known [[red-light district]]. This neighbourhood has become a famous attraction for tourists. It consists of a network of roads and alleys containing several hundred small, one-room apartments rented by [[sex worker]]s who offer their services from behind a window or glass door, typically illuminated with red lights.

Shops in Amsterdam range from large high end department stores such as [[De Bijenkorf]] founded in 1870 to small specialty shops. Amsterdam's high-end shops are found in the streets [[P.C. Hooftstraat]] and "Cornelis Schuytstraat", which are located in the vicinity of the [[Vondelpark]]. One of Amsterdam's busiest high streets is the narrow, medieval [[Kalverstraat]] in the heart of the city. Other shopping areas include the "Negen Straatjes" and Haarlemmerdijk and Haarlemmerstraat. "Negen Straatjes" are nine narrow streets within the "Grachtengordel", the concentric canal system of Amsterdam. The Negen Straatjes differ from other shopping districts with the presence of a large diversity of privately owned shops. The Haarlemmerstraat and Haarlemmerdijk were voted best shopping street in the Netherlands in 2011. These streets have as the "Negen Straatjes" a large diversity of privately owned shops. But as the "Negen Straatjes" are dominated by fashion stores the Haarlemmerstraat and Haarlemmerdijk offer a very wide variety of all kinds of stores, just to name some specialties: candy and other food related stores, lingerie, sneakers, wedding clothing, interior shops, books, Italian deli's, racing and mountain bikes, skatewear, etc.

The city also features a large number of open-air markets such as the [[Albert Cuyp Market]], Westerstraat-markt, Ten Katemarkt, and [[Dappermarkt]]. Some of these markets are held on a daily basis, like the Albert Cuypmarkt and the Dappermarkt. Others, like the Westerstraatmarkt, are held on a weekly basis.

[[File:AmsterdamBikeGirl.png|thumb|A typically well-attired Amsterdamer waits for a traffic light to change at Muntplein in the heart of Amsterdam.]]
Several fashion brands and designers are based in Amsterdam. Brands include [[G-Star Raw|G-star]], [[10 feet]] and [[Warmenhoven & Venderbos]], and fashion designers include [[Iris van Herpen]], [[Mart Visser]], [[Viktor & Rolf]], [[Marlies Dekkers]] and [[Frans Molenaar]]. [[Modeling agency|Modelling agencies]] [[Elite Model Management|Elite Models]], Touche models and Tony Jones have opened branches in Amsterdam. Fashion models like [[Yfke Sturm]], [[Doutzen Kroes]] and [[Kim Noorda]] started their careers in Amsterdam. Amsterdam has its garment centre in the World Fashion Center. Buildings which formerly housed brothels in the red light district have been converted to ateliers for young fashion designers, AKA eagle fuel. Fashion photographers [[Inez and Vinoodh|Inez van Lamsweerde and Vinoodh Matadin]] were born in Amsterdam.

[[File:Amsterdam rijkmuseum.JPG|thumb|The [[Rijksmuseum]] houses [[Rembrandt]]'s "[[The Night Watch]]".]]
[[File:Van Gogh Museum.jpg|thumb|The [[Van Gogh Museum]] houses the world's largest collection of [[Vincent van Gogh|Van Gogh]]'s paintings and letters.]]
[[File:De nieuwe vleugel van het Stedelijk Museum Amsterdam.jpg|thumb|The [[Stedelijk Museum Amsterdam]] is an international museum dedicated to modern and contemporary art and design.]]
During the later part of the 16th-century Amsterdam's Rederijkerskamer ([[Chamber of rhetoric]]) organised contests between different Chambers in the reading of poetry and drama. In 1637, [[Schouwburg]], the first theatre in Amsterdam was built, opening on January 3, 1638. The first ballet performances in the Netherlands were given in Schouwburg in 1642 with the "Ballet of the Five Senses". In the 18th century, French theatre became popular. While Amsterdam was under the influence of German music in the 19th century there were few national opera productions; the Hollandse Opera of Amsterdam was built in 1888 for the specific purpose of promoting Dutch opera. In the 19th century, popular culture was centred on the Nes area in Amsterdam (mainly [[vaudeville]] and [[music hall|music-hall]]). An improved [[metronome]] was invented in 1812 by [[Dietrich Nikolaus Winkel]]. The [[Rijksmuseum]] (1885) and [[Stedelijk Museum Amsterdam|Stedelijk Museum]] (1895) were built and opened. In 1888, the [[Royal Concertgebouw Orchestra|Concertgebouworkest]] orchestra was established. With the 20th century came cinema, radio and television. Though most studios are located in [[Hilversum]] and [[Aalsmeer]], Amsterdam's influence on programming is very strong. Many people who work in the television industry live in Amsterdam. Also, the headquarters of the Dutch [[SBS 6|SBS Broadcasting Group]] is located in Amsterdam.

The most important museums of Amsterdam are located on the [[Museumplein]] (Museum Square), located at the southwestern side of the Rijksmuseum. It was created in the last quarter of the 19th century on the grounds of the former [[Internationale Koloniale en Uitvoerhandel Tentoonstelling|World's fair]]. The northeastern part of the square is bordered by the very large Rijksmuseum. In front of the Rijksmuseum on the square itself is a long, rectangular pond. This is transformed into an ice rink in winter. The northwestern part of the square is bordered by the Van Gogh Museum, Stedelijk Museum, House of Bols Cocktail & Genever Experience and Coster Diamonds. The southwestern border of the Museum Square is the Van Baerlestraat, which is a major thoroughfare in this part of Amsterdam. The Concertgebouw is situated across this street from the square. To the southeast of the square are situated a number of large houses, one of which contains the American consulate. A [[Multi-storey car park|parking garage]] can be found underneath the square, as well as a supermarket. The Museumplein is covered almost entirely with a lawn, except for the northeastern part of the square which is covered with gravel. The current appearance of the square was realised in 1999, when the square was remodelled. The square itself is the most prominent site in Amsterdam for festivals and outdoor concerts, especially in the summer. Plans were made in 2008 to remodel the square again, because many inhabitants of Amsterdam are not happy with its current appearance.

[[File:Rembrandt.JPG|thumb|left|upright=0.8|[[Rembrandt]] monument on [[Rembrandtplein]].]]
The [[Rijksmuseum]] possesses the largest and most important collection of classical [[Dutch art]].
It opened in 1885. Its collection consists of nearly one million objects. The artist most associated with Amsterdam is [[Rembrandt]], whose work, and the work of his pupils, is displayed in the Rijksmuseum. Rembrandt's masterpiece "[[The Night Watch]]" is one of top pieces of art of the museum. It also houses paintings from artists like [[Bartholomeus van der Helst|Van der Helst]], [[Johannes Vermeer|Vermeer]], [[Frans Hals]], [[Ferdinand Bol]], [[Aelbert Cuyp|Albert Cuyp]], [[Jacob van Ruisdael]] and [[Paulus Potter]]. Aside from paintings, the collection consists of a large variety of [[Decorative arts|decorative art]]. This ranges from [[Delftware]] to giant doll-houses from the 17th century. The architect of the [[Gothic Revival architecture|gothic revival]] building was P.J.H. Cuypers. The museum underwent a 10-year, 375 million euro renovation starting in 2003. The full collection was reopened to the public on 13 April 2013 and the Rijksmuseum has established itself as the most visited museum in Amsterdam with 2.2 million visitors in 2013.

Van Gogh lived in Amsterdam for a short while and there is a [[Van Gogh Museum|museum dedicated to his work]]. The museum is housed in one of the few modern buildings in this area of Amsterdam. The building was designed by [[Gerrit Rietveld]]. This building is where the permanent collection is displayed. A new building was added to the museum in 1999. This building, known as the performance wing, was designed by Japanese architect [[Kisho Kurokawa]]. Its purpose is to house temporary exhibitions of the museum. Some of Van Gogh's most famous paintings, like "[[The Potato Eaters]]" and "[[Sunflowers (series of paintings)|Sunflowers]]", are in the collection. The Van Gogh museum is the second most visited museum in Amsterdam, with 1.4 million annual visitors.

Next to the Van Gogh museum stands the [[Stedelijk Museum Amsterdam|Stedelijk Museum]]. This is Amsterdam's most important museum of modern art. The museum is as old as the square it borders and was opened in 1895. The permanent collection consists of works of art from artists like [[Piet Mondrian|Piet Mondriaan]], [[Karel Appel]], and [[Kazimir Malevich]]. After renovations lasting several years the museum opened in September 2012 with a new composite extension that has been called 'The Bathtub' due to its resemblance to one.

Amsterdam contains many other museums throughout the city. They range from small museums such as the [[Verzetsmuseum]] (Resistance Museum), the [[Anne Frank House]], and the [[Rembrandt House Museum]], to the very large, like the [[Tropenmuseum]] (Museum of the Tropics), [[Amsterdam Museum]] (formerly known as Amsterdam Historical Museum), [[Hermitage Amsterdam]] (a dependency of the [[Hermitage Museum]] in Saint Petersburg) and the [[Joods Historisch Museum]] (Jewish Historical Museum). The modern-styled [[NEMO (museum)|Nemo]] is dedicated to child-friendly science exhibitions.

[[File:Coldplay perform "Adventure of a Lifetime", Amsterdam Arena, June 2016 (5).jpg|thumb|[[Coldplay]] performing at the [[Johan Cruyff Arena|Amsterdam Arena]], 2016.]]
Amsterdam's musical culture includes a large collection of songs which treat the city nostalgically and lovingly. The 1949 song "Aan de Amsterdamse grachten" ("On the canals of Amsterdam") was performed and recorded by many artists, including [[John Kraaijkamp Sr.]]; the best-known version is probably that by [[Wim Sonneveld]] (1962). In the 1950s [[Johnny Jordaan]] rose to fame with "Geef mij maar Amsterdam" ("I prefer Amsterdam"), which praises the city above all others (explicitly Paris); Jordaan sang especially about his own neighbourhood, the [[Jordaan]] ("Bij ons in de Jordaan"). Colleagues and contemporaries of Johnny include [[Tante Leen]] and [[Manke Nelis]]. Other notable Amsterdam songs are "[[Amsterdam (Jacques Brel song)|Amsterdam]]" by [[Jacques Brel]] (1964) and "Deze Stad" by [[De Dijk]] (1989). A 2011 poll by Amsterdam newspaper "[[Het Parool]]" that Trio Bier's "Oude Wolf" was voted "Amsterdams lijflied". Notable Amsterdam bands from the modern era include the [[Osdorp Posse]] and [[The Ex (band)|The Ex]].

[[AFAS Live]] (formerly known as the Heineken Music Hall) is a concert hall located near the [[Johan Cruyff Arena]] (known as the Amsterdam Arena until 2018). Its main purpose is to serve as a podium for pop concerts for big audiences. Many famous international artists have performed there. Two other notable venues, [[Paradiso (Amsterdam)|Paradiso]] and the [[Melkweg]] are located near the [[Leidseplein]]. Both focus on broad programming, ranging from [[indie rock]] to [[hip hop music|hip hop]], [[Rhythm and blues|R&B]], and other popular genres. Other more subcultural music venues are [[OCCII]], [[OT301]], De Nieuwe Anita, Winston Kingdom and Zaal 100. [[Jazz]] has a strong following in Amsterdam, with the [[Bimhuis]] being the premier venue. In 2012, [[Ziggo Dome]] was opened, also near Amsterdam Arena, a state-of-the-art indoor music arena.

[[AFAS Live]] is also host to many [[electronic dance music]] festivals, alongside many other venues. [[Armin van Buuren]] and [[Tiesto]], some of the world's leading [[Trance music|Trance]] DJ's hail from the Netherlands and perform frequently in Amsterdam. Each year in October, the city hosts the Amsterdam Dance Event (ADE) which is one of the leading electronic music conferences and one of the biggest club festivals for electronic music in the world, attracting over 350,000 visitors each year. Another popular dance festival is 5daysoff, which takes place in the venues [[Paradiso (Amsterdam)|Paradiso]] and [[Melkweg]]. In summer time there are several big outdoor dance parties in or nearby Amsterdam, such as Awakenings, [[Dance Valley]], [[Mysteryland|Mystery Land]], Loveland, A Day at the Park, Welcome to the Future, and Valtifest.

[[File:Amsterdam Concertgebouw.jpg|thumb|The [[Concertgebouw]] or Royal Concert Hall houses performances of the [[Royal Concertgebouw Orchestra]] and other musical events.]]
Amsterdam has a world-class symphony orchestra, the [[Royal Concertgebouw Orchestra]]. Their home is the [[Concertgebouw]], which is across the Van Baerlestraat from the Museum Square. It is considered by critics to be a [[List of concert halls|concert hall]] with some of the best [[acoustics]] in the world. The building contains three halls, Grote Zaal, Kleine Zaal, and Spiegelzaal. Some nine hundred concerts and other events per year take place in the Concertgebouw, for a public of over 700,000, making it one of the most-visited concert halls in the world. The opera house of Amsterdam is situated adjacent to the city hall. Therefore, the two buildings combined are often called the [[Stopera]], (a word originally coined by protesters against it very construction: "Stop the Opera[-house]"). This huge modern complex, opened in 1986, lies in the former Jewish neighbourhood at "Waterlooplein" next to the river [[Amstel]]. The "Stopera" is the homebase of [[Dutch National Opera]], [[Dutch National Ballet]] and the [[Holland Symfonia]]. [[Muziekgebouw aan 't IJ]] is a concert hall, which is situated in the [[IJ (Amsterdam)|IJ]] near the central station. Its concerts perform mostly [[20th-century classical music|modern classical music]]. Located adjacent to it, is the "[[Bimhuis]]", a concert hall for improvised and [[Jazz]] music.

[[File:Stadsschouwburg amsterdam.jpg|thumb|[[Stadsschouwburg]], Amsterdam's best known theatre.]]
Amsterdam has three main theatre buildings.

The [[Stadsschouwburg]] at the [[Leidseplein]] is the home base of [[Toneelgroep Amsterdam]]. The current building dates from 1894. Most plays are performed in the Grote Zaal (Great Hall). The normal programme of events encompasses all sorts of theatrical forms. The Stadsschouwburg is currently being renovated and expanded. The third theatre space, to be operated jointly with next door [[Melkweg]], will open in late 2009 or early 2010.

The [[Stopera|Dutch National Opera and Ballet]] (formerly known as "Het Muziektheater"), dating from 1986, is the principal opera house and home to [[Dutch National Opera]] and [[Dutch National Ballet]]. [[Carré Theatre|Royal Theatre Carré]] was built as a permanent circus theatre in 1887 and is currently mainly used for musicals, [[cabaret]] performances and pop concerts.

The recently re-opened DeLaMar Theater houses the more commercial plays and musicals. A new theatre has also moved into Amsterdam scene in 2014, joining other established venues: Theater Amsterdam is situated in the west part of Amsterdam, on the Danzigerkade. It is housed in a modern building with a panoramic view over the harbour. The theatre is the first ever purpose-built venue to showcase a single play entitled ANNE, the play based on Anne Frank's life.

On the east side of town there is a small theatre in a converted bath house, the [[Badhuistheater]]. The theatre often has English programming.

The Netherlands has a tradition of cabaret or "kleinkunst", which combines music, storytelling, commentary, theatre and comedy. Cabaret dates back to the 1930s and artists like [[Wim Kan]], [[Wim Sonneveld]] and [[Toon Hermans]] were pioneers of this form of art in the Netherlands. In Amsterdam is the Kleinkunstacademie (English: Cabaret Academy). Contemporary popular artists are [[Youp van 't Hek]], [[Freek de Jonge]], [[Herman Finkers]], [[Hans Teeuwen]], [[Theo Maassen]], [[Herman van Veen]], [[Najib Amhali]], [[Raoul Heertje]], [[Jörgen Raymann]], [[Brigitte Kaandorp]] and [[Comedytrain]]. The English spoken comedy scene was established with the founding of [[Boom Chicago]] in 1993. They have their own theatre at Leidseplein.

Amsterdam is famous for its vibrant and diverse nightlife. Amsterdam has many "[[bar (establishment)|cafés]]" (bars). They range from large and modern to small and cozy. The typical "Bruine Kroeg" (brown "café") breathe a more old fashioned atmosphere with dimmed lights, candles, and somewhat older clientele. Most "cafés" have terraces in summertime. A common sight on the Leidseplein during summer is a square full of terraces packed with people drinking beer or wine. Many restaurants can be found in Amsterdam as well. Since Amsterdam is a multicultural city, a lot of different ethnic restaurants can be found. Restaurants range from being rather luxurious and expensive to being ordinary and affordable. Amsterdam also possesses many [[discothèque]]s. The two main nightlife areas for tourists are the [[Leidseplein]] and the [[Rembrandtplein]]. The [[Paradiso (Amsterdam)|Paradiso]], [[Melkweg]] and Sugar Factory are cultural centres, which turn into discothèques on some nights. Examples of discothèques near the Rembrandtplein are the Escape, Air, John Doe and Club Abe. Also noteworthy are Panama, Hotel Arena (East), TrouwAmsterdam and Studio 80. [[Bimhuis]] located near the Central Station, with its rich programming hosting the best in the field is considered one of the best jazz clubs in the world. The Reguliersdwarsstraat is the main street for the [[LGBT]] community and nightlife.

In 2008, there were 140 festivals and events in Amsterdam.

Famous festivals and events in Amsterdam include: "[[Koningsdag]]" (which was named "Koninginnedag" until the crowning of King Willem-Alexander in 2013) (King's Day – Queen's Day); the [[Holland Festival]] for the performing arts; the yearly [[Prinsengrachtconcert]] (classical concerto on the Prinsen canal) in August; the '[[Stille Omgang]]' (a silent Roman Catholic evening procession held every March); [[Amsterdam Gay Pride]]; The [[Cannabis Cup]]; and the [[Uitmarkt]]. On Koninginnedag—that was held each year on 30 April—hundreds of thousands of people travel to Amsterdam to celebrate with the city's residents and Koningsdag is held on 27 April. The entire city becomes overcrowded with people buying products from the "freemarket," or visiting one of the many music concerts.

[[File:Amsterdam Gay Pride 2013 boat no37 Hot Spot Cafe pic7.JPG|thumb|left|One of the decorated boats participating in the 2013 Canal Parade of the [[Amsterdam Gay Pride]].]]
The yearly Holland Festival attracts international artists and visitors from all over Europe. [[Amsterdam Gay Pride]] is a yearly local LGBT parade of boats in Amsterdam's canals, held on the first Saturday in August. The annual Uitmarkt is a three-day cultural event at the start of the cultural season in late August. It offers previews of many different artists, such as musicians and poets, who perform on [[Podium|podia]].

Amsterdam is home of the "[[Eredivisie]]" football club [[AFC Ajax]]. The stadium [[Johan Cruyff Arena]] is the home of Ajax. It is located in the [[Amsterdam Zuidoost|south-east]] of the city next to the new [[Amsterdam Bijlmer ArenA railway station]]. Before moving to their current location in 1996, Ajax played their regular matches in [[De Meer Stadion]].
In 1928, Amsterdam hosted the [[1928 Summer Olympics|Summer Olympics]]. The [[Olympic Stadium (Amsterdam)|Olympic Stadium]] built for the occasion has been completely restored and is now used for cultural and sporting events, such as the [[Amsterdam Marathon]]. In 1920, Amsterdam assisted in hosting some of the [[Sailing at the 1920 Summer Olympics|sailing]] events for the [[1920 Summer Olympics|Summer Olympics]] held in neighbouring [[Antwerp]], Belgium by hosting events at [[IJ (Amsterdam)|Buiten Y]].
[[File:Feyenoord tegen Ajax 1-0. Nummer 26 Israel in duel met Cruyff.jpg|thumb|[[AFC Ajax]] player [[Johan Cruyff]], 1967.]]
The city holds the [[Dam tot Damloop|Dam to Dam Run]], a race from Amsterdam to [[Zaandam]], as well as the [[Amsterdam Marathon]]. The ice hockey team [[Amstel Tijgers]] play in the [[Jaap Eden]] ice rink. The team competes in the Dutch ice hockey premier league. [[Long track speed skating|Speed skating]] championships have been held on the 400-metre lane of this ice rink.

Amsterdam holds two [[American football]] franchises: the [[Amsterdam Crusaders]] and the Amsterdam Panthers. The [[Amsterdam Pirates]] baseball team competes in the [[Honkbal Hoofdklasse|Dutch Major League]]. There are three [[field hockey]] teams: Amsterdam, Pinoké and Hurley, who play their matches around the [[Wagener Stadium]] in the nearby city of [[Amstelveen]]. The basketball team [[MyGuide Amsterdam]] competes in the Dutch premier division and play their games in the Sporthallen Zuid.

There is one rugbyclub in Amsterdam, which also hosts sports training classes such as RTC (Rugby Talenten Centrum or Rugby Talent Centre) and the National Rugby stadium.

Since 1999 the city of Amsterdam honours the best sportsmen and women at the [[Amsterdam Sportsman of the year|Amsterdam Sports Awards]]. Boxer [[Raymond Joval]] and field hockey midfielder [[Carole Thate]] were the first to receive the awards, in 1999.

[[File:Femke Halsema-roel.jpg|thumb|upright=0.9|[[Femke Halsema]] has been [[Burgemeester|Mayor]] of Amsterdam since 2018.]] 
The city of Amsterdam is a [[List of municipalities of the Netherlands|municipality]] under the Dutch Municipalities Act. It is governed by a directly elected [[Municipal council (Netherlands)|municipal council]], a [[College van burgemeester en wethouders|municipal executive board]] and a [[Burgemeester|mayor]]. Since 1981, the [[List of municipalities of the Netherlands|municipality]] of Amsterdam has gradually been divided into semi-autonomous [[Boroughs of Amsterdam|boroughs]], called "stadsdelen" or 'districts'. Over time, a total of 15 boroughs were created. In May 2010, under a major reform, the number of [[Boroughs of Amsterdam|Amsterdam boroughs]] was reduced to eight: [[Amsterdam-Centrum]] covering the city centre including the [[Canals of Amsterdam|canal belt]], [[Amsterdam-Noord]] consisting of the neighbourhoods north of the [[IJ (Amsterdam)|IJ lake]], [[Amsterdam-Oost]] in the east, [[Amsterdam-Zuid]] in the south, [[Amsterdam-West]] in the west, [[Amsterdam Nieuw-West]] in the far west, [[Amsterdam Zuidoost]] in the southeast, and [[Westpoort (Amsterdam)|Westpoort]] covering the [[Port of Amsterdam]] area.

As with all Dutch municipalities, Amsterdam is governed by a directly elected [[Municipal council (Netherlands)|municipal council]], a [[College van burgemeester en wethouders|municipal executive board]] and a [[Burgemeester|mayor]] ("burgemeester"). The mayor is a member of the municipal executive board, but also has individual responsibilies in maintaining public order. On 27 June 2018 [[Femke Halsema]] (former member of [[House of Representatives (Netherlands)|House of Representatives]] for [[GroenLinks]] from 1998 to 2011) was appointed as the first women to be [[List of mayors of Amsterdam|Mayor of Amsterdam]] by the [[King's Commissioner]] of [[North Holland]] for a six-year term after being nominated by the Amsterdam [[Municipal council (Netherlands)|municipal council]]. and began serving a six-year term on 12 July 2018. She replaces [[Eberhard van der Laan]] ([[Labour Party (Netherlands)|Labour Party]]) who was the Mayor of Amsterdam from 2010 until his death in October 2017. After the [[Dutch municipal elections, 2014|2014 municipal council elections]], a governing majority of [[Democrats 66|D66]], [[People's Party for Freedom and Democracy|VVD]] and [[Socialist Party (Netherlands)|SP]] was formed – the first coalition without the [[Labour Party (Netherlands)|Labour Party]] since [[World War II]]. Next to the [[Burgemeester|Mayor]], the [[College van burgemeester en wethouders|municipal executive board]] consists of eight "wethouders" ('alderpersons') appointed by the [[Municipal council (Netherlands)|municipal council]]: four [[Democrats 66|D66]] alderpersons, two [[People's Party for Freedom and Democracy|VVD]] alderpersons and two [[Socialist Party (Netherlands)|SP]] alderpersons.

On 18 September 2017 it was announced by [[Eberhard van der Laan]] in an open letter to Amsterdam citizens that [[Kajsa Ollongren]] would take up his office as acting Mayor of Amsterdam with immediate effect due to ill health. Ollongren was succeeded as acting Mayor by Eric van der Burg on 26 October 2017 and by [[Jozias van Aartsen]] on 4 December 2017.

[[File:Amsterdamse stadsdelen 2010.png|thumb|upright=1.15|[[Boroughs of Amsterdam]]]]
Unlike most other Dutch municipalities, Amsterdam is subdivided into eight [[Boroughs of Amsterdam|boroughs]], called "stadsdelen" or 'districts', a system that was implemented gradually in the 1980s to improve local governance. The [[Boroughs of Amsterdam|boroughs]] are responsible for many activities that had previously been run by the central city. In 2010, the number of [[Boroughs of Amsterdam|Amsterdam boroughs]] reached fifteen. Fourteen of those had their own district council ("deelraad"), elected by a popular vote. The fifteenth, [[Westpoort]], covers the harbour of Amsterdam and had very few residents. Therefore, it was governed by the central municipal council.

Under the borough system, municipal decisions are made at borough level, except for those affairs pertaining to the whole city such as major infrastructure projects, which are the jurisdiction of the central municipal authorities. In 2010, the [[Boroughs of Amsterdam|borough]] system was restructured, in which many smaller boroughs merged into larger boroughs. In 2014, under a reform of the Dutch Municipalities Act, the [[Boroughs of Amsterdam|Amsterdam boroughs]] lost much of their autonomous status, as their district councils were abolished.

The municipal council of Amsterdam voted to maintain the borough system by replacing the district councils with smaller, but still directly elected district committees ("bestuurscommissies"). Under a municipal ordinance, the new district committees were granted responsibilities through delegation of regulatory and executive powers by the central municipal council.
[[File:Amsterdam Amstel.jpg|thumb|800px|center|View of the [[Stopera]] (left, behind the [[Blauwbrug|blue bridge]]), where the Amsterdam city hall and opera house are located, and the [[Hermitage Amsterdam|Hermitage Museum]] (right) on the [[Amstel]].]]

[[File:Police Headquarters, Amsterdam.jpg|thumb|Police Headquarters of Amsterdam.]]
"Amsterdam" is usually understood to refer to the [[List of municipalities of the Netherlands|municipality]] of Amsterdam. Colloquially, some areas within the municipality, such as the town of [[Durgerdam]], may not be considered part of Amsterdam.

[[Statistics Netherlands]] uses three other definitions of Amsterdam: metropolitan agglomeration Amsterdam ("Grootstedelijke Agglomeratie Amsterdam", not to be confused with "Grootstedelijk Gebied Amsterdam", a synonym of "Groot Amsterdam"), Greater Amsterdam ("Groot Amsterdam", a [[COROP]] region) and the urban region Amsterdam ("Stadsgewest Amsterdam"). The Amsterdam Department for Research and Statistics uses a fourth conurbation, namely the "Stadsregio Amsterdam" ('City Region of Amsterdam'). The city region is similar to Greater Amsterdam but includes the municipalities of [[Zaanstad]] and [[Wormerland]]. It excludes [[Graft-De Rijp]].

The smallest of these areas is the [[List of municipalities of the Netherlands|municipality]] of Amsterdam with a population of 802,938 in 2013. The conurbation had a population of 1,096,042 in 2013. It includes the municipalities of Zaanstad, Wormerland, Oostzaan, Diemen and Amstelveen only, as well as the municipality of Amsterdam. Greater Amsterdam includes 15 municipalities, and had a population of 1,293,208 in 2013. Though much larger in area, the population of this area is only slightly larger, because the definition excludes the relatively populous municipality of [[Zaanstad]]. The largest area by population, the [[Amsterdam Metropolitan Area]] (Dutch: Metropoolregio Amsterdam), has a population of 2,33 million. It includes for instance Zaanstad, Wormerveer, Muiden, Abcoude, Haarlem, Almere and Lelystad but excludes Graft-De Rijp. Amsterdam is part of the conglomerate metropolitan area [[Randstad]], with a total population of 6,659,300 inhabitants.

Of these various metropolitan area configurations, only the "Stadsregio Amsterdam" (City Region of Amsterdam) has a formal governmental status. Its responsibities include regional spatial planning and the metropolitan public transport concessions.

[[File:King Willem-Alexander, Princess Beatrix en Queen Maxima.jpg|thumb|[[Willem-Alexander of the Netherlands|King Willem-Alexander]], [[Beatrix of the Netherlands|Princess Beatrix]], and [[Queen Máxima of the Netherlands|Queen Máxima]] greeting Amsterdammers from the [[Royal Palace of Amsterdam]] during Willem-Alexanders inauguration in 2013.]]
Under the [[Constitution of the Netherlands|Dutch Constitution]], Amsterdam is the [[capital of the Netherlands]]. Since the 1983 constitutional revision, the constitution mentions "Amsterdam" and "capital" in chapter 2, article 32: The king's confirmation by oath and his coronation take place in "the capital Amsterdam" (""de hoofdstad Amsterdam""). Previous versions of the constitution only mentioned "the city of Amsterdam" (""de stad Amsterdam""). For a royal investiture, therefore, the [[States General of the Netherlands]] (the Dutch Parliament) meets for a ceremonial joint session in Amsterdam. The ceremony traditionally takes place at the [[Nieuwe Kerk (Amsterdam)|Nieuwe Kerk]] on [[Dam Square]], immediately after the former monarch has signed the act of abdication at the nearby [[Royal Palace of Amsterdam]]. Normally, however, the Parliament sits in [[The Hague]], the city which has historically been the seat of the [[Politics of the Netherlands|Dutch government]], the [[Monarchy of the Netherlands|Dutch monarchy]], and the [[Supreme Court of the Netherlands|Dutch supreme court]]. Foreign embassies are also located in The Hague.

The coat of arms of Amsterdam is composed of several historical elements. First and centre are three [[Saltire|St Andrew's crosses]], aligned in a vertical band on the city's shield (although Amsterdam's [[patron saint]] was [[Saint Nicholas]]). These St Andrew's crosses can also be found on the cityshields of neighbours [[Amstelveen]] and [[Ouder-Amstel]]. This part of the coat of arms is the basis of the [[flag of Amsterdam]], flown by the city government, but also as [[civil ensign]] for ships registered in Amsterdam. Second is the [[Imperial Crown of Austria]]. In 1489, out of gratitude for services and loans, [[Maximilian I, Holy Roman Emperor|Maximilian I]] awarded Amsterdam the right to adorn its coat of arms with the [[King of the Romans|king's]] crown. Then, in 1508, this was replaced with Maximilian's [[imperial crown]] when he was crowned [[Holy Roman Emperor]]. In the early years of the 17th century, Maximilian's crown in Amsterdam's coat of arms was again replaced, this time with the crown of [[Rudolf II, Holy Roman Emperor|Emperor Rudolph II]], a crown that became the Imperial [[Austrian Crown Jewels|Crown of Austria]]. The lions date from the late 16th century, when city and province became part of the [[Dutch Republic|Republic of the Seven United Netherlands]]. Last came the city's official motto: "Heldhaftig, Vastberaden, Barmhartig" ("Heroic, Determined, Merciful"), bestowed on the city in 1947 by [[Wilhelmina of the Netherlands|Queen Wilhelmina]], in recognition of the city's bravery during the Second World War.

[[File:Amsterdam - Keizersgracht - 1316.jpg|thumb|A tram crossing the Keizersgracht.]]
[[File:NoordZuidLijn Metrostation Europaplein hnapel 004.jpg|thumb|The [[Amsterdam Metro]] is a mixed subway and above ground [[Rapid Transit|rapid transit system]] consisting of five lines.]]
Currently, there are sixteen [[Trams in Amsterdam|tram routes]] and five [[Amsterdam Metro|metro routes]]. All are operated by municipal public transport operator [[Gemeentelijk Vervoerbedrijf]] (GVB), which also runs the city bus network.

Four fare-free GVB ferries carry pedestrians and cyclists across the [[IJ (Amsterdam)|IJ lake]] to the [[Boroughs of Amsterdam|borough]] of [[Amsterdam-Noord]], and two fare-charging ferries run east and west along the harbour. There are also privately operated water taxis, a water bus, a [[boat sharing]] operation, electric rental boats and canal cruises, that transport people along Amsterdam's waterways.

Regional buses, and some suburban buses, are operated by [[Connexxion]] and [[Egged (company)|EBS]]. International coach services are provided by [[Eurolines]] from [[Amsterdam Amstel railway station]], [[IDBUS]] from [[Amsterdam Sloterdijk railway station]], and [[Megabus (Europe)|Megabus]] from the Zuiderzeeweg in the east of the city.

In order to facilitate easier transport to the center of Amsterdam, the city has various P+R Locations where people can park their car at an affordable price and transfer to one of the numerous public transport lines.

Amsterdam was intended in 1932 to be the hub, a kind of [[Kilometre Zero]], of the [[List of motorways in the Netherlands|highway system of the Netherlands]], with freeways numbered One to Eight planned to originate from the city. The outbreak of the Second World War and shifting priorities led to the current situation, where only roads [[A1 motorway (Netherlands)|A1]], [[A2 motorway (Netherlands)|A2]], and [[A4 motorway (Netherlands)|A4]] originate from Amsterdam according to the original plan. The [[A3 motorway (Netherlands)|A3]] to [[Rotterdam]] was cancelled in 1970 in order to conserve the [[Groene Hart]]. Road [[A8 motorway (Netherlands)|A8]], leading north to [[Zaandam]] and the [[A10 motorway (Netherlands)|A10]] [[Beltway|Ringroad]] were opened between 1968 and 1974. Besides the A1, A2, A4 and A8, several freeways, such as the [[A7 motorway (Netherlands)|A7]] and [[A6 motorway (Netherlands)|A6]], carry traffic mainly bound for Amsterdam.

The [[A10 motorway (Netherlands)|A10 ringroad]] surrounding the city connects Amsterdam with the Dutch [[List of motorways in the Netherlands|national network of freeways]]. [[Interchange (road)|Interchanges]] on the A10 allow cars to enter the city by transferring to one of the 18 "city roads", numbered S101 through to S118. These city roads are regional roads without [[grade separation]], and sometimes without a [[central reservation]]. Most are accessible by cyclists. The S100 "Centrumring" is a smaller ringroad circumnavigating the city's centre.

In the city centre, driving a car is discouraged. Parking fees are expensive, and many streets are closed to cars or are [[One-way traffic|one-way]]. The local government sponsors [[carsharing]] and [[carpool]]ing initiatives such as "Autodelen" and "Meerijden.nu".

[[File:Amsterdam Central Station1.jpg|thumb|upright=1.15|[[Amsterdam Centraal station]], the city's main train station.]]
Amsterdam is served by ten [[Railway stations in the Netherlands#A|stations]] of the [[Nederlandse Spoorwegen]] (Dutch Railways). Five are intercity stops: [[Sloterdijk (Amsterdam)|Sloterdijk]], [[Amsterdam Zuid railway station|Zuid]], [[Amsterdam Amstel railway station|Amstel]], [[Amsterdam Bijlmer ArenA railway station|Bijlmer ArenA]] and [[Amsterdam Centraal railway station|Amsterdam Centraal]]. The stations for local services are: [[Amsterdam Lelylaan railway station|Lelylaan]], [[Amsterdam RAI railway station|RAI]], [[Amsterdam Holendrecht railway station|Holendrecht]], [[Amsterdam Muiderpoort railway station|Muiderpoort]] and [[Amsterdam Science Park railway station|Science Park]]. [[Amsterdam Centraal railway station|Amsterdam Centraal]] is also an international railway station. From the station there are regular services to destinations such as Austria, Belarus, Belgium, the Czech Republic, Denmark, France, Germany, Hungary, Poland, Russia, Switzerland and the United Kingdom. Among these trains are international trains of the [[Nederlandse Spoorwegen]] (Amsterdam-Berlin), the [[Eurostar]] (Amsterdam-Brussels-London), [[Thalys]] (Amsterdam-Brussels-Paris/Lille), and [[Intercity-Express|InterCityExpress]] (Amsterdam–Cologne–Frankfurt).

[[File:Schiphol Airport Pier D (7325966610).jpg|thumb|left|[[Amsterdam Airport Schiphol]] ranks as Europe's third-busiest airport for passenger traffic.]]
[[Amsterdam Airport Schiphol]] is less than 20 minutes by train from [[Amsterdam Centraal station]] and is served by domestic and international intercity trains, such as [[Thalys]], [[Eurostar]] and Intercity Brussel. Schiphol is the largest airport in the Netherlands, the third largest in Europe, and the 14th-largest in the world in terms of passengers. It handles over 68 million passengers per year and is the home base of four airlines, [[KLM]], [[Transavia]], [[Martinair]] and [[Arkefly]]. , Schiphol was the fifth [[World's busiest airports by international passenger traffic|busiest airport in the world]] measured by international passenger numbers. This airport is 4 meters below sea level.

[[File:Amsterdam - Bicycles - 1058.jpg|thumb|Police bicyclist crossing a bridge over the Prinsengracht.]]
Amsterdam is one of the most bicycle-friendly large cities in the world and is a centre of [[bicycle culture]] with good facilities for cyclists such as bike paths and [[Bicycle stand|bike racks]], and several guarded bike storage garages ("fietsenstalling") which can be used.

In 2013, there were about 1,200,000 bicycles in Amsterdam outnumbering the amount of citizens in the city. Theft is widespreadin 2011, about 83,000 bicycles were stolen in Amsterdam. Bicycles are used by all socio-economic groups because of their convenience, Amsterdam's small size, the of bike paths, the flat terrain, and the inconvenience of driving an automobile.

[[File:Agnietenkapel Gate.jpg|thumb|left|The Agnietenkapel Gate at the [[University of Amsterdam]], founded in 1632 as the Athenaeum Illustre.]]
Amsterdam has two universities: the [[University of Amsterdam]] ("Universiteit van Amsterdam", UvA), and the "[[Vrije Universiteit Amsterdam]]" (VU). Other institutions for higher education include an [[art school]] – [[Gerrit Rietveld Academie]], a [[Hogeschool|university of applied sciences]] – the [[Hogeschool van Amsterdam]], and the [[Amsterdamse Hogeschool voor de Kunsten]]. Amsterdam's [[International Institute of Social History]] is one of the world's largest documentary and research institutions concerning [[social history]], and especially the [[labor history (discipline)|history of the labour movement]]. Amsterdam's [[Hortus Botanicus (Amsterdam)|Hortus Botanicus]], founded in the early 17th century, is one of the oldest botanical gardens in the world, with many old and rare specimens, among them the [[coffee|coffee plant]] that served as the parent for the entire [[coffee culture]] in Central and South America.

There are over 200 primary schools in Amsterdam. Some of these primary schools base their teachings on particular pedagogic theories like the various [[Maria Montessori|Montessori]] schools. The biggest Montessori high school in Amsterdam is the [[Montessori Lyceum Amsterdam]]. Many schools, however, are based on religion. This used to be primarily Roman Catholicism and various Protestant denominations, but with the influx of Muslim immigrants there has been a rise in the number of Islamic schools. Jewish schools can be found in the southern suburbs of Amsterdam.

Amsterdam is noted for having five independent grammar schools (Dutch: gymnasia), the [[Vossius Gymnasium]], [[Barlaeus Gymnasium]], St. [[Ignatius Gymnasium]], [[Het 4e Gymnasium]] and the Cygnus Gymnasium where a classical curriculum including [[Latin]] and [[Ancient Greek|classical Greek]] is taught. Though believed until recently by many to be an anachronistic and elitist concept that would soon die out, the gymnasia have recently experienced a revival, leading to the formation of a fourth and fifth grammar school in which the three aforementioned schools participate. Most secondary schools in Amsterdam offer a variety of different levels of education in the same school. The city also has various colleges ranging from art and design to politics and economics which are mostly also available for students coming from other countries.

Schools for foreign nationals in Amsterdam include the [[Amsterdam International Community School]], [[British School of Amsterdam]], [[Albert Einstein International School Amsterdam]], [[Lycée Vincent van Gogh La Haye-Amsterdam]] primary campus (French school), [[International School of Amsterdam]], and the [[Japanese School of Amsterdam]].

Amsterdam is a prominent centre for national and international media. Some locally based newspapers include "[[Het Parool]]", a national daily paper; "[[De Telegraaf]]", the largest Dutch daily newspaper; the daily newspapers "[[Trouw]]", "[[de Volkskrant]]" and "[[NRC Handelsblad]]"; "[[De Groene Amsterdammer]]", a weekly newspaper; the free newspapers "[[Sp!ts]]", "[[Metro (Dutch newspaper)|Metro]]", and "[[The Holland Times]]" (printed in English).

Amsterdam is home to the second-largest Dutch commercial TV group [[SBS Broadcasting Group]], consisting of TV-stations [[SBS 6]], [[Net 5]] and [[Veronica (TV channel)|Veronica]]. However, Amsterdam is not considered 'the media city of the Netherlands'. The town of [[Hilversum]], south-east of Amsterdam, has been crowned with this unofficial title. Hilversum is the principal centre for radio and television broadcasting in the Netherlands. [[Radio Netherlands Worldwide|Radio Netherlands]], heard worldwide via shortwave radio since the 1920s, is also based there. Hilversum is home to an extensive complex of audio and television studios belonging to the national broadcast production company NOS, as well as to the studios and offices of all the Dutch public broadcasting organisations and many commercial TV production companies.

In 2012, the music video of Far East Movement, 'Live My Life', was filmed in various parts of Amsterdam.

Also, several movies were filmed in Amsterdam, such as [[James Bond]]'s [[Diamonds Are Forever (film)|Diamonds Are Forever]], [[Ocean's Twelve]], [[Girl with a Pearl Earring (film)|Girl with a Pearl Earring]] and [[The Hitman's Bodyguard]]. Amsterdam is also featured in [[John Green (author)|John Green]]'s book "[[The Fault in Our Stars]]", which has been made into [[The Fault in Our Stars (film)|a film]] as well that partly takes place in Amsterdam.

The housing market is heavily regulated. In Amsterdam, 55% of existing housing and 30% of new housing is owned by Housing Associations, which are Government sponsored entities.

[[Squatting|Squat]] properties are common throughout Amsterdam, due to property law strongly favouring tenants. A number of these squats have become well known, such as [[OT301]], [[Paradiso (Amsterdam)|Paradiso]], Vrankrijk (closed down by city government), and the Binnenpret, and several are now businesses, such as health clubs and licensed restaurants.





[[Category:Amsterdam| ]]
[[Category:Capitals in Europe]]
[[Category:Cities in the Netherlands]]
[[Category:Municipalities of North Holland]]
[[Category:Olympic cycling venues]]
[[Category:Populated places established in the 13th century]]
[[Category:Populated places in North Holland]]
[[Category:Port cities and towns in the Netherlands]]
[[Category:Port cities and towns of the North Sea]]
[[Category:Venues of the 1928 Summer Olympics]]
The Museum of Work, or "Arbetets museum", as it is in Swedish, is a museum located in Norrköping, Sweden. The museum can be found in the 20th century building "The Iron" in the Motala ström river in central Norrköping.



Category:Museums in Östergötland County
Category:Norrköping
Category:Industry museums in Sweden
Category:Cultural heritage of SwedenAudi

Audi AG () is a German automobile manufacturer that designs, engineers, produces, markets and distributes luxury vehicles. Audi is a member of the Volkswagen Group and has its roots at Ingolstadt, Bavaria, Germany. Audi-branded vehicles are produced in nine production facilities worldwide.

The origins of the company are complex, going back to the early 20th century and the initial enterprises (Horch and the "Audiwerke") founded by engineer August Horch; and two other manufacturers (DKW and Wanderer), leading to the foundation of Auto Union in 1932. The modern era of Audi essentially began in the 1960s when Auto Union was acquired by Volkswagen from Daimler-Benz. After relaunching the Audi brand with the 1965 introduction of the Audi F103 series, Volkswagen merged Auto Union with NSU Motorenwerke in 1969, thus creating the present day form of the company.

The company name is based on the Latin translation of the surname of the founder, August Horch. "Horch", meaning "listen" in German, becomes "audi" in Latin. The four rings of the Audi logo each represent one of four car companies that banded together to create Audi's predecessor company, Auto Union. Audi's slogan is "Vorsprung durch Technik", meaning "Being Ahead through Technology". However, Audi USA had used the slogan "Truth in Engineering" from 2007 to 2016, and have not used the slogan since 2016. Audi, along with fellow German marques BMW and Mercedes-Benz, is among the best-selling luxury automobile brands in the world.

Automobile company Wanderer was originally established in 1885, later becoming a branch of Audi AG. Another company, NSU, which also later merged into Audi, was founded during this time, and later supplied the chassis for Gottlieb Daimler's four-wheeler.

On 14 November 1899, August Horch (1868–1951) established the company A. Horch & Cie. in the Ehrenfeld district of Cologne. In 1902, he moved with his company to Reichenbach im Vogtland. On 10 May 1904, he founded the August Horch & Cie. Motorwagenwerke AG, a joint-stock company in Zwickau (State of Saxony).

After troubles with Horch chief financial officer, August Horch left Motorwagenwerke and founded in Zwickau on 16 July 1909, his second company, the August Horch Automobilwerke GmbH. His former partners sued him for trademark infringement. The German Reichsgericht (Supreme Court) in Leipzig
Since August Horch was prohibited from using "Horch" as a trade name in his new car business, he called a meeting with close business friends, Paul and Franz Fikentscher from Zwickau. At the apartment of Franz Fikentscher, they discussed how to come up with a new name for the company. During this meeting, Franz's son was quietly studying Latin in a corner of the room. Several times he looked like he was on the verge of saying something but would just swallow his words and continue working, until he finally blurted out, "Father – "audiatur et altera pars"... wouldn't it be a good idea to call it "audi" instead of "horch"?" "Horch!" in German means "Hark!" or "hear", which is "Audi" in the singular imperative form of "audire" – "to listen" – in Latin. The idea was enthusiastically accepted by everyone attending the meeting. On 25 April 1910 the Audi Automobilwerke GmbH Zwickau (from 1915 on Audiwerke AG Zwickau) was entered in the company's register of Zwickau registration court.

The first Audi automobile, the Audi Type A 10/ Sport-Phaeton, was produced in the same year, followed by the successor Type B 10/28PS in the same year.

Audi started with a 2,612 cc inline-four engine model Type A, followed by a 3,564 cc model, as well as 4,680 cc and 5,720 cc models. These cars were successful even in sporting events. The first six-cylinder model Type M, 4,655 cc appeared in 1924.

August Horch left the "Audiwerke" in 1920 for a high position at the ministry of transport, but he was still involved with Audi as a member of the board of trustees. In September 1921, Audi became the first German car manufacturer to present a production car, the Audi Type K, with left-handed drive. Left-hand drive spread and established dominance during the 1920s because it provided a better view of oncoming traffic, making overtaking safer.

In August 1928, Jørgen Rasmussen, the owner of Dampf-Kraft-Wagen (DKW), acquired the majority of shares in Audiwerke AG. In the same year, Rasmussen bought the remains of the U.S. automobile manufacturer Rickenbacker, including the manufacturing equipment for eight-cylinder engines. These engines were used in "Audi Zwickau" and "Audi Dresden" models that were launched in 1929. At the same time, six-cylinder and four-cylinder (the "four" with a Peugeot engine) models were manufactured. Audi cars of that era were luxurious cars equipped with special bodywork.

In 1932, Audi merged with Horch, DKW, and Wanderer, to form Auto Union AG, Chemnitz. It was during this period that the company offered the Audi Front that became the first European car to combine a six-cylinder engine with front-wheel drive. It used a powertrain shared with the Wanderer, but turned 180-degrees, so that the drive shaft faced the front.

Before World War II
Like most German manufacturing, at the onset of World War II the Auto Union plants were retooled for military production, and were a target for allied bombing during the war which left them damaged.

Overrun by the Soviet Army in 1945, on the orders of the Soviet Union military administration the factories were dismantled as part of war reparations. Following this, the company's entire assets were expropriated without compensation. On 17 August 1948, Auto Union AG of Chemnitz was deleted from the commercial register. These actions had the effect of liquidating Germany's Auto Union AG. The remains of the Audi plant of Zwickau became the VEB (for "People Owned Enterprise") or AWZ (in English: Automobile Works Zwickau).

With no prospect of continuing production in Soviet-controlled East Germany, Auto Union executives began the process of relocating what was left of the company to West Germany. A site was chosen in Ingolstadt, Bavaria, to start a spare parts operation in late 1945, which would eventually serve as the headquarters of the reformed Auto Union in 1949.

The former Audi factory in Zwickau restarted assembly of the pre-war-models in 1949. These DKW models were renamed to IFA F8 and IFA F9 and were similar to the West German versions. West and East German models were equipped with the traditional and renowned DKW two-stroke engines. The Zwickau plant manufactured the infamous Trabant until 1991, when it came under Volkswagen control—effectively bringing it under the same umbrella as Audi since 1945.

A new West German headquartered Auto Union was launched in Ingolstadt with loans from the Bavarian state government and Marshall Plan aid. The reformed company was launched 3 September 1949 and continued DKW's tradition of producing front-wheel drive vehicles with two-stroke engines. This included production of a small but sturdy 125 cc motorcycle and a DKW delivery van, the DKW F89 L at Ingolstadt. The Ingolstadt site was large, consisting of an extensive complex of formerly military buildings which was suitable for administration as well as vehicle warehousing and distribution, but at this stage there was at Ingolstadt no dedicated plant suitable for mass production of automobiles: for manufacturing the company's first post-war mass-market passenger car plant capacity in Düsseldorf was rented from Rheinmetall-Borsig. It was only ten years later, after the company had attracted an investor, when funds became available for construction of major car plant at the Ingolstadt head office site.

In 1958, in response to pressure from Friedrich Flick, then the company's largest single shareholder, Daimler-Benz took an 87% holding in the Auto Union company, and this was increased to a 100% holding in 1959. However, small two-stroke cars were not the focus of Daimler-Benz's interests, and while the early 1960s saw major investment in new Mercedes models and in a state of the art factory for Auto Union's, the company's aging model range at this time did not benefit from the economic boom of the early 1960s to the same extent as competitor manufacturers such as Volkswagen and Opel. The decision to dispose of the Auto Union business was based on its lack of profitability. Ironically, by the time they sold the business, it also included a large new factory and near production-ready modern four-stroke engine, which would enable the Auto Union business, under a new owner, to embark on a period of profitable growth, now producing not Auto Unions or DKWs, but using the "Audi" name, resurrected in 1965 after a 25-year gap.

In 1964, Volkswagen acquired a 50% holding in the business, which included the new factory in Ingolstadt, the DKW and Audi brands along with the rights to the new engine design which had been funded by Daimler-Benz, who in return retained the dormant Horch trademark and the Düsseldorf factory which became a Mercedes-Benz van assembly plant. Eighteen months later, Volkswagen bought complete control of Ingolstadt, and by 1966 were using the spare capacity of the Ingolstadt plant to assemble an additional 60,000 Volkswagen Beetles per year. Two-stroke engines became less popular during the 1960s as customers were more attracted to the smoother four-stroke engines. In September 1965, the DKW F102 was fitted with a four-stroke engine and a facelift for the car's front and rear. Volkswagen dumped the DKW brand because of its associations with two-stroke technology, and having classified the model internally as the F103, sold it simply as the "Audi". Later developments of the model were named after their horsepower ratings and sold as the Audi 60, 75, 80, and Super 90, selling until 1972. Initially, Volkswagen was hostile to the idea of Auto Union as a standalone entity producing its own models having acquired the company merely to boost its own production capacity through the Ingolstadt assembly plant – to the point where Volkswagen executives ordered that the Auto Union name and flags bearing the four rings were removed from the factory buildings. Then VW chief Heinz Nordhoff explicitly forbade Auto Union from any further product development. Fearing that the Volkswagen had no long term ambition for the Audi brand, Auto Union engineers under the leadership of Ludwig Kraus developed the first Audi 100 in secret, without Nordhoff's knowledge. When presented with a finished prototype, Nordhoff was so impressed he authorised the car for production, which when launched in 1968, went on to be a huge success. With this, the resurrection of the Audi brand was now complete, this being followed by the first generation Audi 80
In 1969, Auto Union merged with NSU, based in Neckarsulm, near Stuttgart. In the 1950s, NSU had been the world's largest manufacturer of motorcycles, but had moved on to produce small cars like the NSU Prinz, the TT and TTS versions of which are still popular as vintage race cars. NSU then focused on new rotary engines based on the ideas of Felix Wankel. In 1967, the new NSU Ro 80 was a car well ahead of its time in technical details such as aerodynamics, light weight, and safety. However, teething problems with the rotary engines put an end to the independence of NSU. The Neckarsulm plant is now used to produce the larger Audi models A6 and A8. The Neckarsulm factory is also home of the "quattro GmbH" (from November 2016 "Audi Sport GmbH"), a subsidiary responsible for development and production of Audi high-performance models: the R8 and the "RS" model range.

The new merged company was incorporated on 1 January 1969 and was known as Audi NSU Auto Union AG, with its headquarters at NSU's Neckarsulm plant, and saw the emergence of Audi as a separate brand for the first time since the pre-war era. Volkswagen introduced the Audi brand to the United States for the 1970 model year. That same year, the mid-sized car that NSU had been working on, the K70, originally intended to slot between the rear-engined Prinz models and the futuristic NSU Ro 80, was instead launched as a Volkswagen.

After the launch of the Audi 100 of 1968, the Audi 80/Fox (which formed the basis for the 1973 Volkswagen Passat) followed in 1972 and the Audi 50 (later rebadged as the Volkswagen Polo) in 1974. The Audi 50 was a seminal design because it was the first incarnation of the Golf/Polo concept, one that led to a hugely successful world car. Ultimately, the Audi 80 and 100 (progenitors of the A4 and A6, respectively) became the company's biggest sellers, whilst little investment was made in the fading NSU range; the Prinz models were dropped in 1973 whilst the fatally flawed NSU Ro80 went out of production in 1977, spelling the effective end of the NSU brand. Production of the Audi 100 had been steadily moved from Ingolstadt to Neckarsulm as the 1970s had progressed, any by the appearance of the second generation C2 version in 1976, all production was now at the former NSU plant. Neckarsulm from that point onward would produce Audi's higher end models.

The Audi image at this time was a conservative one, and so, a proposal from chassis engineer Jörg Bensinger was accepted to develop the four-wheel drive technology in Volkswagen's Iltis military vehicle for an Audi performance car and rally racing car. The performance car, introduced in 1980, was named the "Audi Quattro", a turbocharged coupé which was also the first German large-scale production vehicle to feature permanent all-wheel drive through a centre differential. Commonly referred to as the "Ur-Quattro" (the "Ur-" prefix is a German augmentative used, in this case, to mean "original" and is also applied to the first generation of Audi's S4 and S6
In 1986, as the Passat-based Audi 80 was beginning to develop a kind of "grandfather's car" image, the "type 89" was introduced. This completely new development sold extremely well. However, its modern and dynamic exterior belied the low performance of its base engine, and its base package was quite spartan (even the passenger-side mirror was an option.) In 1987, Audi put forward a new and very elegant Audi 90, which had a much superior set of standard features. In the early 1990s, sales began to slump for the Audi 80 series, and some basic construction problems started to surface.

In the early part of the 21st century, Audi set forth on a German racetrack to claim and maintain several world records, such as top speed endurance. This effort was in-line with the company's heritage from the 1930s racing era Silver Arrows.

Through the early 1990s, Audi began to shift its target market upscale to compete against German automakers Mercedes-Benz and BMW. This began with the release of the Audi V8 in 1990. It was essentially a new engine fitted to the Audi 100/200, but with noticeable bodywork differences. Most obvious was the new grille that was now incorporated in the bonnet.

By 1991, Audi had the four-cylinder Audi 80, the 5-cylinder Audi 90 and Audi 100, the turbocharged Audi 200 and the Audi V8. There was also a coupe version of the 80/90 with both 4- and 5-cylinder engines.

Although the five-cylinder engine was a successful and robust powerplant, it was still a little too different for the target market. With the introduction of an all-new Audi 100 in 1992, Audi introduced a 2.8L V6 engine. This engine was also fitted to a face-lifted Audi 80 (all 80 and 90 models were now badged 80 except for the USA), giving this model a choice of four-, five-, and six-cylinder engines, in Saloon, Coupé and Cabriolet body styles.

The five-cylinder was soon dropped as a major engine choice; however, a turbocharged version remained. The engine, initially fitted to the 200 quattro 20V of 1991, was a derivative of the engine fitted to the Sport Quattro. It was fitted to the Audi Coupé, and named the S2 and also to the Audi 100 body, and named the S4. These two models were the beginning of the mass-produced S series of performance cars.

Sales in the United States fell after a series of recalls from 1982 to 1987 of Audi 5000 models associated with reported incidents of sudden unintended acceleration linked to six deaths and 700 accidents. At the time, NHTSA was investigating 50 car models from 20 manufacturers for sudden surges of power.

A "60 Minutes

Audi contended, prior to findings by outside investigators, that the problems were caused by driver error, specifically pedal misapplication. Subsequently, the National Highway Traffic Safety Administration (NHTSA) concluded that the majority of unintended acceleration cases, including all the ones that prompted the "60 Minutes" report, were caused by driver error such as confusion of pedals. CBS did not acknowledge the test results of involved government agencies, but did acknowledge the similar results of another study.

In a review study published in 2012, NHTSA summarized its past findings about the Audi unintended acceleration problems: "Once an unintended acceleration had begun, in the Audi 5000, due to a failure in the idle-stabilizer system (producing an initial acceleration of 0.3g), pedal misapplication resulting from panic, confusion, or unfamiliarity with the Audi 5000 contributed to the severity of the incident."

This summary is consistent with the conclusions of NHTSA's most technical analysis at the time: "Audi idle-stabilization systems were prone to defects which resulted in excessive idle speeds and brief unanticipated accelerations of up to 0.3g [which is similar in magnitude to an emergency stop in a subway car]. These accelerations could not be the sole cause of [(long-duration) sudden acceleration incidents (SAI)], but might have triggered some SAIs by startling the driver. The defective idle-stabilization system performed a type of electronic throttle control. Significantly: multiple "intermittent malfunctions of the electronic control unit were observed and recorded ... and [were also observed and] reported by Transport Canada."

With a series of recall campaigns, Audi made several modifications; the first adjusted the distance between the brake and accelerator pedal on automatic-transmission models. Later repairs, of 250,000 cars dating back to 1978, added a device requiring the driver to press the brake pedal before shifting out of park. A legacy of the Audi 5000 and other reported cases of sudden unintended acceleration are intricate gear stick patterns and brake interlock mechanisms to prevent inadvertent shifting into forward or reverse. It is unclear how the defects in the idle-stabilization system were addressed.

Audi's U.S. sales, which had reached 74,061 in 1985, dropped to 12,283 in 1991 and remained level for three years. – with resale values falling dramatically. Audi subsequently offered increased warranty protection and renamed the affected models – with the "5000" becoming the "100" and "200" in 1989 – and reached the same sales levels again only by model year 2000.

A 2010 "BusinessWeek" article – outlining possible parallels between Audi's experience and 2009–2010 Toyota vehicle recalls – noted a class-action lawsuit filed in 1987 by about 7,500 Audi 5000-model owners remains unsettled and is remains contested in Chicago's Cook County after appeals at the Illinois state and U.S. federal levels.

In the mid-to-late 1990s, Audi introduced new technologies including the use of aluminum construction. Produced from 1999 to 2005, the Audi A2 was a futuristic super mini, born from the Al2 concept, with many features that helped regain consumer confidence, like the aluminium space frame, which was a first in production car design. In the A2 Audi further expanded their TDI technology through the use of frugal three-cylinder engines. The A2 was extremely aerodynamic and was designed around a wind tunnel. The Audi A2 was criticised for its high price and was never really a sales success but it planted Audi as a cutting-edge manufacturer. The model, a Mercedes-Benz A-Class competitor, sold relatively well in Europe. However, the A2 was discontinued in 2005 and Audi decided not to develop an immediate replacement.

The next major model change came in 1995 when the Audi A4 replaced the Audi 80. The new nomenclature scheme was applied to the Audi 100 to become the Audi A6 (with a minor facelift). This also meant the S4 became the S6 and a new S4 was introduced in the A4 body. The S2 was discontinued. The Audi Cabriolet continued on (based on the Audi 80 platform) until 1999, gaining the engine upgrades along the way. A new A3 hatchback model (sharing the Volkswagen Golf Mk4's platform) was introduced to the range in 1996, and the radical Audi TT coupé and roadster were debuted in 1998 based on the same underpinnings.

The engines available throughout the range were now a 1.4 L, 1.6 L and 1.8 L four-cylinder, 1.8 L four-cylinder turbo, 2.6 L and 2.8 L V6, 2.2 L turbo-charged five-cylinder and the 4.2 L V8 engine. The V6s were replaced by new 2.4 L and 2.8 L 30V V6s in 1998, with marked improvement in power, torque and smoothness. Further engines were added along the way, including a 3.7 L V8 and 6.0 L W12 engine for the A8.

Audi's sales grew strongly in the 2000s, with deliveries to customers increasing from 653,000 in 2000 to 1,003,000 in 2008. The largest sales increases came from Eastern Europe (+19.3%), Africa (+17.2%) and the Middle East (+58.5%). China in particular has become a key market, representing 108,000 out of 705,000 cars delivered in the first three quarters of 2009. One factor for its popularity in China is that Audis have become the car of choice for purchase by the Chinese government for officials, and purchases by the government are responsible for 20% of its sales in China. As of late 2009, Audi's operating profit of €1.17-billion ($1.85-billion) made it the biggest contributor to parent Volkswagen Group's nine-month operating profit of €1.5-billion, while the other marques in Group such as Bentley and SEAT had suffered considerable losses. May 2011 saw record sales for Audi of America with the new Audi A7 and Audi A3 TDI Clean Diesel. In May 2012, Audi reported a 10% increase in its sales—from 408 units to 480 in the last year alone.

Audi manufactures vehicles in seven plants around the world, some of which are shared with other VW Group marques although many sub-assemblies such as engines and transmissions are manufactured within other Volkswagen Group plants.

Audi's two principal assembly plants are:


Outside of Germany, Audi produces vehicles at:


In September 2012, Audi announced the construction of its first North American manufacturing plant in Puebla, Mexico. This plant is expected to be operative in 2016 and produce the second generation Q5.

From 2002 up to 2003, Audi headed the Audi Brand Group, a subdivision of the Volkswagen Group's Automotive Division consisting of Audi, Lamborghini and SEAT, that was focused on sporty values, with the marques' product vehicles and performance being under the higher responsibility of the Audi brand.

On January 2014, Audi, along with the Wireless Power Consortium, operated a booth which demonstrated a phone compartment using the Qi open interface standard at the Consumer Electronics Show (CES). In May, most of the Audi dealers in UK falsely claimed that the Audi A7, A8, and R8 were Euro NCAP safety tested, all achieving five out of five stars. In fact none were tested.

In 2015, Audi admitted that at least 2.1 million Audi cars had been involved in the Volkswagen emissions testing scandal in which software installed in the cars manipulated emissions data to fool regulators and allow the cars to pollute at higher than government-mandated levels. The A1, A3, A4, A5, A6, TT, Q3 and Q5 models were implicated in the scandal. Audi promised to quickly find a technical solution and upgrade the cars so they can function within emissions regulations. Ulrich Hackenberg, the head of research and development at Audi, was suspended in relation to the scandal. Despite widespread media coverage about the scandal through the month of September, Audi reported that U.S. sales for the month had increased by 16.2%. Audi's parent company Volkswagen announced on 18 June 2018 that Audi chief executive Rupert Stadler had been arrested.

In November 2015, the U.S. Environmental Protection Agency implicated the 3-liter diesel engine versions of the 2016 Audi A6 Quattro, A7 Quattro, A8, A8L and the Q5 as further models that had emissions regulation defeat-device software installed. Thus, these models emitted nitrogen oxide at up to nine times the legal limit when the car detected that it was not hooked up to emissions testing equipment.

In November 2016, Audi expressed an intention to establish an assembly factory in Pakistan, with the company's local partner acquiring land for a plant in Korangi Creek Industrial Park in Karachi. Approval of the plan would lead to an investment of $30 million in the new plant.

Audi AI is a driver assist feature offered by Audi. The company's stated intent is to offer fully autonomous driving at a future time, acknowledging that legal, regulatory and technical hurdles must be overcome to achieve this goal. On June 4, 2017, Audi stated that its new A8 will be fully self-driving for speeds up to 60 km/h using its Audi AI. Contrary to other cars, the driver will not have to do safety checks such as touching the steering wheel every 15 seconds to use this feature. The Audi A8 will therefore be the first production car to reach level 3 autonomous driving, meaning that the driver can safely turn their attention away from driving tasks, e.g. the driver can text or watch a movie. Audi will also be the first manufacturer to use a 3D LIDAR system in addition to cameras and ultrasonic sensors for their AI.

Audi produces 100% galvanised cars to prevent corrosion, and was the first mass-market vehicle to do so, following introduction of the process by Porsche, c. 1975. Along with other precautionary measures, the full-body zinc coating has proved to be very effective in preventing rust. The body's resulting durability even surpassed Audi's own expectations, causing the manufacturer to extend its original 10-year warranty
Audi introduced a new series of vehicles in the mid-1990s and continues to pursue new technology and high performance. An all-aluminium car was brought forward by Audi, and in 1994 the Audi A8 was launched, which introduced aluminium space frame technology (called "Audi Space Frame" or ASF) which saves weight and improves torsion rigidity compared to a conventional steel frame. Prior to that effort, Audi used examples of the Type 44 chassis fabricated out of aluminium as test-beds for the technique. The disadvantage of the aluminium frame is that it is very expensive to repair and requires a specialized aluminium bodyshop. The weight reduction is somewhat offset by the quattro four-wheel drive system which is standard in most markets. Nonetheless, the A8 is usually the lightest all-wheel drive car in the full-size luxury segment, also having best-in-class fuel economy. The Audi A2, Audi TT and Audi R8 also use Audi Space Frame designs.

For most of its lineup (excluding the A3, A1, and TT models), Audi has not adopted the transverse engine layout which is typically found in economy cars (such as Peugeot and Citroën), since that would limit the type and power of engines that can be installed. To be able to mount powerful engines (such as a V8 engine in the Audi S4 and Audi RS4, as well as the W12 engine in the Audi A8L W12), Audi has usually engineered its more expensive cars with a longitudinally front-mounted engine, in an "overhung" position, over the front wheels in front of the axle line - this layout dates back to the DKW and Auto Union saloons from the 1950s. But while this allows for the easy adoption of all-wheel drive, it goes against the ideal 50:50 weight distribution.

In all its post Volkswagen-era models, Audi has firmly refused to adopt the traditional rear-wheel drive layout favored by its two archrivals Mercedes-Benz and BMW, favoring either front-wheel drive or all-wheel drive. The majority of Audi's lineup in the United States features all-wheel drive standard on most of its expensive vehicles (only the entry-level trims of the A4 and A6 are available with front-wheel drive), in contrast to Mercedes-Benz and BMW whose lineup treats all-wheel drive as an option. BMW did not offer all-wheel drive on its V8-powered cars (as opposed to crossover SUVs) until the 2010 BMW 7 Series and 2011 BMW 5 Series, while the Audi A8 has had all-wheel drive available/standard since the 1990s. Regarding high-performance variants, Audi S and RS models have always had all-wheel drive, unlike their direct rivals from BMW M and Mercedes-AMG whose cars are rear-wheel drive only (although their performance crossover SUVs are all-wheel drive).

Audi has recently applied the "quattro" badge to models such as the A3 and TT which do not use the Torsen-based system as in prior years with a mechanical center differential, but with the Haldex Traction
Prior to the introduction of the Audi 80 and Audi 50 in 1972 and 1974, respectively, Audi had led the development of the "EA111" and "EA827" inline-four engine families. These new power units underpinned the water-cooled revival of parent company Volkswagen (in the Polo, Golf, Passat and Scirocco), whilst the many derivatives and descendants of these two basic engine designs have appeared in every generation of VW Group vehicles right up to the present day.

In the 1980s, Audi, along with Volvo, was the champion of the inline-five cylinder, 2.1/2.2 L engine as a longer-lasting alternative to more traditional six-cylinder engines. This engine was used not only in production cars but also in their race cars. The 2.1 L inline five-cylinder engine was used as a base for the rally cars in the 1980s, providing well over after modification. Before 1990, there were engines produced with a displacement between 2.0 L and 2.3 L. This range of engine capacity allowed for both fuel economy and power.

For the ultra-luxury version of its Audi A8 fullsize luxury flagship sedan, the Audi A8L W12, Audi uses the Volkswagen Group W12 engine instead of the conventional V12 engine favored by rivals Mercedes-Benz and BMW. The W12 engine configuration (also known as a "WR12") is created by forming two imaginary narrow-angle 15° VR6 engines at an angle of 72°, and the narrow angle of each set of cylinders allows just two overhead camshafts to drive each pair of banks, so just four are needed in total. The advantage of the W12 engine is its compact packaging, allowing Audi to build a 12-cylinder sedan with all-wheel drive, whereas a conventional V12 engine could have only a rear-wheel drive configuration as it would have no space in the engine bay for a differential and other components required to power the front wheels. In fact, the 6.0 L W12 in the Audi A8L W12 is smaller in overall dimensions than the 4.2 L V8 that powers the Audi A8 4.2 variants. The 2011 Audi A8 debuted a revised 6.3-litre version of the W12 (WR12) engine with .

New models of the A3, A4, A6 and A8 have been introduced, with the ageing 1.8-litre engine now having been replaced by new Fuel Stratified Injection

In 2003 Volkswagen introduced the Direct-Shift Gearbox (DSG), a type of dual clutch transmission. It is an automated semi-automatic transmission, drivable like a conventional automatic transmission. Based on the gearbox found in the Group B S1, the system includes dual electrohydraulically controlled clutches instead of a torque converter. This is implemented in some VW Golfs, Audi A3, Audi A4 and TT models where DSG is called S-tronic.

Beginning in 2005, Audi has implemented white LED technology as daytime running lights (DRL) in their products. The distinctive shape of the DRLs has become a trademark of sorts. LEDs were first introduced on the Audi A8 W12, the world's first production car to have LED DRLs, and have since spread throughout the entire model range. The LEDs are present on some Audi billboards.

Since 2010, Audi has also offered the LED technology in low- and high-beam headlights
Starting with the 2003 Audi A8, Audi has used a centralised control interface for its on-board infotainment systems, called Multi Media Interface (MMI). It is essentially a rotating control knob and 'segment' buttons – designed to control all in-car entertainment devices (radio, CD changer, iPod, TV tuner), satellite navigation, heating and ventilation, and other car controls with a screen.

The availability of MMI has gradually filtered down the Audi lineup, and following its introduction on the third generation A3 in 2011, MMI is now available across the entire range. It has been generally well received, as it requires less menu-surfing with its segment buttons around a central knob, along with 'main function' direct access buttons – with shortcuts to the radio or phone functions. The colour screen is mounted on the upright dashboard, and on the A4 (new), A5, A6, A8, and Q7, the controls are mounted horizontally.

Audi has assisted with technology to produce synthetic diesel from water and carbon dioxide.

Audi uses scanning gloves for parts registration during assembly, and automatic robots to transfer cars from factory to rail cars.

The following tables list Audi production vehicles that are sold as of 2014:

Audi is planning an alliance with the Japanese electronics giant Sanyo to develop a pilot hybrid electric project for the Volkswagen Group. The alliance could result in Sanyo batteries and other electronic components being used in future models of the Volkswagen Group. Concept electric vehicles unveiled to date include the Audi A1 Sportback Concept, Audi A4 TDI Concept E, and the fully electric Audi e-tron Concept Supercar.

In December 2018, Audi announced to invest 14 billion Euro ($15.9 billion) in e-mobility, self-driving cars.


Audi has competed in various forms of motorsports. Audi's tradition in motorsport began with their former company Auto Union
In 1980, Audi released the Quattro, a four-wheel drive (4WD) turbocharged car that went on to win rallies and races worldwide. It is considered one of the most significant rally cars of all time, because it was one of the first to take advantage of the then-recently changed rules which allowed the use of four-wheel drive in competition racing. Many critics doubted the viability of four-wheel drive racers, thinking them to be too heavy and complex, yet the Quattro was to become a successful car. Leading its first rally it went off the road, however the rally world had been served notice 4WD was the future. The Quattro went on to achieve much success in the World Rally Championship. It won the 1983 (Hannu Mikkola) and the 1984 (Stig Blomqvist) drivers' titles, and brought Audi the manufacturers' title in 1982

In 1984, Audi launched the short-wheelbase Sport Quattro which dominated rally races in Monte Carlo and Sweden, with Audi taking all podium places, but succumbed to problems further into WRC contention. In 1985, after another season mired in mediocre finishes, Walter Röhrl finished the season in his Sport Quattro S1, and helped place Audi second in the manufacturers' points. Audi also received rally honours in the Hong Kong to Beijing rally in that same year. Michèle Mouton, the only female driver to win a round of the World Rally Championship and a driver for Audi, took the Sport Quattro S1, now simply called the "S1", and raced in the Pikes Peak International Hill Climb. The climb race pits a driver and car to drive to the summit of the Pikes Peak mountain in Colorado, and in 1985, Michèle Mouton set a new record of 11:25.39, and being the first woman to set a Pikes Peak record. In 1986, Audi formally left international rally racing following an accident in Portugal involving driver Joaquim Santos in his Ford RS200. Santos swerved to avoid hitting spectators in the road, and left the track into the crowd of spectators on the side, killing three and injuring 30. Bobby Unser used an Audi in that same year to claim a new record for the Pikes Peak Hill Climb at 11:09.22.

In 1987, Walter Röhrl claimed the title for Audi setting a new Pikes Peak International Hill Climb record of 10:47.85 in his Audi S1, which he had retired from the WRC two years earlier. The Audi S1 employed Audi's time-tested inline-five-cylinder turbocharged engine, with the final version generating . The engine was mated to a six-speed gearbox and ran on Audi's famous four-wheel drive system. All of Audi's top drivers drove this car; Hannu Mikkola, Stig Blomqvist, Walter Röhrl and Michèle Mouton. This Audi S1 started the range of Audi 'S' cars, which now represents an increased level of sports-performance equipment within the mainstream Audi model range.

As Audi moved away from rallying and into circuit racing, they chose to move first into America with the Trans-Am in 1988.

In 1989, Audi moved to International Motor Sports Association (IMSA) GTO with the Audi 90, however as they avoided the two major endurance events (Daytona and Sebring) despite winning on a regular basis, they would lose out on the title.

In 1990, having completed their objective to market cars in North America, Audi returned to Europe, turning first to the Deutsche Tourenwagen Meisterschaft (DTM) series with the Audi V8, and then in 1993, being unwilling to build cars for the new formula, they turned their attention to the fast-growing Super Touring series, which are a series of national championships. Audi first entered in the French Supertourisme and Italian Superturismo. In the following year, Audi would switch to the German Super Tourenwagen Cup (known as STW), and then to British Touring Car Championship (BTCC) the year after that.

The Fédération Internationale de l'Automobile (FIA), having difficulty regulating the quattro four-wheel drive system, and the impact it had on the competitors, would eventually ban all four-wheel drive cars from competing in 1998, but by then, Audi switched all their works efforts to sports car racing.

By 2000, Audi would still compete in the US with their RS4 for the SCCA Speed World GT Challenge, through dealer/team Champion Racing competing against Corvettes, Vipers, and smaller BMWs (where it is one of the few series to permit 4WD cars). In 2003, Champion Racing entered an RS6. Once again, the quattro four-wheel drive was superior, and Champion Audi won the championship. They returned in 2004 to defend their title, but a newcomer, Cadillac with the new Omega Chassis CTS-V, gave them a run for their money. After four victories in a row, the Audis were sanctioned with several negative changes that deeply affected the car's performance. Namely, added ballast weights, and Champion Audi deciding to go with different tyres, and reducing the boost pressure of the turbocharger.

In 2004, after years of competing with the TT-R in the revitalised DTM series, with privateer team Abt Racing/Christian Abt taking the 2002 title with Laurent Aïello, Audi returned as a full factory effort to touring car racing by entering two factory supported Joest Racing A4 DTM
Audi began racing prototype sportscars in 1999, debuting at the Le Mans 24 hour. Two car concepts were developed and raced in their first season - the Audi R8R (open-cockpit 'roadster' prototype) and the Audi R8C (closed-cockpit 'coupé' GT-prototype). The R8R scored a credible podium on its racing debut at Le Mans and was the concept which Audi continued to develop into the 2000 season due to favourable rules for open-cockpit prototypes.

However, most of the competitors (such as BMW, Toyota, Mercedes and Nissan) retired at the end of 1999.
The factory-supported Joest Racing team won at Le Mans three times in a row with the Audi R8 (2000–2002), as well as winning every race in the American Le Mans Series in its first year. Audi also sold the car to customer teams such as Champion Racing.

In 2003, two Bentley Speed 8s, with engines designed by Audi, and driven by Joest drivers "loaned" to the fellow Volkswagen Group company, competed in the GTP class, and finished the race in the top two positions, while the Champion Racing R8 finished third overall, and first in the LMP900 class. Audi returned to the winner's podium at the 2004 race, with the top three finishers all driving R8s: Audi Sport Japan Team Goh finished first, Audi Sport UK Veloqx second, and Champion Racing third.

At the 2005 24 Hours of Le Mans, Champion Racing entered two R8s, along with an R8 from the Audi PlayStation Team Oreca. The R8s (which were built to old LMP900 regulations) received a narrower air inlet restrictor, reducing power, and an additional of weight compared to the newer LMP1 chassis. On average, the R8s were about 2–3 seconds off pace compared to the Pescarolo–Judd. But with a team of excellent drivers and experience, both Champion R8s were able to take first and third, while the Oreca team took fourth. The Champion team was also the first American team to win Le Mans since the Gulf Ford GTs in 1967. This also ends the long era of the R8; however, its replacement for 2006, called the Audi R10 TDI, was unveiled on 13 December 2005.

The R10 TDI employed many new and innovative features, the most notable being the twin-turbocharged direct injection diesel engine. It was first raced in the 2006 12 Hours of Sebring as a race-test in preparation for the 2006 24 Hours of Le Mans, which it later went on to win. Audi had a win in the first diesel sports car at 12 Hours of Sebring (the car was developed with a Diesel engine due to ACO regulations that favor diesel engines). As well as winning the 24 Hours of Le Mans in 2006, the R10 TDI beat the Peugeot 908 HDi FAP in , and in , (however Peugeot won the 24h in 2009) with a podium clean-sweep (all four 908 entries retired) while breaking a distance record (set by the Porsche 917K of Martini Racing in ), in with the R15 TDI Plus.

Audi's sports car racing success would continue with the Audi R18's victory at the 2011 24 Hours of Le Mans. Audi Sport Team Joest's Benoît Tréluyer earned Audi their first pole position in five years while the team's sister car locked out the front row. Early accidents eliminated two of Audi's three entries, but the sole remaining Audi R18 TDI of Tréluyer, Marcel Fässler, and André Lotterer held off the trio of Peugeot 908s to claim victory by a margin of 13.8 seconds.

Audi entered a factory racing team run by Joest Racing into the American Le Mans Series under the Audi Sport North America name in 2000. This was a successful operation with the team winning on its debut in the series at the 2000 12 Hours of Sebring. Factory backed Audi R8s were the dominant car in ALMS taking 25 victories between 2000 and the end of the 2002 season. In 2003 Audi sold customer cars to Champion Racing as well as continuing to race the factory Audi Sport North America team. Champion Racing won many races as a private team running Audi R8s and eventually replaced Team Joest as the Audi Sport North America between 2006 and 2008. Since 2009 Audi has not taken part in full American Le Mans Series Championships, but has competed in the series opening races at Sebring, using the 12-hour race as a test for Le Mans, and also as part of the 2012 FIA World Endurance Championship season calendar.

Audi participated in the 2003 1000km of Le Mans which was a one-off sports car race in preparation for the 2004 European Le Mans Series. The factory team Audi Sport UK won races and the championship in the 2004 season but Audi was unable to match their sweeping success of Audi Sport North America in the American Le Mans Series, partly due to the arrival of a factory competitor in LMP1, Peugeot. The French manufacturer's 908 HDi FAP became the car to beat in the series from 2008 onwards with 20 LMP wins. However, Audi were able to secure the championship in 2008 even though Peugeot scored more race victories in the season.

In 2012, the FIA sanctioned a World Endurance Championship which would be organised by the ACO as a continuation of the ILMC. Audi competed won the first WEC race at Sebring and followed this up with a further three successive wins, including the 2012 24 Hours of Le Mans. Audi scored a final 5th victory in the 2012 WEC in Bahrain and were able to win the inaugural WEC Manufacturers' Championship.

As defending champions, Audi once again entered the Audi R18 e-tron quattro chassis into the 2013 WEC and the team won the first five consecutive races, including the 2013 24 Hours of Le Mans. The victory at Round 5, Circuit of the Americas, was of particular significance as it marked the 100th win for Audi in Le Mans prototypes. Audi secured their second consecutive WEC Manufacturers' Championship at Round 6 after taking second place and half points in the red-flagged Fuji race.

For the 2014 season Audi entered a redesigned and upgraded R18 e-tron quattro which featured a 2 MJ energy recovery system. As defending champions, Audi would once again face a challenge in LMP1 from Toyota, and additionally from Porsche who returned to endurance racing after a 16-year absence. The season opening 6hrs of Silverstone was a disaster for Audi who saw both cars retire from the race, marking the first time that an Audi car has failed to score a podium in a World Endurance Championship race.

Audi provide factory support to Abt Sportsline in the FIA Formula E Championship, The team competed under the title of Audi Sport Abt Formula E Team in the inaugural 2014-15 Formula E season. On 13 February 2014 the team announced its driver line up as Daniel Abt and World Endurance Championship driver Lucas di Grassi.

Audi has been linked to Formula One in recent years but has always resisted due to the company's opinion that it is not relevant to road cars, but hybrid power unit technology has been adopted into the sport, swaying the company's view and encouraging research into the program by former Ferrari team principal Stefano Domenicali
The Audi emblem is four overlapping rings that represent the four marques of Auto Union. The Audi emblem symbolises the amalgamation of Audi with DKW, Horch and Wanderer: the first ring from the left represents Audi, the second represents DKW, third is Horch, and the fourth and last ring Wanderer.
The design is popularly believed to have been the idea of Klaus von Oertzen, the director of sales at Wanderer - when Berlin was chosen as the host city for the 1936 Summer Olympics and that a form of the Olympic logo symbolized the newly established Auto Union's desire to succeed. Somewhat ironically, the International Olympic Committee later sued Audi in the International Trademark Court in 1995, where they lost.

The original "Audi" script, with the distinctive slanted tails on the "A" and "d" was created for the historic Audi company in 1920 by the famous graphic designer Lucian Bernhard, and was resurrected when Volkswagen revived the brand in 1965. Following the demise of NSU in 1977, less prominence was given to the four rings, in preference to the "Audi" script encased within a black (later red) ellipse, and was commonly displayed next to the Volkswagen roundel when the two brands shared a dealer network under the V.A.G banner. The ellipse (known as the Audi Oval) was phased out after 1994, when Audi formed its own independent dealer network, and prominence was given back to the four rings - at the same time Audi Sans (a derivative of Univers) was adopted as the font for all marketing materials, corporate communications and was also used in the vehicles themselves.

As part of Audi's centennial celebration in 2009, the company updated the logo, changing the font to left-aligned Audi Type, and altering the shading for the overlapping rings. The revised logo was designed by Rayan Abdullah.

Audi developed a Corporate Sound concept, with Audi Sound Studio designed for producing the Corporate Sound. The Corporate Sound project began with sound agency Klangerfinder GmbH & Co KG and s12 GmbH. Audio samples were created in Klangerfinder's sound studio in Stuttgart, becoming part of Audi Sound Studio collection. Other Audi Sound Studio components include The Brand Music Pool, The Brand Voice. Audi also developed Sound Branding Toolkit including certain instruments, sound themes, rhythm and car sounds which all are supposed to reflect the AUDI sound character.

Audi started using a beating heart sound trademark beginning in 1996. An updated heartbeat sound logo, developed by agencies KLANGERFINDER GmbH & Co KG of Stuttgart and S12 GmbH of Munich, was first used in 2010 in an Audi A8 commercial with the slogan "The Art of Progress."

Audi's corporate tagline is "Vorsprung durch Technik", meaning ""Progress through Technology"". The German-language tagline is used in many European countries, including the United Kingdom, and in other markets, such as Latin America, Oceania and parts of Asia including Japan. A few years ago, the North American tagline was ""Innovation through technology"", but in Canada the German tagline "Vorsprung durch Technik" was used in advertising. Since 2007, Audi has used the slogan "Truth in Engineering" in the U.S. However, since the Audi emissions testing scandal came to light in September 2015, this slogan was lambasted for being discordant with reality. In fact, just hours after disgraced Volkswagen CEO Martin Winterkorn admitted to cheating on emissions data, an advertisement during the 2015 Primetime Emmy Awards promoted Audi's latest advances in low emissions technology with Kermit the Frog stating, "It's not that easy being green."

It was first used in English-language advertising after Sir John Hegarty of the Bartle Bogle Hegarty advertising agency visited the Audi factory in 1982. In the original British television commercials, the phrase was voiced by Geoffrey Palmer. After its repeated use in advertising campaigns, the phrase found its way into popular culture, including the British comedy "Only Fools and Horses", the U2 song "Zooropa" and the Blur song "Parklife". Similar-sounding phrases have also been used, including as the punchline for a joke in the movie "Lock, Stock, and Two Smoking Barrels" and in the British TV series Peep Show.

Audi Sans (based on Univers Extended) was originally created in 1997 by Ole Schäfer for MetaDesign. MetaDesign was later commissioned for a new corporate typeface called Audi Type, designed by Paul van der Laan and Pieter van Rosmalen of Bold Monday
Audi is a strong partner of different kinds of sports. In football, long partnerships exist between Audi and domestic clubs including Bayern Munich, Hamburger SV, 1. FC Nürnberg, Hertha BSC, and Borussia Mönchengladbach and international clubs including Chelsea, Real Madrid, FC Barcelona, A.C. Milan, AFC Ajax and Perspolis. Audi also sponsors winter sports: The Audi FIS Alpine Ski World Cup is named after the company. Additionally, Audi supports the German Ski Association (DSV) as well as the alpine skiing national teams of Switzerland, Sweden, Finland, France, Liechtenstein, Italy, Austria and the U.S. For almost two decades, Audi fosters golf sport: for example with the Audi quattro Cup and the HypoVereinsbank Ladies German Open presented by Audi. In sailing, Audi is engaged in the Medcup regatta and supports the team Luna Rossa during the Louis Vuitton Pacific Series and also is the primary sponsor of the Melges 20 sailboat. Further, Audi sponsors the regional teams ERC Ingolstadt (hockey) and FC Ingolstadt 04 (soccer). In 2009, the year of Audi's 100th anniversary, the company organized the Audi Cup for the first time. Audi also sponsor the New York Yankees as well. In October 2010 they agreed to a three sponsorship year-deal with Everton. Audi also sponsors the England Polo Team and holds the Audi Polo Awards

In 2001, Audi promoted the new multitronic continuously variable transmission with television commercials throughout Europe, featuring an impersonator of musician and actor Elvis Presley. A prototypical dashboard figure – later named "Wackel-Elvis" ("Wobble Elvis" or "Wobbly Elvis") – appeared in the commercials to demonstrate the smooth ride in an Audi equipped with the multitronic transmission. The dashboard figure was originally intended for use in the commercials only, but after they aired the demand for Wackel-Elvis fans grew among fans and the figure was mass-produced in China and marketed by Audi in their factory outlet store.

As part of Audi's attempt to promote its Diesel technology in 2009, the company began Audi Mileage Marathon. The driving tour featured a fleet of 23 Audi TDI vehicles from 4 models (Audi Q7 3.0 TDI, Audi Q5 3.0 TDI, Audi A4 3.0 TDI, Audi A3 Sportback 2.0 TDI with S tronic transmission) travelling across the American continent from New York to Los Angeles, passing major cities like Chicago, Dallas and Las Vegas during the 13 daily stages, as well as natural wonders including the Rocky Mountains, Death Valley and the Grand Canyon.

The next phase of technology Audi is developing is the e-tron electric drive powertrain system. They have shown several concept cars , each with different levels of size and performance. The original e-tron concept shown at the 2009 Frankfurt motor show is based on the platform of the R8 and has been scheduled for limited production. Power is provided by electric motors at all four wheels. The second concept was shown at the 2010 Detroit Motor Show. Power is provided by two electric motors at the rear axle. This concept is also considered to be the direction for a future mid-engined gas-powered 2-seat performance coupe. The Audi A1 e-tron concept, based on the Audi A1 production model, is a hybrid vehicle with a range extending Wankel rotary engine to provide power after the initial charge of the battery is depleted. It is the only concept of the three to have range extending capability. The car is powered through the front wheels, always using electric power.

It is all set to be displayed at the Auto Expo 2012 in New Delhi, India, from 5 January. Powered by a 1.4 litre engine, and can cover a distance up to 54 km s on a single charge. The e-tron was also shown in the 2013 blockbuster film Iron Man 3 and was driven by Tony Stark (Iron Man).

Audi has supported the European version of PlayStation Home, the PlayStation 3's online community-based service, by releasing a dedicated Home space
Category:Baden-Württemberg
Category:Car manufacturers of Germany
Category:Companies based in Bavaria
Category:Companies based in Ingolstadt
Category:Vehicle manufacturing companies established in 1909
Category:Vehicle manufacturing companies disestablished in 1939
Category:Vehicle manufacturing companies established in 1965
Category:German brands
Category:Ingolstadt
Category:Luxury motor vehicle manufacturers
Category:Motor vehicle manufacturers of Germany
Category:Saxony
Category:Sports car manufacturers
Category:Volkswagen Group
Category:1909 establishments in Germany
Category:Car brands

An aircraft is a machine that is able to fly by gaining support from the air. It counters the force of gravity by using either static lift or by using the dynamic lift of an airfoil, or in a few cases the downward thrust from jet engines. Common examples of aircraft include airplanes, helicopters, airships (including blimps), gliders, and hot air balloons. 

The human activity that surrounds aircraft is called "aviation". The science of aviation, including designing and building aircraft, is called "aeronautics." Crewed aircraft are flown by an onboard pilot, but unmanned aerial vehicles may be remotely controlled or self-controlled by onboard computers. Aircraft may be classified by different criteria, such as lift type, aircraft propulsion, usage and others.

Flying model craft and stories of manned flight
Aerostats use buoyancy to float in the air in much the same way that ships float on the water. They are characterized by one or more large gasbags or canopies, filled with a relatively low-density gas such as helium, hydrogen, or hot air, which is less dense than the surrounding air. When the weight of this is added to the weight of the aircraft structure, it adds up to the same weight as the air that the craft displaces.

Small hot-air balloons called sky lanterns were first invented in ancient China prior to the 3rd century BC and used primarily in cultural celebrations, and were only the second type of aircraft to fly, the first being kites which were first invented in ancient China over two thousand years ago (see Han Dynasty
A balloon was originally any aerostat, while the term airship was used for large, powered aircraft designs – usually fixed-wing. In 1919 Frederick Handley Page was reported as referring to "ships of the air," with smaller passenger types as "Air yachts." In the 1930s, large intercontinental flying boats were also sometimes referred to as "ships of the air" or "flying-ships". – though none had yet been built. The advent of powered balloons, called dirigible balloons, and later of rigid hulls allowing a great increase in size, began to change the way these words were used. Huge powered aerostats, characterized by a rigid outer framework and separate aerodynamic skin surrounding the gas bags, were produced, the Zeppelins being the largest and most famous. There were still no fixed-wing aircraft or non-rigid balloons large enough to be called airships, so "airship" came to be synonymous with these aircraft. Then several accidents, such as the Hindenburg disaster in 1937, led to the demise of these airships. Nowadays a "balloon" is an unpowered aerostat and an "airship" is a powered one.

A powered, steerable aerostat is called a "dirigible". Sometimes this term is applied only to non-rigid balloons, and sometimes "dirigible balloon" is regarded as the definition of an airship (which may then be rigid or non-rigid). Non-rigid dirigibles are characterized by a moderately aerodynamic gasbag with stabilizing fins at the back. These soon became known as "blimps". During the Second World War, this shape was widely adopted for tethered balloons; in windy weather, this both reduces the strain on the tether and stabilizes the balloon. The nickname "blimp" was adopted along with the shape. In modern times, any small dirigible or airship is called a blimp, though a blimp may be unpowered as well as powered.

Heavier-than-air aircraft, such as airplanes, must find some way to push air or gas downwards, so that a reaction occurs (by Newton's laws of motion) to push the aircraft upwards. This dynamic movement through the air is the origin of the term "aerodyne". There are two ways to produce dynamic upthrust: aerodynamic lift, and powered lift in the form of engine thrust.

Aerodynamic lift involving wings is the most common, with fixed-wing aircraft being kept in the air by the forward movement of wings, and rotorcraft by spinning wing-shaped rotors sometimes called rotary wings. A wing is a flat, horizontal surface, usually shaped in cross-section as an aerofoil. To fly, air must flow over the wing and generate lift. A "flexible wing" is a wing made of fabric or thin sheet material, often stretched over a rigid frame. A "kite" is tethered to the ground and relies on the speed of the wind over its wings, which may be flexible or rigid, fixed, or rotary.

With powered lift, the aircraft directs its engine thrust vertically downward. V/STOL aircraft, such as the Harrier Jump Jet and F-35B take off and land vertically using powered lift and transfer to aerodynamic lift in steady flight.

A pure rocket
The forerunner of the fixed-wing aircraft is the kite. Whereas a fixed-wing aircraft relies on its forward speed to create airflow over the wings, a kite is tethered to the ground and relies on the wind blowing over its wings to provide lift. Kites were the first kind of aircraft to fly, and were invented in China around 500 BC. Much aerodynamic research was done with kites before test aircraft, wind tunnels, and computer modelling programs became available.

The first heavier-than-air craft capable of controlled free-flight were gliders. A glider designed by George Cayley carried out the first true manned, controlled flight in 1853.

Practical, powered, fixed-wing aircraft (the aeroplane or airplane) were invented by Wilbur and Orville Wright. Besides the method of propulsion, fixed-wing aircraft are in general characterized by their wing configuration. The most important wing characteristics are:

A variable geometry aircraft can change its wing configuration during flight.

A "flying wing" has no fuselage, though it may have small blisters or pods. The opposite of this is a "lifting body", which has no wings, though it may have small stabilizing and control surfaces.

Wing-in-ground-effect vehicles are not considered aircraft. They "fly" efficiently close to the surface of the ground or water, like conventional aircraft during takeoff. An example is the Russian ekranoplan (nicknamed the "Caspian Sea Monster"). Man-powered aircraft also rely on ground effect
Rotorcraft, or rotary-wing aircraft, use a spinning rotor with aerofoil section blades (a "rotary wing") to provide lift. Types include helicopters, autogyros, and various hybrids such as gyrodynes and compound rotorcraft.

"Helicopters" have a rotor turned by an engine-driven shaft. The rotor pushes air downward to create lift. By tilting the rotor forward, the downward flow is tilted backward, producing thrust for forward flight. Some helicopters have more than one rotor and a few have rotors turned by gas jets at the tips.

"Autogyros" have unpowered rotors, with a separate power plant to provide thrust. The rotor is tilted backward. As the autogyro moves forward, air blows upward across the rotor, making it spin. This spinning increases the speed of airflow over the rotor, to provide lift. Rotor kites are unpowered autogyros, which are towed to give them forward speed or tethered to a static anchor in high-wind for kited flight.

"Cyclogyros" rotate their wings about a horizontal axis.

"Compound rotorcraft" have wings that provide some or all of the lift in forward flight. They are nowadays classified as "powered lift" types and not as rotorcraft. "Tiltrotor" aircraft (such as the V-22 Osprey), tiltwing, tailsitter, and coleopter aircraft have their rotors/propellers

The smallest aircraft are toys, and—even smaller – nano-aircraft.

The largest aircraft by dimensions and volume (as of 2016) is the 302-foot-long (about 95 meters) British Airlander 10, a hybrid blimp, with helicopter and fixed-wing features, and reportedly capable of speeds up to 90 mph (about 150 km/h), and an airborne endurance of two weeks with a payload of up to 22,050 pounds (11 tons).

The largest aircraft by weight and largest regular fixed-wing aircraft ever built (as of 2016), is the Antonov An-225. That Ukrainian-built 6-engine Russian transport of the 1980s is 84 meters (276 feet) long, with an 88-meter (289 foot) wingspan. It holds the world payload record, after transporting 428,834 pounds (200 tons) of goods, and has recently flown 100-ton loads commercially. Weighing in at somewhere between 1.1 and 1.4 million pounds (550–700 tons) maximum loaded weight, it is also the heaviest aircraft to be built, to date. It can cruise at 500 mph.

The largest military airplanes are the Ukrainian/Russian Antonov An-124 (world's second-largest airplane, also used as a civilian transport), and American Lockheed C-5 Galaxy transport, weighing, loaded, over 765,000 pounds (over 380 tons). The 8-engine, piston/propeller Hughes HK-1 "Spruce Goose," an American World War II wooden flying boat transport—with a greater wingspan (94 meters / 260 feet) than any current aircraft, and a tail-height equal to the tallest (Airbus A380-800 at 24.1 meters / 78 feet) – flew only one short hop in the late 1940s, and never flew out of ground effect.

The largest civilian airplanes, apart from the above-noted An-225 and An-124, are the Airbus Beluga cargo transport derivative of the Airbus A300 jet airliner, the Boeing Dreamlifter cargo transport derivative of the Boeing 747 jet airliner/transport (the 747-200B was, at its creation in the 1960s, the heaviest aircraft ever built, with a maximum weight of 836,000 pounds (over 400 tons)), and the double-decker Airbus A380 "super-jumbo" jet airliner (the world's largest passenger airliner).

The fastest recorded powered aircraft flight and fastest recorded aircraft flight of an air-breathing powered aircraft was of the NASA X-43A Pegasus, a scramjet-powered, hypersonic, lifting body experimental research aircraft, at Mach 9.6 (nearly 7,000 mph). The X-43A set that new mark, and broke its own world record (of Mach 6.3, nearly 5,000 mph, set in March, 2004) on its third and final flight on Nov. 16, 2004.

Prior to the X-43A, the fastest recorded powered airplane flight (and still the record for the fastest manned, powered airplane / fastest manned, non-spacecraft aircraft) was of the North American X-15A-2, rocket-powered airplane at 4,520 mph (7,274 km/h), Mach 6.72, on October 3, 1967. On one flight it reached an altitude of 354,300 feet.

The fastest known, production aircraft (other than rockets and missiles) currently or formerly operational (as of 2016) are:

Gliders are heavier-than-air aircraft that do not employ propulsion once airborne. Take-off may be by launching forward and downward from a high location, or by pulling into the air on a tow-line, either by a ground-based winch or vehicle, or by a powered "tug" aircraft. For a glider to maintain its forward air speed and lift, it must descend in relation to the air (but not necessarily in relation to the ground). Many gliders can 'soar' – gain height from updrafts such as thermal currents. The first practical, controllable example was designed and built by the British scientist and pioneer George Cayley, whom many recognise as the first aeronautical engineer. Common examples of gliders are sailplanes, hang gliders and paragliders.

Balloons drift with the wind, though normally the pilot can control the altitude, either by heating the air or by releasing ballast, giving some directional control (since the wind direction changes with altitude). A wing-shaped hybrid balloon can glide directionally when rising or falling; but a spherically shaped balloon does not have such directional control.

Kites are aircraft that are tethered to the ground or other object (fixed or mobile) that maintains tension in the tether or kite line; they rely on virtual or real wind blowing over and under them to generate lift and drag. Kytoons are balloon-kite hybrids that are shaped and tethered to obtain kiting deflections, and can be lighter-than-air, neutrally buoyant, or heavier-than-air.

Powered aircraft have one or more onboard sources of mechanical power, typically aircraft engines although rubber and manpower have also been used. Most aircraft engines are either lightweight piston engines or gas turbines. Engine fuel is stored in tanks, usually in the wings but larger aircraft also have additional fuel tanks in the fuselage

Propeller aircraft use one or more propellers (airscrews) to create thrust in a forward direction. The propeller is usually mounted in front of the power source in "tractor configuration" but can be mounted behind in "pusher configuration". Variations of propeller layout include "contra-rotating propellers" and "ducted fans".

Many kinds of power plant have been used to drive propellers. Early airships used man power or steam engines. The more practical internal combustion piston engine was used for virtually all fixed-wing aircraft until World War II and is still used in many smaller aircraft. Some types use turbine engines to drive a propeller in the form of a turboprop or propfan. Human-powered flight has been achieved, but has not become a practical means of transport. Unmanned aircraft and models have also used power sources such as electric motors

Jet aircraft use airbreathing jet engines, which take in air, burn fuel with it in a combustion chamber, and accelerate the exhaust rearwards to provide thrust.

Turbojet and turbofan engines use a spinning turbine to drive one or more fans, which provide additional thrust. An afterburner may be used to inject extra fuel into the hot exhaust, especially on military "fast jets". Use of a turbine is not absolutely necessary: other designs include the pulse jet and ramjet. These mechanically simple designs cannot work when stationary, so the aircraft must be launched to flying speed by some other method. Other variants have also been used, including the motorjet and hybrids such as the Pratt & Whitney J58, which can convert between turbojet and ramjet operation.

Compared to propellers, jet engines can provide much higher thrust, higher speeds and, above about , greater efficiency. They are also much more fuel-efficient than rockets. As a consequence nearly all large, high-speed or high-altitude aircraft use jet engines.

Some rotorcraft, such as helicopters, have a powered rotary wing or "rotor", where the rotor disc can be angled slightly forward so that a proportion of its lift is directed forwards. The rotor may, like a propeller, be powered by a variety of methods such as a piston engine or turbine. Experiments have also used jet nozzles at the rotor blade tips.


Aircraft are designed according to many factors such as customer and manufacturer demand, safety protocols and physical and economic constraints. For many types of aircraft the design process is regulated by national airworthiness authorities.

The key parts of an aircraft are generally divided into three categories:

The approach to structural design varies widely between different types of aircraft. Some, such as paragliders, comprise only flexible materials that act in tension and rely on aerodynamic pressure to hold their shape. A balloon similarly relies on internal gas pressure but may have a rigid basket or gondola slung below it to carry its payload. Early aircraft, including airships, often employed flexible doped aircraft fabric covering to give a reasonably smooth aeroshell stretched over a rigid frame. Later aircraft employed semi-monocoque
Heavier-than-air types are characterised by one or more wings and a central fuselage. The fuselage typically also carries a tail or empennage for stability and control, and an undercarriage for takeoff and landing. Engines may be located on the fuselage or wings. On a fixed-wing aircraft the wings are rigidly attached to the fuselage, while on a rotorcraft the wings are attached to a rotating vertical shaft. Smaller designs sometimes use flexible materials for part or all of the structure, held in place either by a rigid frame or by air pressure. The fixed parts of the structure comprise the airframe.

The avionics comprise the flight control systems and related equipment, including the cockpit instrumentation, navigation, radar, monitoring, and communication systems.

The flight envelope of an aircraft refers to its approved design capabilities in terms of airspeed and load factor

The range is the distance an aircraft can fly between takeoff and landing
Flight dynamics is the science of air vehicle orientation and control in three dimensions. The three critical flight dynamics parameters are the angles of rotation around three axes which pass through the vehicle's center of gravity

An aircraft that is unstable tends to diverge from its current flight path and so is difficult to fly. A very stable aircraft tends to stay on its current flight path and is difficult to manoeuvre—so it is important for any design to achieve the desired degree of stability. Since the widespread use of digital computers, it is increasingly common for designs to be inherently unstable and rely on computerised control systems to provide artificial stability.

A fixed wing is typically unstable in pitch, roll, and yaw. Pitch and yaw stabilities of conventional fixed wing designs require horizontal and vertical stabilisers, which act similarly to the feathers on an arrow. These stabilizing surfaces allow equilibrium of aerodynamic forces and to stabilise the flight dynamics of pitch and yaw. They are usually mounted on the tail section (empennage), although in the canard layout, the main aft wing replaces the canard foreplane as pitch stabilizer. Tandem wing and Tailless aircraft rely on the same general rule to achieve stability, the aft surface being the stabilising one.

A rotary wing is typically unstable in yaw, requiring a vertical stabiliser.

A balloon is typically very stable in pitch and roll due to the way the payload is hung underneath.

Flight control surfaces enable the pilot to control an aircraft's flight attitude and are usually part of the wing or mounted on, or integral with, the associated stabilizing surface. Their development was a critical advance in the history of aircraft, which had until that point been uncontrollable in flight.

Aerospace engineers develop control systems for a vehicle's orientation (attitude) about its center of mass. The control systems include actuators, which exert forces in various directions, and generate rotational forces or moments about the aerodynamic center of the aircraft, and thus rotate the aircraft in pitch, roll, or yaw. For example, a pitching moment is a vertical force applied at a distance forward or aft from the aerodynamic center of the aircraft, causing the aircraft to pitch up or down. Control systems are also sometimes used to increase or decrease drag, for example to slow the aircraft to a safe speed for landing.

The two main aerodynamic forces acting on any aircraft are lift supporting it in the air and drag opposing its motion. Control surfaces or other techniques may also be used to affect these forces directly, without inducing any rotation.

Aircraft permit long distance, high speed travel and may be a more fuel efficient mode of transportation in some circumstances. Aircraft have environmental and climate impacts beyond fuel efficiency considerations, however. They are also relatively noisy compared to other forms of travel and high altitude aircraft generate contrails, which experimental evidence suggests may alter weather patterns.

Aircraft are produced in several different types optimized for various uses; military aircraft, which includes not just combat types but many types of supporting aircraft, and civil aircraft

A military aircraft is any aircraft that is operated by a legal or insurrectionary armed service of any type. Military aircraft can be either combat or non-combat:

Most military aircraft are powered heavier-than-air types. Other types such as gliders and balloons have also been used as military aircraft; for example, balloons were used for observation during the American Civil War and World War I, and military gliders were used during World War II

Civil aircraft divide into "commercial" and "general" types, however there are some overlaps.

Commercial aircraft include types designed for scheduled and charter airline flights, carrying passengers, mail and other cargo. The larger passenger-carrying types are the airliners, the largest of which are wide-body aircraft. Some of the smaller types are also used in general aviation, and some of the larger types are used as VIP aircraft.

General aviation is a catch-all covering other kinds of private (where the pilot is not paid for time or expenses) and commercial use, and involving a wide range of aircraft types such as business jets (bizjets), trainers, homebuilt, gliders, warbirds and hot air balloons to name a few. The vast majority of aircraft today are general aviation types.

An experimental aircraft is one that has not been fully proven in flight, or that carries an FAA Special Airworthiness Certificate

A model aircraft is a small unmanned type made to fly for fun, for static display, for aerodynamic research or for other purposes. A scale modelAlfred Nobel

Alfred Bernhard Nobel (; ; 21 October 1833 – 10 December 1896) was a Swedish chemist, engineer, inventor, businessman, and philanthropist.

Known for inventing dynamite, Nobel also owned Bofors, which he had redirected from its previous role as primarily an iron and steel producer to a major manufacturer of cannon and other armaments. Nobel held 355 different patents, dynamite being the most famous. After reading a premature obituary which condemned him for profiting from the sales of arms, he bequeathed his fortune to institute the Nobel Prizes. The synthetic element nobelium was named after him. His name also survives in modern-day companies such as Dynamit Nobel and AkzoNobel
Born in Stockholm, Alfred Nobel was the third son of Immanuel Nobel (1801–1872), an inventor and engineer, and Carolina Andriette (Ahlsell) Nobel (1805–1889). The couple married in 1827 and had eight children. The family was impoverished, and only Alfred and his three brothers survived past childhood. Through his father, Alfred Nobel was a descendant of the Swedish scientist Olaus Rudbeck (1630–1702), and in his turn the boy was interested in engineering, particularly explosives, learning the basic principles from his father at a young age. Alfred Nobel's interest in technology was inherited from his father, an alumnus of Royal Institute of Technology in Stockholm.

Following various business failures, Nobel's father moved to Saint Petersburg in 1837 and grew successful there as a manufacturer of machine tools and explosives. He invented veneer lathe and started work on the torpedo. In 1842, the family joined him in the city. Now prosperous, his parents were able to send Nobel to private tutors and the boy excelled in his studies, particularly in chemistry and languages, achieving fluency in English, French, German and Russian. For 18 months, from 1841 to 1842, Nobel went to the only school he ever attended as a child, the Jacobs Apologistic School in Stockholm.

As a young man, Nobel studied with chemist Nikolai Zinin; then, in 1850, went to Paris to further the work. There he met Ascanio Sobrero, who had invented nitroglycerin three years before. Sobrero strongly opposed the use of nitroglycerin, as it was unpredictable, exploding when subjected to heat or pressure. But Nobel became interested in finding a way to control and use nitroglycerin as a commercially usable explosive, as it had much more power than gunpowder. At age 18, he went to the United States for one year to study, working for a short period under Swedish-American inventor John Ericsson, who designed the American Civil War ironclad "USS Monitor". Nobel filed his first patent, an English patent for a gas meter, in 1857, while his first Swedish patent, which he received in 1863, was on 'ways to prepare gunpowder'.

The family factory produced armaments for the Crimean War (1853–1856), but had difficulty switching back to regular domestic production when the fighting ended and they filed for bankruptcy. In 1859, Nobel's father left his factory in the care of the second son, Ludvig Nobel (1831–1888), who greatly improved the business. Nobel and his parents returned to Sweden from Russia and Nobel devoted himself to the study of explosives, and especially to the safe manufacture and use of nitroglycerin. Nobel invented a detonator in 1863, and in 1865 designed the blasting cap.

On 3 September 1864, a shed used for preparation of nitroglycerin exploded at the factory in Heleneborg, Stockholm, killing five people, including Nobel's younger brother Emil. Dogged and unfazed by more minor accidents, Nobel went on to build further factories, focusing on improving the stability of the explosives he was developing. Nobel invented dynamite in 1867, a substance easier and safer to handle than the more unstable nitroglycerin. Dynamite was patented in the US and the UK and was used extensively in mining and the building of transport networks internationally. In 1875 Nobel invented gelignite, more stable and powerful than dynamite, and in 1887 patented ballistite, a predecessor of cordite.

Nobel was elected a member of the Royal Swedish Academy of Sciences in 1884, the same institution that would later select laureates for two of the Nobel prizes, and he received an honorary doctorate from Uppsala University
Nobel's brothers Ludvig and Robert exploited oilfields along the Caspian Sea and became hugely rich in their own right. Nobel invested in these and amassed great wealth through the development of these new oil regions. During his life Nobel was issued 355 patents internationally and by his death his business had established more than 90 armaments factories, despite his apparently pacifist character.

In 1888, the death of his brother Ludvig caused several newspapers to publish obituaries of Alfred in error. One French newspaper published an obituary titled "Le marchand de la mort est mort" "("The merchant of death is dead")". Nobel read the obituary and was appalled at the idea that he would be remembered in this way. His decision to posthumously donate the majority of his wealth to found the Nobel Prize has been credited at least in part to him wanting to leave a behind a better legacy.

Accused of “high treason against France” for selling Ballistite to Italy, Nobel moved from Paris to Sanremo, Italy in 1891. On December 10, 1896, Alfred Nobel succumbed to a lingering heart ailment, suffered a stroke, and died. Unbeknownst to his family, friends or colleagues, he had left most of his wealth in trust, in order to fund the awards that would become known as the Nobel Prizes. He is buried in Norra begravningsplatsen in Stockholm.

Through baptism and confirmation Alfred Nobel was Lutheran and during his Paris years he regularly attended the Church of Sweden Abroad, led by pastor Nathan Söderblom, who himself received the Nobel Peace Prize in 1930. He became an agnostic in youth and was an atheist later in life.

Nobel travelled for much of his business life, maintaining companies in various countries in Europe and North America and keeping a permanent home in Paris from 1873 to 1891. He remained a solitary character, given to periods of depression. Though Nobel remained unmarried, his biographers note that he had at least three loves. Nobel's first love was in Russia with a girl named Alexandra, who rejected his proposal. In 1876 Austro-Bohemian Countess Bertha Kinsky became Alfred Nobel's secretary, but after only a brief stay she left him to marry her previous lover, Baron Arthur Gundaccar von Suttner. Though her personal contact with Alfred Nobel had been brief, she corresponded with him until his death in 1896, and it is believed that she was a major influence in his decision to include a peace prize among those prizes provided in his will. As Baroness Bertha von Suttner she was awarded the 1905 Nobel Peace prize, 'for her sincere peace activities'.

Nobel's third and longest-lasting relationship was with Sofie Hess from Vienna, whom he met in 1876. The liaison lasted for 18 years. After his death, according to his biographers Evlanoff, Fluor and Fant, Nobel's letters were locked within the Nobel Institute in Stockholm. They were released only in 1955, to be included with other biographical data.

Despite the lack of formal secondary and tertiary level education, Nobel gained proficiency in six languages: Swedish, French, Russian, English, German and Italian. He also developed sufficient literary skill to write poetry in English. His "Nemesis", a prose tragedy in four acts about Beatrice Cenci, partly inspired by Percy Bysshe Shelley's "The Cenci", was printed while he was dying. The entire stock except for three copies was destroyed immediately after his death, being regarded as scandalous and blasphemous. The first surviving edition (bilingual Swedish–Esperanto) was published in Sweden in 2003. The play has been translated into Slovenian
Nobel found that when nitroglycerin was incorporated in an absorbent inert substance like "kieselguhr" (diatomaceous earth) it became safer and more convenient to handle, and this mixture he patented in 1867 as "dynamite". Nobel demonstrated his explosive for the first time that year, at a quarry in Redhill, Surrey, England. In order to help reestablish his name and improve the image of his business from the earlier controversies associated with the dangerous explosives, Nobel had also considered naming the highly powerful substance "Nobel's Safety Powder", but settled with Dynamite instead, referring to the Greek word for "power" ().

Nobel later combined nitroglycerin with various nitrocellulose compounds, similar to collodion, but settled on a more efficient recipe combining another nitrate explosive, and obtained a transparent, jelly-like substance, which was a more powerful explosive than dynamite. 'Gelignite', or blasting gelatin, as it was named, was patented in 1876; and was followed by a host of similar combinations, modified by the addition of potassium nitrate and various other substances. Gelignite was more stable, transportable and conveniently formed to fit into bored holes, like those used in drilling and mining, than the previously used compounds and was adopted as the standard technology for mining in the "Age of Engineering" bringing Nobel a great amount of financial success, though at a significant cost to his health. An offshoot of this research resulted in Nobel's invention of ballistite 
In 1888 Alfred's brother Ludvig died while visiting Cannes and a French newspaper erroneously published Alfred's obituary. It condemned him for his invention of dynamite and is said to have brought about his decision to leave a better legacy after his death. The obituary stated, "" ("The merchant of death is dead") and went on to say, "Dr. Alfred Nobel, who became rich by finding ways to kill more people faster than ever before, died yesterday." Alfred (who never had a wife or children) was disappointed with what he read and concerned with how he would be remembered.

On 27 November 1895, at the Swedish-Norwegian Club in Paris, Nobel signed his last will and testament and set aside the bulk of his estate to establish the Nobel Prizes, to be awarded annually without distinction of nationality. After taxes and bequests to individuals, Nobel's will allocated 94% of his total assets, 31,225,000 Swedish kronor, to establish the five Nobel Prizes. This converted to £1,687,837 (GBP) at the time. In 2012, the capital was worth around SEK 3.1 billion (US$472 million, EUR 337 million), which is almost twice the amount of the initial capital, taking inflation into account.

The first three of these prizes are awarded for eminence in physical science, in chemistry and in medical science or physiology; the fourth is for literary work "in an ideal direction" and the fifth prize, in the suppression or reduction of standing armies, or in the establishment or furtherance of peace congresses.

The formulation for the literary prize being given for a work "in an ideal direction" (' in Swedish), is cryptic and has caused much confusion. For many years, the Swedish Academy interpreted "ideal" as "idealistic" (') and used it as a reason not to give the prize to important but less romantic authors, such as Henrik Ibsen and Leo Tolstoy. This interpretation has since been revised, and the prize has been awarded to, for example, Dario Fo and José Saramago, who do not belong to the camp of literary idealism.

There was room for interpretation by the bodies he had named for deciding on the physical sciences and chemistry prizes, given that he had not consulted them before making the will. In his one-page testament, he stipulated that the money go to discoveries or inventions in the physical sciences and to discoveries or improvements in chemistry. He had opened the door to technological awards, but had not left instructions on how to deal with the distinction between science and technology. Since the deciding bodies he had chosen were more concerned with the former, the prizes went to scientists more often than engineers, technicians or other inventors.

In 2001, Alfred Nobel's great-great-nephew, Peter Nobel (b. 1931), asked the Bank of Sweden to differentiate its award to economists given "in Alfred Nobel's memory" from the five other awards. This request added to the controversy over whether the Bank of Sweden Prize in Economic Sciences in Memory of Alfred Nobel is actually a legitimate "Nobel Prize".

The "Monument to Alfred Nobel" (, ) in Saint Petersburg is located along the Bolshaya Nevka River on Petrogradskaya Embankment. It was dedicated in 1991 to mark the 90th anniversary of the first Nobel Prize presentation. Diplomat Thomas Bertelman and Professor Arkady Melua
Category:1833 births
Category:1896 deaths
Category:19th-century Swedish scientists
Category:Burials at Norra begravningsplatsen
Category:Members of the Royal Swedish Academy of Sciences
Category:Nobel family
Category:Nobel Prize
Category:People from Stockholm
Category:19th-century Swedish businesspeople
Category:Swedish chemists
Category:Swedish atheists
Category:Swedish engineers
Category:Swedish inventors
Category:Swedish philanthropists
Category:Explosives engineers
Category:National Inventors Hall of Fame inductees
Category:19th-century atheistsAlexander Graham Bell

Alexander Graham Bell ('Graham' pronounced ) (March 3, 1847 – August 2, 1922) was a Scottish-born scientist, inventor, engineer, and innovator who is credited with inventing and patenting the first practical telephone. He also founded the American Telephone and Telegraph Company (AT&T) in 1885.

Bell's father, grandfather, and brother had all been associated with work on elocution and speech and both his mother and wife were deaf, profoundly influencing Bell's life's work. His research on hearing and speech further led him to experiment with hearing devices which eventually culminated in Bell being awarded the first U.S. patent for the telephone in 1876. Bell considered his invention an intrusion on his real work as a scientist and refused to have a telephone in his study.

Many other inventions marked Bell's later life, including groundbreaking work in optical telecommunications, hydrofoils, and aeronautics. Although Bell was not one of the 33 founders of the National Geographic Society, he had a strong influence on the magazine while serving as the second president from January 7, 1898, until 1903.

Alexander Bell was born in Edinburgh, Scotland, on March 3, 1847. The family home was at South Charlotte Street, and has a stone inscription marking it as Alexander Graham Bell's birthplace. He had two brothers: Melville James Bell (1845–70) and Edward Charles Bell (1848–67), both of whom would die of tuberculosis. His father was Professor Alexander Melville Bell, a phonetician, and his mother was Eliza Grace (née Symonds). Born as just "Alexander Bell", at age 10, he made a plea to his father to have a middle name like his two brothers. For his 11th birthday, his father acquiesced and allowed him to adopt the name "Graham", chosen out of respect for Alexander Graham, a Canadian being treated by his father who had become a family friend. To close relatives and friends he remained "Aleck".

As a child, young Bell displayed a natural curiosity about his world, resulting in gathering botanical specimens as well as experimenting even at an early age. His best friend was Ben Herdman, a neighbour whose family operated a flour mill, the scene of many forays. Young Bell asked what needed to be done at the mill. He was told wheat had to be dehusked through a laborious process and at the age of 12, Bell built a homemade device that combined rotating paddles with sets of nail brushes, creating a simple dehusking machine that was put into operation and used steadily for a number of years. In return, Ben's father John Herdman gave both boys the run of a small workshop in which to "invent".

From his early years, Bell showed a sensitive nature and a talent for art, poetry, and music that was encouraged by his mother. With no formal training, he mastered the piano and became the family's pianist. Despite being normally quiet and introspective, he revelled in mimicry and "voice tricks" akin to ventriloquism that continually entertained family guests during their occasional visits. Bell was also deeply affected by his mother's gradual deafness (she began to lose her hearing when he was 12), and learned a manual finger language so he could sit at her side and tap out silently the conversations swirling around the family parlour. He also developed a technique of speaking in clear, modulated tones directly into his mother's forehead wherein she would hear him with reasonable clarity. Bell's preoccupation with his mother's deafness led him to study acoustics.

His family was long associated with the teaching of elocution: his grandfather, Alexander Bell, in London, his uncle in Dublin, and his father, in Edinburgh, were all elocutionists. His father published a variety of works on the subject, several of which are still well known, especially his "The Standard Elocutionist" (1860), which appeared in Edinburgh in 1868. "The Standard Elocutionist" appeared in 168 British editions and sold over a quarter of a million copies in the United States alone. In this treatise, his father explains his methods of how to instruct deaf-mutes (as they were then known) to articulate words and read other people's lip movements to decipher meaning. Bell's father taught him and his brothers not only to write Visible Speech but to identify any symbol and its accompanying sound. Bell became so proficient that he became a part of his father's public demonstrations and astounded audiences with his abilities. He could decipher Visible Speech representing virtually every language, including Latin, Scottish Gaelic, and even Sanskrit, accurately reciting written tracts without any prior knowledge of their pronunciation.

As a young child, Bell, like his brothers, received his early schooling at home from his father. At an early age, he was enrolled at the Royal High School, Edinburgh, Scotland, which he left at the age of 15, having completed only the first four forms. His school record was undistinguished, marked by absenteeism and lacklustre grades. His main interest remained in the sciences, especially biology while he treated other school subjects with indifference, to the dismay of his demanding father. Upon leaving school, Bell travelled to London to live with his grandfather, Alexander Bell. During the year he spent with his grandfather, a love of learning was born, with long hours spent in serious discussion and study. The elder Bell took great efforts to have his young pupil learn to speak clearly and with conviction, the attributes that his pupil would need to become a teacher himself. At the age of 16, Bell secured a position as a "pupil-teacher" of elocution and music, in Weston House Academy at Elgin, Moray, Scotland. Although he was enrolled as a student in Latin and Greek, he instructed classes himself in return for board and £10 per session. The following year, he attended the University of Edinburgh; joining his older brother Melville who had enrolled there the previous year. In 1868, not long before he departed for Canada with his family, Bell completed his matriculation exams and was accepted for admission to University College London.

His father encouraged Bell's interest in speech and, in 1863, took his sons to see a unique automaton developed by Sir Charles Wheatstone based on the earlier work of Baron Wolfgang von Kempelen. The rudimentary "mechanical man" simulated a human voice. Bell was fascinated by the machine and after he obtained a copy of von Kempelen's book, published in German, and had laboriously translated it, he and his older brother Melville built their own automaton head. Their father, highly interested in their project, offered to pay for any supplies and spurred the boys on with the enticement of a "big prize" if they were successful. While his brother constructed the throat and larynx, Bell tackled the more difficult task of recreating a realistic skull. His efforts resulted in a remarkably lifelike head that could "speak", albeit only a few words. The boys would carefully adjust the "lips" and when a bellows forced air through the windpipe, a very recognizable "Mama" ensued, to the delight of neighbours who came to see the Bell invention.

Intrigued by the results of the automaton, Bell continued to experiment with a live subject, the family's Skye Terrier, "Trouve". After he taught it to growl continuously, Bell would reach into its mouth and manipulate the dog's lips and vocal cords to produce a crude-sounding "Ow ah oo ga ma ma". With little convincing, visitors believed his dog could articulate "How are you, grandma?" Indicative of his playful nature, his experiments convinced onlookers that they saw a "talking dog". These initial forays into experimentation with sound led Bell to undertake his first serious work on the transmission of sound, using tuning forks to explore resonance.

At age 19, Bell wrote a report on his work and sent it to philologist Alexander Ellis, a colleague of his father (who would later be portrayed as Professor Henry Higgins in "Pygmalion"). Ellis immediately wrote back indicating that the experiments were similar to existing work in Germany, and also lent Bell a copy of Hermann von Helmholtz's work, "The Sensations of Tone as a Physiological Basis for the Theory of Music".

Dismayed to find that groundbreaking work had already been undertaken by Helmholtz who had conveyed vowel sounds by means of a similar tuning fork "contraption", Bell pored over the German scientist's book. Working from his own erroneous mistranslation of a French edition, Bell fortuitously then made a deduction that would be the underpinning of all his future work on transmitting sound, reporting: "Without knowing much about the subject, it seemed to me that if vowel sounds could be produced by electrical means, so could consonants, so could articulate speech." He also later remarked: "I thought that Helmholtz had done it ... and that my failure was due only to my ignorance of electricity. It was a valuable blunder ... If I had been able to read German in those days, I might never have commenced my experiments!"

In 1865, when the Bell family moved to London, Bell returned to Weston House as an assistant master and, in his spare hours, continued experiments on sound using a minimum of laboratory equipment. Bell concentrated on experimenting with electricity to convey sound and later installed a telegraph wire from his room in Somerset College to that of a friend. Throughout late 1867, his health faltered mainly through exhaustion. His younger brother, Edward "Ted," was similarly bed-ridden, suffering from tuberculosis. While Bell recovered (by then referring to himself in correspondence as "A. G. Bell") and served the next year as an instructor at Somerset College, Bath, England, his brother's condition deteriorated. Edward would never recover. Upon his brother's death, Bell returned home in 1867. His older brother Melville had married and moved out. With aspirations to obtain a degree at University College London, Bell considered his next years as preparation for the degree examinations, devoting his spare time at his family's residence to studying.

Helping his father in Visible Speech demonstrations and lectures brought Bell to Susanna E. Hull's private school for the deaf in South Kensington, London. His first two pupils were deaf-mute girls who made remarkable progress under his tutelage. While his older brother seemed to achieve success on many fronts including opening his own elocution school, applying for a patent on an invention, and starting a family, Bell continued as a teacher. However, in May 1870, Melville died from complications due to tuberculosis, causing a family crisis. His father had also suffered a debilitating illness earlier in life and had been restored to health by a convalescence in Newfoundland. Bell's parents embarked upon a long-planned move when they realized that their remaining son was also sickly. Acting decisively, Alexander Melville Bell asked Bell to arrange for the sale of all the family property, conclude all of his brother's affairs (Bell took over his last student, curing a pronounced lisp), and join his father and mother in setting out for the "New World

In 1870, aged 23, Bell, together with Bell's brother's widow, Caroline Margaret Ottaway, and his parents travelled on the SS "Nestorian" to Canada. After landing at Quebec City, the Bells transferred to another steamer to Montreal and then boarded a train to Paris, Ontario, to stay with the Reverend Thomas Henderson, a family friend. After a brief stay with the Hendersons, the Bell family purchased a farm of at Tutelo Heights (now called Tutela Heights), near Brantford, Ontario. The property consisted of an orchard, large farmhouse, stable, pigsty, hen-house, and a carriage house, which bordered the Grand River.

At the homestead, Bell set up his own workshop in the converted carriage house near to what he called his "dreaming place", a large hollow nestled in trees at the back of the property above the river. Despite his frail condition upon arriving in Canada, Bell found the climate and environs to his liking, and rapidly improved. He continued his interest in the study of the human voice and when he discovered the Six Nations Reserve across the river at Onondaga, he learned the Mohawk language and translated its unwritten vocabulary into Visible Speech symbols. For his work, Bell was awarded the title of Honorary Chief and participated in a ceremony where he donned a Mohawk headdress and danced traditional dances.

After setting up his workshop, Bell continued experiments based on Helmholtz's work with electricity and sound. He also modified a melodeon
Bell's father was invited by Sarah Fuller, principal of the Boston School for Deaf Mutes (which continues today as the public Horace Mann School for the Deaf), in Boston, Massachusetts, United States, to introduce the Visible Speech System by providing training for Fuller's instructors, but he declined the post in favour of his son. Travelling to Boston in April 1871, Bell proved successful in training the school's instructors. He was subsequently asked to repeat the programme at the American Asylum for Deaf-mutes in Hartford, Connecticut, and the Clarke School for the Deaf in Northampton, Massachusetts.

Returning home to Brantford after six months abroad, Bell continued his experiments with his "harmonic telegraph". The basic concept behind his device was that messages could be sent through a single wire if each message was transmitted at a different pitch, but work on both the transmitter and receiver was needed.

Unsure of his future, he first contemplated returning to London to complete his studies, but decided to return to Boston as a teacher. His father helped him set up his private practice by contacting Gardiner Greene Hubbard, the president of the Clarke School for the Deaf for a recommendation. Teaching his father's system, in October 1872, Alexander Bell opened his "School of Vocal Physiology and Mechanics of Speech" in Boston, which attracted a large number of deaf pupils, with his first class numbering 30 students. While he was working as a private tutor, one of his pupils was Helen Keller, who came to him as a young child unable to see, hear, or speak. She was later to say that Bell dedicated his life to the penetration of that "inhuman silence which separates and estranges". In 1893, Keller performed the sod-breaking ceremony for the construction of Bell's new Volta Bureau, dedicated to "the increase and diffusion of knowledge relating to the deaf".

Several influential people of the time, including Bell, viewed deafness as something that should be eradicated, and also believed that with resources and effort, they could teach the deaf to speak and avoid the use of sign language, thus enabling their integration within the wider society from which many were often being excluded. Owing to his efforts to suppress the teaching of sign language, Bell is often viewed negatively by those embracing Deaf culture.

In the following year, Bell became professor of Vocal Physiology and Elocution at the Boston University School of Oratory. During this period, he alternated between Boston and Brantford, spending summers in his Canadian home. At Boston University, Bell was "swept up" by the excitement engendered by the many scientists and inventors residing in the city. He continued his research in sound and endeavored to find a way to transmit musical notes and articulate speech, but although absorbed by his experiments, he found it difficult to devote enough time to experimentation. While days and evenings were occupied by his teaching and private classes, Bell began to stay awake late into the night, running experiment after experiment in rented facilities at his boarding house. Keeping "night owl" hours, he worried that his work would be discovered and took great pains to lock up his notebooks and laboratory equipment. Bell had a specially made table where he could place his notes and equipment inside a locking cover. Worse still, his health deteriorated as he suffered severe headaches. Returning to Boston in fall 1873, Bell made a fateful decision to concentrate on his experiments in sound.

Deciding to give up his lucrative private Boston practice, Bell retained only two students, six-year-old "Georgie" Sanders, deaf from birth, and 15-year-old Mabel Hubbard. Each pupil would play an important role in the next developments. George's father, Thomas Sanders, a wealthy businessman, offered Bell a place to stay in nearby Salem with Georgie's grandmother, complete with a room to "experiment". Although the offer was made by George's mother and followed the year-long arrangement in 1872 where her son and his nurse had moved to quarters next to Bell's boarding house, it was clear that Mr. Sanders was backing the proposal. The arrangement was for teacher and student to continue their work together, with free room and board thrown in. Mabel was a bright, attractive girl who was ten years Bell's junior but became the object of his affection. Having lost her hearing after a near-fatal bout of scarlet fever close to her fifth birthday, she had learned to read lips but her father, Gardiner Greene Hubbard, Bell's benefactor and personal friend, wanted her to work directly with her teacher.

By 1874, Bell's initial work on the harmonic telegraph had entered a formative stage, with progress made both at his new Boston "laboratory" (a rented facility) and at his family home in Canada a big success. While working that summer in Brantford, Bell experimented with a "phonautograph", a pen-like machine that could draw shapes of sound waves on smoked glass by tracing their vibrations. Bell thought it might be possible to generate undulating electrical currents that corresponded to sound waves. Bell also thought that multiple metal reeds tuned to different frequencies like a harp would be able to convert the undulating currents back into sound. But he had no working model to demonstrate the feasibility of these ideas.

In 1874, telegraph message traffic was rapidly expanding and in the words of Western Union President William Orton, had become "the nervous system of commerce". Antonio Meucci sent a telephone model and technical details to the Western Union telegraph company but failed to win a meeting with executives. When he asked for his materials to be returned, in 1874, he was told they had been lost. Two years later Bell, who shared a laboratory with Meucci, filed a patent for a telephone, became a celebrity and made a lucrative deal with Western Union. Meucci sued and was nearing victory - the supreme court agreed to hear the case and fraud charges were initiated against Bell - when the Florentine died in 1889. The legal action died with him. Orton had contracted with inventors Thomas Edison and Elisha Gray to find a way to send multiple telegraph messages on each telegraph line to avoid the great cost of constructing new lines. When Bell mentioned to Gardiner Hubbard and Thomas Sanders that he was working on a method of sending multiple tones on a telegraph wire using a multi-reed device, the two wealthy patrons began to financially support Bell's experiments. Patent matters would be handled by Hubbard's patent attorney, Anthony Pollok.

In March 1875, Bell and Pollok visited the scientist Joseph Henry, who was then director of the Smithsonian Institution, and asked Henry's advice on the electrical multi-reed apparatus that Bell hoped would transmit the human voice by telegraph. Henry replied that Bell had "the germ of a great invention". When Bell said that he did not have the necessary knowledge, Henry replied, "Get it!" That declaration greatly encouraged Bell to keep trying, even though he did not have the equipment needed to continue his experiments, nor the ability to create a working model of his ideas. However, a chance meeting in 1874 between Bell and Thomas A. Watson, an experienced electrical designer and mechanic at the electrical machine shop of Charles Williams, changed all that.

With financial support from Sanders and Hubbard, Bell hired Thomas Watson as his assistant, and the two of them experimented with acoustic telegraphy. On June 2, 1875, Watson accidentally plucked one of the reeds and Bell, at the receiving end of the wire, heard the overtones of the reed; overtones that would be necessary for transmitting speech. That demonstrated to Bell that only one reed or armature was necessary, not multiple reeds. This led to the "gallows" sound-powered telephone, which could transmit indistinct, voice-like sounds, but not clear speech.

In 1875, Bell developed an acoustic telegraph and drew up a patent application for it. Since he had agreed to share U.S. profits with his investors Gardiner Hubbard and Thomas Sanders, Bell requested that an associate in Ontario, George Brown

Meanwhile, Elisha Gray was also experimenting with acoustic telegraphy and thought of a way to transmit speech using a water transmitter. On February 14, 1876, Gray filed a caveat with the U.S. Patent Office for a telephone design that used a water transmitter. That same morning, Bell's lawyer filed Bell's application with the patent office. There is considerable debate about who arrived first and Gray later challenged the primacy of Bell's patent. Bell was in Boston on February 14 and did not arrive in Washington until February 26.

Bell's patent 174,465, was issued to Bell on March 7, 1876, by the U.S. Patent Office. Bell's patent covered "the method of, and apparatus for, transmitting vocal or other sounds telegraphically ... by causing electrical undulations, similar in form to the vibrations of the air accompanying the said vocal or other sound" Bell returned to Boston the same day and the next day resumed work, drawing in his notebook a diagram similar to that in Gray's patent caveat.

On March 10, 1876, three days after his patent was issued, Bell succeeded in getting his telephone to work, using a liquid transmitter similar to Gray's design. Vibration of the diaphragm caused a needle to vibrate in the water, varying the electrical resistance in the circuit. When Bell spoke the sentence "Mr. Watson—Come here—I want to see you" into the liquid transmitter, Watson, listening at the receiving end in an adjoining room, heard the words clearly.

Although Bell was, and still is, accused of stealing the telephone from Gray, Bell used Gray's water transmitter design only after Bell's patent had been granted, and only as a proof of concept scientific experiment, to prove to his own satisfaction that intelligible "articulate speech" (Bell's words) could be electrically transmitted. After March 1876, Bell focused on improving the electromagnetic telephone and never used Gray's liquid transmitter in public demonstrations or commercial use.

The question of priority for the variable resistance feature of the telephone was raised by the examiner before he approved Bell's patent application. He told Bell that his claim for the variable resistance feature was also described in Gray's caveat. Bell pointed to a variable resistance device in Bell's previous application in which Bell described a cup of mercury, not water. Bell had filed the mercury application at the patent office a year earlier on February 25, 1875, long before Elisha Gray described the water device. In addition, Gray abandoned his caveat, and because he did not contest Bell's priority, the examiner approved Bell's patent on March 3, 1876. Gray had reinvented the variable resistance telephone, but Bell was the first to write down the idea and the first to test it in a telephone.

The patent examiner, Zenas Fisk Wilber, later stated in an affidavit that he was an alcoholic who was much in debt to Bell's lawyer, Marcellus Bailey, with whom he had served in the Civil War. He claimed he showed Gray's patent caveat to Bailey. Wilber also claimed (after Bell arrived in Washington D.C. from Boston) that he showed Gray's caveat to Bell and that Bell paid him $100 (). Bell claimed they discussed the patent only in general terms, although in a letter to Gray, Bell admitted that he learned some of the technical details. Bell denied in an affidavit that he ever gave Wilber any money.

Continuing his experiments in Brantford, Bell brought home a working model of his telephone. On August 3, 1876, from the telegraph office in Mount Pleasant
Bell and his partners, Hubbard and Sanders, offered to sell the patent outright to Western Union for $100,000. The president of Western Union balked, countering that the telephone was nothing but a toy. Two years later, he told colleagues that if he could get the patent for $25 million he would consider it a bargain. By then, the Bell company no longer wanted to sell the patent. Bell's investors would become millionaires while he fared well from residuals and at one point had assets of nearly one million dollars.

Bell began a series of public demonstrations and lectures to introduce the new invention to the scientific community as well as the general public. A short time later, his demonstration of an early telephone prototype at the 1876 Centennial Exposition in Philadelphia brought the telephone to international attention. Influential visitors to the exhibition included Emperor Pedro II of Brazil. Later, Bell had the opportunity to demonstrate the invention personally to Sir William Thomson (later, Lord Kelvin), a renowned Scottish scientist, as well as to Queen Victoria, who had requested a private audience at Osborne House, her Isle of Wight home. She called the demonstration "most extraordinary". The enthusiasm surrounding Bell's public displays laid the groundwork for universal acceptance of the revolutionary device.

The Bell Telephone Company was created in 1877, and by 1886, more than 150,000 people in the U.S. owned telephones. Bell Company engineers made numerous other improvements to the telephone, which emerged as one of the most successful products ever. In 1879, the Bell company acquired Edison's patents for the carbon microphone from Western Union. This made the telephone practical for longer distances, and it was no longer necessary to shout to be heard at the receiving telephone.

Emperor Pedro II of Brazil was the first person to buy stock in Bell's company, the Bell Telephone Company. One of the first telephones in a private residence was installed in his palace in Petrópolis, his summer retreat forty miles from Rio de Janeiro.

In January 1915, Bell made the first ceremonial transcontinental telephone call. Calling from the AT&T head office at 15 Dey Street in New York City, Bell was heard by Thomas Watson at 333 Grant Avenue in San Francisco. The "New York Times" reported:

As is sometimes common in scientific discoveries, simultaneous developments can occur, as evidenced by a number of inventors who were at work on the telephone. Over a period of 18 years, the Bell Telephone Company faced 587 court challenges to its patents, including five that went to the U.S. Supreme Court, but none was successful in establishing priority over the original Bell patent and the Bell Telephone Company never lost a case that had proceeded to a final trial stage. Bell's laboratory notes and family letters were the key to establishing a long lineage to his experiments. The Bell company lawyers successfully fought off myriad lawsuits generated initially around the challenges by Elisha Gray and Amos Dolbear. In personal correspondence to Bell, both Gray and Dolbear had acknowledged his prior work, which considerably weakened their later claims.

On January 13, 1887, the U.S. Government moved to annul the patent issued to Bell on the grounds of fraud and misrepresentation. After a series of decisions and reversals, the Bell company won a decision in the Supreme Court, though a couple of the original claims from the lower court cases were left undecided. By the time that the trial wound its way through nine years of legal battles, the U.S. prosecuting attorney had died and the two Bell patents (No. 174,465 dated March 7, 1876, and No. 186,787 dated January 30, 1877) were no longer in effect, although the presiding judges agreed to continue the proceedings due to the case's importance as a precedent. With a change in administration and charges of conflict of interest (on both sides) arising from the original trial, the US Attorney General dropped the lawsuit on November 30, 1897, leaving several issues undecided on the merits.

During a deposition filed for the 1887 trial, Italian inventor Antonio Meucci also claimed to have created the first working model of a telephone in Italy in 1834. In 1886, in the first of three cases in which he was involved, Meucci took the stand as a witness in the hopes of establishing his invention's priority. Meucci's testimony in this case was disputed due to a lack of material evidence for his inventions, as his working models were purportedly lost at the laboratory of American District Telegraph (ADT) of New York, which was later incorporated as a subsidiary of Western Union in 1901. Meucci's work, like many other inventors of the period, was based on earlier acoustic principles and despite evidence of earlier experiments, the final case involving Meucci was eventually dropped upon Meucci's death. However, due to the efforts of Congressman Vito Fossella, the U.S. House of Representatives on June 11, 2002, stated that Meucci's "work in the invention of the telephone should be acknowledged". This did not put an end to the still-contentious issue. Some modern scholars do not agree with the claims that Bell's work on the telephone was influenced by Meucci's inventions.

The value of the Bell patent was acknowledged throughout the world, and patent applications were made in most major countries, but when Bell delayed the German patent application, the electrical firm of Siemens & Halske (S&H) set up a rival manufacturer of Bell telephones under their own patent. The Siemens company produced near-identical copies of the Bell telephone without having to pay royalties. The establishment of the International Bell Telephone Company

On July 11, 1877, a few days after the Bell Telephone Company was established, Bell married Mabel Hubbard (1857–1923) at the Hubbard estate in Cambridge, Massachusetts. His wedding present to his bride was to turn over 1,487 of his 1,497 shares in the newly formed Bell Telephone Company. Shortly thereafter, the newlyweds embarked on a year-long honeymoon in Europe. During that excursion, Bell took a handmade model of his telephone with him, making it a "working holiday". The courtship had begun years earlier; however, Bell waited until he was more financially secure before marrying. Although the telephone appeared to be an "instant" success, it was not initially a profitable venture and Bell's main sources of income were from lectures until after 1897. One unusual request exacted by his fiancée was that he use "Alec" rather than the family's earlier familiar name of "Aleck". From 1876, he would sign his name "Alec Bell". They had four children:
The Bell family home was in Cambridge, Massachusetts, until 1880 when Bell's father-in-law bought a house in Washington, D.C.; in 1882 he bought a home in the same city for Bell's family, so they could be with him while he attended to the numerous court cases involving patent disputes.

Bell was a British subject throughout his early life in Scotland and later in Canada until 1882 when he became a naturalized citizen of the United States. In 1915, he characterized his status as: "I am not one of those hyphenated Americans who claim allegiance to two countries." Despite this declaration, Bell has been proudly claimed as a "native son" by all three countries he resided in: the United States, Canada, and the United Kingdom.

By 1885, a new summer retreat was contemplated. That summer, the Bells had a vacation on Cape Breton Island in Nova Scotia, spending time at the small village of Baddeck. Returning in 1886, Bell started building an estate on a point across from Baddeck, overlooking Bras d'Or Lake. By 1889, a large house, christened "The Lodge" was completed and two years later, a larger complex of buildings, including a new laboratory, were begun that the Bells would name Beinn Bhreagh (Gaelic: "beautiful mountain") after Bell's ancestral Scottish highlands. Bell also built the Bell Boatyard on the estate, employing up to 40 people building experimental craft as well as wartime lifeboats and workboats for the Royal Canadian Navy and pleasure craft for the Bell family. He was an enthusiastic boater, and Bell and his family sailed or rowed a long series of vessels on Bras d'Or Lake, ordering additional vessels from the H.W. Embree and Sons boatyard in Port Hawkesbury, Nova Scotia. In his final, and some of his most productive years, Bell split his residency between Washington, D.C., where he and his family initially resided for most of the year, and Beinn Bhreagh, where they spent increasing amounts of time.

Until the end of his life, Bell and his family would alternate between the two homes, but "Beinn Bhreagh" would, over the next 30 years, become more than a summer home as Bell became so absorbed in his experiments that his annual stays lengthened. Both Mabel and Bell became immersed in the Baddeck community and were accepted by the villagers as "their own". The Bells were still in residence at "Beinn Bhreagh" when the Halifax Explosion
Although Alexander Graham Bell is most often associated with the invention of the telephone, his interests were extremely varied. According to one of his biographers, Charlotte Gray, Bell's work ranged "unfettered across the scientific landscape" and he often went to bed voraciously reading the "Encyclopædia Britannica", scouring it for new areas of interest. The range of Bell's inventive genius is represented only in part by the 18 patents granted in his name alone and the 12 he shared with his collaborators. These included 14 for the telephone and telegraph, four for the photophone, one for the phonograph, five for aerial vehicles, four for "hydroairplanes", and two for selenium cells. Bell's inventions spanned a wide range of interests and included a metal jacket to assist in breathing, the audiometer to detect minor hearing problems, a device to locate icebergs, investigations on how to separate salt from seawater, and work on finding alternative fuels.

Bell worked extensively in medical research and invented techniques for teaching speech to the deaf. During his Volta Laboratory period, Bell and his associates considered impressing a magnetic field on a record as a means of reproducing sound. Although the trio briefly experimented with the concept, they could not develop a workable prototype. They abandoned the idea, never realizing they had glimpsed a basic principle which would one day find its application in the tape recorder, the hard disc and floppy disc drive, and other magnetic media.

Bell's own home used a primitive form of air conditioning, in which fans blew currents of air across great blocks of ice. He also anticipated modern concerns with fuel shortages and industrial pollution. Methane gas, he reasoned, could be produced from the waste of farms and factories. At his Canadian estate in Nova Scotia, he experimented with composting toilets and devices to capture water from the atmosphere. In a magazine interview published shortly before his death, he reflected on the possibility of using solar panels

Bell and his assistant Charles Sumner Tainter jointly invented a wireless telephone, named a photophone, which allowed for the transmission of both sounds and normal human conversations on a beam of light. Both men later became full associates in the Volta Laboratory Association.

On June 21, 1880, Bell's assistant transmitted a wireless voice telephone message a considerable distance, from the roof of the Franklin School in Washington, D.C., to Bell at the window of his laboratory, some away, 19 years before the first voice radio transmissions.

Bell believed the photophone's principles were his life's "greatest achievement", telling a reporter shortly before his death that the photophone was "the greatest invention [I have] ever made, greater than the telephone". The photophone was a precursor to the fiber-optic communication

Bell is also credited with developing one of the early versions of a metal detector in 1881. The device was quickly put together in an attempt to find the bullet in the body of U.S. President James Garfield. According to some accounts, the metal detector worked flawlessly in tests but did not find the assassin's bullet partly because the metal bed frame on which the President was lying disturbed the instrument, resulting in static. The president's surgeons, who were skeptical of the device, ignored Bell's requests to move the president to a bed not fitted with metal springs. Alternatively, although Bell had detected a slight sound on his first test, the bullet may have been lodged too deeply to be detected by the crude apparatus.

Bell's own detailed account, presented to the American Association for the Advancement of Science

The March 1906 "Scientific American" article by American pioneer William E. Meacham explained the basic principle of hydrofoils and hydroplanes. Bell considered the invention of the hydroplane as a very significant achievement. Based on information gained from that article, he began to sketch concepts of what is now called a hydrofoil boat. Bell and assistant Frederick W. "Casey" Baldwin began hydrofoil experimentation in the summer of 1908 as a possible aid to airplane takeoff from water. Baldwin studied the work of the Italian inventor Enrico Forlanini and began testing models. This led him and Bell to the development of practical hydrofoil watercraft.

During his world tour of 1910–11, Bell and Baldwin met with Forlanini in France. They had rides in the Forlanini hydrofoil boat over Lake Maggiore. Baldwin described it as being as smooth as flying. On returning to Baddeck, a number of initial concepts were built as experimental models, including the "Dhonnas Beag" (Scottish Gaelic for "little devil"), the first self-propelled Bell-Baldwin hydrofoil. The experimental boats were essentially proof-of-concept prototypes that culminated in the more substantial HD-4, powered by Renault engines. A top speed of was achieved, with the hydrofoil exhibiting rapid acceleration, good stability, and steering, along with the ability to take waves without difficulty. In 1913, Dr. Bell hired Walter Pinaud, a Sydney yacht designer and builder as well as the proprietor of Pinaud's Yacht Yard in Westmount, Nova Scotia to work on the pontoons of the HD-4. Pinaud soon took over the boatyard at Bell Laboratories on Beinn Bhreagh, Bell's estate near Baddeck, Nova Scotia. Pinaud's experience in boat-building enabled him to make useful design changes to the HD-4. After the First World War, work began again on the HD-4. Bell's report to the U.S. Navy

In 1891, Bell had begun experiments to develop motor-powered heavier-than-air aircraft. The AEA was first formed as Bell shared the vision to fly with his wife, who advised him to seek "young" help as Bell was at the age of 60.

In 1898, Bell experimented with tetrahedral box kites and wings constructed of multiple compound tetrahedral kites covered in maroon silk. The tetrahedral wings were named "Cygnet" I, II, and III, and were flown both unmanned and manned ("Cygnet I" crashed during a flight carrying Selfridge) in the period from 1907–1912. Some of Bell's kites are on display at the Alexander Graham Bell National Historic Site.

Bell was a supporter of aerospace engineering research through the Aerial Experiment Association (AEA), officially formed at Baddeck, Nova Scotia, in October 1907 at the suggestion of his wife Mabel and with her financial support after the sale of some of her real estate. The AEA was headed by Bell and the founding members were four young men: American Glenn H. Curtiss, a motorcycle manufacturer at the time and who held the title "world's fastest man", having ridden his self-constructed motor bicycle around in the shortest time, and who was later awarded the Scientific American Trophy for the first official one-kilometre flight in the Western hemisphere, and who later became a world-renowned airplane manufacturer; Lieutenant Thomas Selfridge, an official observer from the U.S. Federal government and one of the few people in the army who believed that aviation was the future; Frederick W. Baldwin, the first Canadian and first British subject to pilot a public flight in Hammondsport, New York; and J. A .D. McCurdy–Baldwin and McCurdy being new engineering graduates from the University of Toronto.

The AEA's work progressed to heavier-than-air machines, applying their knowledge of kites to gliders. Moving to Hammondsport, the group then designed and built the "Red Wing", framed in bamboo and covered in red silk and powered by a small air-cooled engine. On March 12, 1908, over Keuka Lake, the biplane lifted off on the first public flight in North America. The innovations that were incorporated into this design included a cockpit enclosure and tail rudder (later variations on the original design would add ailerons as a means of control). One of the AEA's inventions, a practical wingtip form of the aileron, was to become a standard component on all aircraft. The "White Wing" and "June Bug" were to follow and by the end of 1908, over 150 flights without mishap had been accomplished. However, the AEA had depleted its initial reserves and only a $15,000 grant from Mrs. Bell allowed it to continue with experiments. Lt. Selfridge had also become the first person killed in a powered heavier-than-air flight in a crash of the Wright Flyer at Fort Myer, Virginia, on September 17, 1908.

Their final aircraft design, the "Silver Dart", embodied all of the advancements found in the earlier machines. On February 23, 1909, Bell was present as the "Silver Dart" flown by J. A. D. McCurdy from the frozen ice of Bras d'Or made the first aircraft flight in Canada. Bell had worried that the flight was too dangerous and had arranged for a doctor to be on hand. With the successful flight, the AEA disbanded and the "Silver Dart" would revert to Baldwin and McCurdy, who began the Canadian Aerodrome Company and would later demonstrate the aircraft to the Canadian Army.

Bell was connected with the eugenics movement in the United States. In his lecture "Memoir upon the formation of a deaf variety of the human race" presented to the National Academy of Sciences on November 13, 1883, he noted that congenitally deaf parents were more likely to produce deaf children and tentatively suggested that couples where both parties were deaf should not marry. However, it was his hobby of livestock breeding which led to his appointment to biologist David Starr Jordan's Committee on Eugenics, under the auspices of the American Breeders' Association. The committee unequivocally extended the principle to humans. From 1912 until 1918, he was the chairman of the board of scientific advisers to the Eugenics Record Office associated with Cold Spring Harbor Laboratory in New York, and regularly attended meetings. In 1921, he was the honorary president of the Second International Congress of Eugenics held under the auspices of the American Museum of Natural History in New York. Organizations such as these advocated passing laws (with success in some states) that established the compulsory sterilization of people deemed to be, as Bell called them, a "defective variety of the human race". By the late 1930s, about half the states in the U.S. had eugenics laws, and California's compulsory sterilization law was used as a model for that of Nazi Germany

Honors and tributes flowed to Bell in increasing numbers as his invention became ubiquitous and his personal fame grew. Bell received numerous honorary degrees from colleges and universities to the point that the requests almost became burdensome. During his life, he also received dozens of major awards, medals, and other tributes. These included statuary monuments to both him and the new form of communication his telephone created, including the Bell Telephone Memorial erected in his honor in "Alexander Graham Bell Gardens" in Brantford
A large number of Bell's writings, personal correspondence, notebooks, papers, and other documents reside in both the United States Library of Congress Manuscript Division (as the "Alexander Graham Bell Family Papers"), and at the Alexander Graham Bell Institute, Cape Breton University, Nova Scotia; major portions of which are available for online viewing.

A number of historic sites and other marks commemorate Bell in North America and Europe, including the first telephone companies in the United States and Canada. Among the major sites are:

In 1880, Bell received the Volta Prize with a purse of 50,000 French francs (approximately US$ in today's dollars) for the invention of the telephone from the French government. Among the luminaries who judged were Victor Hugo and Alexandre Dumas, "fils". The Volta Prize was conceived by Napoleon III in 1852, and named in honor of Alessandro Volta, with Bell becoming the second recipient of the grand prize in its history. Since Bell was becoming increasingly affluent, he used his prize money to create endowment funds (the 'Volta Fund') and institutions in and around the United States capital of Washington, D.C.. These included the prestigious" 'Volta Laboratory Association' "(1880), also known as the" Volta Laboratory "and as the" 'Alexander Graham Bell Laboratory', "and which eventually led to the Volta Bureau (1887) as a center for studies on deafness which is still in operation in Georgetown, Washington, D.C. The Volta Laboratory became an experimental facility devoted to scientific discovery, and the very next year it improved Edison's phonograph by substituting wax for tinfoil as the recording medium and incising the recording rather than indenting it, key upgrades that Edison himself later adopted. The laboratory was also the site where he and his associate invented his "proudest achievement", "the photophone", the "optical telephone" which presaged fibre optical telecommunications while the Volta Bureau would later evolve into the Alexander Graham Bell Association for the Deaf and Hard of Hearing (the AG Bell), a leading center for the research and pedagogy of deafness.

In partnership with Gardiner Greene Hubbard, Bell helped establish the publication "Science" during the early 1880s. In 1898, Bell was elected as the second president of the National Geographic Society, serving until 1903, and was primarily responsible for the extensive use of illustrations, including photography, in the magazine. He also served for many years as a Regent of the Smithsonian Institution (1898–1922). The French government conferred on him the decoration of the Légion d'honneur (Legion of Honor); the Royal Society of Arts in London awarded him the Albert Medal in 1902; the University of Würzburg, Bavaria, granted him a PhD, and he was awarded the Franklin Institute's Elliott Cresson Medal in 1912. He was one of the founders of the American Institute of Electrical Engineers in 1884 and served as its president from 1891–92. Bell was later awarded the AIEE's Edison Medal in 1914 "For meritorious achievement in the invention of the telephone".

The "bel" (B) and the smaller "decibel" (dB) are units of measurement of power level invented by Bell Labs and named after him. Since 1976, the IEEE's Alexander Graham Bell Medal

In 1936, the US Patent Office declared Bell first on its list of the country's greatest inventors, leading to the US Post Office issuing a commemorative stamp honoring Bell in 1940 as part of its 'Famous Americans Series'. The First Day of Issue ceremony was held on October 28 in Boston, Massachusetts, the city where Bell spent considerable time on research and working with the deaf. The Bell stamp became very popular and sold out in little time. The stamp became, and remains to this day, the most valuable one of the series.

The 150th anniversary of Bell's birth in 1997 was marked by a special issue of commemorative £1 banknotes from the Royal Bank of Scotland. The illustrations on the reverse of the note include Bell's face in profile, his signature, and objects from Bell's life and career: users of the telephone over the ages; an audio wave signal; a diagram of a telephone receiver; geometric shapes from engineering structures; representations of sign language and the phonetic alphabet; the geese which helped him to understand flight; and the sheep which he studied to understand genetics. Additionally, the Government of Canada honored Bell in 1997 with a C$100 gold coin, in tribute also to the 150th anniversary of his birth, and with a silver dollar coin in 2009 in honor of the 100th anniversary of flight in Canada. That first flight was made by an airplane designed under Dr. Bell's tutelage, named the Silver Dart. Bell's image, and also those of his many inventions have graced paper money, coinage, and postal stamps in numerous countries worldwide for many dozens of years.

Alexander Graham Bell was ranked 57th among the 100 Greatest Britons (2002) in an official BBC nationwide poll, and among the Top Ten Greatest Canadians (2004), and the 100 Greatest Americans (2005). In 2006, Bell was also named as one of the 10 greatest Scottish scientists in history after having been listed in the National Library of Scotland

Alexander Graham Bell, who could not complete the university program of his youth, received at least a dozen honorary degrees from academic institutions, including eight honorary LL.D.s (Doctorate of Laws), two Ph.D.s, a D.Sc., and an M.D.:


Bell died of complications arising from diabetes on August 2, 1922, at his private estate in Cape Breton, Nova Scotia, at age 75. Bell had also been afflicted with pernicious anemia. His last view of the land he had inhabited was by moonlight on his mountain estate at 2:00 a.m. While tending to him after his long illness, Mabel, his wife, whispered, "Don't leave me." By way of reply, Bell signed "no...", lost consciousness, and died shortly after.

On learning of Bell's death, the Canadian Prime Minister, Mackenzie King, cabled Mrs. Bell, saying:
Bell's coffin was constructed of Beinn Bhreagh pine by his laboratory staff, lined with the same red silk fabric used in his tetrahedral kite experiments. To help celebrate his life, his wife asked guests not to wear black (the traditional funeral color) while attending his service, during which soloist Jean MacDonald sang a verse of Robert Louis Stevenson's "Requiem":

Upon the conclusion of Bell's funeral, "every phone on the continent of North America was silenced in honor of the man who had given to mankind the means for direct communication at a distance".

Dr. Alexander Graham Bell was buried atop Beinn Bhreagh mountain, on his estate where he had resided increasingly for the last 35 years of his life, overlooking Bras d'Or Lake. He was survived by his wife Mabel, his two daughters, Elsie May and Marian, and nine of his grandchildren.




Category:1847 births
Category:1922 deaths
Category:19th-century Scottish scientists
Category:Alumni of the University of Edinburgh
Category:Alumni of University College London
Category:American agnostics
Category:American educational theorists
Category:American eugenicists
Category:American physicists
Category:American Unitarians
Category:Aviation pioneers
Category:Canadian agnostics
Category:Canadian Aviation Hall of Fame inductees
Category:Canadian emigrants to the United States
Category:Canadian eugenicists
Category:Canadian inventors
Category:Canadian physicists
Category:Canadian Unitarians
Category:Deaths from diabetes
Category:Fellows of the American Academy of Arts and Sciences
Category:History of telecommunications
Category:IEEE Edison Medal recipients
Category:Language teachers
Category:Members of the American Philosophical Society
Category:Members of the American Antiquarian Society
Category:Members of the United States National Academy of Sciences
Category:National Aviation Hall of Fame inductees
Category:National Geographic Society
Category:Officiers of the Légion d'honneur
Category:People educated at the Royal High School, Edinburgh
Category:People from Baddeck, Nova Scotia
Category:Businesspeople from Boston
Category:People from Brantford
Category:People from Edinburgh
Category:People from Washington, D.C.
Category:Scottish agnostics
Category:Scottish businesspeople
Category:Scottish emigrants to Canada
Category:Scottish eugenicists
Category:Scottish inventors
Category:Scottish Unitarians
Category:Smithsonian Institution people
Category:Hall of Fame for Great Americans inductees
Category:George Washington University trustees
Category:Canadian activists
Category:Gardiner family
Category:Articles containing video clips
Category:Cosmos Club members
Category:19th-century inventors
Category:Scottish emigrants to the United States
Category:John Fritz Medal recipients
Category:National Inventors Hall of Fame inductees
Category:20th-century American scientists
Category:20th-century American inventors
Category:Canadian educational theorists
Category:Scottish physicists
Category:19th-century Canadian scientists
Category:20th-century Scottish scientists
Category:20th-century Canadian scientistsAnatolia

Anatolia (from Greek '; "east" or "[sun]rise"), also known as Asia Minor (Medieval and Modern Greek: ', "small Asia"; ), Asian Turkey, the Anatolian peninsula, or the Anatolian plateau, is the westernmost protrusion of Asia, which makes up the majority of modern-day Turkey. The region is bounded by the Black Sea to the north, the Mediterranean Sea to the south, the Armenian Highlands to the east, and the Aegean Sea to the west. The Sea of Marmara forms a connection between the Black and Aegean Seas through the Bosphorus and Dardanelles straits and separates Anatolia from Thrace on the European mainland.

The eastern border of Anatolia is traditionally held to be a line between the Gulf of Alexandretta and the Black Sea, bounded by the Armenian Highland to the east and Mesopotamia to the southeast. Thus, traditionally Anatolia is the territory that comprises approximately the western two-thirds of the Asian part of Turkey. Nowadays, Anatolia is also often considered to be synonymous with Asian Turkey, which comprises almost the entire country; its eastern and southeastern borders are widely taken to be Turkey's eastern border. By some definitions, the area called the Armenian highlands lies beyond the boundary of the Anatolian plateau. The official name of this inland region is the Eastern Anatolia Region.

The ancient inhabitants of Anatolia spoke the now-extinct Anatolian languages, which were largely replaced by the Greek language starting from classical antiquity and during the Hellenistic, Roman and Byzantine periods. Major Anatolian languages included Hittite, Luwian, and Lydian among other more poorly attested relatives. The Turkification of Anatolia began under the Seljuk Empire in the late 11th century and continued under the Ottoman Empire between the late 13th and early 20th centuries. However, various non-Turkic languages continue to be spoken by minorities in Anatolia today, including Kurdish, Neo-Aramaic, Armenian, Arabic, Laz, Georgian and Greek. Other ancient peoples in the region included Galatians, Hurrians, Assyrians, Hattians, Cimmerians, as well as Ionian, Dorian, and Aeolian Greeks

Traditionally, Anatolia is considered to extend in the east to an indefinite line running from the Gulf of Alexandretta to the Black Sea, coterminous with the Anatolian Plateau. This traditional geographical definition is used, for example, in the latest edition of "Merriam-Webster's Geographical Dictionary", Under this definition, Anatolia is bounded to the east by the Armenian Highlands, and the Euphrates before that river bends to the southeast to enter Mesopotamia. To the southeast, it is bounded by the ranges that separate it from the Orontes valley in Syria (region) and the Mesopotamian plain.

Following the Armenian genocide, Ottoman Armenia was renamed "Eastern Anatolia" by the newly established Turkish government. Vazken Davidian terms the expanded use of "Anatolia" to apply to territory formerly referred to as Armenia an "ahistorical imposition", and notes that a growing body of literature is uncomfortable with referring to the Ottoman East as "Eastern Anatolia". Most archeological sources consider the boundary of Anatolia to be Turkey's eastern border.

The highest mountains in Anatolia are Mount Süphan (4058 m) and Mount Ararat (5123 m). The Euphrates, Araxes Karasu and Murat rivers connect the Anatolian plateau to the South Caucasus and the Upper Euphrates Valley. Along with the Çoruh, these rivers are the longest in Anatolia.

The oldest known reference to Anatolia – as “Land of the Hatti” – appears on Mesopotamian cuneiform tablets from the period of the Akkadian Empire (2350–2150 BC). The first recorded name the Greeks used for the Anatolian peninsula, Ἀσία (Asía), presumably echoed the name of the Assuwa league in western Anatolia. As the name "Asia" broadened its scope to apply to other areas east of the Mediterranean, Greeks in Late Antiquity came to use the name Μικρὰ Ἀσία ("Mikrá Asía") or Asia Minor, meaning "Lesser Asia" to refer to present-day Anatolia.

The English-language name "Anatolia" itself derives from the Greek ("") meaning “the East” or more literally “sunrise” (comparable to the Latin-derived terms "levant" and "orient"). The precise reference of this term has varied over time, perhaps originally referring to the Aeolian, Ionian and Dorian colonies on the west coast of Asia Minor. In the Byzantine Empire, the Anatolic Theme (Ἀνατολικόν θέμα) was a "theme" covering the western and central parts of Turkey's present-day Central Anatolia Region.

The term "Anatolia" is Medieval Latin.

The modern Turkish form of Anatolia, "Anadolu", derives from the Greek name Aνατολή ("Anatolḗ"). The Russian male name Anatoly and the French Anatole share the same linguistic origin.

The term "Anatolia" originally referred to a northwestern Byzantine province. By the 12th century Europeans had started referring to Anatolia as "Turchia". It has historically also been called "Asia Minor". In earlier times, it was called "(Land of the) Rûm" by both the Greeks and the Seljuqs.

During the era of the Ottoman Empire mapmakers outside the Empire referred to the mountainous plateau in eastern Anatolia as Armenia. Other contemporary sources called the same area Kurdistan. Geographers have variously used the terms east Anatolian plateau and Armenian plateau to refer to the region, although the territory encompassed by each term largely overlaps with the other. According to archaeologist Lori Khatchadourian this difference in terminology "primarily result[s] from the shifting political fortunes and cultural trajectories of the region since the nineteenth century."

Turkey's First Geography Congress in 1941 created two regions to the east of the Gulf of Iskenderun-Black Sea line named the Eastern Anatolia Region and the Southeastern Anatolia Region, the former largely corresponding to the western part of the Armenian Highland, the latter to the northern part of the Mesopotamian plain. According to Richard Hovannisian this changing of toponyms was "necessary to obscure all evidence" of Armenian presence as part of a campaign of genocide denial

Human habitation in Anatolia dates back to the Paleolithic. Neolithic Anatolia has been proposed as the homeland of the Indo-European language family, although linguists tend to favour a later origin in the steppes north of the Black Sea. However, it is clear that the Anatolian languages, the earliest attested branch of Indo-European, have been spoken in Anatolia since at least the 19th century BC.

The earliest historical records of Anatolia stem from the southeast of the region and are from the Mesopotamian-based Akkadian Empire during the reign of Sargon of Akkad in the 24th century BC. Scholars generally believe the earliest indigenous populations of Anatolia were the Hattians and Hurrians. The Hattians spoke a language of unclear affiliation, and the Hurrian language belongs to a small family called Hurro-Urartian, all these languages now being extinct; relationships with indigenous languages of the Caucasus have been proposed but are not generally accepted. The region was famous for exporting raw materials, and areas of Hattian- and Hurrian-populated southeast Anatolia were colonised by the Akkadians.

After the fall of the Akkadian Empire in the mid-21st century BC, the Assyrians, who were the northern branch of the Akkadian people, colonised parts of the region between the 21st and mid-18th centuries BC and claimed its resources, notably silver. One of the numerous cuneiform records dated circa 20th century BC, found in Anatolia at the Assyrian colony of Kanesh
Unlike the Akkadians and their descendants, the Assyrians, whose Anatolian possessions were peripheral to their core lands in Mesopotamia, the Hittites were centred at Hattusa (modern Boğazkale) in north-central Anatolia by the 17th century BC. They were speakers of an Indo-European language, the Hittite language, or "nesili" (the language of Nesa) in Hittite. The Hittites originated of local ancient cultures that grew in Anatolia, in addition to the arrival of Indo-European languages. Attested for the first time in the Assyrian tablets of Nesa around 2000BC, they conquered Hattusa in the 18th century BC, imposing themselves over Hattian- and Hurrian-speaking populations. According to the widely accepted Kurgan theory on the Proto-Indo-European homeland, however, the Hittites (along with the other Indo-European ancient Anatolians) were themselves relatively recent immigrants to Anatolia from the north. However, they did not necessarily displace the population genetically, they would rather assimilate into the former peoples' culture, preserving the Hittite language however.

The Hittites adopted the cuneiform script, invented in Mesopotamia. During the Late Bronze Age circa 1650 BC, they created a kingdom, the Hittite New Kingdom, which became an empire in the 14th century BC after the conquest of Kizzuwatna in the south-east and the defeat of the Assuwa league in western Anatolia. The empire reached its height in the 13th century BC, controlling much of Asia Minor, northwestern Syria and northwest upper Mesopotamia. They failed to reach the Anatolian coasts of the Black Sea, however, as a non-Indo-European people, the semi-nomadic pastoralist and tribal Kaskians, had established themselves there, displacing earlier Palaic-speaking Indo-Europeans. Much of the history of the Hittite Empire concerned war with the rival empires of Egypt, Assyria and the Mitanni.

The Egyptians eventually withdrew from the region after failing to gain the upper hand over the Hittites and becoming wary of the power of Assyria, which had destroyed the Mitanni Empire. The Assyrians and Hittites were then left to battle over control of eastern and southern Anatolia and colonial territories in Syria. The Assyrians had better success than the Egyptians, annexing much Hittite (and Hurrian) territory in these regions.

After 1180 BC, during the Late Bronze Age collapse, the Hittite empire disintegrated into several independent Syro-Hittite states, subsequent to losing much territory to the Middle Assyrian Empire and being finally overrun by the Phrygians, another Indo-European people who are believed to have migrated from the Balkans. The Phrygian expansion into southeast Anatolia was eventually halted by the Assyrians, who controlled that region.

Arameans encroached over the borders of south central Anatolia in the century or so after the fall of the Hittite empire, and some of the Syro-Hittite states in this region became an amalgam of Hittites and Arameans. These became known as Syro-Hittite states
In central and western Anatolia, another Indo-European people, the Luwians, came to the fore, circa 2000 BC. Their language belonged to the same Anatolic clade as the Hittite. The general consensus amongst scholars is that Luwian was spoken—to a greater or lesser degree—across a large area of western Anatolia, including (possibly) Wilusa (Troy), the Seha River Land (to be identified with the Hermos and/or Kaikos valley), and the kingdom of Mira-Kuwaliya with its core territory of the Maeander valley. From the 9th century BC, Luwian regions coalesced into a number of states such as Lydia, Caria and Lycia, all of which had Hellenic influence.

From the 10th to late 7th centuries BC, much of Anatolia (particularly the southeastern regions) fell to the Neo-Assyrian Empire, including all of the Syro-Hittite states, Tabal, Kingdom of Commagene, the Cimmerians and Scythians and swathes of Cappadocia.

The Neo-Assyrian empire collapsed due to a bitter series of civil wars followed by a combined attack by Medes, Persians, Scythians and their own Babylonian relations. The last Assyrian city to fall was Harran in southeast Anatolia. This city was the birthplace of the last king of Babylon, the Assyrian Nabonidus and his son and regent Belshazzar. Much of the region then fell to the short-lived Iran-based Median Empire, with the Babylonians and Scythians briefly appropriating some territory.

From the late 8th century BC, a new wave of Indo-European-speaking raiders entered northern and northeast Anatolia: the Cimmerians and Scythians. The Cimmerians overran Phrygia and the Scythians threatened to do the same to Urartu and Lydia
The north-western coast of Anatolia was inhabited by Greeks of the Achaean/Mycenaean culture from the 20th century BC, related to the Greeks of south eastern Europe and the Aegean. Beginning with the Bronze Age collapse at the end of the 2nd millennium BC, the west coast of Anatolia was settled by Ionian Greeks, usurping the area of the related but earlier Mycenaean Greeks. Over several centuries, numerous Ancient Greek city-states were established on the coasts of Anatolia. Greeks started Western philosophy on the western coast of Anatolia (Pre-Socratic philosophy
In classical antiquity, Anatolia was described by Herodotus and later historians as divided into regions that were diverse in culture, language and religious practices. The northern regions included Bithynia, Paphlagonia and Pontus; to the west were Mysia, Lydia and Caria; and Lycia, Pamphylia and Cilicia belonged to the southern shore. There were also several inland regions: Phrygia, Cappadocia, Pisidia and Galatia

Anatolia is known as the birthplace of minted coinage (as opposed to unminted coinage, which first appears in Mesopotamia at a much earlier date) as a medium of exchange, some time in the 7th century BC in Lydia. The use of minted coins continued to flourish during the Greek and Roman eras.

During the 6th century BC, all of Anatolia was conquered by the Persian Achaemenid Empire, the Persians having usurped the Medes as the dominant dynasty in Iran. In 499 BC, the Ionian city-states on the west coast of Anatolia rebelled against Persian rule. The Ionian Revolt, as it became known, though quelled, initiated the Greco-Persian Wars, which ended in a Greek victory in 449 BC, and the Ionian cities regained their independence, alongside the withdrawal of the Persian forces from their European territories.

In 334 BC, the Macedonian Greek king Alexander the Great
Following the death of Alexander and the breakup of his empire, Anatolia was ruled by a series of Hellenistic kingdoms, such as the Attalids of Pergamum and the Seleucids, the latter controlling most of Anatolia. A period of peaceful Hellenization followed, such that the local Anatolian languages had been supplanted by Greek by the 1st century BC. In 133 BC the last Attalid king bequeathed his kingdom to the Roman Republic, and western and central Anatolia came under Roman control, but Hellenistic culture remained predominant. Further annexations by Rome, in particular of the Kingdom of Pontus by Pompey, brought all of Anatolia under Roman control, except for the eastern frontier with the Parthian Empire, which remained unstable for centuries, causing a series of wars, culminating in the Roman-Parthian Wars.

After the division of the Roman Empire, Anatolia became part of the East Roman, or Byzantine Empire. Anatolia was one of the first places where Christianity spread, so that by the 4th century AD, western and central Anatolia were overwhelmingly Christian and Greek-speaking. For the next 600 years, while Imperial possessions in Europe were subjected to barbarian invasions, Anatolia would be the center of the Hellenic world.

It was one of the wealthiest and most densely populated places in the Late Roman Empire. Anatolia's wealth grew during the 4th and 5th centuries thanks, in part, to the Pilgrim's Road that ran through the peninsula. Literary evidence about the rural landscape has come down to us from the hagiographies of 6th century Nicholas of Sion and 7th century Theodore of Sykeon. Large urban centers included Ephesus, Pergamum, Sardis and Aphrodisias. Scholars continue to debate the cause of urban decline in the 6th and 7th centuries variously attributing it to the Plague of Justinian (541), and the 7th century Persian incursion and Arab conquest of the Levant.

In the ninth and tenth century a resurgent Byzantine Empire regained its lost territories, including even long lost territory such as Armenia and Syria (ancient Aram

In the 10 years following the Battle of Manzikert in 1071, the Seljuk Turks from Central Asia migrated over large areas of Anatolia, with particular concentrations around the northwestern rim. The Turkish language and the Islamic religion were gradually introduced as a result of the Seljuk conquest, and this period marks the start of Anatolia's slow transition from predominantly Christian and Greek-speaking, to predominantly Muslim and Turkish-speaking (although ethnic groups such as Armenians, Greeks, and Assyrians remained numerous and retained Christianity and their native languages). In the following century, the Byzantines managed to reassert their control in western and northern Anatolia. Control of Anatolia was then split between the Byzantine Empire and the Seljuk Sultanate of Rûm, with the Byzantine holdings gradually being reduced.

In 1255, the Mongols swept through eastern and central Anatolia, and would remain until 1335. The Ilkhanate garrison was stationed near Ankara. After the decline of the Ilkhanate from 1335–1353, the Mongol Empire's legacy in the region was the Uyghur Eretna Dynasty that was overthrown by Kadi Burhan al-Din in 1381.

By the end of the 14th century, most of Anatolia was controlled by various Anatolian beyliks. Smyrna fell in 1330, and the last Byzantine stronghold in Anatolia, Philadelphia, fell in 1390. The Turkmen Beyliks were under the control of the Mongols, at least nominally, through declining Seljuk sultans. The Beyliks did not mint coins in the names of their own leaders while they remained under the suzerainty of the Mongol Ilkhanids. The Osmanli ruler Osman I was the first Turkish ruler who minted coins in his own name in 1320s, for it bears the legend "Minted by Osman son of Ertugrul". Since the minting of coins was a prerogative accorded in Islamic practice only to a sovereign, it can be considered that the Osmanli, or Ottoman Turks, became formally independent from the Mongol Khans.

Among the Turkish leaders, the Ottomans emerged as great power under Osman I and his son Orhan I. The Anatolian beyliks were successively absorbed into the rising Ottoman Empire during the 15th century. It is not well understood how the Osmanlı, or Ottoman Turks, came to dominate their neighbours, as the history of medieval Anatolia is still little known. The Ottomans completed the conquest of the peninsula in 1517 with the taking of Halicarnassus (modern Bodrum) from the Knights of Saint John

With the acceleration of the decline of the Ottoman Empire in the early 19th century, and as a result of the expansionist policies of the Russian Empire in the Caucasus, many Muslim nations and groups in that region, mainly Circassians, Tatars, Azeris, Lezgis, Chechens and several Turkic groups left their homelands and settled in Anatolia. As the Ottoman Empire further shrank in the Balkan regions and then fragmented during the Balkan Wars, much of the non-Christian populations of its former possessions, mainly Balkan Muslims (Bosnian Muslims, Albanians, Turks, Muslim Bulgarians and Greek Muslims such as the Vallahades from Greek Macedonia), were resettled in various parts of Anatolia, mostly in formerly Christian villages throughout Anatolia.

A continuous reverse migration occurred since the early 19th century, when Greeks from Anatolia, Constantinople and Pontus area migrated toward the newly independent Kingdom of Greece, and also towards the United States, southern part of the Russian Empire, Latin America and rest of Europe.

Following the Russo-Persian Treaty of Turkmenchay (1828) and the incorporation of the Eastern Armenia into the Russian Empire, another migration involved the large Armenian population of Anatolia, which recorded significant migration rates from Western Armenia (Eastern Anatolia) toward the Russian Empire, especially toward its newly established Armenian provinces.

Anatolia remained multi-ethnic until the early 20th century (see the rise of nationalism under the Ottoman Empire). During World War I, the Armenian Genocide, the Greek genocide (especially in Pontus), and the Assyrian genocide almost entirely removed the ancient indigenous communities of Armenian, Greek, and Assyrian populations in Anatolia and surrounding regions. Following the Greco-Turkish War of 1919–1922, most remaining ethnic Anatolian Greeks were forced out during the 1923 population exchange between Greece and Turkey. Many more have left Turkey since, leaving fewer than 5,000 Greeks in Anatolia today. Since the foundation of the Republic of Turkey in 1923, Anatolia has been within Turkey, its inhabitants being mainly Turks and Kurds (see demographics of Turkey and history of Turkey).

Anatolia's terrain is structurally complex. A central massif composed of uplifted blocks and downfolded troughs, covered by recent deposits and giving the appearance of a plateau with rough terrain, is wedged between two folded mountain ranges that converge in the east. True lowland is confined to a few narrow coastal strips along the Aegean, Mediterranean, and Black Sea coasts. Flat or gently sloping land is rare and largely confined to the deltas of the Kızıl River, the coastal plains of Çukurova and the valley floors of the Gediz River and the Büyük Menderes River as well as some interior high plains in Anatolia, mainly around Lake Tuz (Salt Lake) and the Konya Basin ("Konya Ovasi").

There are two mountain ranges in southern Anatolia: the Taurus and the Zagros mountains.

Anatolia has a varied range of climates. The central plateau is characterized by a continental climate, with hot summers and cold snowy winters. The south and west coasts enjoy a typical Mediterranean climate, with mild rainy winters, and warm dry summers. The Black Sea and Marmara coasts have a temperate oceanic climate, with cool foggy summers and much rainfall throughout the year.

There is a diverse number of plant and animal communities.

The mountains and coastal plain of northern Anatolia experiences humid and mild climate. There are temperate broadleaf, mixed and coniferous forests. The central and eastern plateau, with its drier continental climate, has deciduous forests and forest steppes. Western and southern Anatolia, which have a Mediterranean climate, contain Mediterranean forests, woodlands, and scrub ecoregions.

Almost 80% of the people currently residing in Anatolia are Turks. Kurds constitute a major community in southeastern Anatolia, and are the largest ethnic minority. Abkhazians, Albanians, Arabs, Arameans, Armenians, Assyrians, Azerbaijanis, Bosnian Muslims, Circassians, Gagauz, Georgians, Serbs, Greeks, Hemshin, Jews, Laz, Levantines, Pomaks, Zazas and a number of other ethnic groups also live in Anatolia in smaller numbers.

Bamia is a traditional Anatolian-era stew dish prepared using lamb, okra and tomatoes
Category:Peninsulas of Asia
Category:Geography of Western Asia
Category:Near East
Category:Geography of Armenia
Category:Geography of Turkey
Category:Peninsulas of Turkey
Category:Regions of Turkey
Category:Regions of Asia
Category:Ancient Near East
Category:Ancient Greek geography
Category:Physiographic provinces
Category:Historical regionsApple Inc.

Apple Inc. is an American multinational technology company headquartered in Cupertino, California, that designs, develops, and sells consumer electronics, computer software, and online services. It is considered one of the Big Four of technology along with Amazon, Google, and Facebook.

The company's hardware products include the iPhone smartphone, the iPad tablet computer, the Mac personal computer, the iPod portable media player, the Apple Watch smartwatch, the Apple TV digital media player, and the HomePod smart speaker. Apple's software includes the macOS and iOS operating systems, the iTunes media player, the Safari web browser, and the iLife and iWork creativity and productivity suites, as well as professional applications like Final Cut Pro, Logic Pro, and Xcode. Its online services include the iTunes Store, the iOS App Store and Mac App Store, Apple Music, and iCloud.

Apple was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976 to develop and sell Wozniak's Apple I personal computer. It was incorporated as Apple Computer, Inc., in January 1977, and sales of its computers, including the Apple II, grew quickly. Within a few years, Jobs and Wozniak had hired a staff of computer designers and had a production line. Apple went public in 1980 to instant financial success. Over the next few years, Apple shipped new computers featuring innovative graphical user interfaces, such as the original Macintosh in 1984, and Apple's marketing advertisements for its products received widespread critical acclaim. However, the high price tag of its products and limited software titles caused problems, as did power struggles between executives at the company. In 1985, Wozniak stepped away from Apple, while Jobs resigned and founded a new company—NeXT—with former Apple employees.

As the market for personal computers increased, Apple's computers lost share to lower-priced products, particularly ones that ran the Microsoft Windows operating system, and the company was financially on the brink. After more executive job shuffles, CEO Gil Amelio in 1997 bought NeXT to bring Jobs back. Jobs regained leadership within the company and became the new CEO shortly after. He began to rebuild Apple's status, opening Apple's own retail stores in 2001, acquiring numerous companies to create a portfolio of software titles, and changing some of the hardware used in its computers. The company returned to profitability. In January 2007, Jobs renamed the company Apple Inc., reflecting its shifted focus toward consumer electronics, and announced the iPhone, which saw critical acclaim and significant financial success. In August 2011, Jobs resigned as CEO due to health complications, and Tim Cook became the new CEO. Two months later, Jobs died, marking the end of an era for the company.

Apple is well known for its size and revenues. Its worldwide annual revenue totaled $265billion for the 2018 fiscal year. Apple is the world's largest information technology company by revenue and the world's third-largest mobile phone manufacturer after Samsung and Huawei. In August 2018, Apple became the first public U.S. company to be valued at over US$1 trillion. The company employs 123,000 full-time employees and maintains 504 retail stores in 24 countries . It operates the iTunes Store, which is the world's largest music retailer. , more than 1.3 billion Apple products are actively in use worldwide. The company also has a high level of brand loyalty and is ranked as the world's most valuable brand. However, Apple receives significant criticism regarding the labor practices of its contractors, its environmental practices and unethical business practices, including anti-competitive behavior

Apple Computer Company was founded on April 1, 1976, by Steve Jobs, Steve Wozniak and Ronald Wayne. The company's first product was the Apple I, a computer single-handedly designed and hand-built by Wozniak, and first shown to the public at the Homebrew Computer Club. Apple I was sold as a motherboard (with CPU, RAM, and basic textual-video chips), which was less than what is now considered a complete personal computer. The Apple I went on sale in July 1976 and was market-priced at $666.66 ($ in dollars, adjusted for inflation).

Apple Computer, Inc. was incorporated on January 3, 1977, without Wayne, who left and sold his share of the company back to Jobs and Wozniak for $800 only a couple weeks after co-founding Apple. Multimillionaire Mike Markkula provided essential business expertise and funding of $250,000 during the incorporation of Apple. During the first five years of operations revenues grew exponentially, doubling about every four months. Between September 1977 and September 1980, yearly sales grew from $775,000 to $118million, an average annual growth rate of 533%.

The Apple II, also invented by Wozniak, was introduced on April 16, 1977, at the first West Coast Computer Faire. It differed from its major rivals, the TRS-80 and Commodore PET, because of its character cell-based color graphics and open architecture. While early Apple II models used ordinary cassette tapes as storage devices, they were superseded by the introduction of a -inch floppy disk drive and interface called the Disk II. The Apple II was chosen to be the desktop platform for the first "killer app" of the business world: VisiCalc, a spreadsheet program. VisiCalc created a business market for the Apple II and gave home users an additional reason to buy an Apple II: compatibility with the office. Before VisiCalc, Apple had been a distant third place competitor to Commodore and Tandy.

By the end of the 1970s, Apple had a staff of computer designers and a production line. The company introduced the Apple III in May 1980 in an attempt to compete with IBM and Microsoft in the business and corporate computing market. Jobs and several Apple employees, including human–computer interface expert Jef Raskin, visited Xerox PARC in December 1979 to see the Xerox Alto. Xerox granted Apple engineers three days of access to the PARC facilities in return for the option to buy 100,000 shares (800,000 split-adjusted shares) of Apple at the pre-IPO price of $10 a share.

Jobs was immediately convinced that all future computers would use a graphical user interface (GUI), and development of a GUI began for the Apple Lisa. In 1982, however, he was pushed from the Lisa team due to infighting. Jobs then took over Wozniak and Raskin's low-cost-computer project, the Macintosh. A race broke out between the Lisa team and the Macintosh team over which product would ship first. Lisa won the race in 1983 and became the first personal computer sold to the public with a GUI, but was a commercial failure due to its high price tag and limited software titles.

On December 12, 1980, Apple went public at $22 per share, generating more capital than any IPO since Ford Motor Company
In 1984, Apple launched the Macintosh, the first personal computer to be sold without a programming language. Its debut was signified by "1984", a $1.5million television advertisement directed by Ridley Scott that aired during the third quarter of Super Bowl XVIII on January 22, 1984. This is now hailed as a watershed event for Apple's success and was called a "masterpiece" by CNN and one of the greatest TV advertisements of all time by "TV Guide".

The Macintosh initially sold well, but follow-up sales were not strong due to its high price and limited range of software titles. The machine's fortunes changed with the introduction of the LaserWriter, the first PostScript laser printer to be sold at a reasonable price, and PageMaker, an early desktop publishing package. It has been suggested that the combination of these three products were responsible for the creation of the desktop publishing market. The Macintosh was particularly powerful in the desktop publishing market due to its advanced graphics capabilities, which had necessarily been built in to create the intuitive Macintosh GUI.

In 1985, a power struggle developed between Jobs and CEO John Sculley, who had been hired two years earlier. The Apple board of directors instructed Sculley to "contain" Jobs and limit his ability to launch expensive forays into untested products. Rather than submit to Sculley's direction, Jobs attempted to oust him from his leadership role at Apple. Sculley found out that Jobs had been attempting to organize a coup and called a board meeting at which Apple's board of directors sided with Sculley and removed Jobs from his managerial duties. Jobs resigned from Apple and founded NeXT Inc.
After Jobs' and Wozniak's departure, the Macintosh product line underwent a steady change of focus to higher price points, the so-called "high-right policy" named for the position on a chart of price vs. profits. Jobs had argued the company should produce products aimed at the consumer market and aimed for a $1000 price for the Macintosh, which they were unable to meet. Newer models selling at higher price points offered higher profit margin, and appeared to have no effect on total sales as power users snapped up every increase in power. Although some worried about pricing themselves out of the market, the high-right policy was in full force by the mid-1980s, notably due to Jean-Louis Gassée's mantra of "fifty-five or die", referring to the 55% profit margins of the Macintosh II.

This policy began to backfire in the last years of the decade as new desktop publishing programs appeared on PC clones that offered some or much of the same functionality of the Macintosh but at far lower price points. The company lost its monopoly in this market and had already estranged many of its original consumer customer base who could no longer afford their high-priced products. The Christmas season of 1989 was the first in the company's history that saw declining sales, and led to a 20% drop in Apple's stock price. Gassée's objections were overruled, and he was forced from the company in 1990. Later that year, Apple introduced three lower cost models, the Macintosh Classic, Macintosh LC and Macintosh IIsi, all of which saw significant sales due to pent-up demand.

In 1991, Apple introduced the PowerBook, replacing the "luggable" Macintosh Portable with a design that set the current shape for almost all modern laptops. The same year, Apple introduced System 7, a major upgrade to the operating system which added color to the interface and introduced new networking capabilities. It remained the architectural basis for the Classic Mac OS. The success of the PowerBook and other products brought increasing revenue. For some time, Apple was doing incredibly well, introducing fresh new products and generating increasing profits in the process. The magazine "MacAddict" named the period between 1989 and 1991 as the "first golden age" of the Macintosh.

Apple believed the Apple II series was too expensive to produce and took away sales from the low-end Macintosh. In the 1990s, Apple released the Macintosh LC, and began efforts to promote that computer by advising developer technical support staff to recommend developing applications for Macintosh rather than Apple II, and authorizing salespersons to direct consumers towards Macintosh and away from Apple II. The Apple IIe
The success of Apple's lower-cost consumer models, especially the LC, also led to cannibalization of their higher priced machines. To address this, management introduced several new brands, selling largely identical machines at different price points aimed at different markets. These were the high-end Quadra, the mid-range Centris line, and the ill-fated Performa series. This led to significant market confusion, as customers did not understand the difference between models.

Apple also experimented with a number of other unsuccessful consumer targeted products during the 1990s, including digital cameras, portable CD audio players, speakers, video consoles, the eWorld online service, and TV appliances. Enormous resources were also invested in the problem-plagued Newton division based on John Sculley's unrealistic market forecasts. Ultimately, none of these products helped and Apple's market share and stock prices continued to slide.

Throughout this period, Microsoft continued to gain market share with Windows by focusing on delivering software to cheap commodity personal computers, while Apple was delivering a richly engineered but expensive experience. Apple relied on high profit margins and never developed a clear response; instead, they sued Microsoft for using a GUI similar to the Apple Lisa in "Apple Computer, Inc. v. Microsoft Corp." The lawsuit dragged on for years before it was finally dismissed. At this time, a series of major product flops and missed deadlines sullied Apple's reputation, and Sculley was replaced as CEO by Michael Spindler

By the early 1990s, Apple was developing alternative platforms to the Macintosh, such as A/UX. The Macintosh platform itself was becoming outdated because it was not built for multitasking and because several important software routines were programmed directly into the hardware. In addition, Apple was facing competition from OS/2 and UNIX vendors such as Sun Microsystems. The Macintosh would need to be replaced by a new platform or reworked to run on more powerful hardware.

In 1994, Apple allied with IBM and Motorola in the AIM alliance with the goal of creating a new computing platform (the PowerPC Reference Platform), which would use IBM and Motorola hardware coupled with Apple software. The AIM alliance hoped that PReP's performance and Apple's software would leave the PC far behind and thus counter Microsoft. The same year, Apple introduced the Power Macintosh, the first of many Apple computers to use Motorola's PowerPC processor.

In 1996, Spindler was replaced by Gil Amelio as CEO. Amelio made numerous changes at Apple, including extensive layoffs and cut costs. After numerous failed attempts to improve Mac OS, first with the Taligent project and later with Copland and Gershwin, Amelio chose to purchase NeXT and its NeXTSTEP operating system and bring Steve Jobs back to Apple.

At the 1997 Macworld Expo, Jobs announced that Apple would join Microsoft to release new versions of Microsoft Office for the Macintosh, and that Microsoft had made a $150million investment in non-voting Apple stock. On November 10, 1997, Apple introduced the Apple Online Store, which was tied to a new build-to-order manufacturing strategy.

The NeXT deal was finalized on February 9, 1997, bringing Jobs back to Apple as an advisor. On July 9, 1997, Amelio was ousted by the board of directors after overseeing a three-year record-low stock price and crippling financial losses. Jobs acted as the interim CEO and began restructuring the company's product line; it was during this period that he identified the design talent of Jonathan Ive, and the pair worked collaboratively to rebuild Apple's status.

On August 15, 1998, Apple introduced a new all-in-one computer reminiscent of the Macintosh 128K: the iMac. The iMac design team was led by Ive, who would later design the iPod and the iPhone. The iMac featured modern technology and a unique design, and sold almost 800,000 units in its first five months.

During this period, Apple completed numerous acquisitions to create a portfolio of digital production software for both professionals and consumers. In 1998, Apple purchased Macromedia's Key Grip software project, signaling an expansion into the digital video editing market. The sale was an outcome of Macromedia's decision to solely focus upon web development software. The product, still unfinished at the time of the sale, was renamed "Final Cut Pro" when it was launched on the retail market in April 1999. The development of Key Grip also led to Apple's release of the consumer video-editing product iMovie in October 1999. Next, Apple successfully acquired the German company Astarte, which had developed DVD authoring technology, as well as Astarte's corresponding products and engineering team in April 2000. Astarte's digital tool DVDirector was subsequently transformed into the professional-oriented DVD Studio Pro software product. Apple then employed the same technology to create iDVD for the consumer market. In July 2001, Apple acquired Spruce Technologies, a PC DVD authoring platform, to incorporate their technology into Apple's expanding portfolio of digital video projects.

In 2002, Apple purchased Nothing Real for their advanced digital compositing application Shake, as well as Emagic for the music productivity application Logic. The purchase of Emagic made Apple the first computer manufacturer to own a music software company. The acquisition was followed by the development of Apple's consumer-level GarageBand application. The release of iPhoto in the same year completed the iLife suite.

Mac OS X, based on NeXT's OPENSTEP and BSD Unix, was released on March 24, 2001, after several years of development. Aimed at consumers and professionals alike, Mac OS X aimed to combine the stability, reliability, and security of Unix with the ease of use afforded by an overhauled user interface. To aid users in migrating from Mac OS 9, the new operating system allowed the use of OS 9 applications within Mac OS X via the Classic Environment.

On May 19, 2001, Apple opened its first official eponymous retail stores in Virginia and California. On October 23 of the same year, Apple debuted the iPod portable digital audio player. The product, which was first sold on November 10, 2001, was phenomenally successful with over 100million units sold within six years. In 2003, Apple's iTunes Store was introduced. The service offered online music downloads
At the Worldwide Developers Conference keynote address on June 6, 2005, Jobs announced that Apple would begin producing Intel-based Mac computers in 2006. On January 10, 2006, the new MacBook Pro and iMac became the first Apple computers to use Intel's Core Duo CPU. By August 7, 2006, Apple made the transition to Intel chips for the entire Mac product line—over one year sooner than announced. The Power Mac, iBook and PowerBook brands were retired during the transition; the Mac Pro, MacBook, and MacBook Pro became their respective successors. On April 29, 2009, "The Wall Street Journal" reported that Apple was building its own team of engineers to design microchips. Apple also introduced Boot Camp in 2006 to help users install Windows XP or Windows Vista on their Intel Macs alongside Mac OS X.

Apple's success during this period was evident in its stock price. Between early 2003 and 2006, the price of Apple's stock increased more than tenfold, from around $6 per share (split-adjusted) to over $80. In January 2006, Apple's market cap surpassed that of Dell. Nine years prior, Dell's CEO Michael Dell had said that if he ran Apple he would "shut it down and give the money back to the shareholders." Although Apple's market share in computers had grown, it remained far behind its competitor Microsoft Windows, accounting for about 8% of desktops and laptops in the US.

Since 2001, Apple's design team has progressively abandoned the use of translucent colored plastics first used in the iMac G3. This design change began with the titanium-made PowerBook and was followed by the iBook's white polycarbonate structure and the flat-panel iMac
During his keynote speech at the Macworld Expo on January 9, 2007, Jobs announced that Apple Computer, Inc. would thereafter be known as "Apple Inc.", because the company had shifted its emphasis from computers to consumer electronics. This event also saw the announcement of the iPhone and the Apple TV. The company sold 270,000 iPhone units during the first 30 hours of sales, and the device was called "a game changer for the industry". Apple would achieve widespread success with its iPhone, iPod Touch and iPad products, which introduced innovations in mobile phones, portable music players and personal computers respectively. Furthermore, by early 2007, 800,000 Final Cut Pro users were registered.

In an article posted on Apple's website on February 6, 2007, Jobs wrote that Apple would be willing to sell music on the iTunes Store without digital rights management (DRM), thereby allowing tracks to be played on third-party players, if record labels would agree to drop the technology. On April 2, 2007, Apple and EMI jointly announced the removal of DRM technology from EMI's catalog in the iTunes Store, effective in May 2007. Other record labels eventually followed suit and Apple published a press release in January 2009 to announce the corresponding changes to the iTunes Store.

In July 2008, Apple launched the App Store to sell third-party applications for the iPhone and iPod Touch. Within a month, the store sold 60million applications and registered an average daily revenue of $1million, with Jobs speculating in August 2008 that the App Store could become a billion-dollar business for Apple. By October 2008, Apple was the third-largest mobile handset supplier in the world due to the popularity of the iPhone.

On December 16, 2008, Apple announced that 2009 would be the last year the corporation would attend the Macworld Expo, after more than 20 years of attendance, and that senior vice president of Worldwide Product Marketing Phil Schiller would deliver the 2009 keynote address in lieu of the expected Jobs. The official press release explained that Apple was "scaling back" on trade shows in general, including Macworld Tokyo and the Apple Expo in Paris, France, primarily because the enormous successes of the Apple Retail Stores and website had rendered trade shows a minor promotional channel.

On January 14, 2009, Jobs announced in an internal memo that he would be taking a six-month medical leave of absence from Apple until the end of June 2009 and would spend the time focusing on his health. In the email, Jobs stated that "the curiosity over my personal health continues to be a distraction not only for me and my family, but everyone else at Apple as well", and explained that the break would allow the company "to focus on delivering extraordinary products". Though Jobs was absent, Apple recorded its best non-holiday quarter (Q1 FY 2009) during the recession with revenue of $8.16billion and profit of $1.21billion.
After years of speculation and multiple rumored "leaks", Apple unveiled a large screen, tablet-like media device known as the iPad on January 27, 2010. The iPad ran the same touch-based operating system as the iPhone, and many iPhone apps were compatible with the iPad. This gave the iPad a large app catalog on launch, though having very little development time before the release. Later that year on April 3, 2010, the iPad was launched in the US. It sold more than 300,000 units on its first day, and 500,000 by the end of the first week. In May of the same year, Apple's market cap exceeded that of competitor Microsoft for the first time since 1989.

In June 2010, Apple released the iPhone 4, which introduced video calling, multitasking, and a new uninsulated stainless steel design that acted as the phone's antenna. Later that year, Apple again refreshed its iPod line of MP3 players by introducing a multi-touch iPod Nano, an iPod Touch with FaceTime, and an iPod Shuffle that brought back the buttons of earlier generations. Additionally, on October 20, Apple updated the MacBook Air laptop, iLife suite of applications, and unveiled Mac OS X Lion, the last version with the name Mac OS X.

In October 2010, Apple shares hit an all-time high, eclipsing $300.

On January 6, 2011, the company opened its Mac App Store, a digital software distribution platform similar to the iOS App Store.

Alongside peer entities such as Atari and Cisco Systems, Apple was featured in the documentary "Something Ventured", which premiered in 2011 and explored the three-decade era that led to the establishment and dominance of Silicon Valley.

On January 17, 2011, Jobs announced in an internal Apple memo that he would take another medical leave of absence for an indefinite period to allow him to focus on his health. Chief Operating Officer Tim Cook assumed Jobs's day-to-day operations at Apple, although Jobs would still remain "involved in major strategic decisions". Apple became the most valuable consumer-facing brand in the world. In June 2011, Jobs surprisingly took the stage and unveiled iCloud, an online storage and syncing service for music, photos, files and software which replaced MobileMe, Apple's previous attempt at content syncing.

This would be the last product launch Jobs would attend before his death. It has been argued that Apple has achieved such efficiency in its supply chain that the company operates as a monopsony (one buyer, many sellers) and can dictate terms to its suppliers. In July 2011, due to the American debt-ceiling crisis, Apple's financial reserves were briefly larger than those of the U.S. Government.

On August 24, 2011, Jobs resigned his position as CEO of Apple. He was replaced by Cook and Jobs became Apple's chairman. Prior to this, Apple did not have a chairman and instead had two co-lead directors, Andrea Jung and Arthur D. Levinson, who continued with those titles until Levinson became chairman of the board in November.

On October 5, 2011, Steve Jobs died, marking the end of an era for Apple. The first major product announcement by Apple following Jobs's passing occurred on January 19, 2012, when Apple's Phil Schiller introduced iBooks Textbooks for iOS and iBook Author for Mac OS X in New York City. Jobs had stated in his biography that he wanted to reinvent the textbook industry and education.

From 2011 to 2012, Apple released the iPhone 4S and iPhone 5, which featured improved cameras, an intelligent software assistant named Siri, and cloud-sourced data with iCloud; the third and fourth generation iPads, which featured Retina displays; and the iPad Mini, which featured a 7.9-inch screen in contrast to the iPad's 9.7-inch screen. These launches were successful, with the iPhone 5 (released September 21, 2012) becoming Apple's biggest iPhone launch with over two million pre-orders and sales of three million iPads in three days following the launch of the iPad Mini and fourth generation iPad (released November 3, 2012). Apple also released a third-generation 13-inch MacBook Pro with a Retina display and new iMac and Mac Mini computers.

On August 20, 2012, Apple's rising stock price increased the company's market capitalization to a world-record $624billion. This beat the non-inflation-adjusted record for market capitalization set by Microsoft in 1999. On August 24, 2012, a US jury ruled that Samsung should pay Apple $1.05billion (£665m) in damages in an intellectual property lawsuit. Samsung appealed the damages award, which the Court reduced by $450million. The Court further granted Samsung's request for a new trial. On November 10, 2012, Apple confirmed a global settlement that would dismiss all lawsuits between Apple and HTC up to that date, in favor of a ten-year license agreement for current and future patents between the two companies. It is predicted that Apple will make $280million a year from this deal with HTC.

A previously confidential email written by Jobs a year before his death was presented during the proceedings of the "Apple Inc. v. Samsung Electronics Co." lawsuits and became publicly available in early April 2014. With a subject line that reads "Top 100 – A," the email was sent only to the company's 100 most senior employees and outlines Jobs's vision of Apple Inc.'s future under 10 subheadings. Notably, Jobs declares a "Holy War with Google" for 2011 and schedules a "new campus" for 2015.

In March 2013, Apple filed a patent for an augmented reality (AR) system that can identify objects in a live video stream and present information corresponding to these objects through a computer-generated information layer overlaid on top of the real-world image. The company also made several high-profile hiring decisions in 2013. On July 2, 2013, Apple recruited Paul Deneve, Belgian President and CEO of Yves Saint Laurent as a vice president reporting directly to Tim Cook. A mid-October 2013 announcement revealed that Burberry executive Angela Ahrendts will commence as a senior vice president at Apple in mid-2014. Ahrendts oversaw Burberry's digital strategy for almost eight years and, during her tenure, sales increased to about US$3.2 billion and shares gained more than threefold.

Alongside Google vice-president Vint Cerf and AT&T CEO Randall Stephenson, Cook attended a closed-door summit held by President Obama on August 8, 2013, in regard to government surveillance and the Internet in the wake of the Edward Snowden NSA incident. On February 4, 2014, Cook met with Abdullah Gül, the President of Turkey, in Ankara to discuss the company's involvement in the Fatih project.

In the first quarter of 2014, Apple reported sales of 51million iPhones and 26million iPads, becoming all-time quarterly sales records. It also experienced a significant year-over-year increase in Mac sales. This was contrasted with a significant drop in iPod sales. In May 2014, the company confirmed its intent to acquire Dr. Dre and Jimmy Iovine's audio company Beats Electronics—producer of the "Beats by Dr. Dre" line of headphones and speaker products, and operator of the music streaming service Beats Music—for $3billion, and to sell their products through Apple's retail outlets and resellers. Iovine believed that Beats had always "belonged" with Apple, as the company modeled itself after Apple's "unmatched ability to marry culture and technology." The acquisition was the largest purchase in Apple's history.

Apple has been at the top of Interbrand's annual Best Global Brands report for 4 years in a row; 2013, 2014, 2015, and 2016, with a valuation of $178.1billion.

In January 2016, it was announced that one billion Apple devices were in active use worldwide.

On May 12, 2016, Apple Inc., invested US$1billion in DiDi, a Chinese transportation network company. "The Information" reported in October 2016 that Apple had taken a board seat in Didi Chuxing, a move that James Vincent of "The Verge" speculated could be a strategic company decision by Apple to get closer to the automobile industry, particularly Didi Chuxing's reported interest in self-driving cars.

On June 6, 2016, Forbes released their list of companies ranked on revenue generation. In the trailing fiscal year, Apple appeared on the list as the top tech company. It ranked third, overall, with $233billion in revenue. This represents a movement upward of two spots from the previous year's list.

On April 6, 2017, Apple launched Clips, an app that allows iPad and iPhone users to make and edit videos. The app provides a way to produce short videos to share with other users on the Messages app, Instagram, Facebook and other social networks. Apple also introduced Live Titles for Clips that allows users to add live animated captions and titles using their voice.

In May 2017, Apple refreshed two of its website designs. Their public relations "Apple Press Info" website was changed to an "Apple Newsroom" site, featuring a greater emphasis on imagery and therefore lower information density, and combines press releases, news items, and photos. Its "Apple Leadership" overview of company executives was also refreshed, adding a simpler layout with a prominent header image and two-column text fields. "9to5Mac" noted the design similarities to several of Apple's redesigned apps in iOS 10, particularly its Apple Music and News software.

In June 2017, Apple announced the HomePod, its smart speaker aimed to compete against Sonos and Amazon Echo. Towards the end of the year, "TechCrunch" reported that Apple was acquiring Shazam, a company specializing in music, TV, film and advertising recognition. The acquisition was confirmed a few days later, reportedly costing Apple $400million, with media reports noting that the purchase looked like a move by Apple to get data and tools to bolster its Apple Music streaming service. The purchase was approved by EU later in September 2018.

Also in June 2017, Apple appointed Jamie Erlicht and Zack Van Amburg to head their newly formed worldwide video unit. In November 2017, Apple announced it was branching out into original scripted programming: a drama series starring Jennifer Aniston and Reese Witherspoon, and a reboot of the anthology series Amazing Stories. In June 2018, Apple signed the Writer's Guild of America's minimum basic agreement and Oprah Winfrey to a multi-year content partnership. Additional partnerships for original series include Sesame Workshop and DHX Media and its subsidairy Peanuts Worldwide as well as a partnership with A24 to create original films. As of January 2019, Apple has ordered twenty-one television series and one film. Furthermore, there are five series in development at Apple. 

On June 5, 2018, Apple deprecated OpenGL across all Operating Systems and urges developers to use Metal instead.

In August 2018, Apple purchased Akonia Holographics for its augmented reality goggle lens. On February 14, 2019, Apple acquired DataTiger for its digital marketing technology.

Macs currently in production:
Apple sells a variety of computer accessories for Macs, including Thunderbolt Display, Magic Mouse, Magic Trackpad, Magic Keyboard, the AirPort wireless networking products, and Time Capsule

On October 23, 2001, Apple introduced the iPod digital music player. Several updated models have since been introduced, and the iPod brand is now the market leader in portable music players by a significant margin. More than 350million units have shipped . Apple has partnered with Nike to offer the Nike+iPod Sports Kit, enabling runners to synchronize and monitor their runs with iTunes and the Nike+ website.

In late July 2017, Apple discontinued its iPod Nano and iPod Shuffle models, leaving only the iPod Touch

At the Macworld Conference & Expo in January 2007, Steve Jobs introduced the long-anticipated iPhone, a convergence of an Internet-enabled smartphone and iPod. The first-generation iPhone was released on June 29, 2007, for $499 (4 GB) and $599 (8 GB) with an AT&T contract. On February 5, 2008, it was updated to have 16 GB of memory, in addition to the 8 GB and 4 GB models. It combined a 2.5G quad band GSM and EDGE cellular phone with features found in handheld devices, running scaled-down versions of Apple's Mac OS X (dubbed iPhone OS, later renamed iOS), with various Mac OS X applications such as Safari and Mail. It also includes web-based and Dashboard apps such as Google Maps and Weather. The iPhone features a touchscreen display, Bluetooth, and Wi-Fi (both "b" and "g").

A second version, the iPhone 3G, was released on July 11, 2008, with a reduced price of $199 for the 8 GB version and $299 for the 16 GB version. This version added support for 3G networking and assisted GPS navigation. The flat silver back and large antenna square of the original model were eliminated in favor of a glossy, curved black or white back. Software capabilities were improved with the release of the App Store, which provided iPhone-compatible applications to download. On April 24, 2009, the App Store surpassed one billion downloads. On June 8, 2009, Apple announced the iPhone 3GS. It provided an incremental update to the device, including faster internal components, support for faster 3G speeds, video recording capability, and voice control.

At the Worldwide Developers Conference (WWDC) on June 7, 2010, Apple announced the redesigned iPhone 4. It featured a 960 × 640 display, the Apple A4 processor, a gyroscope for enhanced gaming, a 5MP camera with LED flash, front-facing VGA camera and FaceTime video calling. Shortly after its release, reception issues were discovered by consumers, due to the stainless steel band around the edge of the device, which also serves as the phone's cellular signal and Wi-Fi antenna. The issue was corrected by a "Bumper Case" distributed by Apple for free to all owners for a few months. In June 2011, Apple overtook Nokia to become the world's biggest smartphone maker by volume. On October 4, 2011, Apple unveiled the iPhone 4S, which was first released on October 14, 2011. It features the Apple A5 processor and Siri voice assistant technology, the latter of which Apple had acquired in 2010. It also features an updated 8MP camera with new optics. Apple began a new accessibility feature, Made for iPhone Hearing Aids with the iPhone 4S. Made for iPhone Hearing Aids feature Live Listen, it can help the user hear a conversation in a noisy room or hear someone speaking across the room. Apple sold 4million iPhone 4S phones in the first three days of availability.

On September 12, 2012, Apple introduced the iPhone 5. It has a 4-inch display, 4G LTE connectivity, and the upgraded Apple A6 chip, among several other improvements. Two million iPhones were sold in the first twenty-four hours of pre-ordering and over five million handsets were sold in the first three days of its launch. Upon the launch of the iPhone 5S and iPhone 5C, Apple set a new record for first-weekend smartphone sales by selling over nine million devices in the first three days of its launch. The release of the iPhone 5S and 5C was the first time that Apple simultaneously launched two models.

A patent filed in July 2013 revealed the development of a new iPhone battery system that uses location data in combination with data on the user's habits to moderate the handsets power settings accordingly. Apple is working towards a power management system that will provide features such as the ability of the iPhone to estimate the length of time a user will be away from a power source to modify energy usage and a detection function that adjusts the charging rate to best suit the type of power source that is being used.

In a March 2014 interview, Apple designer Jonathan Ive used the iPhone as an example of Apple's ethos of creating high-quality, life-changing products. He explained that the phones are comparatively expensive due to the intensive effort that is used to make them:

On September 9, 2014, Apple introduced the iPhone 6, alongside the iPhone 6 Plus that both have screen sizes over 4-inches. One year later, Apple introduced the iPhone 6S, and iPhone 6S Plus, which introduced a new technology called 3D Touch, including an increase of the rear camera to 12 MP, and the FaceTime camera to 5 MP. On March 21, 2016, Apple introduced the iPhone SE that has a 4-inch screen size last used with the 5S and has nearly the same internal hardware as the 6S.

In July 2016, Apple announced that one billion iPhones had been sold.

On September 7, 2016, Apple introduced the iPhone 7 and the iPhone 7 Plus
On September 12, 2017, Apple introduced the iPhone 8 and iPhone 8 Plus, standing as evolutionary updates to its previous phones with a faster processor, improved display technology, upgraded camera systems and wireless charging. The company also announced iPhone X, which radically changes the hardware of the iPhone lineup, removing the home button in favor of facial recognition technology and featuring a near bezel-less design along with wireless charging.

On September 12, 2018, Apple introduced the iPhone XS, iPhone XS Max and iPhone XR
On January 27, 2010, Apple introduced their much-anticipated media tablet, the iPad. It offers multi-touch interaction with multimedia formats including newspapers, e-books, photos, videos, music, word processing documents, video games, and most existing iPhone apps using a 9.7-inch screen. It also includes a mobile version of Safari for web browsing, as well as access to the App Store, iTunes Library, iBookstore, Contacts, and Notes. Content is downloadable via Wi-Fi and optional 3G service or synced through the user's computer. AT&T was initially the sole U.S. provider of 3G wireless access for the iPad.

On March 2, 2011, Apple introduced the iPad 2, which had a faster processor and a camera on the front and back. It also added support for optional 3G service provided by Verizon in addition to AT&T. The availability of the iPad 2 was initially limited as a result of a devastating earthquake and tsunami in Japan in March 2011.

The third-generation iPad was released on March 7, 2012, and marketed as "the new iPad". It added LTE service from AT&T or Verizon, an upgraded A5X processor, and Retina display. The dimensions and form factor remained relatively unchanged, with the new iPad being a fraction thicker and heavier than the previous version and featuring minor positioning changes.

On October 23, 2012, Apple's fourth-generation iPad came out, marketed as the "iPad with Retina display". It added the upgraded A6X processor and replaced the traditional 30-pin dock connector with the all-digital Lightning connector. The iPad Mini was also introduced. It featured a reduced 7.9-inch display and much of the same internal specifications as the iPad 2.

On October 22, 2013, Apple introduced the iPad Air and the iPad Mini with Retina Display, both featuring a new 64-bit Apple A7 processor.

The iPad Air 2 was unveiled on October 16, 2014. It added better graphics and central processing and a camera burst mode as well as minor updates. The iPad Mini 3 was unveiled at the same time.

Since its launch, iPad users have downloaded over three billion apps. The total number of App Store downloads, , is over 100billion.

On September 9, 2015, Apple announced the iPad Pro, an iPad with a 12.9-inch display that supports two new accessories, the Smart Keyboard and Apple Pencil. An updated IPad Mini 4

The original Apple Watch smartwatch was announced by Tim Cook on September 9, 2014, being introduced as a product with health and fitness-tracking. It was released on April 24, 2015.

The second generation of Apple Watch, Apple Watch Series 2, was released in September 2016, featuring greater water resistance, a faster processor, and brighter display.

On September 12, 2017, Apple introduced the Apple Watch Series 3 featuring LTE cellular connectivity, giving the wearable independence from an iPhone except for the setup process.

On September 12, 2018, Apple introduced the Apple Watch Series 4

At the 2007 Macworld conference, Jobs demonstrated the Apple TV (previously known as the iTV), a set-top video device intended to bridge the sale of content from iTunes with high-definition televisions. The device links up to a user's TV and syncs, either via Wi-Fi or a wired network, with one computer's iTunes library and streams content from an additional four. The Apple TV originally incorporated a 40 GB hard drive for storage, included outputs for HDMI and component video, and played video at a maximum resolution of 720p. On May 30, 2007, a 160 GB hard disk drive was released alongside the existing 40 GB model. A software update released on January 15, 2008, allowed media to be purchased directly from the Apple TV.

In September 2009, Apple discontinued the original 40 GB Apple TV and now continues to produce and sell the 160 GB Apple TV. On September 1, 2010, Apple released a completely redesigned Apple TV. The new device is 1/4 the size, runs quieter, and replaces the need for a hard drive with media streaming from any iTunes library on the network along with 8 GB of flash memory to cache media downloaded. Like the iPad and the iPhone, Apple TV runs on an A4 processor. The memory included in the device is half of that in the iPhone 4 at 256 MB; the same as the iPad, iPhone 3GS, third and fourth-generation iPod Touch.

It has HDMI out as the only video output source. Features include access to the iTunes Store to rent movies and TV shows (purchasing has been discontinued), streaming from internet video sources, including YouTube and Netflix, and media streaming from an iTunes library. Apple also reduced the price of the device to $99. A third generation of the device was introduced at an Apple event on March 7, 2012, with new features such as higher resolution (1080p) and a new user interface.

At the September 9, 2015, event, Apple unveiled an overhauled Apple TV, which now runs a variant of macOS, called tvOS, and contains 32GB or 64 GB of NAND Flash to store games, programs, and to cache the current media playing. The release also coincided with the opening of a separate Apple TV App Store and a new Siri Remote with a glass touchpad, gyroscope, and microphone.

At the September 12, 2017 event, Apple released a new 4K Apple TV with the same form factor as the 4th Generation model. The 4K model is powered by the A10X SoC designed in-house that also powers their second-generation iPad Pro. The 4K model also has support for high dynamic range
Apple's first smart speaker, the HomePod was released on February 9, 2018 after being delayed from its initial December 2017 release. It also features 7 tweeters in the base, a four-inch woofer

Apple develops its own operating systems to run on its devices, including macOS for Mac personal computers, iOS for its iPhone, iPad and iPod Touch smartphones and tablets, watchOS for its Apple Watch smartwatches, and tvOS for its Apple TV digital media player.

For iOS and macOS, Apple also develops its own software titles, including Pages for writing, Numbers for spreadsheets, and Keynote for presentations, as part of its iWork productivity suite. For macOS, it also offers iMovie and Final Cut Pro X for video editing, and GarageBand and Logic Pro X for music creation.

Apple's range of server software includes the operating system macOS Server; Apple Remote Desktop, a remote systems management application; and Xsan, a storage area network file system.

Apple also offers online services with iCloud, which provides cloud storage and synchronization for a wide range of user data, including documents, photos, music, device backups, and application data, and Apple Music, its music and video streaming service.

According to the "Sydney Morning Herald", Apple wants to start producing an electric car with autonomous driving as soon as 2020. Apple has made efforts to recruit battery development engineers and other electric automobile engineers from A123 Systems, LG Chem, Samsung Electronics, Panasonic, Toshiba, Johnson Controls and Tesla Motors.

Apple Energy, LLC is a wholly owned subsidiary of Apple Inc. that sells solar energy. , Apple's solar farms in California and Nevada have been declared to provide 217.9 megawatts of solar generation capacity. In addition to the company's solar energy production, Apple has received regulatory approval to construct a landfill gas energy plant in North Carolina. Apple will use the methane emissions to generate electricity. Apple's North Carolina data center is already powered entirely with energy from renewable sources.

According to Steve Jobs, the company's name was inspired by his visit to an apple farm while on a fruitarian diet. Jobs thought the name "Apple" was "fun, spirited and not intimidating".

Apple's first logo, designed by Ron Wayne, depicts Sir Isaac Newton sitting under an apple tree. It was almost immediately replaced by Rob Janoff's "rainbow Apple", the now-familiar rainbow-colored silhouette of an apple with a bite taken out of it. Janoff presented Jobs with several different monochromatic themes for the "bitten" logo, and Jobs immediately took a liking to it. However, Jobs insisted that the logo be colorized to humanize the company. The logo was designed with a bite so that it would not be confused with a cherry. The colored stripes were conceived to make the logo more accessible, and to represent the fact the Apple II could generate graphics in color. This logo is often erroneously referred to as a tribute to Alan Turing, with the bite mark a reference to his method of suicide. Both Janoff and Apple deny any homage to Turing in the design of the logo.

On August 27, 1999 (the year following the introduction of the iMac G3), Apple officially dropped the rainbow scheme and began to use monochromatic logos nearly identical in shape to the previous rainbow incarnation. An Aqua-themed version of the monochrome logo was used from 1998 to 2003, and a glass-themed version was used from 2007 to 2013.

Steve Jobs and Steve Wozniak were Beatles fans, but Apple Inc. had name and logo trademark issues with Apple Corps Ltd., a multimedia company started by the Beatles in 1967. This resulted in a series of lawsuits and tension between the two companies. These issues ended with the settling of their lawsuit in 2007.

Apple's first slogan, "Byte into an Apple", was coined in the late 1970s. From 1997 to 2002, the slogan "Think Different" was used in advertising campaigns, and is still closely associated with Apple. Apple also has slogans for specific product lines — for example, "iThink, therefore iMac" was used in 1998 to promote the iMac, and "Say hello to iPhone" has been used in iPhone advertisements. "Hello" was also used to introduce the original Macintosh, Newton, iMac ("hello (again)"), and iPod.

From the introduction of the Macintosh in 1984, with the 1984 Super Bowl advertisement to the more modern Get a Mac adverts, Apple has been recognized for its efforts towards effective advertising and marketing for its products. However, claims made by later campaigns were criticized, particularly the 2005 Power Mac ads. Apple's product advertisements gained a lot of attention as a result of their eye-popping graphics and catchy tunes. Musicians who benefited from an improved profile as a result of their songs being included on Apple advertisements include Canadian singer Feist with the song "1234" and Yael Naïm with the song "New Soul".

Apple owns a YouTube channel where they release advertisements, tips, and introductions for their devices.

Apple customers gained a reputation for devotion and loyalty early in the company's history. "BYTE
Apple evangelists were actively engaged by the company at one time, but this was after the phenomenon had already been firmly established. Apple evangelist Guy Kawasaki has called the brand fanaticism "something that was stumbled upon," while Ive explained in 2014 that "People have an incredibly personal relationship" with Apple's products. Apple Store openings and new product releases can draw crowds of hundreds, with some waiting in line as much as a day before the opening. The opening of New York City's Fifth Avenue "Cube" store in 2006 became the setting of a marriage proposal, and had visitors from Europe who flew in for the event. In June 2017, a newlywed couple took their wedding photos inside the then-recently opened Orchard Road Apple Store in Singapore. The high level of brand loyalty has been criticized and ridiculed, applying the epithet "Apple fanboy" and mocking the lengthy lines before a product launch. An internal memo leaked in 2015 suggested the company planned to discourage long lines and direct customers to purchase its products on its website.

"Fortune" magazine named Apple the most admired company in the United States in 2008, and in the world from 2008 to 2012. On September 30, 2013, Apple surpassed Coca-Cola to become the world's most valuable brand in the Omnicom Group's "Best Global Brands" report. Boston Consulting Group has ranked Apple as the world's most innovative brand every year since 2005.

"The New York Times" in 1985 stated that "Apple above all else is a marketing company". John Sculley agreed, telling "The Guardian" newspaper in 1997 that "People talk about technology, but Apple was a marketing company. It was the marketing company of the decade." Research in 2002 by NetRatings indicate that the average Apple consumer was usually more affluent and better educated than other PC company consumers. The research indicated that this correlation could stem from the fact that on average Apple Inc. products were more expensive than other PC products.

In response to a query about the devotion of loyal Apple consumers, Jonathan Ive responded:

The Apple website home page has been used to commemorate, or pay tribute to, milestones and events outside of Apple's product offerings:



Apple Inc.'s world corporate headquarters are located in the middle of Silicon Valley, at 1–6 Infinite Loop, Cupertino, California. This Apple campus has six buildings that total and was built in 1993 by Sobrato Development Cos.

Apple has a satellite campus in neighboring Sunnyvale, California, where it houses a testing and research laboratory. AppleInsider published article in March 2014 claiming that Apple has a tucked away a top-secret facility where is developing the SG5 electric vehicle project codenamed "Titan" under the shell company name SixtyEight Research
In 2006, Apple announced its intention to build a second campus in Cupertino about east of the current campus and next to Interstate 280. The new campus building has been designed by Norman Foster. The Cupertino City Council approved the proposed "spaceship" design campus on October 15, 2013, after a 2011 presentation by Jobs detailing the architectural design of the new building and its environs. The new campus is planned to house up to 13,000 employees in one central, four-storied, circular building surrounded by extensive landscape. It will feature a café with room for 3,000 sitting people and parking underground as well as in a parking structure. The 2.8million square foot facility will also include Jobs's original designs for a fitness center and a corporate auditorium.
Apple has expanded its campuses in Austin, Texas concurrently with building Apple Park in Cupertino. The expansion consists of two locations, with one having 1.1million square feet of workspace, and the other 216,000 square feet. Apple will invest $1 billion to build the North Austin campus. At the biggest location, 6,000 employees work on technical support, manage Apple's network of suppliers to fulfill product shipments, aid in maintaining iTunes Store and App Store, handle economy, and continuously update Apple Maps with new data. At its smaller campus, 500 engineers work on next-generation processor chips to run in future Apple products.

Apple's headquarters for Europe, the Middle East and Africa (EMEA) are located in Cork in the south of Ireland. The facility, which opened in 1980, was Apple's first location outside of the United States. Apple Sales International, which deals with all of Apple's international sales outside of the US, is located at Apple's campus in Cork along with Apple Distribution International, which similarly deals with Apple's international distribution network. On April 20, 2012, Apple added 500 new jobs at its European headquarters, increasing the total workforce from around 2,800 to 3,300 employees. The company will build a new office block on its Hollyhill Campus to accommodate the additional staff. Its United Kingdom headquarters is at Stockley Park on the outskirts of London.

In February 2015, Apple opened their new 180,000-square-foot headquarters in Herzliya, Israel, which will accommodate approximately 800 employees. This opening was Apple's third office located within Israel; the first, also in Herzliya, was obtained as part of the Anobit acquisition, and the other is a research center in Haifa.

In December 2015, Apple bought the 70,000-square-foot manufacturing facility in North San Jose previously used by Maxim Integrated, in an $18.2million deal.

The first Apple Stores were originally opened as two locations in May 2001 by then-CEO Steve Jobs, after years of attempting but failing store-within-a-store concepts. Seeing a need for improved retail presentation of the company's products, he began an effort in 1997 to revamp the retail program to get an improved relationship to consumers, and hired Ron Johnson in 2000. Jobs relaunched Apple's online store in 1997, and opened the first two physical stores in 2001. The media initially speculated that Apple would fail, but its stores were highly successful, bypassing the sales numbers of competing nearby stores and within three years reached US$1 billion in annual sales, becoming the fastest retailer in history to do so. Over the years, Apple has expanded the number of retail locations and its geographical coverage, with 499 stores across 22 countries worldwide . Strong product sales have placed Apple among the top-tier retail stores, with sales over $16 billion globally in 2011.

In May 2016, Angela Ahrendts, Apple's current Senior Vice President of Retail, unveiled a significantly redesigned Apple Store in Union Square, San Francisco, featuring large glass doors for the entry, open spaces, and rebranded rooms. In addition to purchasing products, consumers can get advice and help from "Creative Pros" – individuals with specialized knowledge of creative arts; get product support in a tree-lined Genius Grove; and attend sessions, conferences and community events, with Ahrendts commenting that the goal is to make Apple Stores into "town squares", a place where people naturally meet up and spend time. The new design will be applied to all Apple Stores worldwide, a process that has seen stores temporarily relocate or close.

Many Apple Stores are located inside shopping malls, but Apple has built several stand-alone "flagship" stores in high-profile locations. It has been granted design patents and received architectural awards for its stores' designs and construction, specifically for its use of glass staircases and cubes. The success of Apple Stores have had significant influence over other consumer electronics retailers, who have lost traffic, control and profits due to a perceived higher quality of service and products at Apple Stores. Apple's notable brand loyalty among consumers causes long lines of hundreds of people at new Apple Store openings or product releases. Due to the popularity of the brand, Apple receives a large number of job applications, many of which come from young workers. Although Apple Store employees receive above-average pay, are offered money toward education and health care, and receive product discounts, there are limited or no paths of career advancement. A May 2016 report with an anonymous retail employee highlighted a hostile work environment
Apple was one of several highly successful companies founded in the 1970s that bucked the traditional notions of corporate culture. Jobs often walked around the office barefoot even after Apple became a Fortune 500 company. By the time of the "1984" television advertisement, Apple's informal culture had become a key trait that differentiated it from its competitors. According to a 2011 report in "Fortune," this has resulted in a corporate culture more akin to a startup rather than a multinational corporation.

As the company has grown and been led by a series of differently opinionated chief executives, it has arguably lost some of its original character. Nonetheless, it has maintained a reputation for fostering individuality and excellence that reliably attracts talented workers, particularly after Jobs returned to the company. Numerous Apple employees have stated that projects without Jobs's involvement often took longer than projects with it.

To recognize the best of its employees, Apple created the Apple Fellows program which awards individuals who make extraordinary technical or leadership contributions to personal computing while at the company. The Apple Fellowship has so far been awarded to individuals including Bill Atkinson, Steve Capps, Rod Holt, Alan Kay, Guy Kawasaki, Al Alcorn, Don Norman, Rich Page, and Steve Wozniak
At Apple, employees are specialists who are not exposed to functions outside their area of expertise. Jobs saw this as a means of having "best-in-class" employees in every role. For instance, Ron Johnson—Senior Vice President of Retail Operations until November 1, 2011—was responsible for site selection, in-store service, and store layout, yet had no control of the inventory in his stores (this was done by Cook, who had a background in supply-chain management). Apple is also known for strictly enforcing accountability. Each project has a "directly responsible individual," or "DRI" in Apple jargon. As an example, when iOS senior vice president Scott Forstall refused to sign Apple's official apology for numerous errors in the redesigned Maps app, he was forced to resign. Unlike other major U.S. companies Apple provides a relatively simple compensation policy for executives that does not include perks enjoyed by other CEOs like country club fees or private use of company aircraft. The company typically grants stock options to executives every other year.

In 2015, Apple had 110,000 full-time employees. This increased to 116,000 full-time employees the next year, a notable hiring decrease, largely due to its first revenue decline. Apple does not specify how many of its employees work in retail, though its 2014 SEC filing put the number at approximately half of its employee base. In September 2017, Apple announced that it had over 123,000 full-time employees.

Apple has a strong culture of corporate secrecy, and has an anti-leak Global Security team that recruits from the National Security Agency, the Federal Bureau of Investigation and the United States Secret Service.

In December 2017, Glassdoor named Facebook the best place to work, according to reviews from anonymous employees, with Apple dropping to 48th place, having originally entered at rank 19 in 2009, peaking at rank 10 in 2012, and falling down the ranks in subsequent years.

An editorial article in "The Verge" in September 2016 by technology journalist Thomas Ricker explored some of the public's perceived lack of innovation at Apple in recent years, specifically stating that Samsung has "matched and even surpassed Apple in terms of smartphone industrial design" and citing the belief that Apple is incapable of producing another breakthrough moment in technology with its products. He goes on to write that the criticism focuses on individual pieces of hardware rather than the ecosystem as a whole, stating "Yes, iteration is boring. But it's also how Apple does business. [...] It enters a new market and then refines and refines and continues refining until it yields a success". He acknowledges that people are wishing for the "excitement of revolution", but argues that people want "the comfort that comes with harmony". Furthermore, he writes that "a device is only the starting point of an experience that will ultimately be ruled by the ecosystem in which it was spawned", referring to how decent hardware products can still fail without a proper ecosystem (specifically mentioning that Walkman didn't have an ecosystem to keep users from leaving once something better came along), but how Apple devices in different hardware segments are able to communicate and cooperate through the iCloud cloud service with features including Universal Clipboard (in which text copied on one device can be pasted on a different device) as well as inter-connected device functionality including Auto Unlock (in which an Apple Watch can unlock a Mac in close proximity). He argues that Apple's ecosystem is its greatest innovation.

"The Wall Street Journal" reported in June 2017 that Apple's increased reliance on Siri, its virtual personal assistant, has raised questions about how much Apple can actually accomplish in terms of functionality. Whereas Google and Amazon make use of big data and analyze customer information to personalize results, Apple has a strong pro-privacy stance, intentionally not retaining user data. "Siri is a textbook of leading on something in tech and then losing an edge despite having all the money and the talent and sitting in Silicon Valley", Holger Mueller, a technology analyst, told the "Journal". The report further claims that development on Siri has suffered due to team members and executives leaving the company for competitors, a lack of ambitious goals, and shifting strategies. Though switching Siri's functions to machine learning and algorithms, which dramatically cut its error rate, the company reportedly still failed to anticipate the popularity of Amazon's Echo, which features the Alexa personal assistant. Improvements to Siri stalled, executives clashed, and there were disagreements over the restrictions imposed on third-party app interactions. While Apple acquired an England-based startup specializing in conversational assistants, Google's Assistant had already become capable of helping users select Wi-Fi networks by voice, and Siri was lagging in functionality.

In December 2017, two articles from "The Verge" and "ZDNet" debated what had been a particularly devastating week for Apple's macOS and iOS software platforms. The former had experienced a severe security vulnerability, in which Macs running the then-latest macOS High Sierra software were vulnerable to a bug that let anyone gain administrator privileges by entering "root" as the username in system prompts, leaving the password field empty and twice clicking "unlock", gaining full access. The bug was publicly disclosed on Twitter, rather than through proper bug bounty programs. Apple released a security fix within a day and issued an apology, stating that "regrettably we stumbled" in regards to the security of the latest updates. After installing the security patch, however, file sharing was broken for users, with Apple releasing a support document with instructions to separately fix that issue. Though Apple publicly stated the promise of "auditing our development processes to help prevent this from happening again", users who installed the security update while running the older 10.13.0 version of the High Sierra operating system rather than the then-newest 10.13.1 release experienced that the "root" security vulnerability was re-introduced, and persisted even after fully updating their systems. On iOS, a date bug caused iOS devices that received local app notifications at 12:15am on December 2, 2017 to repeatedly restart. Users were recommended to turn off notifications for their apps. Apple quickly released an update, done during the nighttime in Cupertino, California time and outside of their usual software release window, with one of the headlining features of the update needing to be delayed for a few days. The combined problems of the week on both macOS and iOS caused "The Verge"s Tom Warren to call it a "nightmare" for Apple's software engineers and described it as a significant lapse in Apple's ability to protect its more than 1 billion devices. "ZDNet"s Adrian Kingsley-Hughes wrote that "it's hard to not come away from the last week with the feeling that Apple is slipping". Kingsley-Hughes also concluded his piece by referencing an earlier article, in which he wrote that "As much as I don't want to bring up the tired old "Apple wouldn't have done this under Steve Jobs' watch" trope, a lot of what's happening at Apple lately is different from what came to expect under Jobs. Not to say that things didn't go wrong under his watch, but product announcements and launches felt a lot tighter for sure, as did the overall quality of what Apple was releasing." He did, however, also acknowledge that such failures "may indeed have happened" with Jobs in charge, though returning to the previous praise for Jobs' quality, stating "it's almost guaranteed that given his personality that heads would have rolled, which limits future failures".

The company's manufacturing, procurement, and logistics enable it to execute massive product launches without having to maintain large, profit-sapping inventories. In 2011, Apple's profit margins were 40 percent, compared with between 10 and 20 percent for most other hardware companies. Cook's catchphrase to describe his focus on the company's operational arm is: "Nobody wants to buy sour milk".

During the Mac's early history Apple generally refused to adopt prevailing industry standards for hardware, instead creating their own. This trend was largely reversed in the late 1990s, beginning with Apple's adoption of the PCI bus in the 7500/8500/9500 Power Macs. Apple has since joined the industry standards groups to influence the future direction of technology standards such as USB, AGP, HyperTransport, Wi-Fi, NVMe, PCIe and others in its products. FireWire is an Apple-originated standard that was widely adopted across the industry after it was standardized as IEEE 1394 and is a legally mandated port in all Cable TV boxes in the United States.

Apple has gradually expanded its efforts in getting its products into the Indian market. In July 2012, during a conference call with investors, CEO Tim Cook said that he "[loves] India", but that Apple saw larger opportunities outside the region. India's requirement that 30% of products sold be manufactured in the country was described as "really adds cost to getting product to market". In October 2013, Indian Apple executives unveiled a plan for selling devices through instalment plans and store-within-a-store concepts, in an effort to expand further into the market. The news followed Cook's acknowledgment of the country in July when sales results showed that iPhone sales in India grew 400% during the second quarter of 2013. In March 2016, "The Times of India" reported that Apple had sought permission from the Indian government to sell refurbished iPhones in the country. However, two months later, the application was rejected, citing official country policy. In May 2016, Apple opened an iOS app development center in Bangalore and a maps development office for 4,000 staff in Hyderabad. In February 2017, Apple once again requested permission to sell used iPhones in the country. The same month, "Bloomberg" reported that Apple was close to receiving permission to open its first retail store in the country. In March, "The Wall Street Journal" reported that Apple would begin manufacturing iPhone models in India "over the next two months", and in May, the "Journal" wrote that an Apple manufacturer had begun production of iPhone SE in the country, while Apple told "CNBC" that the manufacturing was for a "small number" of units. Reuters reported in December 2017, that Apple and the Indian government were clashing over planned increases to import taxes for components used in mobile phone production, with Apple having engaged in talks with government officials to try to delay the plans, but the Indian government sticking to its policies of no exemptions to its "Made in India" initiative. The import tax increases went into effect a few days later, with Apple being hurt the most out of all phone manufacturers, having nine of out ten phones imported into the country, whereas main smartphone competitor Samsung produces almost all of its devices locally.

In May 2017, the company announced a $1 billion funding project for "advanced manufacturing" in the United States, and subsequently invested $200million in Corning Inc., a manufacturer of toughened Gorilla Glass technology used in its iPhone devices. The following December, Apple's chief operating officer, Jeff Williams, told "CNBC" that the "$1 billion" amount was "absolutely not" the final limit on its spending, elaborating that "We're not thinking in terms of a fund limit. ... We're thinking about, where are the opportunities across the U.S. to help nurture companies that are making the advanced technology — and the advanced manufacturing that goes with that — that quite frankly is essential to our innovation".

The company advertised its products as being made in America until the late 1990s; however, as a result of outsourcing initiatives in the 2000s, almost all of its manufacturing is now handled abroad. According to a report by "The New York Times", Apple insiders "believe the vast scale of overseas factories, as well as the flexibility, diligence and industrial skills of foreign workers, have so outpaced their American counterparts that "Made in the U.S.A." is no longer a viable option for most Apple products".

In 2006, the "Mail on Sunday" reported on the working conditions of the Chinese factories where contract manufacturers Foxconn and Inventec produced the iPod. The article stated that one complex of factories that assembled the iPod and other items had over 200,000 workers living and working within it. Employees regularly worked more than 60 hours per week and made around $100 per month. A little over half of the workers' earnings was required to pay for rent and food from the company.

Apple immediately launched an investigation after the 2006 media report, and worked with their manufacturers to ensure acceptable working conditions. In 2007, Apple started yearly audits of all its suppliers regarding worker's rights, slowly raising standards and pruning suppliers that did not comply. Yearly progress reports have been published since 2008. In 2011, Apple admitted that its suppliers' child labor practices in China had worsened.

The Foxconn suicides occurred between January and November 2010, when 18 Foxconn (Chinese: 富士康) employees attempted suicide, resulting in 14 deaths—the company was the world's largest contract electronics manufacturer, for clients including Apple, at the time. The suicides drew media attention, and employment practices at Foxconn were investigated by Apple. Apple issued a public statement about the suicides, and company spokesperson Steven Dowling said:

The statement was released after the results from the company's probe into its suppliers' labor practices were published in early 2010. Foxconn was not specifically named in the report, but Apple identified a series of serious labor violations of labor laws, including Apple's own rules, and some child labor existed in a number of factories. Apple committed to the implementation of changes following the suicides.

Also in 2010, workers in China planned to sue iPhone contractors over poisoning by a cleaner used to clean LCD screens. One worker claimed that he and his coworkers had not been informed of possible occupational illnesses. After a high suicide rate in a Foxconn facility in China making iPads and iPhones, albeit a lower rate than that of China as a whole, workers were forced to sign a legally binding document guaranteeing that they would not kill themselves. Workers in factories producing Apple products have also been exposed to n-hexane, a neurotoxin that is a cheaper alternative than alcohol for cleaning the products.

A 2014 BBC investigation found excessive hours and other problems persisted, despite Apple's promise to reform factory practice after the 2010 Foxconn suicides. The Pegatron factory was once again the subject of review, as reporters gained access to the working conditions inside through recruitment as employees. While the BBC maintained that the experiences of its reporters showed that labor violations were continuing since 2010, Apple publicly disagreed with the BBC and stated: "We are aware of no other company doing as much as Apple to ensure fair and safe working conditions".

In December 2014, the Institute for Global Labour and Human Rights published a report which documented inhumane conditions for the 15,000 workers at a Zhen Ding Technology factory in Shenzhen, China, which serves as a major supplier of circuit boards for Apple's iPhone and iPad. According to the report, workers are pressured into 65-hour work weeks which leaves them so exhausted that they often sleep during lunch breaks. They are also made to reside in "primitive, dark and filthy dorms" where they sleep "on plywood, with six to ten workers in each crowded room." Omnipresent security personnel also routinely harass and beat the workers.

Following a Greenpeace protest, Apple released a statement on April 17, 2012, committing to ending its use of coal and shifting to 100% renewable clean energy. By 2013, Apple was using 100% renewable energy to power their data centers. Overall, 75% of the company's power came from clean renewable sources.

In 2010, Climate Counts, a nonprofit organization dedicated to directing consumers toward the greenest companies, gave Apple a score of 52 points out of a possible 100, which puts Apple in their top category "Striding". This was an increase from May 2008, when Climate Counts only gave Apple 11 points out of 100, which placed the company last among electronics companies, at which time Climate Counts also labeled Apple with a "stuck icon", adding that Apple at the time was "a choice to avoid for the climate conscious consumer".

In May 2015, Greenpeace evaluated the state of the Green Internet and commended Apple on their environmental practices saying, "Apple's commitment to renewable energy has helped set a new bar for the industry, illustrating in very concrete terms that a 100% renewable Internet is within its reach, and providing several models of intervention for other companies that want to build a sustainable Internet."

, Apple states that 100% of its U.S. operations run on renewable energy, 100% of Apple's data centers run on renewable energy and 93% of Apple's global operations run on renewable energy. However, the facilities are connected to the local grid which usually contains a mix of fossil and renewable sources, so Apple carbon offsets its electricity use. The Electronic Product Environmental Assessment Tool (EPEAT) allows consumers to see the effect a product has on the environment. Each product receives a Gold, Silver, or Bronze rank depending on its efficiency and sustainability. Every Apple tablet, notebook, desktop computer, and display that EPEAT ranks achieves a Gold rating, the highest possible. Although Apple's data centers recycle water 35 times, the increased activity in retail, corporate and data centers also increase the amount of water use to 573million gallons in 2015.

During an event on March 21, 2016, Apple provided a status update on its environmental initiative to be 100% renewable in all of its worldwide operations. Lisa P. Jackson, Apple's vice president of Environment, Policy and Social Initiatives who reports directly to CEO, Tim Cook, announced that , 93% of Apple's worldwide operations are powered with renewable energy. Also featured was the company's efforts to use sustainable paper in their product packaging; 99% of all paper used by Apple in the product packaging comes from post-consumer recycled paper or sustainably managed forests, as the company continues its move to all paper packaging for all of its products. Apple working in partnership with Conservation Fund, have preserved 36,000 acres of working forests in Maine and North Carolina. Another partnership announced is with the World Wildlife Fund to preserve up to 1,000,000 acres of forests in China. Featured was the company's installation of a 40 MW solar power plant in the Sichuan province of China that was tailor-made to coexist with the indigenous yaks that eat hay produced on the land, by raising the panels to be several feet off of the ground so the yaks and their feed would be unharmed grazing beneath the array. This installation alone compensates for more than all of the energy used in Apple's Stores and Offices in the whole of China, negating the company's energy carbon footprint in the country. In Singapore, Apple has worked with the Singaporean government to cover the rooftops of 800 buildings in the city-state with solar panels allowing Apple's Singapore operations to be run on 100% renewable energy. Liam was introduced to the world, an advanced robotic disassembler and sorter designed by Apple Engineers in California specifically for recycling outdated or broken iPhones. Reuses and recycles parts from traded in products.

Apple announced on August 16, 2016, that Lens Technology, one of its major suppliers in China, has committed to power all its glass production for Apple with 100 percent renewable energy by 2018. The commitment is a large step in Apple's efforts to help manufacturers lower their carbon footprint in China. Apple also announced that all 14 of its final assembly sites in China are now compliant with UL's Zero Waste to Landfill validation. The standard, which started in January 2015, certifies that all manufacturing waste is reused, recycled, composted, or converted into energy (when necessary). Since the program began, nearly, 140,000 metric tons of waste have been diverted from landfills.

Following further campaigns by Greenpeace, in 2008, Apple became the first electronics manufacturer to fully eliminate all polyvinyl chloride (PVC) and brominated flame retardants (BFRs) in its complete product line. In June 2007, Apple began replacing the cold cathode fluorescent lamp (CCFL) backlit LCD displays in its computers with mercury-free LED-backlit LCD displays and arsenic-free glass, starting with the upgraded MacBook Pro. Apple offers comprehensive and transparent information about the COe, emissions, materials, and electrical usage concerning every product they currently produce or have sold in the past (and which they have enough data needed to produce the report), in their portfolio on their homepage. Allowing consumers to make informed purchasing decisions on the products they offer for sale. In June 2009, Apple's iPhone 3GS was free of PVC, arsenic, and BFRs. All Apple products now have mercury-free LED-backlit LCD displays, arsenic-free glass, and non-PVC cables. All Apple products have EPEAT Gold status and beat the latest Energy Star guidelines in each product's respective regulatory category.

In November 2011, Apple was featured in Greenpeace's Guide to Greener Electronics, which ranks electronics manufacturers on sustainability, climate and energy policy, and how "green" their products are. The company ranked fourth of fifteen electronics companies (moving up five places from the previous year) with a score of 4.6/10. Greenpeace praises Apple's sustainability, noting that the company exceeded its 70% global recycling goal in 2010. It continues to score well on the products rating with all Apple products now being free of PVC plastic and BFRs. However, the guide criticizes Apple on the Energy criteria for not seeking external verification of its greenhouse gas emissions data and for not setting out any targets to reduce emissions. In January 2012, Apple requested that its cable maker, Volex, begin producing halogen-free USB and power cables.

In February 2016, Apple issued a US$1.5billion green bond (climate bond), the first ever of its kind by a U.S. tech company. The green bond proceeds are dedicated to the financing of environmental projects.

Apple is the world's largest information technology company by revenue, the world's largest technology company by total assets, and the world's second-largest mobile phone manufacturer after Samsung.

In its fiscal year ending in September 2011, Apple Inc. reported a total of $108billion in annual revenues—a significant increase from its 2010 revenues of $65billion—and nearly $82billion in cash reserves. On March 19, 2012, Apple announced plans for a $2.65-per-share dividend beginning in fourth quarter of 2012, per approval by their board of directors.

The company's worldwide annual revenue in 2013 totaled $170billion. In May 2013, Apple entered the top ten of the Fortune 500 list of companies for the first time, rising 11 places above its 2012 ranking to take the sixth position. , Apple has around US$234billion of cash and marketable securities, of which 90% is located outside the United States for tax purposes.

Apple amassed 65% of all profits made by the eight largest worldwide smartphone manufacturers in quarter one of 2014, according to a report by Canaccord Genuity. In the first quarter of 2015, the company garnered 92% of all earnings.

On April 30, 2017, "The Wall Street Journal" reported that Apple had cash reserves of $250 billion, officially confirmed by Apple as specifically $256.8 billion a few days later.

, Apple is the largest publicly traded corporation in the world by market capitalization. On August 2, 2018, Apple became the first publicly traded U.S. company to reach a $1 trillion market value. Apple is currently ranked #4 on the Fortune 500 rankings of the largest United States corporations by total revenue.

Apple has created subsidiaries in low-tax places such as Ireland, the Netherlands, Luxembourg and the British Virgin Islands to cut the taxes it pays around the world. According to "The New York Times," in the 1980s Apple was among the first tech companies to designate overseas salespeople in high-tax countries in a manner that allowed the company to sell on behalf of low-tax subsidiaries on other continents, sidestepping income taxes. In the late 1980s, Apple was a pioneer of an accounting technique known as the "Double Irish with a Dutch sandwich," which reduces taxes by routing profits through Irish subsidiaries and the Netherlands and then to the Caribbean.

British Conservative Party Member of Parliament Charlie Elphicke published research on October 30, 2012, which showed that some multinational companies, including Apple Inc., were making billions of pounds of profit in the UK, but were paying an effective tax rate to the UK Treasury of only 3 percent, well below standard corporation tax. He followed this research by calling on the Chancellor of the Exchequer George Osborne to force these multinationals, which also included Google and The Coca-Cola Company, to state the effective rate of tax they pay on their UK revenues. Elphicke also said that government contracts should be withheld from multinationals who do not pay their fair share of UK tax.

Apple Inc. claims to be the single largest taxpayer to the Department of the Treasury of the United States of America with an effective tax rate of approximately of 26% as of the Second Quarter of the Apple Fiscal Year 2016. In an interview with the German newspaper FAZ in October 2017, Tim Cook stated, that Apple is the biggest taxpayer worldwide.

In 2015, Reuters reported that Apple had earnings abroad of $54.4billion which were untaxed by the IRS of the United States. Under U.S. tax law governed by the IRC, corporations don't pay income tax on overseas profits unless the profits are repatriated into the United States and as such Apple argues that to benefit its shareholders it will leave it overseas until a repatriation holiday or comprehensive tax reform takes place in the United States.

On July 12, 2016 the Central Statistics Office (Ireland) announced that 2015 Irish GDP had grown by 26.3%, and 2015 Irish GNP had grown by 18.7%. The figures attracted international scorn, and were labelled by Nobel-prize winning economist, Paul Krugman, as leprechaun economics. It was not until 2018 that Irish economists could definitively prove that the 2015 growth was due to Apple restructuring its controversial double Irish subsidiaries (Apple Sales International), which Apple converted into a new Irish capital allowances for intangible assets tax scheme (expires in January 2020). The affair required the Central Bank of Ireland to create a new measure of Irish economic growth, Modified GNI* to replace Irish GDP, given the distortion of Apple's tax schemes. Irish GDP is 143% of Irish Modified GNI*.

On August 30, 2016, after a two-year investigation, the EU Competition Commissioner concluded Apple received "illegal State aid" from Ireland. The EU ordered Apple to pay 13billion euros ($14.5billion), plus interest, in unpaid Irish taxes for 2004-2014. It is the largest tax fine in history. The Commission found that Apple had benefitted from a private Irish Revenue Commissioners tax ruling regarding its double Irish tax structure, Apple Sales International (ASI). Instead of using two companies for its double Irish structure, Apple was given a ruling to split ASI into two internal "branches". The Chancellor of Austria, Christian Kern, put this decision into perspective by stating that "every Viennese cafe, every sausage stand pays more tax in Austria than a multinational corporation".

, Apple agreed to start paying €13 billion in back taxes to the Irish government, the repayments will be held in an escrow account while Apple and the Irish government continue their appeals in EU courts.

Apple Inc. is a joint-stock company registered with the SEC. , it has 4,829,926,000 outstanding shares. These are mainly held by institutional investors and funds.

Apple has been a participant in various legal proceedings and claims since it began operation. In particular, Apple is known for and promotes itself as actively and aggressively enforcing its intellectual property interests. Some litigation examples include "Apple v. Samsung", "Apple v. Microsoft", "Motorola Mobility v. Apple Inc.", and "Apple Corps v. Apple Computer". Apple has also had to defend itself against charges on numerous occasions of violating intellectual property rights. Most have been dismissed in the courts as shell companies known as patent trolls, with no evidence of actual use of patents in question. On December 21, 2016, Nokia announced that in the U.S. and Germany, it has filed a suit against Apple, claiming that the latter's products infringe on Nokia's patents. Most recently, in November 2017, the United States International Trade Commission announced an investigation into allegations of patent infringement in regards to Apple's remote desktop technology; Aqua Connect, a company that builds remote desktop software, has claimed that Apple infringed on two of its patents.

Apple has a notable pro-privacy stance, actively making privacy-conscious features and settings part of its conferences, promotional campaigns, and public image. With its iOS 8 mobile operating system in 2014, the company started encryption all contents of iOS devices through users' passcodes, making it impossible for the company to provide customer data to law enforcement requests seeking such information. With the popularity rise of cloud storage solutions, Apple began a technique in 2016 to do deep learning scans for facial data in photos on the user's local device and encrypting the content before uploading it to Apple's iCloud storage system. It also introduced "differential privacy", a way to collect crowdsourced data from many users, while keeping individual users anonymous, in a system that "Wired" described as "trying to learn as much as possible about a group while learning as little as possible about any individual in it". Users are explicitly asked if they want to participate, and can actively opt-in or opt-out.

However, Apple aids law enforcement in criminal investigations by providing iCloud backups of users' devices, and the company's commitment to privacy has been questioned by its efforts to promote biometric authentication technology in its newer iPhone models, which don't have the same level of constitutional privacy as a passcode in the United States.

Apple is a partner of (PRODUCT)RED, a fundraising campaign for AIDS charity. In November 2014, Apple arranged for all App Store revenue in a two-week period to go to the fundraiser, generating more than US$20 million, and in March 2017, it released an iPhone 7 with a red color finish.

Apple contributes financially to fundraisers in times of natural disasters. In November 2012, it donated $2.5million to the American Red Cross to aid relief efforts after Hurricane Sandy, and in 2017 it donated $5million to relief efforts for both Hurricane Irma and Hurricane Harvey, as well as for the 2017 Central Mexico earthquake. The company has also used its iTunes platform to encourage donations, including, but not limited to, help the American Red Cross in the aftermath of the 2010 Haiti earthquake, followed by similar procedure in the aftermath of the 2011 Japan earthquake, Typhoon Haiyan in the Philippines in November 2013, and European migrant crisis in September 2015. Apple emphasizes that it does not incur any processing or other fees for iTunes donations, sending 100% of the payments directly to relief efforts, though it also acknowledges that the Red Cross does not receive any personal information on the users donating and that the payments may not be tax deductible.

On April 14, 2016, Apple and the World Wide Fund for Nature (WWF) announced that they have engaged in a partnership to, "help protect life on our planet." Apple released a special page in the iTunes App Store, Apps for Earth. In the arrangement, Apple has committed that through April 24, WWF will receive 100% of the proceeds from the applications participating in the App Store via both the purchases of any paid apps and the In-App Purchases. Apple and WWF's Apps for Earth campaign raised more than $8million in total proceeds to support WWF's conservation work. WWF announced the results at WWDC 2016 in San Francisco.

Apple has been criticised for alleged unethical business practices such as anti-competitive behavior, rash litigation, and dubious tax tactics, production methods involving the use of sweatshop labor, customer service issues involving allegedly misleading warranties and insufficient data security, as well as its products' environmental footprint. Critics have claimed that Apple products combine stolen and/or purchased designs that Apple claims are its original creations. Additionally, it has been criticized for its alleged collaboration with the U.S. surveillance program PRISM.

Apple has dealt with a number of issues regarding music over the years, including issues with the European Union regarding iTunes, trouble over updating the Spotify app on Apple devices and collusion with record labels.

Apple has also faced scrutiny for its tax practices, including using a Double Irish Arrangement
Category:1976 establishments in California
Category:1980s initial public offerings
Category:Companies based in Cupertino, California
Category:Companies in the Dow Jones Industrial Average
Category:Companies in the PRISM network
Category:Companies listed on NASDAQ
Category:Computer companies established in 1976
Category:Computer companies of the United States
Category:Computer hardware companies
Category:Display technology companies
Category:Electronics companies of the United States
Category:Electronics companies
Category:Home computer hardware companies
Category:Mobile phone manufacturers
Category:Multinational companies headquartered in the United States
Category:Networking hardware companies
Category:Portable audio player manufacturers
Category:Retail companies of the United States
Category:Software companies based in the San Francisco Bay Area
Category:Software companies established in 1976
Category:Steve Jobs
Category:Technology companies based in the San Francisco Bay Area
Category:Technology companies established in 1976
Category:Technology companies of the United States
Category:American brands
Aberdeenshire (; ) is one of the 32 council areas of Scotland.

It takes its name from the County of Aberdeen which has substantially different boundaries. The Aberdeenshire council area includes all of the area of the historic counties of Aberdeenshire and Kincardineshire (except the area making up the City of Aberdeen), as well as part of Banffshire. The county boundaries are officially used for a few purposes, namely land registration and lieutenancy.

Aberdeenshire Council is headquartered at Woodhill House, in Aberdeen, making it the only Scottish council whose headquarters are located outside its jurisdiction. Aberdeen itself forms a different council area (Aberdeen City). Aberdeenshire borders onto Angus and Perth and Kinross to the south, Highland and Moray to the west and Aberdeen City to the east.

Traditionally, it has been economically dependent upon the primary sector (agriculture, fishing, and forestry) and related processing industries. Over the last 40 years, the development of the oil and gas industry and associated service sector has broadened Aberdeenshire's economic base, and contributed to a rapid population growth of some 50% since 1975. Its land represents 8% of Scotland's overall territory. It covers an area of .

Aberdeenshire has a rich prehistoric and historic heritage. It is the locus of a large number of Neolithic and Bronze Age archaeological sites, including Longman Hill, Kempstone Hill, Catto Long Barrow and Cairn Lee. The area was settled in the Bronze Age by the Beaker culture, who arrived from the south around 2000–1800 BC. Stone circles and cairns were constructed predominantly in this era. In the Iron Age, hill forts were built. Around the 1st century AD, the Taexali people, who have left little history, were believed to have resided along the coast. The Picts were the next documented inhabitants of the area, and were no later than 800–900 AD. The Romans also were in the area during this period, as they left signs at Kintore. Christianity influenced the inhabitants early on, and there were Celtic monasteries at Old Deer and Monymusk.

Since medieval times there have been a number of traditional paths that crossed the Mounth (a spur of mountainous land that extends from the higher inland range to the North Sea slightly north of Stonehaven) through present-day Aberdeenshire from the Scottish Lowlands to the Highlands. Some of the most well known and historically important trackways are the Causey Mounth and Elsick Mounth.

Aberdeenshire played an important role in the fighting between the Scottish clans. Clan MacBeth and the Clan Canmore were two of the larger clans. Macbeth fell at Lumphanan in 1057. During the Anglo-Norman penetration, other families arrives such as House of Balliol, Clan Bruce, and Clan Cumming (Comyn). When the fighting amongst these newcomers resulted in the Scottish Wars of Independence, the English king Edward I traveled across the area twice, in 1296 and 1303. In 1307, Robert the Bruce was victorious near Inverurie. Along with his victory came new families, namely the Forbeses and the Gordons.

These new families set the stage for the upcoming rivalries during the 14th and 15th centuries. This rivalry grew worse during and after the Protestant Reformation, when religion was another reason for conflict between the clans. The Gordon family adhered to Catholicism and the Forbes to Protestantism. Aberdeenshire was the historic seat of the clan Dempster. Three universities were founded in the area prior to the 17th century, King's College in Old Aberdeen (1494), Marischal College in Aberdeen (1593), and the University of Fraserburgh (1597).

After the end of the Revolution of 1688, an extended peaceful period was interrupted only by such fleeting events such as the Rising of 1715 and the Rising of 1745. The latter resulted in the end of the ascendancy of Episcopalianism and the feudal power of landowners. An era began of increased agricultural and industrial progress. During the 17th century, Aberdeenshire was the location of more fighting, centered on the Marquess of Montrose and the English Civil Wars. This period also saw increased wealth due to the increase in trade with Germany, Poland, and the Low Countries.

The present council area is named after the historic county of Aberdeenshire, which has different boundaries and was abandoned as an administrative area in 1975 under the Local Government (Scotland) Act 1973. It was replaced by Grampian Regional Council and five district councils: Banff and Buchan, Gordon, Kincardine and Deeside, Moray and the City of Aberdeen. Local government functions were shared between the two levels. In 1996, under the Local Government etc (Scotland) Act 1994, the Banff and Buchan district, Gordon district and Kincardine and Deeside district were merged to form the present Aberdeenshire council area. Moray and the City of Aberdeen were made their own council areas. The present Aberdeenshire council area consists of all of the historic counties of Aberdeenshire and Kincardineshire (except the area of those two counties making up the City of Aberdeen), as well as northeast portions of Banffshire.

The population of the council area has risen over 50% since 1971 to approximately , representing 4.7% of Scotland's total. Aberdeenshire's population has increased by 9.1% since 2001, while Scotland's total population grew by 3.8%.
The census lists a relatively high proportion of under 16s and slightly fewer people of working-age compared with the Scottish average.

Aberdeenshire is one of the most homogeneous regions of the UK. In 2011 82.2% of residents identified as 'White Scottish', followed by 12.3% who are 'White British'. The largest ethnic minority group are Asian Scottish/British at 0.8%.

The fourteen biggest settlements in Aberdeenshire (with 2011 population estimates) are:


Aberdeenshire's Gross Domestic Product (GDP) is estimated at £3,496m (2011), representing 5.2% of the Scottish total. Aberdeenshire's economy is closely linked to Aberdeen City's (GDP £7,906m) and in 2011 the region as a whole was calculated to contribute 16.8% of Scotland's GDP. Between 2012 and 2014 the combined Aberdeenshire and Aberdeen City economic forecast GDP growth rate is 6.8%, the highest growth rate of any local council area and above the Scottish rate of 4.8%.

A significant proportion of Aberdeenshire's working residents commute to Aberdeen City for work, varying from 11.5% from Fraserburgh to 65% from Westhill.

Average Gross Weekly Earnings (for full-time employees employed in work places in Aberdeenshire in 2011) are £570.60. This is lower than the Scottish average by £4.10 and a fall of 2.6% on the 2010 figure. The average gross weekly pay of people resident in Aberdeenshire is much higher, at £641.90, as many people commute out
of Aberdeenshire, principally into Aberdeen City.

Total employment (excluding farm data) in Aberdeenshire is estimated at 93,700 employees (Business Register and
Employment Survey 2009). The majority of employees work within the service sector, predominantly in public administration, education and health. Almost 19% of employment is within the public sector. Aberdeenshire's economy remains closely linked to Aberdeen City's and the North Sea oil industry, with many employees in oil related jobs.

The average monthly unemployment (claimant count) rate for Aberdeenshire in 2011 was 1.5%. This is lower than the average rates for Aberdeen City (2.3%), Scotland (4.2%) and the UK (3.8%).


The council has 70 councillors, elected in 19 multi-member wards by single transferable vote. The 2017 elections

The overall political composition of the council, following subsequent defections and by-elections, is as follows:
The Council's Revenue Budget for 2012/13 totals approx £548 million. The Education, Learning and Leisure Service takes the largest share of budget (52.3%), followed by Housing and Social Work (24.3%), Infrastructure Services (15.9%), Joint Boards (such as Fire and Police) and Misc services (7.9%) and Trading Activities (0.4%).

21.5% of the revenue is raised locally through the Council Tax. Average Band D Council Tax is £1,141 (2012/13), no change on the previous year.
The current chief executive of the Council is Jim Savege and the elected Council Co-Leaders are Richard Thomson and Alison Evison. Aberdeenshire also has a Provost, who is Councillor Hamish Vernal.

The council has devolved power to six area committees: Banff and Buchan; Buchan; Formartine; Garioch; Marr; and Kincardine and Mearns

The following significant structures or places are within Aberdeenshire:


There are numerous rivers and burns in Aberdeenshire, including Cowie Water, Carron Water, Burn of Muchalls, River Dee, River Don, River Ury, River Ythan, Water of Feugh, Burn of Myrehouse, Laeca Burn and Luther Water. Numerous bays and estuaries are found along the seacoast of Aberdeenshire, including Banff Bay, Ythan Estuary, Stonehaven Bay and Thornyhive Bay. Aberdeenshire is in the rain shadow of the Grampians, therefore it is a generally dry climate, with portions of the coast, receiving of moisture annually. Summers are mild and winters are typically cold in Aberdeenshire; Coastal temperatures are moderated by the North Sea such that coastal areas are typically cooler in the summer and warmer in winter than inland locations. Coastal areas are also subject to haar, or coastal fog.



Category:Council areas of ScotlandAztlan Underground

Aztlan Underground is a band from Los Angeles, California that combines Hip-Hop, Punk Rock, Jazz, and electronic music with Chican@ and Native American themes, and indigenous instrumentation. They are often cited as progenitors of Chican@/Native rap and hip-hop.

The band traces its roots to the late-1980s hardcore scene in the Eastside of Los Angeles. They have played rapcore, with elements of punk, hip hop, rock, funk, jazz, indigenous music, and spoken word. Indigenous drums, flutes, and rattles are also commonly used in their music. Their lyrics often address the family and economic issues faced by the Chicano community, and they have been noted as activists for that community.

As an example of the politically active and culturally important artists in Los Angeles in the 1990s, Aztlan Underground appeared on "Culture Clash" on Fox in 1993; and was part of "Breaking Out", a concert on pay per view in 1998, The band was featured in the independent films "Algun Dia" and "Frontierland" in the 1990s, and on the upcoming "Studio 49". The band has been mentioned or featured in various newspapers and magazines: "the Vancouver Sun", "New Times", "BLU Magazine" (an underground hip hop magazine), "BAM Magazine", "La Banda Elastica Magazine", and the "Los Angeles Times" calendar section. The band is also the subject of a chapter in the book "It's Not About a Salary", by Brian Cross.

Aztlan Underground remains active in the community, lending their voice to annual events such as The Farce of July, and the recent movement to recognize Indigenous People's Day in Los Angeles and beyond.

In addition to forming their own label, Xicano Records and Film, Aztlan Underground were signed to the Basque record label Esan Ozenki in 1999 which enabled them to tour Spain extensively and perform in France and Portugal. Aztlan Underground have also performed in Canada, Australia, and Venezuela. The band has been recognized for their music with nominations in the "New Times" 1998 "Best Latin Influenced" category, the "BAM Magazine" 1999 "Best Rock en Español" category, and the "LA Weekly" 1999 "Best Hip Hop" category. The release of their eponymous third album on August 29, 2009 was met with positive reviews and earned the band four Native American Music Award (NAMMY) nominations in 2010.

Year:1995


Year:1998


Year: 2009


Category:Native American rappers
Category:American rappers of Mexican descent
Category:Musical groups from Los Angeles
Category:Rapcore groups
Category:West Coast hip hop musiciansAmerican Civil War

The American Civil War (also known by other names) was a war fought in the United States from 1861 to 1865, between the North and the South. The Civil War is the most studied and written about episode in U.S. history. Primarily as a result of the long-standing controversy over the enslavement of black people, war broke out in April 1861 when secessionist forces attacked Fort Sumter in South Carolina shortly after Abraham Lincoln had been inaugurated as the President of the United States. The loyalists of the Union in the North proclaimed support for the Constitution. They faced secessionists of the Confederate States in the South, who advocated for states' rights to uphold slavery.

Among the 34 U.S. states in February 1861, secessionist partisans in seven Southern slave states declared state secessions from the country and unveiled their defiant formation of a Confederate States of America in rebellion against the U.S. Constitutional government. The Confederacy grew to control over half the territory in eleven states, and it claimed the additional states of Kentucky and Missouri by assertions from exiled native secessionists without territory or population. These were then given full representation in the Confederate Congress throughout the Civil War. The two remaining slave holding states of Delaware and Maryland were invited to join the Confederacy, but nothing substantial developed. 

The Confederate States was never diplomatically recognized by the government of the United States or by that of any foreign country. The states that remained loyal to the U.S. were known as the Union. The Union and the Confederacy quickly raised volunteer and conscription armies that fought mostly in the South over the course of four years. Intense combat left 620,000 to 750,000 people dead, more than the number of U.S. military deaths in all other wars combined.

The war ended when General Robert E. Lee surrendered to General Ulysses S. Grant at the Battle of Appomattox Court House. Confederate generals throughout the southern states followed suit. Much of the South's infrastructure was destroyed, especially the transportation systems. The Confederacy collapsed, slavery was abolished, and four million black slaves were freed. During the Reconstruction Era that followed the war, national unity was slowly restored, the national government expanded its power, and civil rights were granted to freed black slaves through amendments to the Constitution
In the 1860 presidential election, Republicans, led by Abraham Lincoln, supported banning slavery in all the U.S. territories. The Southern states viewed this as a violation of their constitutional rights and as the first step in a grander Republican plan to eventually abolish slavery. The three pro-Union candidates together received an overwhelming 82% majority of the votes cast nationally: Republican Lincoln's votes centered in the north, Democrat Stephen A. Douglas' votes were distributed nationally and Constitutional Unionist John Bell's votes centered in Tennessee, Kentucky, and Virginia. The Republican Party, dominant in the North, secured a plurality of the popular votes and a majority of the electoral votes nationally; thus Lincoln was constitutionally elected president. He was the first Republican Party candidate to win the presidency. However, before his inauguration, seven slave states with cotton-based economies declared secession and formed the Confederacy. The first six to declare secession had the highest proportions of slaves in their populations, with an average of 49 percent. Of those states whose legislatures resolved for secession, the first seven voted with split majorities for unionist candidates Douglas and Bell (Georgia with 51% and Louisiana with 55%), or with sizable minorities for those unionists (Alabama with 46%, Mississippi with 40%, Florida with 38%, Texas with 25%, and South Carolina, which cast Electoral College
Eight remaining slave states continued to reject calls for secession. Outgoing Democratic President James Buchanan and the incoming Republicans rejected secession as illegal. Lincoln's March 4, 1861, inaugural address declared that his administration would not initiate a civil war. Speaking directly to the "Southern States", he attempted to calm their fears of any threats to slavery, reaffirming, "I have no purpose, directly or indirectly to interfere with the institution of slavery in the United States where it exists. I believe I have no lawful right to do so, and I have no inclination to do so." After Confederate forces seized numerous federal forts within territory claimed by the Confederacy, efforts at compromise failed and both sides prepared for war. The Confederates assumed that European countries were so dependent on "King Cotton" that they would intervene, but none did, and none recognized the new Confederate States of America.

Hostilities began on April 12, 1861, when Confederate forces fired upon Fort Sumter. While in the Western Theater the Union made significant permanent gains, in the Eastern Theater, the battle was inconclusive during 1861–1862. Later, in September 1862, Lincoln issued the Emancipation Proclamation, which made ending slavery a war goal. To the west, by summer 1862 the Union destroyed the Confederate river navy, then much of its western armies, and seized New Orleans. The successful 1863 Union siege of Vicksburg split the Confederacy in two at the Mississippi River. In 1863, Robert E. Lee's Confederate incursion north ended at the Battle of Gettysburg. Western successes led to Ulysses S. Grant's command of all Union armies in 1864. Inflicting an ever-tightening naval blockade of Confederate ports, the Union marshaled the resources and manpower to attack the Confederacy from all directions, leading to the fall of Atlanta to William T. Sherman and his march to the sea. The last significant battles raged around the Siege of Petersburg. Lee's escape attempt ended with his surrender at Appomattox Court House, on April 9, 1865. While the military war was coming to an end, the political reintegration of the nation was to take another 12 years, known as the Reconstruction Era

The American Civil War was among the earliest industrial wars. Railroads, the telegraph, steamships and iron-clad ships, and mass-produced weapons were employed extensively. The mobilization of civilian factories, mines, shipyards, banks, transportation, and food supplies all foreshadowed the impact of industrialization in World War I, World War II, and subsequent conflicts. It remains the deadliest war in American history. From 1861 to 1865, it is estimated that 620,000 to 750,000 soldiers died, along with an undetermined number of civilians. By one estimate, the war claimed the lives of 10 percent of all Northern men 20–45 years old, and 30 percent of all Southern white men aged 18–40.

The causes of secession were complex and have been controversial since the war began, but most academic scholars identify slavery as a central cause of the war. James C. Bradford wrote that the issue has been further complicated by historical revisionists, who have tried to offer a variety of reasons for the war. Slavery was the central source of escalating political tension in the 1850s. The Republican Party was determined to prevent any spread of slavery, and many Southern leaders had threatened secession if the Republican candidate, Lincoln, won the 1860 election. After Lincoln won, many Southern leaders felt that disunion was their only option, fearing that the loss of representation would hamper their ability to promote pro-slavery acts and policies.

[[File:US Secession map 1861.svg|thumb|upright=1.15|right| 

Slavery was a major cause of disunion. Although there were opposing views even in the Union States, most northern soldiers were mostly indifferent on the subject of slavery, while Confederates fought the war mainly to protect a southern society of which slavery was an integral part. From the anti-slavery perspective, the issue was primarily about whether the system of slavery was an anachronistic evil that was incompatible with [[Republicanism in the United States|republicanism]]. The strategy of the anti-slavery forces was containment—to stop the expansion and thus put slavery on a path to gradual extinction. The slave-holding interests in the South denounced this strategy as infringing upon their Constitutional rights. Southern whites believed that the emancipation of slaves would destroy the South's economy, due to the large amount of capital invested in slaves and fears of integrating the ex-slave black population. In particular, Southerners feared a repeat of [[1804 Haiti massacre|"the horrors of Santo Domingo"]], in which nearly all white people – including men, women, children, and even many sympathetic to abolition – were killed after the [[Haitian Revolution|successful slave revolt in Haiti]]. Historian Thomas Fleming points to the historical phrase "a disease in the public mind" used by critics of this idea, and proposes it contributed to the segregation in the [[Jim Crow]] era following emancipation. These fears were exacerbated by the [[John Brown's raid on Harpers Ferry|recent attempt]] of [[John Brown (abolitionist)|John Brown]] to instigate an armed slave rebellion in the South.

Slavery was illegal in much of the North, having been outlawed in the late 18th and early 19th centuries. It was also fading in the border states and in Southern cities, but it was expanding in the highly profitable cotton districts of the rural South and Southwest. Subsequent writers on the American Civil War looked to several factors explaining the geographic divide.

Between 1803 and 1854, the United States achieved a vast expansion of territory through purchase, negotiation, and conquest. At first, the new states carved out of these territories entering the union were apportioned equally between slave and free states. Pro- and anti-slavery forces collided over the territories west of the Mississippi.

With the conquest of northern [[Mexico]] west to [[Alta California|California]] in 1848, slaveholding interests looked forward to expanding into these lands and perhaps Cuba and Central America as well.
Northern "free soil" interests vigorously sought to curtail any further expansion of slave territory. The [[Compromise of 1850]] over California balanced a free-soil state with stronger fugitive slave laws for a political settlement after four years of strife in the 1840s. But the states admitted following California were all free: Minnesota (1858), Oregon (1859) and Kansas (1861). In the Southern states the question of the territorial expansion of slavery westward again became explosive. Both the South and the North drew the same conclusion: "The power to decide the question of slavery for the territories was the power to determine the future of slavery itself."

By 1860, four doctrines had emerged to answer the question of federal control in the territories, and they all claimed they were sanctioned by the Constitution, implicitly or explicitly. The first of these "conservative" theories, represented by the [[Constitutional Union Party (United States)|Constitutional Union Party]], argued that the [[Missouri Compromise]] apportionment of territory north for free soil and south for slavery should become a Constitutional mandate. The [[Crittenden Compromise]] of 1860 was an expression of this view.

The second doctrine of Congressional preeminence, championed by Abraham Lincoln and the Republican Party, insisted that the Constitution did not bind legislators to a policy of balance—that slavery could be excluded in a territory as it was done in the [[Northwest Ordinance]] of 1787 at the discretion of Congress; thus Congress could restrict human bondage, but never establish it. The [[Wilmot Proviso]] announced this position in 1846.

Senator [[Stephen A. Douglas]] proclaimed the doctrine of territorial or "popular" sovereignty—which asserted that the settlers in a territory had the same rights as states in the Union to establish or disestablish slavery as a purely local matter. The [[Kansas–Nebraska Act]] of 1854 legislated this doctrine. In the Kansas Territory, years of [[Bleeding Kansas|pro and anti-slavery violence]] and political conflict erupted; the congressional House of Representatives voted to admit Kansas as a free state in early 1860, but its admission in the Senate was delayed until January 1861, after the 1860 elections when Southern states began to leave.

The fourth theory was advocated by Mississippi Senator [[Jefferson Davis]], one of state sovereignty ("states' rights"), also known as the "Calhoun doctrine", named after the South Carolinian political theorist and statesman [[John Caldwell Calhoun|John C. Calhoun]]. Rejecting the arguments for federal authority or self-government, state sovereignty would empower states to promote the expansion of slavery as part of the federal union under the U.S. Constitution. "States' rights" was an ideology formulated and applied as a means of advancing slave state interests through federal authority. As historian Thomas L. Krannawitter points out, the "Southern demand for federal slave protection represented a demand for an unprecedented expansion of federal power." These four doctrines comprised the dominant ideologies presented to the American public on the matters of slavery, the territories, and the U.S. Constitution before the 1860 presidential election.

The South argued that just as each state had decided to join the Union, a state had the right to secede—leave the Union—at any time. Northerners (including President Buchanan) rejected that notion as opposed to the will of the [[Founding Fathers]], who said they were setting up a perpetual union. Historian James McPherson writes concerning states' rights and other non-slavery explanations:

[[Sectionalism]] resulted from the different economies, social structure, customs, and political values of the North and South. Regional tensions came to a head during the [[War of 1812]], resulting in the [[Hartford Convention]], which manifested Northern dissastisfaction with a foreign trade embargo that affected the industrial North disproportionately, the [[Three-Fifths Compromise]], dilution of Northern power by new states, and a succession of [[Virginia Dynasty|Southern presidents]]. Sectionalism increased steadily between 1800 and 1860 as the North, which phased slavery out of existence, industrialized, urbanized, and built prosperous farms, while the deep South concentrated on plantation agriculture based on slave labor, together with [[subsistence farming]] for poor whites. In the 1840s and 50s, the issue of accepting slavery (in the guise of rejecting slave-owning bishops and missionaries) split the nation's largest religious denominations (the Methodist, Baptist, and Presbyterian churches) into separate Northern and Southern denominations.

Historians have debated whether economic differences between the mainly industrial North and the mainly agricultural South helped cause the war. Most historians now disagree with the [[economic determinism]] of historian [[Charles A. Beard]] in the 1920s, and emphasize that Northern and Southern economies were largely complementary. While socially different, the sections economically benefited each other.

Slave owners preferred low-cost manual labor with no mechanization. Northern manufacturing interests supported tariffs and protectionism while southern planters demanded free trade, The Democrats in Congress, controlled by Southerners, wrote the tariff laws in the 1830s, 1840s, and 1850s, and kept reducing rates so that the 1857 rates were the lowest since 1816. The Republicans called for an increase in tariffs in the 1860 election. The increases were only enacted in 1861 after Southerners resigned their seats in Congress. The tariff issue was a Northern grievance. However, [[neo-Confederate]] writers have claimed it as a Southern grievance. In 1860–61 none of the groups that proposed compromises to head off secession raised the tariff issue. Pamphleteers North and South rarely mentioned the tariff.

Nationalism was a powerful force in the early 19th century, with famous spokesmen such as [[Andrew Jackson]] and [[Daniel Webster]]. While practically all Northerners supported the Union, Southerners were split between those loyal to the entire United States (called "unionists") and those loyal primarily to the southern region and then the Confederacy. [[C. Vann Woodward]] said of the latter group,

Perceived insults to Southern collective honor included the enormous popularity of "[[Uncle Tom's Cabin]]" (1852) and the actions of abolitionist [[John Brown (abolitionist)|John Brown]] in trying to incite a [[John Brown's raid on Harpers Ferry|slave rebellion]] in 1859.

While the South moved towards a Southern nationalism, leaders in the North were also becoming more nationally minded, and they rejected any notion of splitting the Union. The Republican national electoral platform of 1860 warned that Republicans regarded disunion as [[treason]] and would not tolerate it: "We denounce those threats of disunion ... as denying the vital principles of a free government, and as an avowal of contemplated treason, which it is the imperative duty of an indignant people sternly to rebuke and forever silence." The South ignored the warnings: Southerners did not realize how ardently the North would fight to hold the Union together.

[[File:Abraham Lincoln seated, Feb 9, 1864.jpg|thumb|190px|Abraham Lincoln in 1864]]

The election of Abraham Lincoln in November 1860 was the final trigger for secession. Efforts at compromise, including the "[[Corwin Amendment]]" and the "[[Crittenden Compromise]]", failed.
Southern leaders feared that Lincoln would stop the expansion of slavery and put it on a course toward extinction. The slave states, which had already become a minority in the House of Representatives, were now facing a future as a perpetual minority in the Senate and Electoral College against an increasingly powerful North. Before Lincoln took office in March 1861, seven slave states had declared their secession and joined to form the Confederacy.

According to Lincoln, the people had shown that they can be successful in "establishing" and "administering" a republic, but a third challenge faced the nation, "maintaining" a republic based on the people's vote against an attempt to overthrow it.

The election of Lincoln caused the legislature of South Carolina to call a state convention to consider secession. Prior to the war, South Carolina did more than any other Southern state to advance the notion that a state had the right to [[Nullification (U.S. Constitution)|nullify]] federal laws, and even to secede from the United States. The convention summoned unanimously voted to secede on December 20, 1860, and adopted the "[[Declaration of the Immediate Causes Which Induce and Justify the Secession of South Carolina from the Federal Union]]". It argued for states' rights for slave owners in the South, but contained a complaint about states' rights in the North in the form of opposition to the [[Fugitive Slave Law of 1850|Fugitive Slave Act]], claiming that Northern states were not fulfilling their federal obligations under the Constitution. The "cotton states" of Mississippi, Florida, Alabama, Georgia, Louisiana, and Texas followed suit, seceding in January and February 1861.

[[File:Charleston Mercury Secession Broadside, 1860.jpg|thumb|upright|left|The first published imprint of secession, a [[Broadside (printing)|broadside]] issued by the "[[Charleston Mercury]]", December 20, 1860]]

Among the ordinances of secession passed by the individual states, those of three—Texas, Alabama, and Virginia—specifically mentioned the plight of the "slaveholding states" at the hands of northern abolitionists. The rest make no mention of the slavery issue, and are often brief announcements of the dissolution of ties by the legislatures. However, at least four states—South Carolina, Mississippi, Georgia, and Texas—also passed lengthy and detailed explanations of their causes for secession, all of which laid the blame squarely on the movement to abolish slavery and that movement's influence over the politics of the northern states. The southern states believed slaveholding was a constitutional right because of the [[Fugitive slave clause]] of the Constitution.

These states agreed to form a new federal government, the [[Confederate States of America]], on February 4, 1861. They took control of federal forts and other properties within their boundaries with little resistance from outgoing President [[James Buchanan]], whose term ended on March 4, 1861. Buchanan said that the [[Dred Scott decision]] was proof that the South had no reason for secession, and that the Union "was intended to be perpetual", but that "The power by force of arms to compel a State to remain in the Union" was not among the "enumerated powers granted to Congress". One quarter of the U.S. Army—the entire garrison in Texas—was surrendered in February 1861 to state forces by its commanding general, [[David E. Twiggs]], who then joined the Confederacy.

As Southerners resigned their seats in the Senate and the House, Republicans were able to pass bills for projects that had been blocked by Southern Senators before the war. These included the [[Morrill Tariff]], land grant colleges (the [[Morrill Land-Grant Colleges Act|Morrill Act]]), a [[Homestead Act]], a transcontinental railroad (the [[Pacific Railway Acts]]), the [[National Banking Act]] and the authorization of [[United States Note]]s by the Legal Tender Act of 1862. The [[Revenue Act of 1861]] introduced the [[income tax]] to help finance the war.

On December 18, 1860, the [[Crittenden Compromise]] was proposed to re-establish the [[Missouri Compromise]] line by constitutionally banning slavery in territories to the north of the line while guaranteeing it to the south. The adoption of this compromise likely would have prevented the secession of every southern state apart from South Carolina, but Lincoln and the Republicans rejected it. It was then proposed to hold a national referendum on the compromise. The Republicans again rejected the idea, although a majority of both Northerners and Southerners would have voted in favor of it. A pre-war February [[Peace Conference of 1861]] met in Washington, proposing a solution similar to that of the Crittenden compromise, it was rejected by Congress. The Republicans proposed an [[Corwin amendment|alternative compromise]] to not interfere with slavery where it existed but the South regarded it as insufficient. Nonetheless, the remaining eight slave states rejected pleas to join the Confederacy following a two-to-one no-vote in Virginia's First Secessionist Convention on April 4, 1861.

[[File:President-Jefferson-Davis.jpg|thumb|upright|[[Jefferson Davis]], [[President of the Confederate States of America]] (1861–1865)|alt=Middle-aged man in a goatee posed standing in a suit, vest and bowtie]]

On March 4, 1861, [[Abraham Lincoln]] was sworn in as President. In his [[Inauguration|inaugural address]], he argued that the Constitution was a "[[Preamble to the United States Constitution|more perfect union]]" than the earlier [[Articles of Confederation|Articles of Confederation and Perpetual Union]], that it was a binding contract, and called any secession "legally void". He had no intent to invade Southern states, nor did he intend to end slavery where it existed, but said that he would use force to maintain possession of Federal property. The government would make no move to recover post offices, and if resisted, mail delivery would end at state lines. Where popular conditions did not allow peaceful enforcement of Federal law, U.S. marshals and judges would be withdrawn. No mention was made of bullion lost from U.S. mints in Louisiana, Georgia, and North Carolina. He stated that it would be U.S. policy to only collect import duties at its ports; there could be no serious injury to the South to justify armed revolution during his administration. His speech closed with a plea for restoration of the bonds of union, famously calling on "the mystic chords of memory" binding the two regions.

The South sent delegations to Washington and offered to pay for the federal properties and enter into a peace treaty with the United States. Lincoln rejected any negotiations with Confederate agents because he claimed the Confederacy was not a legitimate government, and that making any treaty with it would be tantamount to recognition of it as a sovereign government. Secretary of State [[William H. Seward|William Seward]], who at the time saw himself as the real governor or "prime minister" behind the throne of the inexperienced Lincoln, engaged in unauthorized and indirect negotiations that failed. President Lincoln was determined to hold all remaining Union-occupied forts in the Confederacy: [[Fort Monroe]] in Virginia, [[Fort Pickens]], [[Fort Jefferson, Florida|Fort Jefferson]] and [[Fort Zachary Taylor|Fort Taylor]] in Florida, and [[Fort Sumter]] – located at the cockpit of secession in Charleston, South Carolina.

[[File:Fort sumter 1861.jpg|thumb|left|The Confederate "Stars and Bars" flying from Fort Sumter]]
Fort Sumter was located in the middle of the harbor of [[Charleston, South Carolina in the American Civil War|Charleston]], South Carolina. Its garrison recently moved there to avoid incidents with local militias in the streets of the city. Lincoln told Maj. Anderson to hold on until fired upon. Jefferson Davis ordered the surrender of the fort. Anderson gave a conditional reply that the Confederate government rejected, and Davis ordered General [[P. G. T. Beauregard]] to attack the fort before a relief expedition could arrive. He bombarded Fort Sumter on April 12–13, forcing its capitulation.

The attack on Fort Sumter rallied the North to the defense of American nationalism. Historian [[Allan Nevins]] said:

[[File:Great Meeting Union Square.jpg|thumb|220px|Mass meeting in New York City April 20, 1861, to support the Union.]]

Union leaders incorrectly assumed that only a minority of Southerners were in favor of secession and that there were large numbers of southern Unionists that could be counted on. Had Northerners realized that most Southerners favored secession, they might have hesitated at attempting the enormous task of conquering a united South.

Lincoln called on all the states to send forces to recapture the fort and other federal properties. The scale of the rebellion appeared to be small, so he called for only [[75,000 volunteers]] for 90 days. The governor of Massachusetts had state regiments on trains headed south the next day. In western Missouri, local secessionists seized [[Liberty Arsenal]]. On May 3, 1861, Lincoln called for an additional 42,000 volunteers for a period of three years.

Four states in the middle and upper South had repeatedly rejected Confederate overtures, but now [[Virginia in the American Civil War|Virginia]], [[Tennessee in the American Civil War|Tennessee]], [[Arkansas in the American Civil War|Arkansas]], and [[North Carolina in the American Civil War|North Carolina]] refused to send forces against their neighbors, declared their secession, and joined the Confederacy. To reward Virginia, the Confederate capital was moved to [[Richmond, Virginia|Richmond]].

[[File:US Secession map 1863 (BlankMap derived).png|thumb|upright=1.15|right|US Secession map 1863. The [[Union (American Civil War)|Union]] vs. the [[Confederate States of America|Confederacy.]]

[[Maryland]], [[Delaware]], [[Missouri]], and [[Kentucky]] were slave states that were opposed to both secession and coercing the South. [[West Virginia]] then joined them as an additional border state after it separated from [[Virginia]] and became a state of the [[Union (American Civil War)|Union]] in 1863.

Maryland's territory surrounded the United States' capital of [[Washington DC in the Civil War|Washington, DC]] and could cut it off from the North. It had numerous anti-Lincoln officials who tolerated anti-army [[Baltimore riot of 1861|rioting in Baltimore]] and the burning of bridges, both aimed at hindering the passage of troops to the South. Maryland's legislature voted overwhelmingly (53–13) to stay in the Union, but also rejected hostilities with its southern neighbors, voting to close Maryland's rail lines to prevent them from being used for war. Lincoln responded by establishing [[martial law]] and unilaterally suspending [[habeas corpus]] in Maryland, along with sending in militia units from the North. Lincoln rapidly took control of Maryland and the District of Columbia by seizing many prominent figures, including arresting 1/3 of the members of the [[Maryland General Assembly]] on the day it reconvened. All were held without trial, ignoring a ruling by the Chief Justice of the U.S. Supreme Court [[Roger Taney]], a Maryland native, that only Congress (and not the president) could suspend habeas corpus ([[Ex parte Merryman]]). Indeed, federal troops imprisoned a prominent Baltimore newspaper editor, [[Frank Key Howard]], Francis Scott Key's grandson, after he criticized Lincoln in an editorial for ignoring the Supreme Court Chief Justice's ruling.

In Missouri, an [[Missouri Constitutional Convention (1861–63)|elected convention]] on secession voted decisively to remain within the Union. When pro-Confederate Governor [[Claiborne Fox Jackson|Claiborne F. Jackson]] called out the state militia, it was attacked by federal forces under General [[Nathaniel Lyon]], who chased the governor and the rest of the State Guard to the southwestern corner of the state ("see also": [[Missouri secession]]). In the resulting vacuum, the convention on secession reconvened and took power as the Unionist provisional government of Missouri.

Kentucky did not secede; for a time, it declared itself neutral. When Confederate forces entered the state in September 1861, neutrality ended and the state reaffirmed its Union status, while trying to maintain slavery. During a brief invasion by Confederate forces, Confederate sympathizers organized a secession convention, inaugurated a governor, and gained recognition from the Confederacy. The rebel government soon went into exile and never controlled Kentucky.

After Virginia's secession, a [[Restored Government of Virginia|Unionist government]] in [[Wheeling, West Virginia|Wheeling]] asked 48 counties to vote on an ordinance to create a new state on October 24, 1861. A voter turnout of 34 percent approved the statehood bill (96 percent approving). The inclusion of 24 secessionist counties in the state and the ensuing guerrilla war engaged about 40,000 Federal troops for much of the war. Congress admitted [[West Virginia]] to the Union on June 20, 1863. West Virginia provided about 20,000–22,000 soldiers to both the Confederacy and the Union.

A Unionist secession attempt occurred in [[East Tennessee]], but was suppressed by the Confederacy, which arrested over 3,000 men suspected of being loyal to the Union. They were held without trial.

The Civil War was a contest marked by the ferocity and frequency of battle. Over four years, 237 named battles were fought, as were many more minor actions and skirmishes, which were often characterized by their bitter intensity and high casualties. In his book "The American Civil War", John Keegan writes that "The American Civil War was to prove one of the most ferocious wars ever fought". Without geographic objectives, the only target for each side was the enemy's soldier.

As the first seven states began organizing a Confederacy in Montgomery, the entire U.S. army numbered 16,000. However, Northern governors had begun to mobilize their militias. The Confederate Congress authorized the new nation up to 100,000 troops sent by governors as early as February. By May, Jefferson Davis was pushing for 100,000 men under arms for one year or the duration, and that was answered in kind by the U.S. Congress.

In the first year of the war, both sides had far more volunteers than they could effectively train and equip. After the initial enthusiasm faded, reliance on the cohort of young men who came of age every year and wanted to join was not enough. Both sides used a draft law—[[conscription]]—as a device to encourage or force volunteering; relatively few were drafted and served. The Confederacy passed a draft law in April 1862 for young men aged 18 to 35; overseers of slaves, government officials, and clergymen were exempt. The U.S. Congress followed in July, authorizing a militia draft within a state when it could not meet its quota with volunteers. European [[History of Immigration to the United States#1850 to 1930|immigrants]] joined the [[Union Army]] in large numbers, including 177,000 born in Germany and 144,000 born in Ireland.

When the Emancipation Proclamation went into effect in January 1863, ex-slaves were energetically recruited by the states, and used to meet the state quotas. States and local communities offered higher and higher cash bonuses for white volunteers. Congress tightened the law in March 1863. Men selected in the draft could provide substitutes or, until mid-1864, pay commutation money. Many eligibles pooled their money to cover the cost of anyone drafted. Families used the substitute provision to select which man should go into the army and which should stay home. There was much evasion and overt resistance to the draft, especially in Catholic areas. The [[New York Draft Riots|draft riot in New York City]] in July 1863 involved Irish immigrants who had been signed up as citizens to swell the vote of the [[Tammany Hall|city's Democratic political machine]], not realizing it made them liable for the draft. Of the 168,649 men procured for the Union through the draft, 117,986 were substitutes, leaving only 50,663 who had their personal services conscripted.

[[File:NYRiot.jpg|thumb|upright|Rioters attacking a building during the [[New York City draft riots|New York anti-draft riots]] of 1863]]

In both the North and South, the draft laws were highly unpopular. In the North, some 120,000 men evaded conscription, many of them fleeing to Canada, and another 280,000 soldiers deserted during the war. At least 100,000 Southerners deserted, or about 10 percent. In the South, many men deserted temporarily to take care of their distressed families, then returned to their units. In the North, "bounty jumpers" enlisted to get the generous bonus, deserted, then went back to a second recruiting station under a different name to sign up again for a second bonus; 141 were caught and executed.

From a tiny frontier force in 1860, the Union and Confederate armies had grown into the "largest and most efficient armies in the world" within a few years. European observers at the time dismissed them as amateur and unprofessional, but British historian [[John Keegan]] concluded that each outmatched the French, Prussian and Russian armies of the time, and but for the Atlantic, would have threatened any of them with defeat.

Perman and Taylor (2010) write that historians are of two minds on why millions of men seemed so eager to fight, suffer and die over four years:

At the start of the civil war, a system of paroles operated. Captives agreed not to fight until they were officially exchanged. Meanwhile, they were held in camps run by their army. They were paid, but they were not allowed to perform any military duties. The system of exchanges collapsed in 1863 when the Confederacy refused to exchange black prisoners. After that, about 56,000 of the 409,000 POWs died in prisons during the war, accounting for nearly 10 percent of the conflict's fatalities.

The small [[Union Navy|U.S. Navy]] of 1861 was rapidly enlarged to 6,000 officers and 45,000 men in 1865, with 671 vessels, having a tonnage of 510,396. Its mission was to blockade Confederate ports, take control of the river system, defend against Confederate raiders on the high seas, and be ready for a possible war with the British [[Royal Navy]]. Meanwhile, the main riverine war was fought in the West, where a series of major rivers gave access to the Confederate heartland. The U.S. Navy eventually gained control of the Red, Tennessee, Cumberland, Mississippi, and Ohio rivers. In the East, the Navy supplied and moved army forces about, and occasionally shelled Confederate installations.

[[File:NavalBattleOfFortPillow.jpg|thumb|upright=1.15|Clashes on the rivers were melees of [[ironclads]], [[Cottonclad warship|cottonclads]], [[gunboats]] and rams, complicated by torpedoes and [[Fire ship|fire rafts]].]]The Civil War occurred during the early stages of the industrial revolution. Many naval innovations emerged during this time, most notably the advent of the [[ironclad warship]]. It began when the Confederacy, knowing they had to meet or match the Union's naval superiority, responded to the Union blockade by building or converting more than 130 vessels, including twenty-six ironclads and floating batteries. Only half of these saw active service. Many were equipped with ram bows, creating "ram fever" among Union squadrons wherever they threatened. But in the face of overwhelming Union superiority and the Union's ironclad warships, they were unsuccessful.

[[File:Battle of Hampton Roads 3g01752u.jpg|240px|thumb|left| Battle between the Monitor and Merrimack.]]

In addition to ocean-going warships coming up the Mississippi, the Union Navy used timberclads, tinclads, and armored gunboats. Shipyards at Cairo, Illinois, and St. Louis built new boats or modified steamboats for action.

The Confederacy experimented with the [[submarine]] , which didn't work satisfactorily, and with building an ironclad ship, , which was based on rebuilding a sunken Union ship, . On its first foray on March 8, 1862, "Virginia" inflicted significant damage to the Union's wooden fleet, but the next day the first Union ironclad, , arrived to challenge it in the [[Chesapeake Bay]]. The resulting three hour [[Battle of Hampton Roads]] was a draw, but it proved that ironclads were effective warships. Not long after the battle the Confederacy was forced to scuttle the "Virginia" to prevent its capture, while the Union built many copies of the "Monitor". Lacking the technology and infrastructure to build effective warships, the Confederacy attempted to obtain warships from Britain.

[[File:Scott-anaconda.jpg|thumb|upright=1.3|General Scott's "[[Anaconda Plan]]" 1861. Tightening naval blockade, forcing rebels out of Missouri along the Mississippi River, Kentucky Unionists sit on the fence, idled cotton industry illustrated in Georgia.|alt=A cartoon map of the South surrounded by a snake.]]

By early 1861, General [[Winfield Scott]] had devised the [[Anaconda Plan]] to win the war with as little bloodshed as possible. Scott argued that a Union blockade of the main ports would weaken the Confederate economy. Lincoln adopted parts of the plan, but he overruled Scott's caution about 90-day volunteers. Public opinion, however, demanded an immediate attack by the army to capture Richmond.

In April 1861, Lincoln announced the Union blockade of all Southern ports; commercial ships could not get insurance and regular traffic ended. The South blundered in embargoing cotton exports in 1861 before the blockade was effective; by the time they realized the mistake, it was too late. "King Cotton" was dead, as the South could export less than 10 percent of its cotton. The blockade shut down the ten Confederate seaports with railheads that moved almost all the cotton, especially New Orleans, Mobile, and Charleston. By June 1861, warships were stationed off the principal Southern ports, and a year later nearly 300 ships were in service.

[[File:First Charleston Harbor.jpg|thumb|upright=1.15|Gunline of nine Union ironclads. [[Union blockade#South Atlantic Blockading Squadron|South Atlantic Blockading Squadron]] off Charleston. Continuous blockade of all major ports was sustained by North's ov

erwhelming war production.]]

British investors built small, fast, steam-driven [[Blockade runners of the American Civil War|blockade runners]] that traded arms and luxuries brought in from Britain through Bermuda, Cuba, and the Bahamas in return for high-priced cotton. Many of the ships were designed for speed and were so small that only a small amount of cotton went out. When the Union Navy seized a blockade runner, the ship and cargo were condemned as a [[Prize of war]] and sold, with the proceeds given to the Navy sailors; the captured crewmen were mostly British, and they were released.

The Southern economy nearly collapsed during the war. There were multiple reasons for this: the severe deterioration of food supplies, especially in cities, the failure of Southern railroads, the loss of control of the main rivers, foraging by Northern armies, and the seizure of animals and crops by Confederate armies.

Most historians agree that the blockade was a major factor in ruining the Confederate economy; however, Wise argues that the blockade runners provided just enough of a lifeline to allow Lee to continue fighting for additional months, thanks to fresh supplies of 400,000 rifles, lead, blankets, and boots that the homefront economy could no longer supply.

Surdam argues that the blockade was a powerful weapon that eventually ruined the Southern economy, at the cost of few lives in combat. Practically, the entire Confederate cotton crop was useless (although it was sold to Union traders), costing the Confederacy its main source of income. Critical imports were scarce and the coastal trade was largely ended as well. The measure of the blockade's success was not the few ships that slipped through, but the thousands that never tried it. Merchant ships owned in Europe could not get insurance and were too slow to evade the blockade, so they stopped calling at Confederate ports.

To fight an offensive war, the Confederacy purchased ships from Britain, converted them to warships, and raided American merchant ships in the Atlantic and Pacific oceans. Insurance rates skyrocketed and the American flag virtually disappeared from international waters. However, the same ships were reflagged with European flags and continued unmolested. After the war, the U.S. demanded that Britain pay for the damage done, and Britain paid the U.S. $15 million in 1871.

Although the Confederacy hoped that Britain and France would join them against the Union, this was never likely, and so they instead tried to bring Britain and France in as mediators. The Union, under Lincoln and Secretary of State [[William H. Seward]] worked to block this, and threatened war if any country officially recognized the existence of the Confederate States of America. In 1861, Southerners voluntarily embargoed cotton shipments, hoping to start an economic depression in Europe that would force Britain to enter the war to get cotton, but this did not work. Worse, Europe developed other cotton suppliers, which they found superior, hindering the South's recovery after the war.
[[File:USS Wissahickon Crewmembers.jpg|thumb|upright=1.3|Crewmembers of by the ship's [[Dahlgren gun]], circa 1863|alt=A group of twenty-six sailors posing around a rifled naval cannon]]
[[Cotton diplomacy]] proved a failure as Europe had a surplus of cotton, while the 1860–62 crop failures in Europe made the North's grain exports of critical importance. It also helped to turn European opinion further away from the Confederacy. It was said that "King Corn was more powerful than King Cotton", as U.S. grain went from a quarter of the British import trade to almost half. When Britain did face a cotton shortage, it was temporary, being replaced by increased cultivation in Egypt and India. Meanwhile, the war created employment for arms makers, ironworkers, and British ships to transport weapons.

Lincoln's administration failed to appeal to European public opinion. Diplomats explained that the United States was not committed to the ending of slavery, and instead repeated legalistic arguments about the unconstitutionality of secession. Confederate representatives, on the other hand, were much more successful by ignoring slavery and instead focusing on their struggle for liberty, their commitment to free trade, and the essential role of cotton in the European economy. The European aristocracy was "absolutely gleeful in pronouncing the American debacle as proof that the entire experiment in popular government had failed. European government leaders welcomed the fragmentation of the ascendant American Republic."

U.S. [[ambassador|minister]] to Britain [[Charles Francis Adams, Sr.|Charles Francis Adams]] proved particularly adept and convinced Britain not to boldly challenge the blockade. The Confederacy purchased several warships from commercial shipbuilders in Britain (, , , , , and some others). The most famous, the , did considerable damage and led to serious [[Alabama Claims|postwar disputes]]. However, public opinion against slavery created a political liability for politicians in Britain, where the antislavery movement was powerful.

War loomed in late 1861 between the U.S. and Britain over the [[Trent Affair|"Trent" affair]], involving the U.S. Navy's boarding of the British ship and seizure of two Confederate diplomats. However, London and Washington were able to smooth over the problem after Lincoln released the two. In 1862, the British considered mediation between North and South, though even such an offer would have risked war with the United States. British Prime Minister [[Henry John Temple, 3rd Viscount Palmerston|Lord Palmerston]] reportedly read "[[Uncle Tom's Cabin]]" three times when deciding on this.

The Union victory in the [[Battle of Antietam]] caused them to delay this decision. The [[Emancipation Proclamation]] over time would reinforce the political liability of supporting the Confederacy. Despite sympathy for the Confederacy, France's [[French intervention in Mexico|seizure of Mexico]] ultimately deterred them from war with the Union. Confederate offers late in the war to end slavery in return for diplomatic recognition were not seriously considered by London or Paris. After 1863, the [[January Uprising|Polish revolt against Russia]] further distracted the European powers, and ensured that they would remain neutral.

[[File:American Civil War Battles by Theater, Year.png|thumb|[[County (United States)|County]] map of Civil War battles by theater and year]]

The Eastern theater refers to the military operations east of the [[Appalachian Mountains]], including the states of [[Virginia]], [[West Virginia]], [[Maryland]], and [[Pennsylvania]], the [[District of Columbia]], and the coastal fortifications and seaports of [[North Carolina]].

Maj. Gen. [[George B. McClellan]] took command of the Union [[Army of the Potomac]] on July 26 (he was briefly general-in-chief of all the Union armies, but was subsequently relieved of that post in favor of Maj. Gen. [[Henry Halleck|Henry W. Halleck]]), and the war began in earnest in 1862. The 1862 Union strategy called for simultaneous advances along four axes:


[[File:Robert_Edward_Lee.jpg|thumb|140px|Robert E. Lee]]
The primary Confederate force in the Eastern theater was the [[Army of Northern Virginia]]. The Army originated as the [[Confederate Army of the Potomac|(Confederate) Army of the Potomac]], which was organized on June 20, 1861, from all operational forces in northern Virginia. On July 20 and July 21, the [[Army of the Shenandoah (Confederate)|Army of the Shenandoah]] and forces from the District of Harpers Ferry were added. Units from the [[Army of the Northwest (Confederate)|Army of the Northwest]] were merged into the Army of the Potomac between March 14 and May 17, 1862. The Army of the Potomac was renamed "Army of Northern Virginia" on March 14. The [[Army of the Peninsula]] was merged into it on April 12, 1862. 
[[File:Flag of the Army of Northern Virginia.svg|thumb|left|150px|Flag of Army of Northern Virginia]]
When Virginia declared its secession in April 1861, [[Robert E. Lee]] chose to follow his home state, despite his desire for the country to remain intact and an offer of a senior Union command.

Lee's biographer, [[Douglas S. Freeman]], asserts that the army received its final name from Lee when he issued orders assuming command on June 1, 1862. However, Freeman does admit that Lee corresponded with Brigadier General [[Joseph E. Johnston]], his predecessor in army command, prior to that date and referred to Johnston's command as the Army of Northern Virginia. Part of the confusion results from the fact that Johnston commanded the Department of Northern Virginia (as of October 22, 1861) and the name Army of Northern Virginia can be seen as an informal consequence of its parent department's name. Jefferson Davis and Johnston did not adopt the name, but it is clear that the organization of units as of March 14 was the same organization that Lee received on June 1, and thus it is generally referred to today as the Army of Northern Virginia, even if that is correct only in retrospect. [[Jeb Stuart]] commanded the Army of Northern Virginia's cavalry.

[[File:Stonewall Jackson by Routzahn, 1862.png|thumb|150px|"Stonewall" Jackson got his nickname at the First Battle of Bull Run.]]In one of the first highly visible battles, in July 1861, a march by Union troops under the command of [[Major General|Maj. Gen.]] [[Irvin McDowell]] on the Confederate forces led by Gen. [[P. G. T. Beauregard]] near Washington was repulsed at the [[First Battle of Bull Run]]. 
[[File:George B McClellan - retouched.jpg|thumb|180px|left|George McClellan]]
The Union had the upper hand at first, nearly pushing confederate forces holding a defensive position into a rout, but Confederate reinforcements under. Joseph E. Johnston arrived from the [[Shenandoah Valley]] by railroad, and the course of the battle quickly changed. A [[Stonewall Brigade|brigade of Virginians]] under the relatively unknown brigadier general from the [[Virginia Military Institute]], [[Stonewall Jackson|Thomas J. Jackson]], stood its ground, which resulted in Jackson receiving his famous nickname, "Stonewall".


Upon the strong urging of President Lincoln to begin offensive operations, McClellan attacked Virginia in the spring of 1862 by way of the [[Virginia Peninsula|peninsula]] between the [[York River (Virginia)|York River]] and [[James River]], southeast of Richmond. McClellan's army reached the gates of Richmond in the [[Peninsula Campaign]],

[[File:Bayonet-charge-1250.jpg|thumb|Union forces performing a bayonet charge, 1862]]Also in the spring of 1862, in the Shenandoah Valley, Stonewall Jackson led his [[Jackson's Valley Campaign|Valley Campaign]]. Employing audacity and rapid, unpredictable movements on interior lines, Jackson's 17,000 men marched 646 miles (1,040 km) in 48 days and won several minor battles as they successfully engaged three Union armies (52,000 men), including those of [[Nathaniel P. Banks]] and [[John C. Frémont|John C. Fremont]], preventing them from reinforcing the Union offensive against Richmond. The swiftness of Jackson's men earned them the nickname of "foot-cavalry".

Johnston halted McClellan's advance at the [[Battle of Seven Pines]], but he was wounded in the battle, and Robert E. Lee assumed his position of command. General Lee and top subordinates [[James Longstreet]] and Stonewall Jackson defeated McClellan in the [[Seven Days Battles]] and forced his retreat.

The [[Northern Virginia Campaign]], which included the [[Second Battle of Bull Run]], ended in yet another victory for the South. McClellan resisted General-in-Chief Halleck's orders to send reinforcements to [[John Pope (military officer)|John Pope's]] Union [[Army of Virginia]], which made it easier for Lee's Confederates to defeat twice the number of combined enemy troops.

[[File:Battle of Antietam by Thulstrup.jpg|thumb|240px|The [[Battle of Antietam]], the Civil War's deadliest one-day fight.]]

Emboldened by Second Bull Run, the Confederacy made its first invasion of the North with the [[Maryland Campaign]]. General Lee led 45,000 men of the Army of Northern Virginia across the [[Potomac River]] into Maryland on September 5. Lincoln then restored Pope's troops to McClellan. McClellan and Lee fought at the [[Battle of Antietam]] near [[Sharpsburg, Maryland|Sharpsburg]], Maryland, on September 17, 1862, the bloodiest single day in United States military history. Lee's army, checked at last, returned to Virginia before McClellan could destroy it. Antietam is considered a Union victory because it halted Lee's invasion of the North and provided an opportunity for Lincoln to announce his [[Emancipation Proclamation]].

When the cautious McClellan failed to follow up on Antietam, he was replaced by Maj. Gen. [[Ambrose Burnside]]. Burnside was soon defeated at the [[Battle of Fredericksburg]] on December 13, 1862, when more than 12,000 Union soldiers were killed or wounded during repeated futile frontal assaults against Marye's Heights. After the battle, Burnside was replaced by Maj. Gen. [[Joseph Hooker]].

[[File:Conf dead chancellorsville edit1.jpg|thumb|200px|Confederate dead overrun at Marye's Heights, reoccupied next day May 4, 1863]]
Hooker, too, proved unable to defeat Lee's army; despite outnumbering the Confederates by more than two to one, his Chancellorsville Campaign proved ineffective and he was humiliated in the [[Battle of Chancellorsville]] in May 1863. Chancellorsville is known as Lee's "perfect battle" because his risky decision to divide his army in the presence of a much larger enemy force resulted in a significant Confederate victory. Gen. Stonewall Jackson was shot in the arm by accidental friendly fire during the battle and subsequently died of complications. Lee famously said "He has lost his left arm; but I have lost my right arm."

The fiercest fighting of the battle—and the second bloodiest day of the Civil War—occurred on May 3 as Lee launched multiple attacks against the Union position at Chancellorsville. That same day, [[John Sedgwick]] advanced across the [[Rappahannock River]], defeated the small Confederate force at Marye's Heights in the [[Second Battle of Fredericksburg]], and then moved to the west. The Confederates fought a successful delaying action at the [[Battle of Salem Church]]

[[File:Thure de Thulstrup - L. Prang and Co. - Battle of Gettysburg - Restoration by Adam Cuerden.jpg|thumb|260px|Pickett's Charge]]
Gen. Hooker was replaced by Maj. Gen. [[George Meade]] during Lee's [[Gettysburg Campaign|second invasion of the North]], in June. Meade defeated Lee at the [[Battle of Gettysburg]] (July 1 to 3, 1863). This was the bloodiest battle of the war, and has been called the war's [[Turning point of the American Civil War|turning point]]. [[Pickett's Charge]] on July 3 is often considered the [[high-water mark of the Confederacy]] because it signaled the collapse of serious Confederate threats of victory. Lee's army suffered 28,000 casualties (versus Meade's 23,000). However, Lincoln was angry that Meade failed to intercept Lee's retreat.

The Western theater refers to military operations between the Appalachian Mountains and the [[Mississippi River]], including the states of [[Alabama]], [[Georgia (U.S. state)|Georgia]], [[Florida]], [[Mississippi]], [[North Carolina]], [[Kentucky]], [[South Carolina]] and [[Tennessee]], as well as parts of [[Louisiana]].

[[File:Gen. Ulysses S. Grant (4228634580).jpg|thumb|160px|Ulysses S. Grant]]
The primary Union forces in the Western theater were the [[Army of the Tennessee]] and the [[Army of the Cumberland]], named for the two rivers, the [[Tennessee River]] and [[Cumberland River]]. After Meade's inconclusive fall campaign, Lincoln turned to the Western Theater for new leadership. At the same time, the Confederate stronghold of Vicksburg surrendered, giving the Union control of the Mississippi River, permanently isolating the western Confederacy, and producing the new leader Lincoln needed, [[Ulysses S. Grant]].

The primary Confederate force in the Western theater was the [[Army of Tennessee]]. The army was formed on November 20, 1862, when General [[Braxton Bragg]] renamed the former [[Army of Mississippi]]. While the Confederate forces had numerous successes in the Eastern Theater, they were defeated many times in the West.

The Union's key strategist and tactician in the West was Ulysses S. Grant, who won victories at Forts [[Battle of Fort Henry|Henry]] (February 6, 1862) and [[Battle of Fort Donelson|Donelson]] (February 11 to 16, 1862), by which the Union seized control of the Tennessee and Cumberland Rivers. [[Nathan Bedford Forrest]] rallied nearly 4,000 troops and led them to escape across the Cumberland. [[Nashville, Tennessee|Nashville]] and central [[Tennessee]] thus fell to the Union, leading to attrition of local food supplies and livestock and a breakdown in social organization.

[[File:ASJohnston.jpg|thumb|160px|Albert Sidney Johnston died at the Battle of Shiloh.]]

[[Leonidas Polk]]'s invasion of [[Columbus, Kentucky|Columbus]] ended Kentucky's policy of neutrality and turned it against the Confederacy. Grant used river transport and [[Andrew H. Foote|Andrew Foote's]] gunboats of the Western Flotilla to threaten the Confederacy's "Gibraltar of the West" at Columbus, Kentucky. Although rebuffed at Belmont, Grant cut off Columbus. The Confederates, lacking their own gunboats, were forced to retreat and the Union took control of western Kentucky and opened Tennessee in March 1862.

At [[Battle of Shiloh|the Battle of Shiloh]] (Pittsburg Landing), in Tennessee in April 1862, the Confederates made a surprise attack that pushed Union forces against the river as night fell. Overnight, the Navy landed additional reinforcements, and Grant counter-attacked. Grant and the Union won a decisive victory—the first battle with the high casualty rates that would repeat over and over. The Confederates lost [[Albert Sidney Johnston]], considered their finest general before the emergence of Lee.

One of the early Union objectives in the war was the capture of the [[Mississippi River]], in order to cut the Confederacy in half. "The key to the river was New Orleans, the South's largest port [and] greatest industrial center." The Mississippi was opened to Union traffic to the southern border of Tennessee with the taking of [[Battle of Island Number Ten|Island No. 10]] and [[New Madrid, Missouri|New Madrid]], Missouri, and then [[Memphis, Tennessee]].

[[File:Cgs05255 (9716190703).jpg|thumb|By 1863 the Union controlled large portions of the Western Theater, especially areas surrounding the Mississippi river]]

In April 1862, the [[Union Navy]] [[Capture of New Orleans|captured New Orleans]]. U.S. Naval forces under [[David Farragut|Farragut]] ran past Confederate defenses south of New Orleans. Confederate forces abandoned the city, giving the Union a critical anchor in the deep South. which allowed Union forces to begin moving up the Mississippi. [[Battle of Memphis|Memphis fell to Union forces]] on June 6, 1862, and became a key base for further advances south along the Mississippi River. Only the fortress city of [[Vicksburg, Mississippi|Vicksburg]], Mississippi, prevented Union control of the entire river.

Bragg's second Confederate invasion of Kentucky included [[Edmund Kirby Smith|Kirby Smith]]'s triumph at the [[Battle of Richmond]] and ended with a meaningless victory over Maj. Gen. [[Don Carlos Buell]] at the [[Battle of Perryville]]. Bragg was forced to end his attempt at invading Kentucky and retreat due to lack of support for the Confederacy in that state.

Bragg was narrowly defeated by Maj. Gen. [[William Rosecrans]] at the [[Battle of Stones River]] in [[Tennessee]], the culmination of the [[Stones River Campaign]].

Naval forces assisted Grant in the long, complex [[Vicksburg Campaign]] that resulted in the Confederates surrendering at the [[Siege of Vicksburg|Battle of Vicksburg]] in July 1863, which cemented Union control of the Mississippi River and is considered one of the [[Turning point of the American Civil War|turning points]] of the war.

[[File:Chickamauga.jpg|thumb|220px|The [[Battle of Chickamauga]], the highest two-day losses.]]

The one clear Confederate victory in the West was the [[Battle of Chickamauga]]. After Rosecrans successful [[Tullahoma Campaign]], Bragg, reinforced by Lt. Gen. James Longstreet's corps (from Lee's army in the east), defeated Rosecrans, despite the heroic defensive stand of Maj. Gen. [[George Henry Thomas]].

Rosecrans retreated to [[Chattanooga, Tennessee|Chattanooga]], which Bragg then besieged in the [[Chattanooga Campaign]]. Grant marched to the relief of Rosecrans and defeated Bragg at the [[Chattanooga Campaign|Third Battle of Chattanooga]], eventually causing Longstreet to abandon his [[Knoxville Campaign]] and driving Confederate forces out of Tennessee and opening a route to Atlanta and the heart of the Confederacy.

The Trans-Mississippi theater refers to military operations west of the Mississippi River, not including the areas bordering the Pacific Ocean.

[[File:Wilson's Creek charge of 1st Iowa.jpg|thumb|220px|[[Nathaniel Lyon]] secured St. Louis docks and arsenal, led Union forces to expel Missouri Confederate forces and government.]]
The first battle of the Trans-Mississippi theater was the [[Battle of Wilson's Creek]]. The Confederates were driven from Missouri early in the war as a result of the [[Battle of Pea Ridge]].

Extensive [[guerrilla warfare]] characterized the trans-Mississippi region, as the Confederacy lacked the troops and the logistics to support regular armies that could challenge Union control. Roving Confederate bands such as [[Quantrill's Raiders]] terrorized the countryside, striking both military installations and civilian settlements. The "Sons of Liberty" and "Order of the American Knights" attacked pro-Union people, elected officeholders, and unarmed uniformed soldiers. These partisans could not be entirely driven out of the state of Missouri until an entire regular Union infantry division was engaged. By 1864, these violent activities harmed the nationwide anti-war movement organizing against the re-election of Lincoln. Missouri not only stayed in the Union, but Lincoln took 70 percent of the vote for re-election.

Numerous small-scale military actions south and west of Missouri sought to control [[Indian Territory in the American Civil War|Indian Territory]] and [[New Mexico Territory in the American Civil War|New Mexico Territory]] for the Union. The [[Battle of Glorieta Pass]] was the decisive [[battle]] of the [[New Mexico Campaign]]. The Union repulsed Confederate incursions into New Mexico in 1862, and the exiled Arizona government withdrew into Texas. In the Indian Territory, civil war broke out within tribes. About 12,000 Indian warriors fought for the Confederacy, and smaller numbers for the Union. The most prominent Cherokee was Brigadier General [[Stand Watie]], the last Confederate general to surrender.

After the fall of [[Siege of Vicksburg|Vicksburg]] in July 1863, General Kirby Smith in Texas was informed by Jefferson Davis that he could expect no further help from east of the Mississippi River. Although he lacked resources to beat Union armies, he built up a formidable arsenal at Tyler, along with his own Kirby Smithdom economy, a virtual "independent fiefdom" in Texas, including railroad construction and international smuggling. The Union in turn did not directly engage him. Its 1864 [[Red River Campaign]] to take Shreveport, Louisiana was a failure and Texas remained in Confederate hands throughout the war.

The Lower Seaboard theater refers to military and naval operations that occurred near the coastal areas of the Southeast: in Alabama, Florida, Louisiana, Mississippi, South Carolina, and Texas) as well as southern part of the Mississippi River (Port Hudson and south). Union Naval activities were dictated by the Anaconda Plan.

One of the earliest battles of the war was fought at [[Battle of Port Royal|Port Royal Sound]], south of Charleston. Much of the war along the South Carolina coast concentrated on capturing [[Charleston, South Carolina|Charleston]]. In attempting to capture Charleston, the Union military tried two approaches, by land over James or Morris Islands or through the harbor. However, the Confederates were able to drive back each Union attack. One of the most famous of the land attacks was the [[Second Battle of Fort Wagner]], in which the [[54th Massachusetts Volunteer Infantry|54th Massachusetts Infantry]] took part. The Federals suffered a serious defeat in this battle, losing 1,500 men while the Confederates lost only 175.

Fort Pulaski on the Georgia coast was an early target for the Union navy. Following the capture of Port Royal, an expedition was organized with engineer troops under the command of Captain [[Quincy Adams Gillmore|Quincy A. Gillmore]], forcing a Confederate surrender. The Union army occupied the fort for the rest of the war after making repair.

[[File:New Orleans h76369k.jpg|220px|thumb| New Orleans captured.]]
In April 1862, a Union naval task force commanded by Commander [[David Dixon Porter|David D. Porter]] attacked [[Battle of Forts Jackson and St. Philip|Forts Jackson and St. Philip]], which guarded the river approach to New Orleans from the south. While part of the fleet bombarded the forts, other vessels forced a break in the obstructions in the river and enabled the rest of the fleet to steam upriver to the city. A Union army force commanded by Major General [[Benjamin Butler (politician)|Benjamin Butler]] landed near the forts and forced their surrender. Butler's controversial command of New Orleans earned him the nickname "Beast".

The following year, the Union [[Army of the Gulf]] commanded by Major General Nathaniel P. Banks laid [[Siege of Port Hudson|siege to Port Hudson]] for nearly eight weeks, the longest siege in US military history. The Confederates attempted to defend with the [[Bayou Teche Campaign]], but surrendered after Vicksburg. These two surrenders gave the Union control over the entire Mississippi.

Several small skirmishes were fought in Florida, but no major battles. The biggest was the [[Battle of Olustee]] in early 1864.

The Pacific Coast theater refers to military operations on the Pacific Ocean and in the states and Territories west of the Continental Divide.

At the beginning of 1864, Lincoln made Grant commander of all Union armies. Grant made his headquarters with the Army of the Potomac, and put Maj. Gen. [[William Tecumseh Sherman]] in command of most of the western armies. Grant understood the concept of [[total war]] and believed, along with Lincoln and Sherman, that only the utter defeat of Confederate forces and their economic base would end the war. This was total war not in killing civilians but rather in taking provisions and forage and destroying homes, farms, and railroads, that Grant said "would otherwise have gone to the support of secession and rebellion. This policy I believe exercised a material influence in hastening the end." Grant devised a coordinated strategy that would strike at the entire Confederacy from multiple directions. Generals [[George Meade]] and Benjamin Butler were ordered to move against Lee near Richmond, General [[Franz Sigel]] (and later [[Philip Sheridan]]) were to [[Valley Campaigns of 1864|attack the Shenandoah Valley]], General Sherman was to capture Atlanta and march to the sea (the Atlantic Ocean), Generals [[George Crook]] and [[William W. Averell]] were to operate against railroad supply lines in [[West Virginia]], and Maj. Gen. Nathaniel P. Banks was to capture [[Mobile, Alabama|Mobile]], Alabama.

[[File:EwellsDeadSpotsylvania1864crop01.jpg|thumb|These dead soldiers—from [[Richard S. Ewell|Ewell]]'s May 1864 attack at [[Battle of Spotsylvania|Spotsylvania]]—delayed Grant's advance on Richmond in the [[Overland Campaign]].]]Grant's army set out on the [[Overland Campaign]] with the goal of drawing Lee into a defense of Richmond, where they would attempt to pin down and destroy the Confederate army. The Union army first attempted to maneuver past Lee and fought several battles, notably at the [[Battle of the Wilderness|Wilderness]], [[Battle of Spotsylvania Court House|Spotsylvania]], and [[Battle of Cold Harbor|Cold Harbor]]. These battles resulted in heavy losses on both sides, and forced Lee's Confederates to fall back repeatedly. At the [[Battle of Yellow Tavern]], the Confederates lost Jeb Stuart.
[[File:Philip Sheridan 1-restored.jpg|thumb|left|160px|Philip Sheridan]]
An attempt to outflank Lee from the south failed under Butler, who was trapped inside the [[Bermuda Hundred Campaign|Bermuda Hundred]] river bend. Each battle resulted in setbacks for the Union that mirrored what they had suffered under prior generals, though unlike those prior generals, Grant fought on rather than retreat. Grant was tenacious and kept pressing Lee's Army of Northern Virginia back to Richmond. While Lee was preparing for an attack on Richmond, Grant unexpectedly turned south to cross the [[James River]] and began the protracted [[Siege of Petersburg]], where the two armies engaged in [[trench warfare]] for over nine months.

Grant finally found a commander, General Philip Sheridan, aggressive enough to prevail in the [[Valley Campaigns of 1864]]. Sheridan was initially repelled at the [[Battle of New Market]] by former U.S. Vice President and Confederate Gen. [[John C. Breckinridge]]. The Battle of New Market was the Confederacy's last major victory of the war, and included a charge by teenage VMI cadets. After redoubling his efforts, Sheridan defeated Maj. Gen. [[Jubal Early|Jubal A. Early]] in a series of battles, including a final decisive defeat at the [[Battle of Cedar Creek]]. Sheridan then proceeded to destroy the agricultural base of the [[Shenandoah Valley]], a strategy similar to the tactics Sherman later employed in Georgia.

Meanwhile, Sherman maneuvered from Chattanooga to Atlanta, defeating Confederate Generals [[Joseph E. Johnston]] and [[John Bell Hood]] along the way. The [[Battle of Atlanta|fall of Atlanta]] on September 2, 1864, guaranteed the reelection of Lincoln as president. Hood left the Atlanta area to swing around and menace Sherman's supply lines and invade Tennessee in the [[Franklin–Nashville Campaign]]. Union Maj. Gen. [[John Schofield]] defeated Hood at the [[Battle of Franklin (1864)|Battle of Franklin]], and [[George Henry Thomas|George H. Thomas]] dealt Hood a massive defeat at the [[Battle of Nashville]], effectively destroying Hood's army.[[File:The Peacemakers 1868.jpg|thumb|"[[The Peacemakers]]" by [[George Peter Alexander Healy]] portrays [[William T. Sherman|Sherman]], [[Ulysses S. Grant|Grant]], [[Abraham Lincoln|Lincoln]], and [[David Dixon Porter|Porter]] discussing plans for the last weeks of the Civil War aboard the steamer "[[River Queen (steamboat)|River Queen]]" in March 1865.]]

Leaving Atlanta, and his base of supplies, Sherman's army marched with an unknown destination, laying waste to about 20 percent of the farms in Georgia in his "[[Sherman's March to the Sea|March to the Sea]]". He reached the Atlantic Ocean at [[Savannah, Georgia|Savannah]], Georgia in December 1864. Sherman's army was followed by thousands of freed slaves; there were no major battles along the March. Sherman turned north through South Carolina and North Carolina to approach the Confederate Virginia lines from the south, increasing the pressure on Lee's army.

Lee's army, thinned by desertion and casualties, was now much smaller than Grant's. One last Confederate attempt to break the Union hold on Petersburg failed at the decisive [[Battle of Five Forks]] (sometimes called "the [[Waterloo in popular culture#Other|Waterloo]] of the Confederacy") on April 1. This meant that the Union now controlled the entire perimeter surrounding Richmond-Petersburg, completely cutting it off from the Confederacy. Realizing that the capital was now lost, Lee decided to evacuate his army. The Confederate capital fell to the [[XXV Corps (Union Army)|Union XXV Corps]], composed of black troops. The remaining Confederate units fled west after a defeat at [[Battle of Sayler's Creek|Sayler's Creek]].

[[File:Civil war 1861-1865.png|thumb|upright=1.35|Map of Confederate territory losses year by year|alt=A map of the U.S. South showing shrinking territory under rebel control]]

Initially, Lee did not intend to surrender, but planned to regroup at the [[Appomattox Court House National Historical Park|village of Appomattox Court House]], where supplies were to be waiting, and then continue the war. Grant chased Lee and got in front of him, so that when Lee's army reached Appomattox Court House, they were surrounded. After an initial battle, Lee decided that the fight was now hopeless, and surrendered his Army of Northern Virginia on April 9, 1865, at the [[McLean House (Appomattox, Virginia)|McLean House]]. In an untraditional gesture and as a sign of Grant's respect and anticipation of peacefully restoring Confederate states to the Union, Lee was permitted to keep his sword and his horse, [[Traveller (horse)|Traveller]].

On April 14, 1865, President Lincoln was [[Abraham Lincoln assassination|shot]] by [[John Wilkes Booth]], a Southern sympathizer. Lincoln died early the next morning, and [[Andrew Johnson]] became the president. Meanwhile, Confederate forces across the South surrendered as news of Lee's surrender reached them. On April 26, 1865, General [[Joseph E. Johnston]] surrendered nearly 90,000 men of the [[Army of Tennessee]] to Major General [[William T. Sherman]] at the [[Bennett Place]] near present-day Durham, North Carolina. It proved to be the largest surrender of Confederate forces, effectively bringing the war to an end. President Johnson officially declared a virtual end to the insurrection on May 9, 1865; President [[Jefferson Davis]] was captured the following day. On June 2, Kirby Smith officially surrendered his troops in the Trans-Mississippi Department. On June 23, Cherokee leader [[Stand Watie]] became the last Confederate general to surrender his forces.

The [[Origins of the American Civil War|causes of the war]], the reasons for its outcome, and even [[Naming the American Civil War|the name of the war itself]] are subjects of lingering contention today. The North and West grew rich while the once-rich South became poor for a century. The national political power of the slaveowners and rich southerners ended. Historians are less sure about the results of the postwar Reconstruction, especially regarding the second class citizenship of the Freedmen and their poverty.

Historians have debated whether the Confederacy could have won the war. Most scholars, including [[James M. McPherson|James McPherson]], argue that Confederate victory was at least possible. McPherson argues that the North's advantage in population and resources made Northern victory likely but not guaranteed. He also argues that if the Confederacy had fought using unconventional tactics, they would have more easily been able to hold out long enough to exhaust the Union.

Confederates did not need to invade and hold enemy territory to win, but only needed to fight a defensive war to convince the North that the cost of winning was too high. The North needed to conquer and hold vast stretches of enemy territory and defeat Confederate armies to win. Lincoln was not a military dictator, and could continue to fight the war only as long as the American public supported a continuation of the war. The Confederacy sought to win independence by out-lasting Lincoln; however, after Atlanta fell and Lincoln defeated McClellan in the election of 1864, all hope for a political victory for the South ended. At that point, Lincoln had secured the support of the Republicans, War Democrats, the border states, emancipated slaves, and the neutrality of Britain and France. By defeating the Democrats and McClellan, he also defeated the [[Copperheads (politics)|Copperheads]] and their peace platform.

Many scholars argue that the Union held an insurmountable long-term advantage over the Confederacy in industrial strength and population. Confederate actions, they argue, only delayed defeat. Civil War historian [[Shelby Foote]] expressed this view succinctly: "I think that the North fought that war with one hand behind its back ... If there had been more Southern victories, and a lot more, the North simply would have brought that other hand out from behind its back. I don't think the South ever had a chance to win that War."

A minority view among historians is that the Confederacy lost because, as [[E. Merton Coulter]] put it, "people did not will hard enough and long enough to win." Marxist historian Armstead Robinson agrees, pointing to a class conflict in the Confederate army between the slave owners and the larger number of non-owners. He argues that the non-owner soldiers grew embittered about fighting to preserve slavery, and fought less enthusiastically. He attributes the major Confederate defeats in 1863 at Vicksburg and Missionary Ridge to this class conflict. However, most historians reject the argument. [[James M. McPherson]], after reading thousands of letters written by Confederate soldiers, found strong patriotism that continued to the end; they truly believed they were fighting for freedom and liberty. Even as the Confederacy was visibly collapsing in 1864–65, he says most Confederate soldiers were fighting hard. Historian [[Gary Gallagher]] cites General Sherman who in early 1864 commented, "The devils seem to have a determination that cannot but be admired." Despite their loss of slaves and wealth, with starvation looming, Sherman continued, "yet I see no sign of let up—some few deserters—plenty tired of war, but the masses determined to fight it out."

Also important were Lincoln's eloquence in rationalizing the national purpose and his skill in keeping the border states committed to the Union cause. The Emancipation Proclamation was an effective use of the President's war powers. The Confederate government failed in its attempt to get Europe involved in the war militarily, particularly Britain and France. Southern leaders needed to get European powers to help break up the blockade the Union had created around the Southern ports and cities. Lincoln's naval blockade was 95 percent effective at stopping trade goods; as a result, imports and exports to the South declined significantly. The abundance of European cotton and Britain's hostility to the institution of slavery, along with Lincoln's Atlantic and Gulf of Mexico naval blockades, severely decreased any chance that either Britain or France would enter the war.

Historian Don Doyle has argued that the Union victory had a major impact on the course of world history. The Union victory energized popular democratic forces. A Confederate victory, on the other hand, would have meant a new birth of slavery, not freedom. Historian Fergus Bordewich, following Doyle, argues that:

Scholars have debated what the effects of the war were on political and economic power in the South. The prevailing view is that the southern planter elite retained its powerful position in the South. However, a 2017 study challenges this, noting that while some Southern elites retained their economic status, the turmoil of the 1860s created greater opportunities for economic mobility in the South than in the North.

The war resulted in at least 1,030,000 casualties (3 percent of the population), including about 620,000 soldier deaths—two-thirds by disease, and 50,000 civilians. Binghamton University historian J. David Hacker believes the number of soldier deaths was approximately 750,000, 20 percent higher than traditionally estimated, and possibly as high as 850,000. The war accounted for more American deaths than in all other U.S. wars combined.

Based on 1860 census figures, 8 percent of all white men aged 13 to 43 died in the war, including 6 percent in the North and 18 percent in the South. About 56,000 soldiers [[American Civil War prison camps|died in prison camps]] during the War. An estimated 60,000 men lost limbs in the war.

Union army dead, amounting to 15 percent of the over two million who served, was broken down as follows:

In addition there were 4,523 deaths in the Navy (2,112 in battle) and 460 in the Marines (148 in battle).

Black troops made up 10 percent of the Union death toll, they amounted to 15 percent of disease deaths but less than 3 percent of those killed in battle. Losses among [[African American]]s were high, in the last year and a half and from all reported casualties, approximately 20 percent of all African Americans enrolled in the military lost their lives during the Civil War. Notably, their mortality rate was significantly higher than white soldiers:
Confederate records compiled by historian William F. Fox list 74,524 killed and died of wounds and 59,292 died of disease. Including Confederate estimates of battle losses where no records exist would bring the Confederate death toll to 94,000 killed and died of wounds. Fox complained, however, that records were incomplete, especially during the last year of the war, and that battlefield reports likely under-counted deaths (many men counted as wounded in battlefield reports subsequently died of their wounds). Thomas L. Livermore, using Fox's data, put the number of Confederate non-combat deaths at 166,000, using the official estimate of Union deaths from disease and accidents and a comparison of Union and Confederate enlistment records, for a total of 260,000 deaths. However, this excludes the 30,000 deaths of Confederate troops in prisons, which would raise the minimum number of deaths to 290,000.

The United States National Park Service uses the following figures in its official tally of war losses:

Union: 853,838

Confederate: 914,660

[[File:Burial of the dead on the Antietam battlefield army.mil-2008-09-10-145638.jpg|thumb|Burying Union dead on the [[Battle of Antietam|Antietam]] battlefield, 1862]]

While the figures of 360,000 army deaths for the Union and 260,000 for the Confederacy remained commonly cited, they are incomplete. In addition to many Confederate records being missing, partly as a result of Confederate widows not reporting deaths due to being ineligible for benefits, both armies only counted troops who died during their service, and not the tens of thousands who died of wounds or diseases after being discharged. This often happened only a few days or weeks later. [[Francis Amasa Walker]], Superintendent of the 1870 Census, used census and Surgeon General data to estimate a minimum of 500,000 Union military deaths and 350,000 Confederate military deaths, for a total death toll of 850,000 soldiers. While Walker's estimates were originally dismissed because of the 1870 Census's undercounting, it was later found that the census was only off by 6.5%, and that the data Walker used would be roughly accurate.

Analyzing the number of dead by using census data to calculate the deviation of the death rate of men of fighting age from the norm suggests that at least 627,000 and at most 888,000, but most likely 761,000 soldiers, died in the war. This would break down to approximately 350,000 Confederate and 411,000 Union military deaths, going by the proportion of Union to Confederate battle losses.

Deaths among former slaves has proven much harder to estimate, due to the lack of reliable census data at the time, though they were known to be considerable, as former slaves were set free or escaped in massive numbers in an area where the Union army did not have sufficient shelter, doctors, or food for them. University of Connecticut Professor James Downs states that tens to hundreds of thousands of slaves died during the war from disease, starvation, exposure, or execution at the hands of the Confederates, and that if these deaths are counted in the war's total, the death toll would exceed 1 million.

Losses were far higher than during the recent [[Mexican–American War|defeat of Mexico]], which saw roughly thirteen thousand American deaths, including fewer than two thousand killed in battle, between 1846 and 1848. One reason for the high number of battle deaths during the war was the continued use of tactics similar to those of the [[Napoleonic Wars]] at the turn of the century, such as [[charge (warfare)|charging]]. With the advent of more accurate rifled barrels, [[Minié ball]]s and (near the end of the war for the [[Union army]]) repeating firearms such as the [[Spencer repeating rifle|Spencer Repeating Rifle]] and the [[Henry rifle|Henry Repeating Rifle]], soldiers were mowed down when standing in lines in the open. This led to the adoption of [[trench warfare]], a style of fighting that defined much of World War I.

The wealth amassed in slaves and slavery for the Confederacy's 3.5 million blacks effectively ended when Union armies arrived; they were nearly all freed by the Emancipation Proclamation. Slaves in the border states and those located in some former Confederate territory occupied before the Emancipation Proclamation were freed by state action or (on December 6, 1865) by the [[Thirteenth Amendment to the United States Constitution|Thirteenth Amendment]].

The war destroyed much of the wealth that had existed in the South. All accumulated investment Confederate bonds was forfeit; most banks and railroads were bankrupt. Income per person in the South dropped to less than 40 percent of that of the North, a condition that lasted until well into the 20th century. Southern influence in the U.S. federal government, previously considerable, was greatly diminished until the latter half of the 20th century. The full restoration of the Union was the work of a highly contentious postwar era known as [[Reconstruction Era of the United States|Reconstruction]].

While not all Southerners saw themselves as fighting to preserve slavery, most of the officers and over a third of the rank and file in [[Robert E. Lee|Lee]]'s army had close family ties to slavery. To Northerners, in contrast, the motivation was primarily to preserve the [[Union (American Civil War)|Union]], not to abolish slavery. Abraham Lincoln consistently made preserving the Union the central goal of the war, though he increasingly saw slavery as a crucial issue and made ending it an additional goal. Lincoln's decision to issue the [[Emancipation Proclamation]] angered both [[Peace Democrats]] ("Copperheads") and [[War Democrats]], but energized most Republicans. By warning that free blacks would flood the North, Democrats made gains in the [[1862 congressional elections|1862 elections]], but they did not gain control of Congress. The Republicans' counterargument that slavery was the mainstay of the enemy steadily gained support, with the Democrats losing decisively in the 1863 elections in the northern state of Ohio when they tried to resurrect anti-black sentiment.

The Emancipation Proclamation enabled African-Americans, both free blacks and escaped slaves, to join the Union Army. About 190,000 volunteered, further enhancing the numerical advantage the Union armies enjoyed over the Confederates, who did not dare emulate the equivalent manpower source for fear of fundamentally undermining the legitimacy of slavery.

During the Civil War, sentiment concerning slaves, enslavement and emancipation in the United States was divided. In 1861, Lincoln worried that premature attempts at emancipation would mean the loss of the border states, and that "to lose Kentucky is nearly the same as to lose the whole game." [[Copperheads (politics)|Copperheads]] and some [[War Democrats]] opposed emancipation, although the latter eventually accepted it as part of [[total war]] needed to save the Union.

At first, Lincoln reversed attempts at emancipation by Secretary of War [[Simon Cameron]] and Generals [[John C. Frémont]] (in Missouri) and [[David Hunter]] (in South Carolina, Georgia and Florida) to keep the loyalty of the border states and the War Democrats. Lincoln warned the border states that a more radical type of emancipation would happen if his gradual plan based on compensated emancipation and voluntary colonization was rejected. But only the District of Columbia accepted Lincoln's gradual plan, which was enacted by Congress. When Lincoln told his cabinet about his proposed emancipation proclamation, Seward advised Lincoln to wait for a victory before issuing it, as to do otherwise would seem like "our last shriek on the retreat". Lincoln laid the groundwork for public support in an open letter published in abolitionist Horace Greeley's newspaper.

In September 1862, the [[Battle of Antietam]] provided this opportunity, and the subsequent [[War Governors' Conference]] added support for the proclamation. Lincoln issued his preliminary [[Emancipation Proclamation]] on September 22, 1862, and his final Emancipation Proclamation on January 1, 1863. In his letter to [[Albert G. Hodges]], Lincoln explained his belief that "If slavery is not wrong, nothing is wrong ... And yet I have never understood that the Presidency conferred upon me an unrestricted right to act officially upon this judgment and feeling ... I claim not to have controlled events, but confess plainly that events have controlled me."

Lincoln's moderate approach succeeded in inducing border states, War Democrats and emancipated slaves to fight for the Union. The Union-controlled border states (Kentucky, Missouri, Maryland, Delaware and West Virginia) and Union-controlled regions around New Orleans, Norfolk and elsewhere, were not covered by the Emancipation Proclamation. All abolished slavery on their own, except Kentucky and Delaware.

Since the Emancipation Proclamation was based on the President's war powers, it only included territory held by Confederates at the time. However, the Proclamation became a symbol of the Union's growing commitment to add emancipation to the Union's definition of liberty. The Emancipation Proclamation greatly reduced the Confederacy's hope of getting aid from Britain or France. By late 1864, Lincoln was playing a leading role in getting Congress to vote for the [[Thirteenth Amendment to the United States Constitution|Thirteenth Amendment]], which made emancipation universal and permanent.

In "[[Texas v. White]]", the United States Supreme Court ruled that Texas had remained a state ever since it first joined the Union, despite claims that it joined the [[Confederate States of America|Confederate States]]; the court further held that the [[Constitution of the United States|Constitution]] did not permit [[U.S. state|states]] to unilaterally [[secession|secede]] from the United States, and that the ordinances of secession, and all the acts of the legislatures within seceding states intended to give effect to such ordinances, were "absolutely [[Void (law)|null]]", under the constitution.

[[File:Freedmen richmond sewing women.jpg|thumb|Northern teachers traveled into the South to provide education and training for the newly freed population.]]
Reconstruction began during the war, with the Emancipation Proclamation of January 1, 1863, and it continued until 1877. It comprised multiple complex methods to resolve the outstanding issues of the war's aftermath, the most important of which were the three "[[Reconstruction Amendments]]" to the Constitution, which remain in effect to the present time: the 13th (1865), the 14th (1868) and the 15th (1870). From the Union perspective, the goals of Reconstruction were to consolidate the Union victory on the battlefield by reuniting the Union; to guarantee a "[[Republicanism in the United States|republican form of government]] for the ex-Confederate states; and to permanently end slavery—and prevent semi-slavery status.

President Johnson took a lenient approach and saw the achievement of the main war goals as realized in 1865, when each ex-rebel state repudiated secession and ratified the Thirteenth Amendment. [[Radical Republicans]] demanded proof that Confederate nationalism was dead and that the slaves were truly free. They came to the fore after the 1866 elections and undid much of Johnson's work. In 1872 the [[Liberal Republican Party (United States)|"Liberal Republicans"]] argued that the war goals had been achieved and that Reconstruction should end. They ran a presidential ticket in 1872 but were decisively defeated. In 1874, Democrats, primarily Southern, took control of Congress and opposed any more reconstruction. The [[Compromise of 1877]] closed with a national consensus that the Civil War had finally ended. With the withdrawal of federal troops, however, whites retook control of every Southern legislature; the [[Jim Crow]] period of disenfranchisement and legal segregation was about to begin.

The Civil War is one of the central events in American collective memory. There are innumerable statues, commemorations, books and archival collections. The memory includes the home front, military affairs, the treatment of soldiers, both living and dead, in the war's aftermath, depictions of the war in literature and art, evaluations of heroes and villains, and considerations of the moral and political lessons of the war. The last theme includes moral evaluations of [[racism]] and slavery, heroism in combat and heroism behind the lines, and the issues of democracy and minority rights, as well as the notion of an "[[Empire of Liberty]]" influencing the world.

Professional historians have paid much more attention to the causes of the war, than to the war itself. Military history has largely developed outside academe, leading to a proliferation of solid studies by non-scholars who are thoroughly familiar with the primary sources, pay close attention to battles and campaigns, and write for the large public readership, rather than the small scholarly community. [[Bruce Catton]] and [[Shelby Foote]] are among the best-known writers. Practically every major figure in the war, both North and South, has had a serious biographical study.
Deeply religious Southerners saw the hand of God in history, which demonstrated His wrath at their sinfulness, or His rewards for their suffering. Historian Wilson Fallin has examined the sermons of white and black [[Baptists|Baptist]] preachers after the War. Southern white preachers said:
In sharp contrast, Black preachers interpreted the Civil War as:

Memory of the war in the white South crystallized in the myth of the [[Lost Cause of the Confederacy|"Lost Cause"]]: that the Confederate cause was a just and heroic one. The myth shaped regional identity and race relations for generations. Alan T. Nolan notes that the Lost Cause was expressly "a rationalization, a cover-up to vindicate the name and fame" of those in rebellion. Some claims revolve around the insignificance of slavery; some appeals highlight cultural differences between North and South; the military conflict by Confederate actors is idealized; in any case, secession was said to be lawful. Nolan argues that the adoption of the Lost Cause perspective facilitated the reunification of the North and the South while excusing the [[Nadir of American race relations|"virulent racism" of the 19th century]], sacrificing African-American progress to a white man's reunification. He also deems the Lost Cause "a caricature of the truth. This caricature wholly misrepresents and distorts the facts of the matter" in every instance.

The economic and political-power determinism forcefully presented by [[Charles A. Beard]] and Mary R. Beard in "The Rise of American Civilization" (1927) was highly influential among historians and the general public until the [[civil rights movement]] of the 1950s and 1960s. The Beards downplayed slavery, abolitionism, and issues of morality. They ignored constitutional issues of states' rights and even ignored American nationalism as the force that finally led to victory in the war. Indeed, the ferocious combat itself was passed over as merely an ephemeral event. Much more important was the calculus of class conflict. The Beards announced that the Civil War was really:

The Beards themselves abandoned their interpretation by the 1940s and it became defunct among historians in the 1950s, when scholars shifted to an emphasis on slavery. However, Beardian themes still echo among Lost Cause writers.

[[File:Civil War centennial issues.jpg|upright=1.35|thumb|Beginning in 1961 the U.S. Post Office released [[Commemorative stamp]]s for five famous battles, each issued on the 100th anniversary of the respective battle.]]

The first efforts at Civil War battlefield preservation and memorialization came during the war itself with the establishment of National Cemeteries at Gettysburg, Mill Springs and Chattanooga. Soldiers began erecting markers on battlefields beginning with the [[First Battle of Bull Run]] in July 1861, but the oldest surviving monument is the Hazen monument, erected at Stones River near [[Murfreesboro, Tennessee]], in the summer of 1863 by soldiers in Union Col. [[William Babcock Hazen|William B. Hazen's]] brigade to mark the spot where they buried their dead in the [[Battle of Stones River]]. In the 1890s, the United States government established five Civil War battlefield parks under the jurisdiction of the War Department, beginning with the creation of the [[Chickamauga and Chattanooga National Military Park]] in Tennessee and the [[Antietam National Battlefield]] in Maryland in 1890. The [[Shiloh National Military Park]] was established in 1894, followed by the [[Gettysburg National Military Park]] in 1895 and [[Vicksburg National Military Park]] in 1899. In 1933, these five parks and other national monuments were transferred to the jurisdiction of the National Park Service.

The modern Civil War battlefield preservation movement began in 1987 with the founding of the Association for the Preservation of Civil War Sites (APCWS), a grassroots organization created by Civil War historians and others to preserve battlefield land by acquiring it. In 1991, the original Civil War Trust was created in the mold of the Statue of Liberty/Ellis Island Foundation, but failed to attract corporate donors and soon helped manage the disbursement of U.S. Mint Civil War commemorative coin revenues designated for battlefield preservation. Although the two non-profit organizations joined forces on a number of battlefield acquisitions, ongoing conflicts prompted the boards of both organizations to facilitate a merger, which happened in 1999 with the creation of the Civil War Preservation Trust. In 2011, the organization was renamed, again becoming the [[Civil War Trust]]. After expanding its mission in 2014 to include battlefields of the Revolutionary War and War of 1812, the non-profit became the [[American Battlefield Trust]] in May 2018, operating with two divisions, the Civil War Trust and the Revolutionary War Trust. From 1987 through May 2018, the Trust and its predecessor organizations, along with their partners, preserved 49,893 acres of battlefield land through acquisition of property or conservation easements at more than 130 battlefields in 24 states.

The American Civil War has been commemorated in many capacities ranging from the reenactment of battles, to statues and memorial halls erected, to films being produced, to stamps and coins with Civil War themes being issued, all of which helped to shape public memory. This varied advent occurred in greater proportions on the 100th and 150th anniversary.

[[Cinema of the United States|Hollywood]]'s take on the war has been especially influential in shaping public memory, as seen in such film classics as "[[Birth of a Nation]]" (1915), "[[Gone with the Wind (film)|Gone with the Wind]]" (1939), and more recently "[[Lincoln (film)|Lincoln]]" (2012). [[Ken Burns]] produced a notable PBS series on television titled "[[The Civil War (TV series)|The Civil War]]" (1990). It was digitally remastered and re-released in 2015.

There were numerous technological innovations during the Civil War that had a great impact on 19th-century science. The Civil War was one of the earliest examples of an "[[Industrial warfare|industrial war]]", in which technological might is used to achieve military supremacy in a war. New inventions, such as the [[Military railways|train]] and [[Telegraphy|telegraph]], delivered soldiers, supplies and messages at a time when horses were considered to be the fastest way to travel. It was also in this war when countries first used aerial warfare, in the form of reconnaissance [[History of aerial warfare#American Civil War|balloons]], to a significant effect. It saw the first action involving steam-powered [[ironclad warships]] in naval warfare history. [[Repeating rifle|Repeating firearms]] such as the [[Henry rifle]], [[Spencer rifle]], [[Colt revolving rifle]], [[Triplett & Scott carbine]] and others, first appeared during the Civil War; they were a revolutionary invention that would soon replace muzzle-loading and single-shot firearms in warfare, as well as the first appearances of rapid-firing weapons and [[machine gun]]s such as the [[Agar gun]] and the [[Gatling gun]].













[[Category:American Civil War| ]]
[[Category:Rebellions in the United States]]
[[Category:Conflicts in 1861]]
[[Category:Conflicts in 1862]]
[[Category:Conflicts in 1863]]
[[Category:Conflicts in 1864]]
[[Category:Conflicts in 1865]]
[[Category:19th-century conflicts]]
[[Category:Wars involving the United States|Civil War]]
[[Category:1860s in the United States]]
[[Category:Wars of independence]]
[[Category:Internal wars of the United States]]
[[Category:1860s conflicts]]Andy Warhol

Andy Warhol (; born Andrew Warhola; August 6, 1928 – February 22, 1987) was an American artist, director and producer who was a leading figure in the visual art movement known as pop art. His works explore the relationship between artistic expression, celebrity culture, and advertising that flourished by the 1960s, and span a variety of media, including painting, silkscreening, photography, film, and sculpture. Some of his best known works include the silkscreen paintings "Campbell's Soup Cans" (1962) and "Marilyn Diptych" (1962), the experimental film "Chelsea Girls" (1966), and the multimedia events known as the "Exploding Plastic Inevitable" (1966–67).

Born and raised in Pittsburgh, Warhol initially pursued a successful career as a commercial illustrator. After exhibiting his work in several galleries in the late 1950s, he began to receive recognition as an influential and controversial artist. His New York studio, The Factory, became a well-known gathering place that brought together distinguished intellectuals, drag queens, playwrights, Bohemian street people, Hollywood celebrities, and wealthy patrons. He promoted a collection of personalities known as Warhol superstars, and is credited with coining the widely used expression "15 minutes of fame." In the late 1960s, he managed and produced the experimental rock band The Velvet Underground and founded "Interview" magazine. He authored numerous books, including "The Philosophy of Andy Warhol" and "Popism: The Warhol Sixties". He lived openly as a gay man before the gay liberation movement. After gallbladder surgery, Warhol died of cardiac arrhythmia in February 1987 at the age of 58.

Warhol has been the subject of numerous retrospective exhibitions, books, and feature and documentary films. The Andy Warhol Museum in his native city of Pittsburgh, which holds an extensive permanent collection of art and archives, is the largest museum in the United States dedicated to a single artist. Many of his creations are very collectible and highly valuable. The highest price ever paid for a Warhol painting is US$105 million for a 1963 canvas titled "Silver Car Crash (Double Disaster)"; his works include some of the most expensive paintings ever sold. A 2009 article in "The Economist" described Warhol as the "bellwether
Warhol was born on August 6, 1928, in Pittsburgh, Pennsylvania. He was the fourth child of Ondrej Warhola (Americanized as Andrew Warhola, Sr., 1889–1942) and Julia ("née" Zavacká, 1892–1972), whose first child was born in their homeland and died before their move to the U.S.

His parents were working-class Lemko emigrants from Mikó, Austria-Hungary (now called Miková, located in today's northeastern Slovakia). Warhol's father emigrated to the United States in 1914, and his mother joined him in 1921, after the death of Warhol's grandparents. Warhol's father worked in a coal mine. The family lived at 55 Beelen Street and later at 3252 Dawson Street in the Oakland neighborhood of Pittsburgh. The family was Ruthenian Catholic and attended St. John Chrysostom Byzantine Catholic Church. Andy Warhol had two older brothers—Pavol (Paul), the oldest, was born before the family emigrated; Ján was born in Pittsburgh. Pavol's son, James Warhola, became a successful children's book illustrator.

In third grade, Warhol had Sydenham's chorea (also known as St. Vitus' Dance), the nervous system disease that causes involuntary movements of the extremities, which is believed to be a complication of scarlet fever which causes skin pigmentation blotchiness. At times when he was confined to bed, he drew, listened to the radio and collected pictures of movie stars around his bed. Warhol later described this period as very important in the development of his personality, skill-set and preferences. When Warhol was 13, his father died in an accident.

As a teenager, Warhol graduated from Schenley High School in 1945. Also as a teen, Warhol won a Scholastic Art and Writing Award. After graduating from high school, his intentions were to study art education at the University of Pittsburgh in the hope of becoming an art teacher, but his plans changed and he enrolled in the Carnegie Institute of Technology, now Carnegie Mellon University in Pittsburgh, where he studied commercial art. During his time there, Warhol joined the campus Modern Dance Club and Beaux Arts Society. He also served as art director of the student art magazine, "Cano", illustrating a cover in 1948 and a full-page interior illustration in 1949. These are believed to be his first two published artworks. Warhol earned a Bachelor of Fine Arts in pictorial design in 1949. Later that year, he moved to New York City and began a career in magazine illustration and advertising.

Warhol's early career was dedicated to commercial and advertising art, where his first commission had been to draw shoes for "Glamour" magazine in the late 1940s. In the 1950s, Warhol worked as a designer for shoe manufacturer Israel Miller. American photographer John Coplans recalled that

Warhol's "whimsical" ink drawings of shoe advertisements figured in some of his earliest showings at the Bodley Gallery in New York.

Warhol was an early adopter of the silk screen printmaking process as a technique for making paintings. A young Warhol was taught silk screen printmaking techniques by Max Arthur Cohn at his graphic arts business in Manhattan. While working in the shoe industry, Warhol developed his "blotted line" technique, applying ink to paper and then blotting the ink while still wet, which was akin to a printmaking process on the most rudimentary scale. His use of tracing paper and ink allowed him to repeat the basic image and also to create endless variations on the theme, a method that prefigures his 1960s silk-screen canvas. In his book "Popism: The Warhol Sixties", Warhol writes: "When you do something exactly wrong, you always turn up something."

Warhol habitually used the expedient of tracing photographs projected with an epidiascope. Using prints by Edward Wallowitch, his 'first boyfriend' the photographs would undergo a subtle transformation during Warhol's often cursory tracing of contours and hatching of shadows. Warhol used Wallowitch's photograph "Young Man Smoking a Cigarette" (c.1956), for a 1958 design for a book cover he submitted to Simon and Schuster for the Walter Ross pulp novel "The Immortal", and later used others for his dollar bill series, and for "Big Campbell's Soup Can with Can Opener (Vegetable)", of 1962 which initiated Warhol's most sustained motif, the soup can.

With the rapid expansion of the record industry, RCA Records
He began exhibiting his work during the 1950s. He held exhibitions at the Hugo Gallery and the Bodley Gallery in New York City; in California, his first West Coast gallery exhibition was on July 9, 1962, in the Ferus Gallery of Los Angeles with Campbell's Soup Cans. The exhibition marked his West Coast debut of pop art.
Andy Warhol's first New York solo pop art exhibition was hosted at Eleanor Ward's Stable Gallery November 6–24, 1962. The exhibit included the works "Marilyn Diptych", "100 Soup Cans", "100 Coke Bottles", and "100 Dollar Bills". At the Stable Gallery exhibit, the artist met for the first time poet John Giorno who would star in Warhol's first film, "Sleep", in 1963.

It was during the 1960s that Warhol began to make paintings of iconic American objects such as dollar bills, mushroom clouds, electric chairs, Campbell's Soup Cans, Coca-Cola bottles, celebrities such as Marilyn Monroe, Elvis Presley, Marlon Brando, Troy Donahue, Muhammad Ali, and Elizabeth Taylor, as well as newspaper headlines or photographs of police dogs attacking African-American protesters during the Birmingham campaign in the civil rights movement. During these years, he founded his studio, "The Factory" and gathered about him a wide range of artists, writers, musicians, and underground celebrities. His work became popular and controversial. Warhol had this to say about Coca-Cola:

New York City's Museum of Modern Art

A pivotal event was the 1964 exhibit "The American Supermarket", a show held in Paul Bianchini's Upper East Side gallery. The show was presented as a typical U.S. small supermarket environment, except that everything in it—from the produce, canned goods, meat, posters on the wall, etc.—was created by six prominent pop artists of the time, among them the controversial (and like-minded) Billy Apple, Mary Inman, and Robert Watts

As an advertisement illustrator in the 1950s, Warhol used assistants to increase his productivity. Collaboration would remain a defining (and controversial) aspect of his working methods throughout his career; this was particularly true in the 1960s. One of the most important collaborators during this period was Gerard Malanga. Malanga assisted the artist with the production of silkscreens, films, sculpture, and other works at "The Factory", Warhol's aluminum foil-and-silver-paint-lined studio on 47th Street (later moved to Broadway). Other members of Warhol's Factory crowd included Freddie Herko, Ondine, Ronald Tavel, Mary Woronov, Billy Name, and Brigid Berlin (from whom he apparently got the idea to tape-record his phone conversations).

During the 1960s, Warhol also groomed a retinue of bohemian and counterculture eccentrics upon whom he bestowed the designation "Superstars", including Nico, Joe Dallesandro, Edie Sedgwick, Viva, Ultra Violet, Holly Woodlawn, Jackie Curtis, and Candy Darling. These people all participated in the Factory films, and some—like Berlin—remained friends with Warhol until his death. Important figures in the New York underground art/cinema world, such as writer John Giorno and film-maker Jack Smith, also appear in Warhol films (many premiering at the New Andy Warhol Garrick Theatre and 55th Street Playhouse) of the 1960s, revealing Warhol's connections to a diverse range of artistic scenes during this time. Less well known was his support and collaboration with several teen-agers during this era, who would achieve prominence later in life including writer David Dalton, photographer Stephen Shore and artist Bibbe Hansen (mother of pop musician Beck).

On June 3, 1968, radical feminist writer Valerie Solanas shot Warhol and Mario Amaya, art critic and curator, at Warhol's studio. Before the shooting, Solanas had been a marginal figure in the Factory scene. She authored in 1967 the "S.C.U.M. Manifesto", a separatist feminist tract that advocated the elimination of men; and appeared in the 1968 Warhol film "I, a Man". Earlier on the day of the attack, Solanas had been turned away from the Factory after asking for the return of a script she had given to Warhol. The script had apparently been misplaced.

Amaya received only minor injuries and was released from the hospital later the same day. Warhol was seriously wounded by the attack and barely survived: surgeons opened his chest and massaged his heart to help stimulate its movement again. He suffered physical effects for the rest of his life, including being required to wear a surgical corset. The shooting had a profound effect on Warhol's life and art.

Solanas was arrested the day after the assault, after turning herself in to police. By way of explanation, she said that Warhol "had too much control over my life." She was subsequently diagnosed with paranoid schizophrenia and eventually sentenced to three years under the control of the Department of Corrections

Compared to the success and scandal of Warhol's work in the 1960s, the 1970s were a much quieter decade, as he became more entrepreneurial. According to Bob Colacello, Warhol devoted much of his time to rounding up new, rich patrons for portrait commissions—including Shah of Iran Mohammad Reza Pahlavi, his wife Empress Farah Pahlavi, his sister Princess Ashraf Pahlavi, Mick Jagger, Liza Minnelli, John Lennon, Diana Ross, and Brigitte Bardot. Warhol's famous portrait of Chinese Communist leader Mao Zedong was created in 1973. He also founded, with Gerard Malanga, "Interview" magazine, and published "The Philosophy of Andy Warhol" (1975). An idea expressed in the book: "Making money is art, and working is art and good business is the best art."

Warhol socialized at various nightspots in New York City, including Max's Kansas City; and, later in the 1970s, Studio 54. He was generally regarded as quiet, shy, and a meticulous observer. Art critic Robert Hughes called him "the white mole of Union Square."

In 1979, along with his longtime friend Stuart Pivar, Warhol founded the New York Academy of Art.

Warhol had a re-emergence of critical and financial success in the 1980s, partially due to his affiliation and friendships with a number of prolific younger artists, who were dominating the "bull market" of 1980s New York art: Jean-Michel Basquiat, Julian Schnabel, David Salle and other so-called Neo-Expressionists, as well as members of the Transavantgarde movement in Europe, including Francesco Clemente and Enzo Cucchi. Before the 1984 Sarajevo Winter Olympics, he teamed with 15 other artists, including David Hockney and Cy Twombly, and contributed a Speed Skater print to the Art and Sport collection. The Speed Skater was used for the official Sarajevo Winter Olympics poster.

By this time, graffiti artist Fab Five Freddy paid homage to Warhol when he painted an entire train with Campbell soup cans. This was instrumental in Freddy becoming involved in the underground NYC art scene and becoming an affiliate of Basquiat.

By this period, Warhol was being criticized for becoming merely a "business artist". In 1979, reviewers disliked his exhibits of portraits of 1970s personalities and celebrities, calling them superficial, facile and commercial, with no depth or indication of the significance of the subjects. They also criticized his 1980 exhibit of 10 portraits at the Jewish Museum in Manhattan, entitled "Jewish Geniuses", which Warhol—who was uninterested in Judaism and Jews—had described in his diary as "They're going to sell." In hindsight, however, some critics have come to view Warhol's superficiality and commerciality as "the most brilliant mirror of our times," contending that "Warhol had captured something irresistible about the zeitgeist of American culture in the 1970s."

Warhol also had an appreciation for intense Hollywood glamour. He once said: "I love Los Angeles. I love Hollywood. They're so beautiful. Everything's plastic, but I love plastic. I want to be plastic."

In 1984, Warhol immortalized the singer Prince by creating one of his final portraits, "Orange Prince (1984)", a commission from Vanity Fair to accompany an article to celebrate the success of Prince's album and movie entitled "Purple Rain". Referencing the many celebrity portraits produced by Warhol across his career, "Orange" "Prince (1984)" was created using a similar composition to the Marilyn "Flavors" series from 1962, among some of Warhol's very first celebrity portraits. Prince is depicted in a pop color palette commonly used by Warhol, in bright orange with highlights of bright green and blue. The facial features and hair are screen-printed in black over the orange background.

In the "Andy Warhol Diaries", Warhol recorded how excited he was to see Prince and Billy Idol together at a party in the mid 1980s, and he compared them to the Hollywood movie stars of the 1950s and 1960s who also inspired his portraits: "...seeing these two glamour boys, its like "boys" are the new Hollywood glamour girls, like Jean Harlow and Marilyn Monroe".

By the beginning of the 1960s, pop art was an experimental form that several artists were independently adopting; some of these pioneers, such as Roy Lichtenstein, would later become synonymous with the movement. Warhol, who would become famous as the "Pope of Pop", turned to this new style, where popular subjects could be part of the artist's palette. His early paintings show images taken from cartoons and advertisements, hand-painted with paint drips. Marilyn Monroe was a pop art painting that Warhol had done and it was very popular. Those drips emulated the style of successful abstract expressionists (such as Willem de Kooning). Warhol's first pop art paintings were displayed in April 1961, serving as the backdrop for New York Department Store Bronwit Teller's window display. This was the same stage his Pop Art contemporaries Jasper Johns, James Rosenquist and Robert Rauschenberg
It was the gallerist Muriel Latow who came up with the ideas for both the soup cans and Warhol's dollar paintings. On November 23, 1961, Warhol wrote Latow a check for $50 which, according to the 2009 Warhol biography, "Pop, The Genius of Warhol", was payment for coming up with the idea of the soup cans as subject matter. For his first major exhibition, Warhol painted his famous cans of Campbell's soup, which he claimed to have had for lunch for most of his life. A 1964 "Large Campbell's Soup Can" was sold in a 2007 Sotheby's auction to a South American collector for £5.1 million ($7.4 million).

He loved celebrities, so he painted them as well. From these beginnings he developed his later style and subjects. Instead of working on a signature subject matter, as he started out to do, he worked more and more on a signature style, slowly eliminating the handmade from the artistic process. Warhol frequently used silk-screening; his later drawings were traced from slide projections. At the height of his fame as a painter, Warhol had several assistants who produced his silk-screen multiples, following his directions to make different versions and variations.

In 1979, Warhol was commissioned by BMW to paint a Group-4 race version of the then "elite supercar" BMW M1 for the fourth installment in the BMW Art Car Project. It was reported at the time that, unlike the three artists before him, Warhol opted to paint directly onto the automobile himself instead of letting technicians transfer his scale-model design to the car. It was indicated that Warhol spent only a total of 23 minutes to paint the entire car.

Warhol produced both comic and serious works; his subject could be a soup can or an electric chair. Warhol used the same techniques—silkscreens, reproduced serially, and often painted with bright colors—whether he painted celebrities, everyday objects, or images of suicide, car crashes, and disasters, as in the 1962–63 "Death and Disaster" series. The "Death and Disaster" paintings included "Red Car Crash", "Purple Jumping Man", and "Orange Disaster." One of these paintings, the diptych "Silver Car Crash", became the highest priced work of his when it sold at Sotheby's Contemporary Art Auction on Wednesday, November 13, 2013, for $105.4 million.

Some of Warhol's work, as well as his own personality, has been described as being Keatonesque. Warhol has been described as playing dumb to the media. He sometimes refused to explain his work. He has suggested that all one needs to know about his work is "already there 'on the surface'."

His Rorschach inkblots are intended as pop comments on art and what art could be. His cow wallpaper (literally, wallpaper with a cow motif) and his oxidation paintings (canvases prepared with copper paint that was then oxidized with urine) are also noteworthy in this context. Equally noteworthy is the way these works—and their means of production—mirrored the atmosphere at Andy's New York "Factory". Biographer Bob Colacello provides some details on Andy's "piss paintings":

Warhol's first portrait of "Basquiat" (1982) is a black photo-silkscreen over an oxidized copper "piss painting".

After many years of silkscreen, oxidation, photography, etc., Warhol returned to painting with a brush in hand in a series of more than 50 large collaborative works done with Jean-Michel Basquiat between 1984 and 1986. Despite negative criticism when these were first shown, Warhol called some of them "masterpieces," and they were influential for his later work.

Andy Warhol was commissioned in 1984 by collector and gallerist Alexander Iolas to produce work based on Leonardo da Vinci's "The Last Supper" for an exhibition at the old refectory of the Palazzo delle Stelline in Milan, opposite from the Santa Maria delle Grazie where Leonardo da Vinci's mural can be seen. Warhol exceeded the demands of the commission and produced nearly 100 variations on the theme, mostly silkscreens and paintings, and among them a collaborative sculpture with Basquiat, the "Ten Punching Bags (Last Supper)".
The Milan exhibition that opened in January 1987 with a set of 22 silk-screens, was the last exhibition for both the artist and the gallerist. The series of "The Last Supper" was seen by some as "arguably his greatest," but by others as "wishy-washy, religiose" and "spiritless." It is the largest series of religious-themed works by any U.S. artist.

Artist Maurizio Cattelan describes that it is difficult to separate daily encounters from the art of Andy Warhol: "That's probably the greatest thing about Warhol: the way he penetrated and summarized our world, to the point that distinguishing between him and our everyday life is basically impossible, and in any case useless." Warhol was an inspiration towards Cattelan's magazine and photography compilations, such as "Permanent Food, Charley", and "Toilet Paper".

In the period just before his death, Warhol was working on "Cars", a series of paintings for Mercedes-Benz.

A self-portrait by Andy Warhol (1963–64), which sold in New York at the May Post-War and Contemporary evening sale in Christie's, fetched $38.4 million.

On May 9, 2012, his classic painting "Double Elvis (Ferus Type)" sold at auction at Sotheby's in New York for US$33 million. With commission, the sale price totaled US$37,042,500, short of the $50 million that Sotheby's had predicted the painting might bring. The piece (silkscreen ink and spray paint on canvas) shows Elvis Presley in a gunslinger pose. It was first exhibited in 1963 at the Ferus Gallery in Los Angeles. Warhol made 22 versions of the "Double Elvis", nine of which are held in museums.

In November 2013, his "Silver Car Crash (Double Disaster)" diptych sold at Sotheby's Contemporary Art Auction for $105.4 million, a new record for the pop artist (pre-auction estimates were at $80 million). Created in 1963, this work had rarely been seen in public in the previous years. In November 2014, "Triple Elvis
Warhol worked across a wide range of media—painting, photography, drawing, and sculpture. In addition, he was a highly prolific filmmaker. Between 1963 and 1968, he made more than 60 films, plus some 500 short black-and-white "screen test" portraits of Factory visitors. One of his most famous films, "Sleep", monitors poet John Giorno sleeping for six hours. The 35-minute film "Blow Job" is one continuous shot of the face of DeVeren Bookwalter supposedly receiving oral sex from filmmaker Willard Maas, although the camera never tilts down to see this. Another, "Empire" (1964), consists of eight hours of footage of the Empire State Building in New York City at dusk. The film "Eat" consists of a man eating a mushroom for 45 minutes. Warhol attended the 1962 premiere of the static composition by LaMonte Young called "Trio for Strings" and subsequently created his famous series of static films including "Kiss", "Eat", and "Sleep" (for which Young initially was commissioned to provide music). Uwe Husslein cites filmmaker Jonas Mekas, who accompanied Warhol to the Trio premiere, and who claims Warhol's static films were directly inspired by the performance.

"Batman Dracula" is a 1964 film that was produced and directed by Warhol, without the permission of DC Comics. It was screened only at his art exhibits. A fan of the "Batman" series, Warhol's movie was an "homage" to the series, and is considered the first appearance of a blatantly campy Batman. The film was until recently thought to have been lost, until scenes from the picture were shown at some length in the 2006 documentary "Jack Smith and the Destruction of Atlantis".

Warhol's 1965 film "Vinyl" is an adaptation of Anthony Burgess' popular dystopian novel "A Clockwork Orange". Others record improvised encounters between Factory regulars such as Brigid Berlin, Viva, Edie Sedgwick, Candy Darling, Holly Woodlawn, Ondine, Nico, and Jackie Curtis. Legendary underground artist Jack Smith appears in the film "Camp".

His most popular and critically successful film was "Chelsea Girls" (1966). The film was highly innovative in that it consisted of two 16 mm-films being projected simultaneously, with two different stories being shown in tandem. From the projection booth, the sound would be raised for one film to elucidate that "story" while it was lowered for the other. The multiplication of images evoked Warhol's seminal silk-screen works of the early 1960s.

Warhol was a fan of filmmaker Radley Metzger film work and commented that Metzger's film, "The Lickerish Quartet", was "an outrageously kinky masterpiece". "Blue Movie"—a film in which Warhol superstar Viva makes love in bed with Louis Waldon, another Warhol superstar—was Warhol's last film as director. The film, a seminal film in the Golden Age of Porn, was, at the time, controversial for its frank approach to a sexual encounter. "Blue Movie" was publicly screened in New York City in 2005, for the first time in more than 30 years.

After his June 3, 1968, shooting, a reclusive Warhol relinquished his personal involvement in filmmaking. His acolyte and assistant director, Paul Morrissey, took over the film-making chores for the Factory collective, steering Warhol-branded cinema towards more mainstream, narrative-based, B-movie exploitation fare with "Flesh", "Trash", and "Heat". All of these films, including the later "Andy Warhol's Dracula" and "Andy Warhol's Frankenstein", were far more mainstream than anything Warhol as a director had attempted. These latter "Warhol" films starred Joe Dallesandro—more of a Morrissey star than a true Warhol superstar.

In the early 1970s, most of the films directed by Warhol were pulled out of circulation by Warhol and the people around him who ran his business. After Warhol's death, the films were slowly restored by the Whitney Museum and are occasionally projected at museums and film festivals. Few of the Warhol-directed films are available on video or DVD.


In the mid-1960s, Warhol adopted the band the Velvet Underground, making them a crucial element of the Exploding Plastic Inevitable multimedia performance art show. Warhol, with Paul Morrissey, acted as the band's manager, introducing them to Nico (who would perform with the band at Warhol's request). While managing The Velvet Underground, Andy would have them dressed in all black to perform in front of movies that he was also presenting. In 1966 he "produced" their first album "The Velvet Underground & Nico", as well as providing its album art. His actual participation in the album's production amounted to simply paying for the studio time. After the band's first album, Warhol and band leader Lou Reed started to disagree more about the direction the band should take, and their artistic friendship ended. In 1989, after Warhol's death, Reed and John Cale re-united for the first time since 1972 to write, perform, record and release the concept album "Songs for Drella", a tribute to Warhol.

Warhol designed many album covers for various artists starting with the photographic cover of John Wallowitch's debut album, "This Is John Wallowitch!!!" (1964). He designed the cover art for The Rolling Stones' albums "Sticky Fingers" (1971) and "Love You Live" (1977), and the John Cale albums "The Academy in Peril" (1972) and "Honi Soit" in 1981. One of Warhol's last works was a portrait of Aretha Franklin for the cover of her 1986 gold album "Aretha", which was done in the style of the "Reigning Queens" series he had completed the year before.

Warhol strongly influenced the new wave/punk rock band Devo, as well as David Bowie. Bowie recorded a song called "Andy Warhol" for his 1971 album "Hunky Dory". Lou Reed wrote the song "Andy's Chest", about Valerie Solanas, the woman who shot Warhol, in 1968. He recorded it with the Velvet Underground, and this version was released on the "VU" album in 1985. Bowie would later play Warhol in the 1996 movie, "Basquiat
Beginning in the early 1950s, Warhol produced several unbound portfolios of his work.

The first of several bound self-published books by Warhol was "25 Cats Name Sam and One Blue Pussy", printed in 1954 by Seymour Berlin on Arches brand watermarked paper using his blotted line technique for the lithographs. The original edition was limited to 190 numbered, hand colored copies, using Dr. Martin's ink washes. Most of these were given by Warhol as gifts to clients and friends. Copy No. 4, inscribed "Jerry" on the front cover and given to Geraldine Stutz, was used for a facsimile printing in 1987, and the original was auctioned in May 2006 for US$35,000 by Doyle New York.

Other self-published books by Warhol include:

Warhol's book "A La Recherche du Shoe Perdu" (1955) marked his "transition from commercial to gallery artist". (The title is a play on words by Warhol on the title of French author Marcel Proust's "À la recherche du temps perdu".)

After gaining fame, Warhol "wrote" several books that were commercially published:

Warhol created the fashion magazine "Interview" that is still published today. The loopy title script on the cover is thought to be either his own handwriting or that of his mother, Julia Warhola, who would often do text work for his early commercial pieces.

Although Andy Warhol is most known for his paintings and films, he authored works in many different media.

He founded the gossip magazine "Interview", a stage for celebrities he "endorsed" and a business staffed by his friends. He collaborated with others on all of his books (some of which were written with Pat Hackett.) He adopted the young painter Jean-Michel Basquiat, and the band The Velvet Underground, presenting them to the public as his latest interest, and collaborating with them. One might even say that he produced people (as in the Warholian "Superstar" and the Warholian portrait). He endorsed products, appeared in commercials, and made frequent celebrity guest appearances on television shows and in films (he appeared in everything from "Love Boat" to "Saturday Night Live" and the Richard Pryor movie "Dynamite Chicken").

In this respect Warhol was a fan of "Art Business" and "Business Art"—he, in fact, wrote about his interest in thinking about art as business in "The Philosophy of Andy Warhol from A to B and Back Again".

Warhol was gay. Interviewed in 1980, he indicated that he was still a virgin. Biographer Bob Colacello, who was present at the interview, felt it was probably true and that what little sex he had was probably "a mixture of voyeurism and masturbation—to use [Andy's] word "abstract"". Warhol's assertion of virginity would seem to be contradicted by his hospital treatment in 1960 for condylomata, a sexually transmitted disease. It has also been contradicted by his lovers, including Warhol muse BillyBoy, who has said they had sex to orgasm: "When he wasn't being Andy Warhol and when you were just alone with him he was an incredibly generous and very kind person. What seduced me was the Andy Warhol who I saw alone. In fact when I was with him in public he kind of got on my nerves...I'd say: 'You're just obnoxious, I can't bear you." Billy Name also denied that Warhol was only a voyeur, saying: "He was the essence of sexuality. It permeated everything. Andy exuded it, along with his great artistic creativity...It brought a joy to the whole art world in New York." "But his personality was so vulnerable that it became a defense to put up the blank front." Warhol's lovers included John Giorno, Billy Name, Charles Lisanby, and Jon Gould. His boyfriend of 12 years was Jed Johnson, whom he met in 1968, and who later achieved fame as an interior designer.

The fact that Warhol's homosexuality influenced his work and shaped his relationship to the art world is a major subject of scholarship on the artist and is an issue that Warhol himself addressed in interviews, in conversation with his contemporaries, and in his publications ("e.g.", "Popism: The Warhol 1960s"). Throughout his career, Warhol produced erotic photography and drawings of male nudes. Many of his most famous works (portraits of Liza Minnelli, Judy Garland, and Elizabeth Taylor, and films such as "Blow Job", "My Hustler" and "Lonesome Cowboys") draw from gay underground culture or openly explore the complexity of sexuality and desire. As has been addressed by a range of scholars, many of his films premiered in gay porn theaters, including the New Andy Warhol Garrick Theatre and 55th Street Playhouse, in the late 1960s.

The first works that Warhol submitted to a fine art gallery, homoerotic drawings of male nudes, were rejected for being too openly gay. In "Popism", furthermore, the artist recalls a conversation with the film maker Emile de Antonio about the difficulty Warhol had being accepted socially by the then-more-famous (but closeted) gay artists Jasper Johns and Robert Rauschenberg

Warhol was a practicing Ruthenian Catholic. He regularly volunteered at homeless shelters in New York City, particularly during the busier times of the year, and described himself as a religious person. Many of Warhol's later works depicted religious subjects, including two series, "Details of Renaissance Paintings" (1984) and "The Last Supper" (1986). In addition, a body of religious-themed works was found posthumously in his estate.

During his life, Warhol regularly attended Liturgy, and the priest at Warhol's church, Saint Vincent Ferrer, said that the artist went there almost daily, although he was not observed taking Communion or going to Confession and sat or knelt in the pews at the back. The priest thought he was afraid of being recognized; Warhol said he was self-conscious about being seen in a Roman Rite church crossing himself "in the Orthodox way" (right to left instead of the reverse).

His art is noticeably influenced by the Eastern Christian tradition which was so evident in his places of worship.

Warhol's brother has described the artist as "really religious, but he didn't want people to know about that because [it was] private". Despite the private nature of his faith, in Warhol's eulogy John Richardson depicted it as devout: "To my certain knowledge, he was responsible for at least one conversion. He took considerable pride in financing his nephew's studies for the priesthood".

Warhol was an avid collector. His friends referred to his numerous collections, which filled not only his four-story townhouse, but also a nearby storage unit, as "Andy's Stuff." The true extent of his collections was not discovered until after his death, when the Andy Warhol Museum in Pittsburgh took in 641 boxes of his "Stuff."

Warhol's collections included a Coca-cola memorabilia sign, and 19th century paintings along with airplane menus, unpaid invoices, pizza dough, pornographic pulp novels, newspapers, stamps, supermarket flyers, and cookie jars, among other eccentricities. It also included significant works of art, such as George Bellows's "Miss Bentham". One of his main collections was his wigs. Warhol owned more than 40 and felt very protective of his hairpieces, which were sewn by a New York wig-maker from hair imported from Italy. In 1985 a girl snatched Warhol's wig off his head. It was later discovered in Warhol's diary entry for that day that he wrote: "I don't know what held me back from pushing her over the balcony."

Another item found in Warhol's boxes at the museum in Pittsburgh was a mummified human foot from Ancient Egypt. The curator of anthropology at Carnegie Museum of Natural History
Warhol died in Manhattan at 6:32 a.m. on February 22, 1987 at age 58. According to news reports, he had been making a good recovery from gallbladder surgery at New York Hospital before dying in his sleep from a sudden post-operative irregular heartbeat. Prior to his diagnosis and operation, Warhol delayed having his recurring gallbladder problems checked, as he was afraid to enter hospitals and see doctors. His family sued the hospital for inadequate care, saying that the arrhythmia was caused by improper care and water intoxication. The malpractice case was quickly settled out of court; Warhol's family received an undisclosed sum of money.

Shortly before Warhol's death, doctors expected Warhol to survive the surgery, though a revaluation of the case about thirty years after his death showed many indications that Warhol's surgery was in fact riskier than originally thought. It was widely reported at the time that Warhol died of a "routine" surgery, though when considering factors such as his age, a family history of gallbladder problems, his previous gunshot wounds, and his medical state in the weeks leading up to the procedure, the potential risk of death following the surgery appeared to have been significant.

Warhol's brothers took his body back to Pittsburgh, where an open-coffin wake was held at the Thomas P. Kunsak Funeral Home. The solid bronze casket had gold-plated rails and white upholstery. Warhol was dressed in a black cashmere suit, a paisley tie, a platinum wig, and sunglasses. He was laid out holding a small prayer book and a red rose. The funeral liturgy was held at the Holy Ghost Byzantine Catholic Church on Pittsburgh's North Side. The eulogy was given by Monsignor Peter Tay. Yoko Ono and John Richardson were speakers. The coffin was covered with white roses and asparagus ferns. After the liturgy, the coffin was driven to St. John the Baptist Byzantine Catholic Cemetery in Bethel Park, a south suburb of Pittsburgh.

At the grave, the priest said a brief prayer and sprinkled holy water on the casket. Before the coffin was lowered, Paige Powell dropped a copy of "Interview" magazine, an "Interview" T-shirt, and a bottle of the Estee Lauder perfume "Beautiful" into the grave. Warhol was buried next to his mother and father. A memorial service was held in Manhattan for Warhol on April 1, 1987, at St. Patrick's Cathedral, New York.

Warhol's will dictated that his entire estate—with the exception of a few modest legacies to family members—would go to create a foundation dedicated to the "advancement of the visual arts". Warhol had so many possessions that it took Sotheby's nine days to auction his estate after his death; the auction grossed more than US$20 million.

In 1987, in accordance with Warhol's will, the Andy Warhol Foundation for the Visual Arts began. The foundation serves as the estate of Andy Warhol, but also has a mission "to foster innovative artistic expression and the creative process" and is "focused primarily on supporting work of a challenging and often experimental nature."

The Artists Rights Society is the U.S. copyright representative for the Andy Warhol Foundation for the Visual Arts for all Warhol works with the exception of Warhol film stills. The U.S. copyright representative for Warhol film stills is the Warhol Museum in Pittsburgh. Additionally, the Andy Warhol Foundation for the Visual Arts has agreements in place for its image archive. All digital images of Warhol are exclusively managed by Corbis, while all transparency images of Warhol are managed by Art Resource.

The Andy Warhol Foundation released its "20th Anniversary Annual Report" as a three-volume set in 2007: Vol. I, 1987–2007; Vol. II, Grants & Exhibitions; and Vol. III, Legacy Program. The Foundation remains one of the largest grant-giving organizations for the visual arts in the U.S.

Many of Warhol's works and possessions are on display at The Andy Warhol Museum in Pittsburgh

Warhol appeared as himself in the film "Cocaine Cowboys" (1979) and in the film "Tootsie" (1982).

After his death, Warhol was portrayed by Crispin Glover in Oliver Stone's film "The Doors" (1991), by David Bowie in Julian Schnabel's film "Basquiat" (1996), and by Jared Harris in Mary Harron's film "I Shot Andy Warhol" (1996).

Warhol appears as a character in Michael Daugherty's opera "Jackie O" (1997). Actor Mark Bringleson makes a brief cameo as Warhol in "Austin Powers: International Man of Mystery" (1997).

Many films by avant-garde cineast Jonas Mekas have caught the moments of Warhol's life. Sean Gregory Sullivan depicted Warhol in the film "54" (1998). Guy Pearce portrayed Warhol in the film "Factory Girl" (2007) about Edie Sedgwick's life. Actor Greg Travis portrays Warhol in a brief scene from the film "Watchmen" (2009).

In the movie "Highway to Hell" a group of Andy Warhols are part of the "Good Intentions Paving Company" where good-intentioned souls are ground into pavement.

In the film "Men in Black 3" (2012) Andy Warhol turns out to really be undercover MIB Agent W (played by Bill Hader). Warhol is throwing a party at The Factory in 1969, where he is looked up by MIB Agents K and J (J from the future). Agent W is desperate to end his undercover job ("I'm so out of ideas I'm painting soup cans and bananas, for Christ sakes!", "You gotta fake my death, okay? I can't listen to sitar music anymore." and "I can't tell the girls from the boys.").

Andy Warhol (portrayed by Tom Meeten) is one of main characters of the 2012 British television show "Noel Fielding's Luxury Comedy". The character is portrayed as having robot-like mannerisms.

In the 2017 feature "The Billionaire Boys Club" Cary Elwes portrays Warhol in a film based on the true story about Ron Levin (portrayed by Kevin Spacey) a friend of Warhol's who was murdered in 1986.

In September 2016, it was announced that Jared Leto would portray the title character in "Warhol", an upcoming American biographical drama film produced by Michael De Luca and written by Terence Winter, based on the book "Warhol: The Biography" by Victor Bockris.



In 2002, the U.S. Postal Service issued an 18-cent stamp commemorating Warhol. Designed by Richard Sheaff of Scottsdale, Arizona
Category:1928 births
Category:1987 deaths
Category:20th-century American artists
Category:20th-century American musicians
Category:20th-century American painters
Category:American male painters
Category:20th-century American photographers
Category:20th-century American writers
Category:Album-cover and concert-poster artists
Category:American cinematographers
Category:American contemporary artists
Category:American Eastern Catholics
Category:American experimental filmmakers
Category:American film producers
Category:American portrait painters
Category:American people of Ukrainian descent
Category:American people of Lemko descent
Category:American people of Slovak descent
Category:American people of Rusyn descent
Category:American pop artists
Category:American printmakers
Category:American male screenwriters
Category:American shooting survivors
Category:American socialites
Category:Artists from New York (state)
Category:Artists from Pittsburgh
Category:Burials in Pennsylvania
Category:Carnegie Mellon University College of Fine Arts alumni
Category:Catholics from Pennsylvania
Category:Censorship in the arts
Category:Fashion illustrators
Category:Film directors from New York (state)
Category:Film directors from Pennsylvania
Category:Gay artists
Category:Gay writers
Category:Hypochondriacs
Category:LGBT artists from the United States
Category:LGBT Roman Catholics
Category:LGBT directors
Category:LGBT people from New York (state)
Category:LGBT people from Pennsylvania
Category:LGBT producers
Category:LGBT writers from the United States
Category:Photographers from New York (state)
Category:Portrait photographers
Category:Postmodern artists
Category:Ruthenian Catholics
Category:Schenley High School alumni
Category:The Velvet Underground
Category:Warhola family
Category:Writers from New York (state)
Category:Writers from Pittsburgh
Category:American male writers
Category:Experiments in Art and Technology collaborating artists
Category:People associated with The FactoryAlp Arslan

Alp Arslan (honorific in Turkish meaning "Heroic Lion"; in ; full name: "Diya ad-Dunya wa ad-Din Adud ad-Dawlah Abu Shuja Muhammad Alp Arslan ibn Dawud" ; 20 January 1029 – 15 December 1072), real name Muhammad bin Dawud Chaghri, was the second Sultan of the Seljuk Empire and great-grandson of Seljuk, the eponymous founder of the dynasty. As Sultan, Alp Arslan greatly expanded Seljuk territory and consolidated power, defeating rivals to his south and northwest. His victory over the Byzantines at the Battle of Manzikert in 1071 ushered in the Turkish settlement of Anatolia. For his military prowess and fighting skills he obtained the name "Alp Arslan", which means "Heroic Lion" in Turkish.

Alp Arslan accompanied his uncle, Tughril Bey, on campaigns in the south against the Shia Fatimids while his father, Çağrı Bey, remained in Khorasan. Upon Alp Arslan's return to Khorasan, he began his work in administration at his father's suggestion. While there, his father introduced him to Nizam al-Mulk, one of the most eminent statesmen in early Muslim history and Alp Arslan's future vizier.

After the death of his father, Alp Arslan succeeded him as governor of Khorasan in 1059. His uncle Tughril died in 1063 and was succeeded by Suleiman, Arslan's brother. Arslan and his uncle Kutalmish both contested this succession. ("see" Battle of Damghan (1063)) Arslan defeated Kutalmish for the throne and succeeded on 27 April 1064 as sultan of Great Seljuq, thus becoming sole monarch of Persia from the river Oxus to the Tigris.

In consolidating his empire and subduing contending factions, Arslan was ably assisted by Nizam al-Mulk, and the two are credited with helping to stabilize the empire after the death of Tughril. With peace and security established in his dominions, Arslan convoked an assembly of the states and in 1066, he declared his son Malik Shah I his heir and successor. With the hope of capturing Caesarea Mazaca, the capital of Cappadocia, he placed himself at the head of the Turkish cavalry, crossed the Euphrates, and entered and invaded the city. Along with Nizam al-Mulk, he then marched into Armenia and Georgia, which he conquered in 1064. After a siege of 25 days, the Seljuks captured Ani, the capital city of Armenia. An account of the sack and massacres in Ani is given by the historian Sibt ibn al-Jawzi

En route to fight the Fatimids in Syria in 1068, Alp Arslan invaded the Byzantine Empire. The Emperor Romanos IV Diogenes, assuming command in person, met the invaders in Cilicia. In three arduous campaigns, the Turks were defeated in detail and driven across the Euphrates in 1070. The first two campaigns were conducted by the emperor himself, while the third was directed by Manuel Comnenos, great-uncle of Emperor Manuel Comnenos. During this time, Arslan gained the allegiance of Rashid al-Dawla Mahmud, the Mirdasid emir of Aleppo.

In 1071 Romanos again took the field and advanced into Armenia with possibly 30,000 men, including a contingent of Cuman Turks as well as contingents of Franks and Normans, under Ursel de Baieul. Alp Arslan, who had moved his troops south to fight the Fatimids, quickly reversed to meet the Byzantines. At Manzikert, on the Murat River, north of Lake Van, the two forces waged the Battle of Manzikert. The Cuman mercenaries among the Byzantine forces immediately defected to the Turkish side. Seeing this, "the Western mercenaries rode off and took no part in the battle." To be exact, Romanos was betrayed by general Andronikos Doukas

Alp Arslan's victories changed the balance in near Asia completely in favour of the Seljuq Turks and Sunni Muslims. While the Byzantine Empire was to continue for nearly four more centuries, and the Crusades would contest the issue for some time, the victory at Manzikert signalled the beginning of Turkish ascendancy in Anatolia. Most historians, including Edward Gibbon, date the defeat at Manzikert as the beginning of the end of the Eastern Roman Empire.

Alp Arslan's strength lay in the military realm. Domestic affairs were handled by his able vizier, Nizam al-Mulk, the founder of the administrative organization that characterized and strengthened the sultanate during the reigns of Alp Arslan and his son, Malik Shah. Military fiefs, governed by Seljuq princes, were established to provide support for the soldiery and to accommodate the nomadic Turks to the established Anatolian agricultural scene. This type of military fiefdom enabled the nomadic Turks to draw on the resources of the sedentary Persians, Turks, and other established cultures within the Seljuq realm, and allowed Alp Arslan to field a huge standing army without depending on tribute from conquest to pay his soldiers. He not only had enough food from his subjects to maintain his military, but the taxes collected from traders and merchants added to his coffers sufficiently to fund his continuous wars.

According to the poet Saadi Shirazi:
Suleiman ibn Kutalmish was the son of the contender for Arslan's throne; he was appointed governor of the north-western provinces and assigned to completing the invasion of Anatolia. An explanation for this choice can only be conjectured from Ibn al-Athir's account of the battle between Alp-Arslan and Kutalmish, in which he writes that Alp-Arslan wept for the latter's death and greatly mourned the loss of his kinsman.

After Manzikert, the dominion of Alp Arslan extended over much of western Asia. He soon prepared to march for the conquest of Turkestan, the original seat of his ancestors. With a powerful army he advanced to the banks of the Oxus. Before he could pass the river with safety, however, it was necessary to subdue certain fortresses, one of which was for several days vigorously defended by the governor, Yussuf al-Kharezmi, a Khwarezmian. He was obliged to surrender, however, and was carried as a prisoner before the sultan, who condemned him to death. Yussuf, in desperation, drew his dagger and rushed upon the sultan. Alp Arslan, who took great pride in his reputation as an archer, motioned to his guards not to interfere. He drew his bow, but his foot slipped, the arrow glanced aside, and he received the assassin's dagger in his breast. Alp Arslan died from this wound four days later, on 25 November 1072, in his 42nd year, and he was taken to Merv to be buried next to his father, Chaghri Beg.

Alp Arslan is widely regarded as having begun Anatolianism, although unintentionally. His victory at Manzikert is often cited as the beginning of the end of Byzantine power in Anatolia, and the beginning of Turkish identity there.

Alp Arslan's conquest of Anatolia from the Byzantines is also seen as one of the pivotal precursors to the launch of the crusades.

From 2002 to July 2008 under Turkmen calendar reform, the month of August was named after Alp Arslan.


Category:1029 births
Category:1072 deaths
Category:Seljuk rulers
Category:Monarchs of Persia
Category:Byzantine–Seljuq Wars
Category:11th-century murdered monarchs
Category:11th-century Turkic people
Category:Deaths by stabbingAmerican Film Institute

The American Film Institute (AFI) is an American film organization that educates filmmakers and honors the heritage of the motion picture arts in the United States. AFI is supported by private funding and public membership fees.

The institute is composed of leaders from the film, entertainment, business, and academic communities. A board of trustees chaired by Sir Howard Stringer and a board of directors chaired by Robert A. Daly guide the organization, which is led by President and CEO, film historian Bob Gazzale. Prior leaders were founding director George Stevens, Jr. (from the organization's inception in 1967 until 1980) and Jean Picker Firstenberg (from 1980 to 2007).

The American Film Institute was founded by a 1965 presidential mandate announced in the Rose Garden of the White House by Lyndon B. Johnson—to establish a national arts organization to preserve the legacy of American film heritage, educate the next generation of filmmakers, and honor the artists and their work. Two years later, in 1967, AFI was established, supported by the National Endowment for the Arts, the Motion Picture Association of America and the Ford Foundation.

The original 22-member Board of Trustees included actor Gregory Peck as chairman and actor Sidney Poitier as vice-chairman as well as director Francis Ford Coppola, film historian Arthur Schlesinger, Jr., lobbyist Jack Valenti, and other representatives from the arts and academia.

The institute established a training program for filmmakers known then as the Center for Advanced Film Studies. Also created in the early years were a repertory film exhibition program at the Kennedy Center for the Performing Arts and the AFI Catalog of Feature Films — a scholarly source for American film history. The institute moved to its current eight-acre Hollywood campus in 1981. The film training program grew into the AFI Conservatory, an accredited graduate school.

AFI moved its presentation of first-run and auteur films from the Kennedy Center to the historic AFI Silver Theatre and Cultural Center, which hosts the AFI DOCS film festival, making AFI the largest nonprofit film exhibitor in the world. AFI educates audiences and recognizes artistic excellence through its awards programs and 10 Top 10 Lists.

On November 3, 2017, Ilana Bar-Din Giannini claimed that the AFI expelled her after she accused Dezso Magyar of sexual harassing her in the early 1980s.

AFI educational and cultural programs include:

In 1969, the institute established the AFI Conservatory for Advanced Film Studies at Greystone, the Doheny Mansion in Beverly Hills, California. The first class included filmmakers Terrence Malick, Caleb Deschanel, and Paul Schrader. That program grew into the AFI Conservatory, an accredited graduate film school located in the hills above Hollywood, California, providing training in six filmmaking disciplines: cinematography, directing, editing, producing, production design, and screenwriting. Mirroring a professional production environment, Fellows collaborate to make more films than any other graduate level program. Admission to AFI Conservatory is highly selective, with a maximum of 140 graduates per year.

In 2013, Emmy and Oscar-winning director, producer, and screenwriter James L. Brooks ("As Good as It Gets", "Broadcast News", "Terms of Endearment") joined AFI as Artistic Director of the AFI Conservatory where he provides leadership for the film program. Brooks' artistic role at the AFI Conservatory has a rich legacy that includes Daniel Petrie, Jr., Robert Wise, and Frank Pierson. Award-winning director Bob Mandel served as Dean of the AFI Conservatory for nine years. Jan Schuette took over as Dean in 2014 and served until 2017. Film Producer Richard Gladstein became Dean on July 1, 2017.

AFI Conservatory's alumni have careers in film, television and on the web. They have been recognized with all of the major industry awards—Academy Award, Emmy Award, guild awards, and the Tony Award.

Among the alumni of AFI are Andrea Arnold, ("Red Road", "Fish Tank"), Darren Aronofsky ("Requiem for a Dream", "Black Swan"), Carl Colpaert ("Gas Food Lodging", "Hurlyburly", "Swimming with Sharks"), Doug Ellin ("Entourage"), Todd Field ("In the Bedroom", "Little Children"), Jack Fisk ("Badlands", "Days of Heaven", "There Will Be Blood"), Carl Franklin ("One False Move", "Devil in a Blue Dress", "House of Cards"), Patty Jenkins ("Monster", "Wonder Woman"), Janusz Kamiński ("Lincoln", "Schindler's List", "Saving Private Ryan"), Matthew Libatique ("Noah", "Black Swan"), David Lynch ("Mulholland Drive", "Blue Velvet"), Terrence Malick ("Days of Heaven", "The Thin Red Line", "The Tree of Life"), Victor Nuñez, ("Ruby in Paradise", "Ulee's Gold"), Wally Pfister ("Memento", "The Dark Knight", "Inception"), Robert Richardson ("Platoon", "JFK", "Django Unchained"), and many others.

The AFI Catalog, started in 1968, is a web-based filmographic database. A research tool for film historians, the catalog consists of entries on more than 60,000 feature films and 17,000 short films produced from 1893–2011, as well as AFI Awards Outstanding Movies of the Year from 2000 through 2010. Early print copies of this catalog may also be found at your local library.

Each year the AFI Awards honor the ten outstanding films ("Movies of the Year") and ten outstanding television programs ("TV Programs of the Year"). The awards are a non-competitive acknowledgement of excellence.

The Awards are announced in December and a private luncheon for award honorees takes place the following January.

The AFI 100 Years... series, which ran from 1998 to 2008 and created jury-selected lists of America's best movies in categories such as Musicals, Laughs and Thrills, prompted new generations to experience classic American films. The juries consisted of over 1,500 artists, scholars, critics and historians, with movies selected based on the film's popularity over time, historical significance and cultural impact. "Citizen Kane" was voted the greatest American film twice.

AFI operates two film festivals: AFI Fest in Los Angeles, and AFI Docs (formally known as Silverdocs) in Silver Spring, Maryland, and Washington, D.C..

AFI Fest is the American Film Institute's annual celebration of artistic excellence. The festival is a showcase for the best festival films of the year and an opportunity for master filmmakers and emerging artists to come together with audiences in the movie capital of the world. AFI Fest is the only festival of its stature that is free to the public. The Academy of Motion Picture Arts and Sciences recognizes AFI Fest as a qualifying festival for the Short Films category for the annual Academy Awards.

The festival has paid tribute to numerous influential filmmakers and artists over the years, including Agnès Varda, Pedro Almodóvar and David Lynch as guest artistic directors, and has screened scores of films that have produced Oscar nominations and wins. The American Film Market (AFM) is the market partner of AFI Fest. Audi is the festival's presenting sponsor. Additional sponsors include American Airlines and Stella Artois.

Held annually in June, AFI Docs (formerly Silverdocs) is a documentary festival in Washington, D.C.. The festival attracts over 27,000 documentary enthusiasts.

The AFI Silver Theatre and Cultural Center is a moving image exhibition, education and cultural center located in Silver Spring, Maryland. Anchored by the restoration of noted architect John Eberson's historic 1938 Silver Theatre, it features 32,000 square feet of new construction housing two stadium theatres, office and meeting space, and reception and exhibit areas.

The AFI Silver Theatre and Cultural Center presents film and video programming, augmented by filmmaker interviews, panels, discussions,and musical performances.

The Directing Workshop for Women is a training program committed to educating and mentoring participants in an effort to increase the number of women working professionally in screen directing. In this tuition-free program, each participant is required to complete a short film by the end of the year-long program.

Alumnae of the program include Maya Angelou, Anne Bancroft, Dyan Cannon, Ellen Burstyn, Jennifer Getzinger, Lesli Linka Glatter, and Nancy Malone.

AFI released a set of hour-long programs reviewing the career of acclaimed directors. The Directors Series content was copyrighted in 1997 by Media Entertainment Inc and The American Film Institute, and the VHS and DVDs were released between 1999 and 2001 on Winstar TV and Video.

Directors featured included:

Indian investigative journalist Rana Ayyub posed as Maithili Tyagi, a student from the institute. She stung many bureaucrats of Gujarat in an undercover investigation to reveal their views on post-2002 Gujarat riots and Police encounter killings. She has documented the verbatim transcript of these recordings in her 2016 book "Gujarat Files: Anatomy of a Cover Up
Category:Arts organizations based in California
Category:Cinema of Southern California
Category:Hollywood history and culture
Category:Los Feliz, Los Angeles
Category:Organizations based in Los Angeles
Category:1967 establishments in California
Category:Organizations established in 1967Akira Kurosawa

Akira Kurosawa (, "Kurosawa Akira"; March 23, 1910 – September 6, 1998) was a Japanese film director and screenwriter, who directed 30 films in a career spanning 57 years. He is regarded as one of the most important and influential filmmakers in the history of cinema.

Kurosawa entered the Japanese film industry in 1936, following a brief stint as a painter. After years of working on numerous films as an assistant director and scriptwriter, he made his debut as a director during World War II with the popular action film "Sanshiro Sugata" (a.k.a. "Judo Saga"). After the war, the critically acclaimed "Drunken Angel" (1948), in which Kurosawa cast then-unknown actor Toshiro Mifune in a starring role, cemented the director's reputation as one of the most important young filmmakers in Japan. The two men would go on to collaborate on another 15 films.

"Rashomon", which premiered in Tokyo, became the surprise winner of the Golden Lion at the 1951 Venice Film Festival. The commercial and critical success of that film opened up Western film markets for the first time to the products of the Japanese film industry, which in turn led to international recognition for other Japanese filmmakers. Kurosawa directed approximately one film per year throughout the 1950s and early 1960s, including a number of highly regarded (and often adapted) films, such as "Ikiru" (1952), "Seven Samurai" (1954) and "Yojimbo" (1961). After the 1960s he became much less prolific; even so, his later work—including his final two epics, "Kagemusha" (1980) and "Ran" (1985)—continued to win awards, though more often abroad than in Japan.

In 1990, he accepted the Academy Award for Lifetime Achievement. Posthumously, he was named "Asian of the Century" in the "Arts, Literature, and Culture" category by "AsianWeek" magazine and CNN, cited there as being among the five people who most prominently contributed to the improvement of Asia in the 20th century. His career has been honored by many retrospectives, critical studies and biographies in both print and video, and by releases in many consumer media formats.

 was born on March 23, 1910, in Ōimachi in the Ōmori district of Tokyo. His father Isamu (1864–1948), a member of a samurai family from Akita Prefecture, worked as the director of the Army's Physical Education Institute's lower secondary school, while his mother Shima (1870–1952) came from a merchant's family living in Osaka. Akira was the eighth and youngest child of the moderately wealthy family, with two of his siblings already grown up at the time of his birth and one deceased, leaving Kurosawa to grow up with three sisters and a brother.

In addition to promoting physical exercise, Isamu Kurosawa was open to Western traditions and considered theater and motion pictures to have educational merit. He encouraged his children to watch films; young Akira viewed his first movies at the age of six. An important formative influence was his elementary school teacher Mr Tachikawa, whose progressive educational practices ignited in his young pupil first a love of drawing and then an interest in education in general. During this time, the boy also studied calligraphy and Kendo swordsmanship.

Another major childhood influence was Heigo Kurosawa, Akira's older brother by four years. In the aftermath of the Great Kantō earthquake of 1923, which devastated Tokyo, Heigo took the 13-year-old Akira to view the devastation. When the younger brother wanted to look away from the human corpses and animal carcasses scattered everywhere, Heigo forbade him to do so, instead encouraging Akira to face his fears by confronting them directly. Some commentators have suggested that this incident would influence Kurosawa's later artistic career, as the director was seldom hesitant to confront unpleasant truths in his work.

Heigo was academically gifted, but soon after failing to secure a place in Tokyo's foremost high school, he began to detach himself from the rest of the family, preferring to concentrate on his interest in foreign literature. In the late 1920s, Heigo became a benshi (silent film narrator) for Tokyo theaters showing foreign films, and quickly made a name for himself. Akira, who at this point planned to become a painter, moved in with him, and the two brothers became inseparable. With Heigo's guidance, Akira devoured not only films but also theater and circus performances, while exhibiting his paintings and working for the left-wing Proletarian Artists' League. However, he was never able to make a living with his art, and, as he began to perceive most of the proletarian movement as "putting unfulfilled political ideals directly onto the canvas", he lost his enthusiasm for painting.

With the increasing production of talking pictures in the early 1930s, film narrators like Heigo began to lose work, and Akira moved back in with his parents. In July 1933, Heigo committed suicide. Kurosawa has commented on the lasting sense of loss he felt at his brother's death and the chapter of his autobiography ("Something Like an Autobiography
In 1935, the new film studio Photo Chemical Laboratories, known as P.C.L. (which later became the major studio, Toho), advertised for assistant directors. Although he had demonstrated no previous interest in film as a profession, Kurosawa submitted the required essay, which asked applicants to discuss the fundamental deficiencies of Japanese films and find ways to overcome them. His half-mocking view was that if the deficiencies were fundamental, there was no way to correct them. Kurosawa's essay earned him a call to take the follow-up exams, and director Kajirō Yamamoto, who was among the examiners, took a liking to Kurosawa and insisted that the studio hire him. The 25-year-old Kurosawa joined P.C.L. in February 1936.

During his five years as an assistant director, Kurosawa worked under numerous directors, but by far the most important figure in his development was Yamamoto. Of his 24 films as A.D., he worked on 17 under Yamamoto, many of them comedies featuring the popular actor Ken'ichi Enomoto, known as "Enoken". Yamamoto nurtured Kurosawa's talent, promoting him directly from third assistant director to chief assistant director after a year. Kurosawa's responsibilities increased, and he worked at tasks ranging from stage construction and film development to location scouting, script polishing, rehearsals, lighting, dubbing, editing and second-unit directing. In the last of Kurosawa's films as an assistant director for Yamamoto, "Horse" ("Uma", 1941), Kurosawa took over most of the production, as his mentor was occupied with the shooting of another film.

One important piece of advice Yamamoto gave Kurosawa was that a good director needed to master screenwriting. Kurosawa soon realized that the potential earnings from his scripts were much higher than what he was paid as an assistant director. Kurosawa would later write or co-write all of his own films. He also frequently wrote screenplays for other directors such as for the antiwar film director Satsuo Yamamoto's film, "A Triumph of Wings" ("Tsubasa no gaika", 1942). This outside scriptwriting would serve Kurosawa as a lucrative sideline lasting well into the 1960s, long after he became world-famous.

In the two years following the release of "Horse" in 1941, Kurosawa searched for a story he could use to launch his directing career. Towards the end of 1942, about a year after the Japanese attack on Pearl Harbor, novelist Tsuneo Tomita published his Musashi Miyamoto
Shooting of "Sanshiro Sugata" began on location in Yokohama in December 1942. Production proceeded smoothly, but getting the completed film past the censors was an entirely different matter. The censorship office considered the work to be objectionably "British-American" by the standards of wartime Japan, and it was only through the intervention of director Yasujirō Ozu, who championed the film, that "Sanshiro Sugata" was finally accepted for release on March 25, 1943. (Kurosawa had just turned 33.) The movie became both a critical and commercial success. Nevertheless, the censorship office would later decide to cut out some 18 minutes of footage, much of which is now considered lost.

He next turned to the subject of wartime female factory workers in "The Most Beautiful", a propaganda film which he shot in a semi-documentary style in early 1944. In order to coax realistic performances from his actresses, the director had them live in a real factory during the shoot, eat the factory food and call each other by their character names. He would use similar methods with his performers throughout his career.

During production, the actress playing the leader of the factory workers, Yōko Yaguchi, was chosen by her colleagues to present their demands to the director. She and Kurosawa were constantly at loggerheads, and it was through these arguments that the two, paradoxically, became close. They married on May 21, 1945, with Yaguchi two months pregnant (she never resumed her acting career), and the couple would remain together until her death in 1985. They would have two children, both surviving Kurosawa : a son, Hisao, born December 20, 1945, who would serve as producer on some of his father's last projects, and Kazuko, a daughter, born April 29, 1954, who would become a costume designer.

Shortly before his marriage, Kurosawa was pressured by the studio against his will to direct a sequel to his debut film. The often blatantly propagandistic "Sanshiro Sugata Part II", which premiered in May 1945, is generally considered one of his weakest pictures.

Kurosawa decided to write the script for a film that would be both censor-friendly and less expensive to produce. "The Men Who Tread on the Tiger's Tail", based on the Kabuki play "Kanjinchō" and starring the comedian Enoken, with whom Kurosawa had often worked during his assistant director days, was completed in September 1945. By this time, Japan had surrendered and the occupation of Japan had begun. The new American censors interpreted the values allegedly promoted in the picture as overly "feudal" and banned the work. (It would not be released until 1952, the year another Kurosawa film, "Ikiru", was also released.) Ironically, while in production, the film had already been savaged by Japanese wartime censors as too Western and "democratic" (they particularly disliked the comic porter played by Enoken), so the movie most probably would not have seen the light of day even if the war had continued beyond its completion.

After the war, Kurosawa, influenced by the democratic ideals of the Occupation, sought to make films that would establish a new respect towards the individual and the self. The first such film, "No Regrets for Our Youth" (1946), inspired by both the 1933 Takigawa incident and the Hotsumi Ozaki wartime spy case, criticized Japan's prewar regime for its political oppression. Atypically for the director, the heroic central character is a woman, Yukie (Setsuko Hara), who born into upper-middle-class privilege, comes to question her values in a time of political crisis. The original script had to be extensively rewritten and, because of its controversial theme (and because the protagonist was a woman), the completed work divided critics, but it nevertheless managed to win the approval of audiences, who turned variations on the film's title into a postwar catchphrase.

His next film, "One Wonderful Sunday" premiered in July 1947 to mixed reviews. It is a relatively uncomplicated and sentimental love story dealing with an impoverished postwar couple trying to enjoy, within the devastation of postwar Tokyo, their one weekly day off. The movie bears the influence of Frank Capra, D. W. Griffith and F. W. Murnau, each of whom was among Kurosawa's favorite directors. Another film released in 1947 with Kurosawa's involvement was the action-adventure thriller, "Snow Trail", directed by Senkichi Taniguchi
"Drunken Angel" is often considered the director's first major work. Although the script, like all of Kurosawa's occupation-era works, had to go through forced rewrites due to American censorship, Kurosawa felt that this was the first film in which he was able to express himself freely. A grittily realistic story of a doctor who tries to save a gangster (yakuza) with tuberculosis, it was also the director's first film with Toshiro Mifune, who would proceed to play either the main or a major character in all but one ("Ikiru") of the director's next 16 films. While Mifune was not cast as the protagonist in "Drunken Angel", his explosive performance as the gangster so dominates the drama that he shifted the focus from the title character, the alcoholic doctor played by Takashi Shimura, who had already appeared in several Kurosawa movies. However, Kurosawa did not want to smother the young actor's immense vitality, and Mifune's rebellious character electrified audiences in much the way that Marlon Brando's defiant stance would startle American film audiences a few years later. The film premiered in Tokyo in April 1948 to rave reviews and was chosen by the prestigious Kinema Junpo critics poll as the best film of its year, the first of three Kurosawa movies to be so honored.

Kurosawa, with producer Sōjirō Motoki and fellow directors and friends Kajiro Yamamoto, Mikio Naruse and Senkichi Taniguchi, formed a new independent production unit called Film Art Association (Eiga Geijutsu Kyōkai). For this organization's debut work, and first film for Daiei studios, Kurosawa turned to a contemporary play by Kazuo Kikuta and, together with Taniguchi, adapted it for the screen. "The Quiet Duel" starred Toshiro Mifune as an idealistic young doctor struggling with syphilis, a deliberate attempt by Kurosawa to break the actor away from being typecast as gangsters. Released in March 1949, it was a box office success, but is generally considered one of the director's lesser achievements.

His second film of 1949, also produced by Film Art Association and released by Shintoho, was "Stray Dog". It is a detective movie (perhaps the first important Japanese film in that genre) that explores the mood of Japan during its painful postwar recovery through the story of a young detective, played by Mifune, and his fixation on the recovery of his handgun, which was stolen by a penniless war veteran who proceeds to use it to rob and murder. Adapted from an unpublished novel by Kurosawa in the style of a favorite writer of his, Georges Simenon, it was the director's first collaboration with screenwriter Ryuzo Kikushima, who would later help to script eight other Kurosawa films. A famous, virtually wordless sequence, lasting over eight minutes, shows the detective, disguised as an impoverished veteran, wandering the streets in search of the gun thief; it employed actual documentary footage of war-ravaged Tokyo neighborhoods shot by Kurosawa's friend, Ishirō Honda, the future director of "Godzilla". The film is considered a precursor to the contemporary police procedural and buddy cop film genres.

"Scandal", released by Shochiku in April 1950, was inspired by the director's personal experiences with, and anger towards, Japanese yellow journalism. The work is an ambitious mixture of courtroom drama and social problem film about free speech and personal responsibility, but even Kurosawa regarded the finished product as dramatically unfocused and unsatisfactory, and almost all critics agree. However, it would be Kurosawa's second film of 1950, "Rashomon", that would ultimately win him, and Japanese cinema, a whole new international audience.

After finishing "Scandal", Kurosawa was approached by Daiei studios, which asked the director to make another film for them. Kurosawa picked a script by an aspiring young screenwriter, Shinobu Hashimoto, who would survive Kurosawa by 20 years and with whom he would eventually work on nine of his films. Their first joint effort was based on Ryūnosuke Akutagawa's experimental short story "In a Grove", which recounts the murder of a samurai and the rape of his wife from various different and conflicting points-of-view. Kurosawa saw potential in the script, and with Hashimoto's help, polished and expanded it and then pitched it to Daiei, who were happy to accept the project due to its low budget.

Shooting of "Rashomon" began on July 7, 1950, and, after extensive location work in the primeval forest of Nara
Kurosawa's next film, for Shochiku, was "The Idiot", an adaptation of the novel by the director's favorite writer, Fyodor Dostoyevsky. The filmmaker relocated the story from Russia to Hokkaido, but it is otherwise very faithful to the original, a fact seen by many critics as detrimental to the work. A studio-mandated edit shortened it from Kurosawa's original cut of 265 minutes (nearly four-and-a-half hours) to just 166 minutes, making the resulting narrative exceedingly difficult to follow. The severely edited film version is widely considered today to be one of the director's least successful works and the original full length version no longer exists. Contemporary reviews of the much shortened edited version were very negative, but the film was a moderate success at the box office, largely because of the popularity of one of its stars, Setsuko Hara.

Meanwhile, unbeknownst to Kurosawa, "Rashomon" had been entered in the prestigious Venice Film Festival, due to the efforts of Giuliana Stramigioli, a Japan-based representative of an Italian film company, who had seen and admired the movie and convinced Daiei to submit it. On September 10, 1951, "Rashomon" was awarded the festival's highest prize, the Golden Lion, shocking not only Daiei but the international film world, which at the time was largely unaware of Japan's decades-old cinematic tradition.

After Daiei very briefly exhibited a subtitled print of the film in Los Angeles, RKO purchased distribution rights to "Rashomon" in the United States. The company was taking a considerable gamble. It had put out only one prior subtitled film in the American market, and the only previous Japanese talkie commercially released in New York had been Mikio Naruse's comedy, "Wife! Be Like a Rose", in 1937: a critical and box-office flop. However, "Rashomon"s commercial run, greatly helped by strong reviews from critics and even the columnist Ed Sullivan, was very successful. (It earned $35,000 in its first three weeks at a single New York theater, an almost unheard-of sum at the time.)

This success in turn led to a vogue in America and the West for Japanese movies throughout the 1950s, replacing the enthusiasm for Italian neorealist cinema. For example, by the end of 1952 "Rashomon" was released in Japan, the United States, and most of Europe. Among the Japanese filmmakers whose work, as a result, began to win festival prizes and commercial release in the West were Kenji Mizoguchi ("The Life of Oharu", "Ugetsu", "Sansho the Bailiff") and, somewhat later, Yasujirō Ozu ("Tokyo Story", "An Autumn Afternoon")—artists highly respected in Japan but, prior to this period, almost totally unknown in the West. Kurosawa's growing reputation among Western audiences in the 1950s would make Western audiences more sympathetic to the reception of later generations of Japanese filmmakers ranging from Kon Ichikawa, Masaki Kobayashi, Nagisa Oshima and Shohei Imamura to Juzo Itami, Takeshi Kitano and Takashi Miike.

His career boosted by his sudden international fame, Kurosawa, now reunited with his original film studio, Toho (which would go on to produce his next 11 films), set to work on his next project, "Ikiru". The movie stars Takashi Shimura as a cancer-ridden Tokyo bureaucrat, Watanabe, on a final quest for meaning before his death. For the screenplay, Kurosawa brought in Hashimoto as well as writer Hideo Oguni, who would go on to co-write 12 Kurosawa films. Despite the work's grim subject matter, the screenwriters took a satirical approach, which some have compared to the work of Brecht, to both the bureaucratic world of its hero and the U.S. cultural colonization of Japan. (American pop songs figure prominently in the film.) Because of this strategy, the filmmakers are usually credited with saving the picture from the kind of sentimentality common to dramas about characters with terminal illnesses. "Ikiru" opened in October 1952 to rave reviews—it won Kurosawa his second Kinema Junpo "Best Film" award—and enormous box office success. It remains the most acclaimed of all the artist's films set in the modern era.

In December 1952, Kurosawa took his "Ikiru" screenwriters, Shinobu Hashimoto and Hideo Oguni, for a forty-five-day secluded residence at an inn to create the screenplay for his next movie, "Seven Samurai". The ensemble work was Kurosawa's first proper samurai film, the genre for which he would become most famous. The simple story, about a poor farming village in Sengoku period Japan that hires a group of samurai to defend it against an impending attack by bandits, was given a full epic treatment, with a huge cast (largely consisting of veterans of previous Kurosawa productions) and meticulously detailed action, stretching out to almost three-and-a-half hours of screen time.

Three months were spent in pre-production and a month in rehearsals. Shooting took up 148 days spread over almost a year, interrupted by production and financing troubles and Kurosawa's health problems. The film finally opened in April 1954, half a year behind its original release date and about three times over budget, making it at the time the most expensive Japanese film ever made. (However, by Hollywood standards, it was a quite modestly budgeted production, even for that time). The film received positive critical reaction and became a big hit, quickly making back the money invested in it and providing the studio with a product that they could, and did, market internationally—though with extensive edits. Over time—and with the theatrical and home video releases of the uncut version—its reputation has steadily grown. It is now regarded by some commentators as the greatest Japanese film ever made, and in 1979, a poll of Japanese film critics also voted it the best Japanese film ever made. In the most recent (2012) version of the widely respected British Film Institute (BFI) "Sight & Sound" "Greatest Films of All Time" poll, "Seven Samurai" placed 17th among all films from all countries in both the critics' and the directors' polls, receiving a place in the Top Ten lists of 48 critics and 22 directors.

In 1954, nuclear tests in the Pacific were causing radioactive rainstorms in Japan and one particular incident in March had exposed a Japanese fishing boat to nuclear fallout, with disastrous results. It is in this anxious atmosphere that Kurosawa's next film, "Record of a Living Being", was conceived. The story concerned an elderly factory owner (Toshiro Mifune) so terrified of the prospect of a nuclear attack that he becomes determined to move his entire extended family (both legal and extra-marital) to what he imagines is the safety of a farm in Brazil. Production went much more smoothly than the director's previous film, but a few days before shooting ended, Kurosawa's composer, collaborator and close friend Fumio Hayasaka died (of tuberculosis) at the age of 41. The film's score was finished by Hayasaka's student, Masaru Sato, who would go on to score all of Kurosawa's next eight films. "Record of a Living Being" opened in November 1955 to mixed reviews and muted audience reaction, becoming the first Kurosawa film to lose money during its original theatrical run. Today, it is considered by many to be among the finest films dealing with the psychological effects of the global nuclear stalemate.

Kurosawa's next project, "Throne of Blood", an adaptation of William Shakespeare's "Macbeth"—set, like "Seven Samurai", in the Sengoku Era—represented an ambitious transposition of the English work into a Japanese context. Kurosawa instructed his leading actress, Isuzu Yamada, to regard the work as if it were a cinematic version of a "Japanese" rather than a European literary classic. Given Kurosawa's appreciation of traditional Japanese stage acting, the acting of the players, particularly Yamada, draws heavily on the stylized techniques of the Noh theater. It was filmed in 1956 and released in January 1957 to a slightly less negative domestic response than had been the case with the director's previous film. Abroad, "Throne of Blood", regardless of the liberties it takes with its source material, quickly earned a place among the most celebrated Shakespeare adaptations.

Another adaptation of a classic European theatrical work followed almost immediately, with production of "The Lower Depths", based on a play by Maxim Gorky, taking place in May and June 1957. In contrast to the Shakespearean sweep of "Throne of Blood", "The Lower Depths" was shot on only two confined sets, in order to emphasize the restricted nature of the characters' lives. Though faithful to the play, this adaptation of Russian material to a completely Japanese setting—in this case, the late Edo period—unlike his earlier "The Idiot", was regarded as artistically successful. The film premiered in September 1957, receiving a mixed response similar to that of "Throne of Blood". However, some critics rank it among the director's most underrated works.

Kurosawa's three consecutive movies after "Seven Samurai" had not managed to capture Japanese audiences in the way that that film had. The mood of the director's work had been growing increasingly pessimistic and dark, with the possibility of redemption through personal responsibility now very much questioned, particularly in "Throne of Blood" and "The Lower Depths". He recognized this, and deliberately aimed for a more light-hearted and entertaining film for his next production, while switching to the new widescreen format that had been gaining popularity in Japan. The resulting film, "The Hidden Fortress", is an action-adventure comedy-drama about a medieval princess, her loyal general and two peasants who all need to travel through enemy lines in order to reach their home region. Released in December 1958, "The Hidden Fortress" became an enormous box office success in Japan and was warmly received by critics both in Japan and abroad. Today, the film is considered one of Kurosawa's most lightweight efforts, though it remains popular, not least because it is one of several major influences on George Lucas's 1977 space opera, "Star Wars".

Starting with "Rashomon", Kurosawa's productions had become increasingly large in scope and so had the director's budgets. Toho, concerned about this development, suggested that he might help finance his own works, therefore making the studio's potential losses smaller, while in turn allowing himself more artistic freedom as co-producer. Kurosawa agreed, and the Kurosawa Production Company was established in April 1959, with Toho as majority shareholder.

Despite risking his own money, Kurosawa chose a story that was more directly critical of the Japanese business and political elites than any previous work. "The Bad Sleep Well", based on a script by Kurosawa's nephew Mike Inoue, is a revenge drama about a young man who is able to infiltrate the hierarchy of a corrupt Japanese company with the intention of exposing the men responsible for his father's death. Its theme proved topical: while the film was in production, mass demonstrations were held against the new U.S.–Japan Security treaty, which was seen by many Japanese, particularly the young, as threatening the country's democracy by giving too much power to corporations and politicians. The film opened in September 1960 to positive critical reaction and modest box office success. The 25-minute opening sequence depicting a corporate wedding reception is widely regarded as one of Kurosawa's most skillfully executed set pieces, but the remainder of the film is often perceived as disappointing by comparison. The movie has also been criticized for employing the conventional Kurosawan hero to combat a social evil that cannot be resolved through the actions of individuals, however courageous or cunning.

"Yojimbo" ("The Bodyguard"), Kurosawa Production's second film, centers on a masterless samurai, Sanjuro, who strolls into a 19th-century town ruled by two opposing violent factions and provokes them into destroying each other. The director used this work to play with many genre conventions, particularly the Western, while at the same time offering an unprecedentedly (for the Japanese screen) graphic portrayal of violence. Some commentators have seen the Sanjuro character in this film as a fantasy figure who magically reverses the historical triumph of the corrupt merchant class over the samurai class. Featuring Tatsuya Nakadai in his first major role in a Kurosawa movie, and with innovative photography by Kazuo Miyagawa (who shot "Rashomon") and Takao Saito, the film premiered in April 1961 and was a critically and commercially successful venture, earning more than any previous Kurosawa film. The movie and its blackly comic tone were also widely imitated abroad. Sergio Leone's "A Fistful of Dollars
Following the success of "Yojimbo", Kurosawa found himself under pressure from Toho to create a sequel. Kurosawa turned to a script he had written before "Yojimbo", reworking it to include the hero of his previous film. "Sanjuro" was the first of three Kurosawa films to be adapted from the work of the writer Shūgorō Yamamoto (the others would be "Red Beard" and "Dodeskaden"). It is lighter in tone and closer to a conventional period film than "Yojimbo", though its story of a power struggle within a samurai clan is portrayed with strongly comic undertones. The film opened on January 1, 1962, quickly surpassing "Yojimbo"s box office success and garnering positive reviews.

Kurosawa had meanwhile instructed Toho to purchase the film rights to "King's Ransom", a novel about a kidnapping written by American author and screenwriter Evan Hunter, under his pseudonym of Ed McBain, as one of his 87th Precinct series of crime books. The director intended to create a work condemning kidnapping, which he considered one of the very worst crimes. The suspense film, titled "High and Low", was shot during the latter half of 1962 and released in March 1963. It broke Kurosawa's box office record (the third film in a row to do so), became the highest grossing Japanese film of the year, and won glowing reviews. However, his triumph was somewhat tarnished when, ironically, the film was blamed for a wave of kidnappings which occurred in Japan about this time (he himself received kidnapping threats directed at his young daughter, Kazuko). "High and Low" is considered by many commentators to be among the director's strongest works.

Kurosawa quickly moved on to his next project, "Red Beard". Based on a short story collection by Shūgorō Yamamoto and incorporating elements from Dostoyevsky's novel "The Insulted and Injured", it is a period film, set in a mid-nineteenth century clinic for the poor, in which Kurosawa's humanist themes receive perhaps their fullest statement. A conceited and materialistic, foreign-trained young doctor, Yasumoto, is forced to become an intern at the clinic under the stern tutelage of Doctor Niide, known as "Akahige" ("Red Beard"), played by Mifune. Although he resists Red Beard initially, Yasumoto comes to admire his wisdom and courage, and to perceive the patients at the clinic, whom he at first despised, as worthy of compassion and dignity.

Yūzō Kayama, who plays Yasumoto, was an extremely popular film and music star at the time, particularly for his "Young Guy" ("Wakadaishō") series of musical comedies, so signing him to appear in the film virtually guaranteed Kurosawa strong box-office. The shoot, the filmmaker's longest ever, lasted well over a year (after five months of pre-production), and wrapped in spring 1965, leaving the director, his crew and his actors exhausted. "Red Beard" premiered in April 1965, becoming the year's highest-grossing Japanese production and the third (and last) Kurosawa film to top the prestigious Kinema Jumpo yearly critics poll. It remains one of Kurosawa's best-known and most-loved works in his native country. Outside Japan, critics have been much more divided. Most commentators concede its technical merits and some praise it as among Kurosawa's best, while others insist that it lacks complexity and genuine narrative power, with still others claiming that it represents a retreat from the artist's previous commitment to social and political change.

The film marked something of an end of an era for its creator. The director himself recognized this at the time of its release, telling critic Donald Richie that a cycle of some kind had just come to an end and that his future films and production methods would be different. His prediction proved quite accurate. Beginning in the late 1950s, television began increasingly to dominate the leisure time of the formerly large and loyal Japanese cinema audience. And as film company revenues dropped, so did their appetite for risk—particularly the risk represented by Kurosawa's costly production methods.

"Red Beard" also marked the midway point, chronologically, in the artist's career. During his previous twenty-nine years in the film industry (which includes his five years as assistant director), he had directed twenty-three films, while during the remaining twenty-eight years, for many and complex reasons, he would complete only seven more. Also, for reasons never adequately explained, "Red Beard" would be his final film starring Toshiro Mifune. Yu Fujiki, an actor who worked on "The Lower Depths", observed, regarding the closeness of the two men on the set, "Mr. Kurosawa's heart was in Mr. Mifune's body." Donald Richie has described the rapport between them as a unique "symbiosis".

When Kurosawa's exclusive contract with Toho came to an end in 1966, the 56-year-old director was seriously contemplating change. Observing the troubled state of the domestic film industry, and having already received dozens of offers from abroad, the idea of working outside Japan appealed to him as never before.

For his first foreign project, Kurosawa chose a story based on a "Life" magazine article. The Embassy Pictures action thriller, to be filmed in English and called simply "Runaway Train", would have been his first in color. But the language barrier proved a major problem, and the English version of the screenplay was not even finished by the time filming was to begin in autumn 1966. The shoot, which required snow, was moved to autumn 1967, then canceled in 1968. Almost two decades later, another foreign director working in Hollywood, Andrei Konchalovsky, finally made "Runaway Train" (1985), though from a new script loosely based on Kurosawa's.

The director meanwhile had become involved in a much more ambitious Hollywood project. "Tora! Tora! Tora!", produced by 20th Century Fox and Kurosawa Production, would be a portrayal of the Japanese attack on Pearl Harbor from both the American and the Japanese points-of-view, with Kurosawa helming the Japanese half and an English-speaking filmmaker directing the American half. He spent several months working on the script with Ryuzo Kikushima and Hideo Oguni, but very soon the project began to unravel. The director chosen to film the American sequences turned out not to be the prestigious English filmmaker David Lean, as the producers had led Kurosawa to believe, but the much less celebrated special effects expert, Richard Fleischer. The budget was also cut, and the screen time allocated for the Japanese segment would now be no longer than 90 minutes—a major problem, considering that Kurosawa's script ran over four hours. After numerous revisions with the direct involvement of Darryl Zanuck, a more or less finalized cut screenplay was agreed upon in May 1968.

Shooting began in early December, but Kurosawa would last only a little over three weeks as director. He struggled to work with an unfamiliar crew and the requirements of a Hollywood production, while his working methods puzzled his American producers, who ultimately concluded that the director must be mentally ill. Kurosawa was examined at Kyoto University Hospital by a neuropsychologist, Dr. Murakami, whose diagnosis was forwarded to Darryl Zanuck and Richard Zanuck at Fox studios indicating a diagnosis of neurasthenia stating that, "He is suffering from disturbance of sleep, agitated with feelings of anxiety and in manic excitement caused by the above mentioned illness. It is necessary for him to have rest and medical treatment for more than two months." On Christmas Eve 1968, the Americans announced that Kurosawa had left the production due to "fatigue", effectively firing him. He was ultimately replaced, for the film's Japanese sequences, with two directors, Kinji Fukasaku and Toshio Masuda.

"Tora! Tora! Tora!", finally released to unenthusiastic reviews in September 1970, was, as Donald Richie put it, an "almost unmitigated tragedy" in Kurosawa's career. He had spent years of his life on a logistically nightmarish project to which he ultimately did not contribute a foot of film shot by himself. (He had his name removed from the credits, though the script used for the Japanese half was still his and his co-writers'.) He became estranged from his longtime collaborator, writer Ryuzo Kikushima, and never worked with him again. The project had inadvertently exposed corruption in his own production company (a situation reminiscent of his own movie, "The Bad Sleep Well"). His very sanity had been called into question. Worst of all, the Japanese film industry—and perhaps the man himself—began to suspect that he would never make another film.

Knowing that his reputation was at stake following the much publicised "Tora! Tora! Tora!" debacle, Kurosawa moved quickly to a new project to prove he was still viable. To his aid came friends and famed directors Keisuke Kinoshita, Masaki Kobayashi and Kon Ichikawa, who together with Kurosawa established in July 1969 a production company called the Club of the Four Knights (Yonki no kai). Although the plan was for the four directors to create a film each, it has been suggested that the real motivation for the other three directors was to make it easier for Kurosawa to successfully complete a film, and therefore find his way back into the business.

The first project proposed and worked on was a period film to be called "Dora-Heita", but when this was deemed too expensive, attention shifted to "Dodesukaden", an adaptation of yet another Shūgorō Yamamoto work, again about the poor and destitute. The film was shot quickly (by Kurosawa's standards) in about nine weeks, with Kurosawa determined to show he was still capable of working quickly and efficiently within a limited budget. For his first work in color, the dynamic editing and complex compositions of his earlier pictures were set aside, with the artist focusing on the creation of a bold, almost surreal palette of primary colors, in order to reveal the toxic environment in which the characters live. It was released in Japan in October 1970, but though a minor critical success, it was greeted with audience indifference. The picture lost money and caused the Club of the Four Knights to dissolve. Initial reception abroad was somewhat more favorable, but "Dodesukaden" has since been typically considered an interesting experiment not comparable to the director's best work.

Unable to secure funding for further work and allegedly suffering from health problems, Kurosawa apparently reached the breaking point: on December 22, 1971, he slit his wrists and throat multiple times. The suicide attempt proved unsuccessful and the director's health recovered fairly quickly, with Kurosawa now taking refuge in domestic life, uncertain if he would ever direct another film.

In early 1973, the Soviet studio Mosfilm approached the filmmaker to ask if he would be interested in working with them. Kurosawa proposed an adaptation of Russian explorer Vladimir Arsenyev's autobiographical work "Dersu Uzala". The book, about a Goldi hunter who lives in harmony with nature until destroyed by encroaching civilization, was one that he had wanted to make since the 1930s. In December 1973, the 63-year-old Kurosawa set off for the Soviet Union with four of his closest aides, beginning a year-and-a-half stay in the country. Shooting began in May 1974 in Siberia, with filming in exceedingly harsh natural conditions proving very difficult and demanding. The picture wrapped in April 1975, with a thoroughly exhausted and homesick Kurosawa returning to Japan and his family in June. "Dersu Uzala" had its world premiere in Japan on August 2, 1975, and did well at the box office. While critical reception in Japan was muted, the film was better reviewed abroad, winning the Golden Prize at the 9th Moscow International Film Festival, as well as an Academy Award for Best Foreign Language Film. Today, critics remain divided over the film: some see it as an example of Kurosawa's alleged artistic decline, while others count it among his finest works.

Although proposals for television projects were submitted to him, he had no interest in working outside the film world. Nevertheless, the hard-drinking director did agree to appear in a series of television ads for Suntory whiskey, which aired in 1976. While fearing that he might never be able to make another film, the director nevertheless continued working on various projects, writing scripts and creating detailed illustrations, intending to leave behind a visual record of his plans in case he would never be able to film his stories.

In 1977, American director George Lucas released "Star Wars", a wildly successful science fiction film influenced by Kurosawa's "The Hidden Fortress", among other works. Lucas, like many other New Hollywood directors, revered Kurosawa and considered him a role model, and was shocked to discover that the Japanese filmmaker was unable to secure financing for any new work. The two met in San Francisco in July 1978 to discuss the project Kurosawa considered most financially viable: "Kagemusha", the epic story of a thief hired as the double of a medieval Japanese lord of a great clan. Lucas, enthralled by the screenplay and Kurosawa's illustrations, leveraged his influence over 20th Century Fox to coerce the studio that had fired Kurosawa just ten years earlier to produce "Kagemusha", then recruited fellow fan Francis Ford Coppola as co-producer.

Production began the following April, with Kurosawa in high spirits. Shooting lasted from June 1979 through March 1980 and was plagued with problems, not the least of which was the firing of the original lead actor, Shintaro Katsu—creator of the very popular Zatoichi character—due to an incident in which the actor insisted, against the director's wishes, on videotaping his own performance. (He was replaced by Tatsuya Nakadai, in his first of two consecutive leading roles in a Kurosawa movie.) The film was completed only a few weeks behind schedule and opened in Tokyo in April 1980. It quickly became a massive hit in Japan. The film was also a critical and box office success abroad, winning the coveted Palme d'Or at the 1980 Cannes Film Festival
The international success of "Kagemusha" allowed Kurosawa to proceed with his next project, "Ran", another epic in a similar vein. The script, partly based on William Shakespeare's "King Lear", depicted a ruthless, bloodthirsty "daimyō" (warlord), played by Tatsuya Nakadai, who, after foolishly banishing his one loyal son, surrenders his kingdom to his other two sons, who then betray him, thus plunging the entire kingdom into war. As Japanese studios still felt wary about producing another film that would rank among the most expensive ever made in the country, international help was again needed. This time it came from French producer Serge Silberman, who had produced Luis Buñuel's final movies. Filming did not begin until December 1983 and lasted more than a year.

In January 1985, production of "Ran" was halted as Kurosawa's 64-year-old wife Yōko fell ill. She died on February 1. Kurosawa returned to finish his film and "Ran" premiered at the Tokyo Film Festival on 31 May, with a wide release the next day. The film was a moderate financial success in Japan, but a larger one abroad and, as he had done with "Kagemusha", Kurosawa embarked on a trip to Europe and America, where he attended the film's premieres in September and October.

"Ran" won several awards in Japan, but was not quite as honored there as many of the director's best films of the 1950s and 1960s had been. The film world was surprised, however, when Japan passed over the selection of "Ran" in favor of another film as its official entry to compete for an Oscar nomination in the Best Foreign Film category, which was ultimately rejected for competition at the 58th Academy Awards. Both the producer and Kurosawa himself attributed the failure to even submit "Ran" for competition to a misunderstanding: because of the Academy's arcane rules, no one was sure whether "Ran" qualified as a "Japanese" film, a "French" film (due to its financing), or both, so it was not submitted at all. In response to what at least appeared to be a blatant snub by his own countrymen, the director Sidney Lumet led a successful campaign to have Kurosawa receive an Oscar nomination for Best Director that year (Sydney Pollack ultimately won the award for directing "Out of Africa"). "Ran"s costume designer, Emi Wada, won the movie's only Oscar.

"Kagemusha" and "Ran", particularly the latter, are often considered to be among Kurosawa's finest works. After "Ran"s release, Kurosawa would point to it as his best film, a major change of attitude for the director who, when asked which of his works was his best, had always previously answered "my next one".
For his next movie, Kurosawa chose a subject very different from any that he had ever filmed before. While some of his previous pictures (for example, "Drunken Angel" and "Kagemusha") had included brief dream sequences, "Dreams" was to be entirely based upon the director's own dreams. Significantly, for the first time in over forty years, Kurosawa, for this deeply personal project, wrote the screenplay alone. Although its estimated budget was lower than the films immediately preceding it, Japanese studios were still unwilling to back one of his productions, so Kurosawa turned to another famous American fan, Steven Spielberg, who convinced Warner Bros. to buy the international rights to the completed film. This made it easier for Kurosawa's son, Hisao, as co-producer and soon-to-be head of Kurosawa Production, to negotiate a loan in Japan that would cover the film's production costs. Shooting took more than eight months to complete, and "Dreams" premiered at Cannes in May 1990 to a polite but muted reception, similar to the reaction the picture would generate elsewhere in the world. In 1990, he accepted the Academy Award for Lifetime Achievement
Kurosawa now turned to a more conventional story with "Rhapsody in August"—the director's first film fully produced in Japan since "Dodeskaden" over twenty years before—which explored the scars of the nuclear bombing which destroyed Nagasaki at the very end of World War II. It was adapted from a Kiyoko Murata novel, but the film's references to the Nagasaki bombing came from the director rather than from the book. This was his only movie to include a role for an American movie star: Richard Gere, who plays a small role as the nephew of the elderly heroine. Shooting took place in early 1991, with the film opening on 25 May that year to a largely negative critical reaction, especially in the United States, where the director was accused of promulgating naïvely anti-American sentiments, though Kurosawa rejected these accusations.

Kurosawa wasted no time moving onto his next project: "Madadayo", or "Not Yet". Based on autobiographical essays by Hyakken Uchida, the film follows the life of a Japanese professor of German through the Second World War and beyond. The narrative centers on yearly birthday celebrations with his former students, during which the protagonist declares his unwillingness to die just yet—a theme that was becoming increasingly relevant for the film's 81-year-old creator. Filming began in February 1992 and wrapped by the end of September. Its release on April 17, 1993, was greeted by an even more disappointed reaction than had been the case with his two preceding works.

Kurosawa nevertheless continued to work. He wrote the original screenplays "The Sea is Watching" in 1993 and "After the Rain" in 1995. While putting finishing touches on the latter work in 1995, Kurosawa slipped and broke the base of his spine. Following the accident, he would use a wheelchair for the rest of his life, putting an end to any hopes of him directing another film. His longtime wish—to die on the set while shooting a movie—was never to be fulfilled.

After his accident, Kurosawa's health began to deteriorate. While his mind remained sharp and lively, his body was giving up, and for the last half-year of his life, the director was largely confined to bed, listening to music and watching television at home. On September 6, 1998, Kurosawa died of a stroke in Setagaya, Tokyo, at the age of 88. At the time of his death, Kurosawa had two children, his son Hisao Kurosawa who married Hiroko Hayashi and his daughter Kazuko Kurosawa who married Harayuki Kato, along with several grandchildren. One of his grandchildren, the actor Takayuki Kato and grandson by Kazuko, became a supporting actor in two films posthumously developed from screenplays written by Kurosawa which remained unproduced during his own lifetime, Takashi Koizumi's "After the Rain" (1999) and Kei Kumai's "The Sea is Watching" (2002).

From the beginning, Kurosawa displayed a bold, dynamic style, strongly influenced by Western cinema yet quite distinct from it. Kurosawa was extensively involved with every aspect of film production. He was also a gifted screenwriter, and would usually work in close collaboration with his co-writers from the beginning of the development of a film to ensure a high-quality script, which he insisted was the absolute foundation of a good film. He frequently served as editor of his own films and was regarded by his production team as "the greatest editor in the world". Though it was common in the Japanese film industry of that time for established directors to assemble around them a team, or "-gumi", with people drawn from the same pool of creative technicians, crew members and actors working from film to film (for example, the director Hiroshi Inagaki, who worked at Toho during the same period as Kurosawa, had such a team), Kurosawa's team, known as the "Kurosawa-gumi" (Kurosawa group)—including, for example, the cinematographer Asakazu Nakai, the production assistant Teruyo Nogami and the actor Takashi Shimura—was remarkable for its loyalty to the director and the consistent quality of its work.

Kurosawa's style is marked by a number of devices and techniques which Kurosawa introduced in his films over the decades. In his films of the 1940s and 1950s, Kurosawa frequently employs the "axial cut", in which the camera moves closer to, or further away from, the subject, not through the use of tracking shots or dissolves, but through a series of matched jump cuts. Another stylistic trait which scholars have pointed out is Kurosawa's tendency to "cut on motion": that is, to edit a sequence of a character or characters in motion so that an action is depicted in two or more separate shots, rather than one uninterrupted shot.

A form of cinematic punctuation very strongly identified with Kurosawa is the wipe. This is an effect created through an optical printer, in which, when a scene ends, a line or bar appears to move across the screen, "wiping" away the image while simultaneously revealing the first image of the subsequent scene. As a transitional device, it is used as a substitute for the straight cut or the dissolve (though Kurosawa often used both of those devices as well). In his mature work, Kurosawa employed the wipe so frequently that it became a kind of signature. For example, one blogger has counted no fewer than 12 instances of the wipe in "Drunken Angel". Kurosawa by all accounts always gave great attention to the soundtracks of his films, especially with an emphasis on sound-image counterpoint, in which the music or sound effects would ironically comment upon the image rather than merely reinforcing it. (Teruyo Nogami's memoir gives several such examples from "Drunken Angel" and "Stray Dog".) He was also involved with several of Japan's outstanding contemporary composers, including Fumio Hayasaka (who died in 1955) and the internationally famous Tōru Takemitsu.

Kurosawa employed a number of recurring major themes in his films. These include: (a) the master-disciple relationship between a usually older mentor and one or more novices, which often involves spiritual as well as technical mastery and self-mastery; (b) the heroic champion, the exceptional individual who emerges from the mass of people to produce something or right some injustice; (c) the depiction of extremes of weather as both dramatic devices and symbols of human passion; and (d) the recurrence of cycles of inexorable savage violence within history. According to Stephen Prince, the latter theme began with "Throne of Blood" (1957), and recurred in Kurosawa films of the 1980s. Mr. Prince calls this theme "the countertradition to the committed, heroic mode of Kurosawa's cinema".

Criticism of Kurosawa in his legacy has significantly followed a close parity between the main currents of domestic criticism his films received when they were released in Japan with the international reception his individual films received when released abroad during his lifetime. Since the early to mid-1950s, a number of critics from the French New Wave championed the films of the older Japanese master, Kenji Mizoguchi, at the expense of Kurosawa's work. New Wave critic-filmmaker Jacques Rivette, said: "You can compare only what is comparable and that which aims high enough ... [Mizoguchi] seems to be the only Japanese director who is completely Japanese and yet is also the only one that achieves a true universality, that of an individual." According to such French commentators, Mizoguchi seemed, of the two artists, the more authentically Japanese. But at least one film scholar has questioned the validity of this dichotomy between "Japanese" Mizoguchi and "Western" Kurosawa by pointing out that "Mizo" had been at least as much influenced by Western cinema and Western culture in general as Kurosawa had ever been, and that this awareness of foreign trends is reflected in his work.

In Japan, there have been critics and other filmmakers who have accused Kurosawa's work of elitism, because of his focus on exceptional, heroic individuals and groups of men. In her DVD commentary on "Seven Samurai", Joan Mellen maintains that certain shots of the samurai characters Kambei and Kyuzo, which as far as she is concerned reveal Kurosawa "privileging" these samurai, "support the argument voiced by several Japanese critics that Kurosawa was an elitist ... Kurosawa was hardly a progressive director, they argued, since his peasants could not discover among their own ranks leaders who might rescue the village ... Kurosawa defended himself against this charge in his interview with me. 'I wanted to say that after everything the peasants were the stronger, closely clinging to the earth ... It was the samurai who were weak because they were being blown by the winds of time.

Owing to Kurosawa's popularity with European and American audiences from the early 1950s onward, he did not escape the charge of deliberately catering to the tastes of Westerners to achieve or maintain that popularity. Joan Mellen, recording the violently negative reaction (in the 1970s) of the left-wing director Nagisa Oshima to Kurosawa and his work, states: "That Kurosawa had brought Japanese film to a Western audience meant [to Oshima] that he must be pandering to Western values and politics." Kurosawa always strongly denied pandering to Western tastes: "He has never catered to a foreign audience" writes Audie Bock, "and has condemned those who do".

Many celebrated directors have been influenced by Kurosawa and have expressed admiration for his work. The filmmakers cited below can be presented according to four categories: (a) those who, like Kurosawa himself, established international critical reputations in the 1950s and early 1960s; (b) the so-called "New Hollywood
The Swedish director Ingmar Bergman called his own film "The Virgin Spring" "touristic, a lousy imitation of Kurosawa", and added, "At that time my admiration for the Japanese cinema was at its height. I was almost a samurai myself!" In Italy, Federico Fellini in an interview declared the director "the greatest living example of all that an author of the cinema should be"—despite admitting to having seen only one of his films, "Seven Samurai". In France, Roman Polanski in 1965 cited Kurosawa as one of his three favorite filmmakers (with Fellini and Orson Welles), singling out "Seven Samurai", "Throne of Blood" and "The Hidden Fortress" for praise. The Italian director Bernardo Bertolucci considered the Japanese master's influence to be seminal: "Kurosawa's movies and "La Dolce Vita" of Fellini are the things that pushed me, sucked me into being a film director." German New Wave director Werner Herzog has cited Kurosawa as one of his greatest influences: "Of the filmmakers with whom I feel some kinship, Griffith ... Buñuel, Kurosawa and Eisenstein's "Ivan the Terrible", all come to mind." When asked to list his favorite directors, Russian director Andrei Tarkovsky cited Kurosawa as one of his favorites and named "Seven Samurai" as one of his ten favorite films.

According to his personal assistant Anthony Frewin, Stanley Kubrick "thought Kurosawa was one of the great film directors and followed him closely. In fact I cannot think of any other director he spoke so consistently and admiringly about. So, if Kubrick was cast away on a desert island and could only take a few films, what would they be? My money would be on "The Battle of Algiers", "Danton", "Rashomon", "Seven Samurai" and "Throne of Blood"."

Kurosawa's New Hollywood admirers have included Robert Altman, Francis Ford Coppola, Steven Spielberg, Martin Scorsese, George Lucas, and John Milius. In his early years while still a television director, Robert Altman stated that when he first saw "Rashomon" he was so impressed by its cinematographer's achievement of shooting several shots with the camera aimed directly at the sun—allegedly it was the first film in which this was done successfully—that he claims he was inspired the very next day to begin incorporating shots of the sun into his television work. It was Coppola who said of Kurosawa, "One thing that distinguishes [him] is that he didn't make one masterpiece or two masterpieces. He made, you know, "eight" masterpieces." Both Spielberg and Scorsese have praised the older man's role as teacher and role model, and Scorsese called him his "sensei", using the Japanese term. Spielberg has declared, "I have learned more from him than from almost any other filmmaker on the face of the earth", while Scorsese remarked, "Let me say it simply: Akira Kurosawa was my master, and ... the master of so many other filmmakers over the years." Several of these moviemakers were also instrumental in helping Kurosawa obtain financing for his late films: Lucas and Coppola served as co-producers on "Kagemusha", while the Spielberg name, lent to the 1990 production, "Dreams", helped bring that picture to fruition.

As the first Asian filmmaker to achieve international prominence, Kurosawa has naturally served as an inspiration for other Asian "auteurs". Of "Rashomon", the most famous director of India, Satyajit Ray, said: "The effect of the film on me [upon first seeing it in Calcutta in 1952] was electric. I saw it three times on consecutive days, and wondered each time if there was another film anywhere which gave such sustained and dazzling proof of a director's command over every aspect of film making." Other Asian admirers include the Japanese actor and director Takeshi Kitano, Hong Kong filmmaker John Woo, Japanese anime director Hayao Miyazaki and mainland Chinese director Zhang Yimou, who called Kurosawa "the quintessential Asian director".

Even today, Kurosawa continues to inspire and influence contemporary filmmakers. Alexander Payne spent the early part of his career watching Kurosawa's films, most notably "Seven Samurai" and "Ikiru". Guillermo del Toro referred to Kurosawa "one of the essential masters", citing "Throne of Blood", "High and Low" and "Ran" as among his favorite films. Kathryn Bigelow praised Kurosawa as one of "high-impact filmmakers" who can create emotionally invested characters. J.J. Abrams. At the age of 19, Alejandro González Iñárritu remembers being spellbound when he first saw "Ikiru" and praises Kurosawa as "one of the first storytelling geniuses who began to change the narrative structure of films". When Spike Lee posted a list of 87 films every aspiring director should see, he included three Kurosawa movies: "Rashomon", "Yojimbo" and "Ran".

Following Kurosawa's death, several posthumous works based on his unfilmed screenplays have been produced. "After the Rain", directed by Takashi Koizumi, was released in 1999, and "The Sea is Watching", directed by Kei Kumai, premiered in 2002. A script created by the Yonki no Kai ("Club of the Four Knights") (Kurosawa, Keisuke Kinoshita, Masaki Kobayashi, and Kon Ichikawa), around the time that "Dodeskaden" was made, finally was filmed and released (in 2000) as "Dora-Heita", by the only surviving founding member of the club, Kon Ichikawa. Huayi Brothers Media and CKF Pictures in China announced in 2017 plans to produce a film of Kurosawa's posthumous screenplay of "The Masque of the Black Death" by Edgar Allan Poe for 2020. Patrick Frater writing for "Variety" magazine in May 2017 stated that another two unfinished films by Kurosawa were planned, with "Silvering Spear" to start filming in 2018.

In September 2011, it was reported that remake rights to most of Kurosawa's movies and unproduced screenplays were assigned by the Akira Kurosawa 100 Project to the L.A.-based company Splendent. Splendent's chief Sakiko Yamada, stated that he aimed to "help contemporary film-makers introduce a new generation of moviegoers to these unforgettable stories".

Kurosawa Production Co., established in 1959, continues to oversee many of the aspects of Kurosawa's legacy. The director's son, Hisao Kurosawa, is the current head of the company. Its American subsidiary, Kurosawa Enterprises, is located in Los Angeles. Rights to Kurosawa's works were then held by Kurosawa Production and the film studios under which he worked, most notably Toho. These rights were then assigned to the Akira Kurosawa 100 Project before being reassigned in 2011 to the L.A. based company Splendent. Kurosawa Production works closely with the Akira Kurosawa Foundation, established in December 2003 and also run by Hisao Kurosawa. The foundation organizes an annual short film competition and spearheads Kurosawa-related projects, including a recently shelved one to build a memorial museum for the director.

In 1981, the Kurosawa Film Studio was opened in Yokohama; two additional locations have since been launched in Japan. A large collection of archive material, including scanned screenplays, photos and news articles, has been made available through the Akira Kurosawa Digital Archive, a Japanese proprietary website maintained by Ryukoku University Digital Archives Research Center in collaboration with Kurosawa Production. Anaheim University's Akira Kurosawa School of Film was launched in spring 2009 with the backing of Kurosawa Production. It offers online programs in digital film making, with headquarters in Anaheim and a learning center in Tokyo.

Two film awards have also been named in Kurosawa's honor. The Akira Kurosawa Award for Lifetime Achievement in Film Directing is awarded during the San Francisco International Film Festival, while the Akira Kurosawa Award is given during the Tokyo International Film Festival. In 1999 he was named "Asian of the Century" in the "Arts, Literature, and Culture" category by "AsianWeek" magazine and CNN, cited as "one of the [five] people who contributed most to the betterment of Asia in the past 100 years". In commemoration of the 100th anniversary of Kurosawa's birth in 2010, a project called AK100 was launched in 2008. The AK100 Project aims to "expose young people who are the representatives of the next generation, and all people everywhere, to the light and spirit of Akira Kurosawa and the wonderful world he created".

Anaheim University in cooperation with the Kurosawa Family established the Anaheim University Akira Kurosawa School of Film to offer online and blended learning programs on Akira Kurosawa and filmmaking. The animated Wes Anderson film, "Isle of Dogs," is partially inspired by Kurosawa's filming techniques. At the 64th Sydney Film Festival, there was a retrospective of Akira Kurosawa where films of his were screened to remember the great legacy he has created from his work.

A significant number of full-length and short documentaries concerning the life and films of Kurosawa were made during his lifetime and after his death. "A.K." was filmed in 1985 and is a French documentary film directed by Chris Marker. Though it was filmed while Kurosawa was working on "Ran", the film focuses more on Kurosawa's remote but polite personality than on the making of the film. The documentary is sometimes seen as being reflective of Marker's fascination with Japanese culture, which he also drew on for one of his best-known films, "Sans Soleil". The film was screened in the Un Certain Regard section at the 1985 Cannes Film Festival. Other documentaries concerning Kurosawa's life and works produced posthumously include:





Category:1910 births
Category:1998 deaths
Category:20th-century Japanese writers
Category:20th-century male writers
Category:Academy Honorary Award recipients
Category:Akira Kurosawa Award winners
Category:Best Director BAFTA Award winners
Category:César Award winners
Category:David di Donatello winners
Category:Directors Guild of America Award winners
Category:Directors of Best Foreign Language Film Academy Award winners
Category:Directors of Palme d'Or winners
Category:Fellows of the American Academy of Arts and Sciences
Category:Fukuoka Asian Culture Prize winners
Category:Japanese film directors
Category:Japanese film editors
Category:Japanese film producers
Category:Japanese male writers
Category:Japanese screenwriters
Category:Kyoto laureates in Arts and Philosophy
Category:Legion of Honour recipients
Category:Male screenwriters
Category:People from Shinagawa
Category:People of the Empire of Japan
Category:People's Honour Award winners
Category:Propaganda film directors
Category:Ramon Magsaysay Award winners
Category:Recipients of the Order of Culture
Category:Recipients of the Order of Friendship of Peoples
Category:Recipients of the Praemium Imperiale
Category:Samurai film directors
Category:Silver Bear for Best Director recipients
Category:Writers from Tokyo
Category:Yakuza film directors
Ancient Egypt was a civilization of ancient North Africa, concentrated along the lower reaches of the Nile River in the place that is now the country Egypt. Ancient Egyptian civilization followed prehistoric Egypt and coalesced around 3100 BC (according to conventional Egyptian chronology) with the political unification of Upper and Lower Egypt under Menes (often identified with Narmer). The history of ancient Egypt occurred as a series of stable kingdoms, separated by periods of relative instability known as Intermediate Periods: the Old Kingdom of the Early Bronze Age, the Middle Kingdom of the Middle Bronze Age and the New Kingdom of the Late Bronze Age.

Egypt reached the pinnacle of its power in the New Kingdom, ruling much of Nubia and a sizable portion of the Near East, after which it entered a period of slow decline. During the course of its history Egypt was invaded or conquered by a number of foreign powers, including the Hyksos, the Libyans, the Nubians, the Assyrians, the Achaemenid Persians, and the Macedonians under the command of Alexander the Great. The Greek Ptolemaic Kingdom, formed in the aftermath of Alexander's death, ruled Egypt until 30 BC, when, under Cleopatra, it fell to the Roman Empire and became a Roman province.

The success of ancient Egyptian civilization came partly from its ability to adapt to the conditions of the Nile River valley for agriculture. The predictable flooding and controlled irrigation of the fertile valley produced surplus crops, which supported a more dense population, and social development and culture. With resources to spare, the administration sponsored mineral exploitation of the valley and surrounding desert regions, the early development of an independent writing system, the organization of collective construction and agricultural projects, trade with surrounding regions, and a military intended to assert Egyptian dominance. Motivating and organizing these activities was a bureaucracy of elite scribes, religious leaders, and administrators under the control of a pharaoh, who ensured the cooperation and unity of the Egyptian people in the context of an elaborate system of religious beliefs.

The many achievements of the ancient Egyptians include the quarrying, surveying and construction techniques that supported the building of monumental pyramids, temples, and obelisks; a system of mathematics, a practical and effective system of medicine, irrigation systems and agricultural production techniques, the first known planked boats, Egyptian faience and glass technology, new forms of literature, and the earliest known peace treaty, made with the Hittites. Ancient Egypt has left a lasting legacy. Its art and architecture were widely copied, and its antiquities carried off to far corners of the world. Its monumental ruins have inspired the imaginations of travelers and writers for centuries. A new-found respect for antiquities and excavations in the early modern period by Europeans and Egyptians led to the scientific investigation

The Nile has been the lifeline of its region for much of human history. The fertile floodplain of the Nile gave humans the opportunity to develop a settled agricultural economy and a more sophisticated, centralized society that became a cornerstone in the history of human civilization. Nomadic modern human hunter-gatherers began living in the Nile valley through the end of the Middle Pleistocene some 120,000 years ago. By the late Paleolithic
In Predynastic and Early Dynastic times, the Egyptian climate was much less arid than it is today. Large regions of Egypt were covered in treed savanna and traversed by herds of grazing ungulates. Foliage and fauna were far more prolific in all environs and the Nile region supported large populations of waterfowl. Hunting would have been common for Egyptians, and this is also the period when many animals were first domesticated.

By about 5500 BC, small tribes living in the Nile valley had developed into a series of cultures demonstrating firm control of agriculture and animal husbandry, and identifiable by their pottery and personal items, such as combs, bracelets, and beads. The largest of these early cultures in upper (Southern) Egypt was the Badari, which probably originated in the Western Desert; it was known for its high quality ceramics, stone tools
The Badari was followed by the Amratian (Naqada I) and Gerzeh (Naqada II) cultures, which brought a number of technological improvements. As early as the Naqada I Period, predynastic Egyptians imported obsidian from Ethiopia, used to shape blades and other objects from flakes. In Naqada II times, early evidence exists of contact with the Near East, particularly Canaan and the Byblos coast. Over a period of about 1,000 years, the Naqada culture developed from a few small farming communities into a powerful civilization whose leaders were in complete control of the people and resources of the Nile valley. Establishing a power center at Nekhen (in Greek, Hierakonpolis), and later at Abydos, Naqada III leaders expanded their control of Egypt northwards along the Nile. They also traded with Nubia to the south, the oases of the western desert to the west, and the cultures of the eastern Mediterranean and Near East to the east.

The Naqada culture manufactured a diverse selection of material goods, reflective of the increasing power and wealth of the elite, as well as societal personal-use items, which included combs, small statuary, painted pottery, high quality decorative stone vases, cosmetic palettes, and jewelry made of gold, lapis, and ivory. They also developed a ceramic glaze known as faience, which was used well into the Roman Period to decorate cups, amulets, and figurines. During the last predynastic phase, the Naqada culture began using written symbols that eventually were developed into a full system of hieroglyphs for writing the ancient Egyptian language.

 The Early Dynastic Period was approximately contemporary to the early Sumerian-Akkadian civilisation of Mesopotamia and of ancient Elam. The third-century BC Egyptian priest Manetho grouped the long line of kings from Menes to his own time into 30 dynasties, a system still used today. He began his official history with the king named "Meni" (or "Menes" in Greek) who was believed to have united the two kingdoms of Upper and Lower Egypt.

The transition to a unified state happened more gradually than ancient Egyptian writers represented, and there is no contemporary record of Menes. Some scholars now believe, however, that the mythical Menes may have been the king Narmer, who is depicted wearing royal regalia on the ceremonial "Narmer Palette," in a symbolic act of unification. In the Early Dynastic Period, which began about 3000 BC, the first of the Dynastic kings solidified control over lower Egypt by establishing a capital at Memphis, from which he could control the labour force and agriculture of the fertile delta region, as well as the lucrative and critical trade routes to the Levant. The increasing power and wealth of the kings during the early dynastic period was reflected in their elaborate mastaba

Major advances in architecture, art, and technology were made during the Old Kingdom, fueled by the increased agricultural productivity and resulting population, made possible by a well-developed central administration. Some of ancient Egypt's crowning achievements, the Giza pyramids and Great Sphinx, were constructed during the Old Kingdom. Under the direction of the vizier, state officials collected taxes, coordinated irrigation projects to improve crop yield, drafted peasants to work on construction projects, and established a justice system

With the rising importance of central administration in Egypt a new class of educated scribes and officials arose who were granted estates by the king in payment for their services. Kings also made land grants to their mortuary cults and local temples, to ensure that these institutions had the resources to worship the king after his death. Scholars believe that five centuries of these practices slowly eroded the economic vitality of Egypt, and that the economy could no longer afford to support a large centralized administration. As the power of the kings diminished, regional governors called nomarchs began to challenge the supremacy of the office of king. This, coupled with severe droughts between 2200 and 2150 BC, is believed to have caused the country to enter the 140-year period of famine and strife known as the First Intermediate Period.

After Egypt's central government collapsed at the end of the Old Kingdom, the administration could no longer support or stabilize the country's economy. Regional governors could not rely on the king for help in times of crisis, and the ensuing food shortages and political disputes escalated into famines and small-scale civil wars. Yet despite difficult problems, local leaders, owing no tribute to the king, used their new-found independence to establish a thriving culture in the provinces. Once in control of their own resources, the provinces became economically richer—which was demonstrated by larger and better burials among all social classes. In bursts of creativity, provincial artisans adopted and adapted cultural motifs formerly restricted to the royalty of the Old Kingdom, and scribes developed literary styles that expressed the optimism and originality of the period.

Free from their loyalties to the king, local rulers began competing with each other for territorial control and political power. By 2160 BC, rulers in Herakleopolis controlled Lower Egypt in the north, while a rival clan based in Thebes, the Intef family, took control of Upper Egypt in the south. As the Intefs grew in power and expanded their control northward, a clash between the two rival dynasties became inevitable. Around 2055 BC the northern Theban forces under Nebhepetre Mentuhotep II finally defeated the Herakleopolitan rulers, reuniting the Two Lands. They inaugurated a period of economic and cultural renaissance known as the Middle Kingdom

The kings of the Middle Kingdom restored the country's stability and prosperity, thereby stimulating a resurgence of art, literature, and monumental building projects. Mentuhotep II and his Eleventh Dynasty successors ruled from Thebes, but the vizier Amenemhat I, upon assuming the kingship at the beginning of the Twelfth Dynasty around 1985 BC, shifted the nation's capital to the city of Itjtawy, located in Faiyum. From Itjtawy, the kings of the Twelfth Dynasty undertook a far-sighted land reclamation and irrigation scheme to increase agricultural output in the region. Moreover, the military reconquered territory in Nubia that was rich in quarries and gold mines, while laborers built a defensive structure in the Eastern Delta, called the "Walls-of-the-Ruler", to defend against foreign attack.

With the kings having secured the country militarily and politically and with vast agricultural and mineral wealth at their disposal, the nation's population, arts, and religion flourished. In contrast to elitist Old Kingdom attitudes towards the gods, the Middle Kingdom displayed an increase in expressions of personal piety. Middle Kingdom literature featured sophisticated themes and characters written in a confident, eloquent style. The relief and portrait sculpture of the period captured subtle, individual details that reached new heights of technical sophistication.

The last great ruler of the Middle Kingdom, Amenemhat III, allowed Semitic-speaking Canaanite settlers from the Near East into the Delta region to provide a sufficient labour force for his especially active mining and building campaigns. These ambitious building and mining activities, however, combined with severe Nile floods later in his reign, strained the economy and precipitated the slow decline into the Second Intermediate Period during the later Thirteenth and Fourteenth dynasties. During this decline, the Canaanite settlers began to assume greater control of the Delta region, eventually coming to power in Egypt as the Hyksos
Around 1785 BC, as the power of the Middle Kingdom kings weakened, a Western Asian people called the Hyksos, who had already settled in the Delta, seized control of Egypt and established their capital at Avaris, forcing the former central government to retreat to Thebes. The king was treated as a vassal and expected to pay tribute. The Hyksos ("foreign rulers") retained Egyptian models of government and identified as kings, thereby integrating Egyptian elements into their culture. They and other invaders introduced new tools of warfare into Egypt, most notably the composite bow and the horse-drawn chariot.

After retreating south, the native Theban kings found themselves trapped between the Canaanite Hyksos ruling the north and the Hyksos' Nubian allies, the Kushites, to the south. After years of vassalage, Thebes gathered enough strength to challenge the Hyksos in a conflict that lasted more than 30 years, until 1555 BC. The kings Seqenenre Tao II and Kamose were ultimately able to defeat the Nubians to the south of Egypt, but failed to defeat the Hyksos. That task fell to Kamose's successor, Ahmose I, who successfully waged a series of campaigns that permanently eradicated the Hyksos' presence in Egypt. He established a new dynasty and, in the New Kingdom that followed, the military became a central priority for the kings, who sought to expand Egypt's borders and attempted to gain mastery of the Near East.

The New Kingdom pharaohs established a period of unprecedented prosperity by securing their borders and strengthening diplomatic ties with their neighbours, including the Mitanni Empire, Assyria, and Canaan. Military campaigns waged under Tuthmosis I and his grandson Tuthmosis III extended the influence of the pharaohs to the largest empire Egypt had ever seen. Beginning with Merneptah the rulers of Egypt adopted the title of pharaoh
Between their reigns, Hatshepsut, a queen who established herself as pharaoh, launched many building projects, including restoration of temples damaged by the Hyksos, and sent trading expenditions to Punt and the Sinai. When Tuthmosis III died in 1425 BC, Egypt had an empire extending from Niya in north west Syria to the Fourth Cataract of the Nile in Nubia, cementing loyalties and opening access to critical imports such as bronze and wood.

The New Kingdom pharaohs began a large-scale building campaign to promote the god Amun, whose growing cult was based in Karnak. They also constructed monuments to glorify their own achievements, both real and imagined. The Karnak temple is the largest Egyptian temple ever built.

Around 1350 BC, the stability of the New Kingdom was threatened when Amenhotep IV ascended the throne and instituted a series of radical and chaotic reforms. Changing his name to Akhenaten, he touted the previously obscure sun deity Aten as the supreme deity, suppressed the worship of most other deities, and moved the capital to the new city of Akhetaten (modern-day Amarna). He was devoted to his new religion and artistic style. After his death, the cult of the Aten was quickly abandoned and the traditional religious order restored. The subsequent pharaohs, Tutankhamun, Ay, and Horemheb, worked to erase all mention of Akhenaten's heresy, now known as the Amarna Period
Around 1279 BC, Ramesses II, also known as Ramesses the Great, ascended the throne, and went on to build more temples, erect more statues and obelisks, and sire more children than any other pharaoh in history. A bold military leader, Ramesses II led his army against the Hittites in the Battle of Kadesh (in modern Syria) and, after fighting to a stalemate, finally agreed to the first recorded peace treaty, around 1258 BC.

Egypt's wealth, however, made it a tempting target for invasion, particularly by the Libyan Berbers to the west, and the Sea Peoples, a conjectured confederation of seafarers from the Aegean Sea. Initially, the military was able to repel these invasions, but Egypt eventually lost control of its remaining territories in southern Canaan, much of it falling to the Assyrians. The effects of external threats were exacerbated by internal problems such as corruption, tomb robbery, and civil unrest. After regaining their power, the high priests at the temple of Amun in Thebes accumulated vast tracts of land and wealth, and their expanded power splintered the country during the Third Intermediate Period.

Following the death of Ramesses XI in 1078 BC, Smendes assumed authority over the northern part of Egypt, ruling from the city of Tanis. The south was effectively controlled by the High Priests of Amun at Thebes, who recognized Smendes in name only. During this time, Libyans had been settling in the western delta, and chieftains of these settlers began increasing their autonomy. Libyan princes took control of the delta under Shoshenq I in 945 BC, founding the so-called Libyan or Bubastite dynasty that would rule for some 200 years. Shoshenq also gained control of southern Egypt by placing his family members in important priestly positions. Libyan control began to erode as a rival dynasty in the delta arose in Leontopolis, and Kushites threatened from the south. Around 727 BC the Kushite king Piye invaded northward, seizing control of Thebes and eventually the Delta.

Egypt's far-reaching prestige declined considerably toward the end of the Third Intermediate Period. Its foreign allies had fallen under the Assyrian sphere of influence, and by 700 BC war between the two states became inevitable. Between 671 and 667 BC the Assyrians began their attack on Egypt. The reigns of both Taharqa and his successor, Tanutamun, were filled with constant conflict with the Assyrians, against whom Egypt enjoyed several victories. Ultimately, the Assyrians pushed the Kushites back into Nubia, occupied Memphis, and sacked the temples of Thebes.

The Assyrians left control of Egypt to a series of vassals who became known as the Saite kings of the Twenty-Sixth Dynasty. By 653 BC, the Saite king Psamtik I was able to oust the Assyrians with the help of Greek mercenaries, who were recruited to form Egypt's first navy. Greek influence expanded greatly as the city-state of Naukratis became the home of Greeks in the Nile Delta. The Saite kings based in the new capital of Sais witnessed a brief but spirited resurgence in the economy and culture, but in 525 BC, the powerful Persians, led by Cambyses II, began their conquest of Egypt, eventually capturing the pharaoh Psamtik III at the battle of Pelusium. Cambyses II then assumed the formal title of pharaoh, but ruled Egypt from Iran, leaving Egypt under the control of a satrapy. A few successful revolts against the Persians marked the 5th century BC, but Egypt was never able to permanently overthrow the Persians.

Following its annexation by Persia, Egypt was joined with Cyprus and Phoenicia in the sixth satrapy of the Achaemenid Persian Empire. This first period of Persian rule over Egypt, also known as the Twenty-Seventh dynasty, ended in 402 BC, when Egypt regained independence under a series of native dynasties. The last of these dynasties, the Thirtieth, proved to be the last native royal house of ancient Egypt, ending with the kingship of Nectanebo II. A brief restoration of Persian rule, sometimes known as the Thirty-First Dynasty, began in 343 BC, but shortly after, in 332 BC, the Persian ruler Mazaces handed Egypt over to Alexander the Great
In 332 BC, Alexander the Great conquered Egypt with little resistance from the Persians and was welcomed by the Egyptians as a deliverer. The administration established by Alexander's successors, the Macedonian Ptolemaic Kingdom, was based on an Egyptian model and based in the new capital city of Alexandria. The city showcased the power and prestige of Hellenistic rule, and became a seat of learning and culture, centered at the famous Library of Alexandria. The Lighthouse of Alexandria lit the way for the many ships that kept trade flowing through the city—as the Ptolemies made commerce and revenue-generating enterprises, such as papyrus manufacturing, their top priority.

Hellenistic culture did not supplant native Egyptian culture, as the Ptolemies supported time-honored traditions in an effort to secure the loyalty of the populace. They built new temples in Egyptian style, supported traditional cults, and portrayed themselves as pharaohs. Some traditions merged, as Greek and Egyptian gods were syncretized into composite deities, such as Serapis, and classical Greek forms of sculpture influenced traditional Egyptian motifs. Despite their efforts to appease the Egyptians, the Ptolemies were challenged by native rebellion, bitter family rivalries, and the powerful mob of Alexandria that formed after the death of Ptolemy IV. In addition, as Rome relied more heavily on imports of grain from Egypt, the Romans took great interest in the political situation in the country. Continued Egyptian revolts, ambitious politicians, and powerful opponents from the Near East

Egypt became a province of the Roman Empire in 30 BC, following the defeat of Marc Antony and Ptolemaic Queen Cleopatra VII by Octavian (later Emperor Augustus) in the Battle of Actium. The Romans relied heavily on grain shipments from Egypt, and the Roman army, under the control of a prefect appointed by the Emperor, quelled rebellions, strictly enforced the collection of heavy taxes, and prevented attacks by bandits, which had become a notorious problem during the period. Alexandria became an increasingly important center on the trade route with the orient, as exotic luxuries were in high demand in Rome.

Although the Romans had a more hostile attitude than the Greeks towards the Egyptians, some traditions such as mummification and worship of the traditional gods continued. The art of mummy portraiture flourished, and some Roman emperors had themselves depicted as pharaohs, though not to the extent that the Ptolemies had. The former lived outside Egypt and did not perform the ceremonial functions of Egyptian kingship. Local administration became Roman in style and closed to native Egyptians.

From the mid-first century AD, Christianity took root in Egypt and it was originally seen as another cult that could be accepted. However, it was an uncompromising religion that sought to win converts from Egyptian Religion and Greco-Roman religion and threatened popular religious traditions. This led to the persecution of converts to Christianity, culminating in the great purges of Diocletian starting in 303, but eventually Christianity won out. In 391 the Christian Emperor Theodosius introduced legislation that banned pagan rites and closed temples. Alexandria became the scene of great anti-pagan riots with public and private religious imagery destroyed. As a consequence, Egypt's native religious culture was continually in decline. While the native population certainly continued to speak their language, the ability to read hieroglyphic writing slowly disappeared as the role of the Egyptian temple priests and priestesses diminished. The temples themselves were sometimes converted to churches or abandoned to the desert.

In the fourth century, as the Roman Empire divided, Egypt found itself in the Eastern Empire with its capital at Constantinople. In the waning years of the Empire, Egypt fell to the Sassanid Persian army (618–628 AD), was recaptured by the Roman Emperor Heraclius (629–639 AD), and then was finally captured by Muslim Rashidun army

The pharaoh was the absolute monarch of the country and, at least in theory, wielded complete control of the land and its resources. The king was the supreme military commander and head of the government, who relied on a bureaucracy of officials to manage his affairs. In charge of the administration was his second in command, the vizier, who acted as the king's representative and coordinated land surveys, the treasury, building projects, the legal system, and the archives. At a regional level, the country was divided into as many as 42 administrative regions called nomes each governed by a nomarch, who was accountable to the vizier for his jurisdiction. The temples formed the backbone of the economy. Not only were they houses of worship, but were also responsible for collecting and storing the nation's wealth in a system of granaries and treasuries administered by overseers, who redistributed grain and goods.

Much of the economy was centrally organized and strictly controlled. Although the ancient Egyptians did not use coinage until the Late period, they did use a type of money-barter system, with standard sacks of grain and the "deben", a weight of roughly of copper or silver, forming a common denominator. Workers were paid in grain; a simple laborer might earn 5 sacks (200 kg or 400 lb) of grain per month, while a foreman might earn 7 sacks (250 kg or 550 lb). Prices were fixed across the country and recorded in lists to facilitate trading; for example a shirt cost five copper deben, while a cow cost 140 deben. Grain could be traded for other goods, according to the fixed price list. During the fifth century BC coined money was introduced into Egypt from abroad. At first the coins were used as standardized pieces of precious metal rather than true money, but in the following centuries international traders came to rely on coinage.

Egyptian society was highly stratified, and social status was expressly displayed. Farmers made up the bulk of the population, but agricultural produce was owned directly by the state, temple, or noble family that owned the land. Farmers were also subject to a labor tax and were required to work on irrigation or construction projects in a corvée system. Artists and craftsmen were of higher status than farmers, but they were also under state control, working in the shops attached to the temples and paid directly from the state treasury. Scribes and officials formed the upper class in ancient Egypt, known as the "white kilt class" in reference to the bleached linen garments that served as a mark of their rank. The upper class prominently displayed their social status in art and literature. Below the nobility were the priests, physicians, and engineers with specialized training in their field. Slavery
The ancient Egyptians viewed men and women, including people from all social classes except slaves, as essentially equal under the law, and even the lowliest peasant was entitled to petition the vizier and his court for redress. Although slaves were mostly used as indentured servants, they were able to buy and sell their servitude, work their way to freedom or nobility, and were usually treated by doctors in the workplace. Both men and women had the right to own and sell property, make contracts, marry and divorce, receive inheritance, and pursue legal disputes in court. Married couples could own property jointly and protect themselves from divorce by agreeing to marriage contracts, which stipulated the financial obligations of the husband to his wife and children should the marriage end. Compared with their counterparts in ancient Greece, Rome, and even more modern places around the world, ancient Egyptian women had a greater range of personal choices and opportunities for achievement. Women such as Hatshepsut and Cleopatra VII even became pharaohs, while others wielded power as Divine Wives of Amun
The head of the legal system was officially the pharaoh, who was responsible for enacting laws, delivering justice, and maintaining law and order, a concept the ancient Egyptians referred to as Ma'at. Although no legal codes from ancient Egypt survive, court documents show that Egyptian law was based on a common-sense view of right and wrong that emphasized reaching agreements and resolving conflicts rather than strictly adhering to a complicated set of statutes. Local councils of elders, known as "Kenbet" in the New Kingdom, were responsible for ruling in court cases involving small claims and minor disputes. More serious cases involving murder, major land transactions, and tomb robbery were referred to the "Great Kenbet", over which the vizier or pharaoh presided. Plaintiffs and defendants were expected to represent themselves and were required to swear an oath that they had told the truth. In some cases, the state took on both the role of prosecutor and judge, and it could torture the accused with beatings to obtain a confession and the names of any co-conspirators. Whether the charges were trivial or serious, court scribes documented the complaint, testimony, and verdict of the case for future reference.

Punishment for minor crimes involved either imposition of fines, beatings, facial mutilation, or exile, depending on the severity of the offense. Serious crimes such as murder and tomb robbery were punished by execution, carried out by decapitation, drowning, or impaling the criminal on a stake. Punishment could also be extended to the criminal's family. Beginning in the New Kingdom, oracles played a major role in the legal system, dispensing justice in both civil and criminal cases. The procedure was to ask the god a "yes" or "no" question concerning the right or wrong of an issue. The god, carried by a number of priests, rendered judgment by choosing one or the other, moving forward or backward, or pointing to one of the answers written on a piece of papyrus or an ostracon

A combination of favorable geographical features contributed to the success of ancient Egyptian culture, the most important of which was the rich fertile soil resulting from annual inundations of the Nile River. The ancient Egyptians were thus able to produce an abundance of food, allowing the population to devote more time and resources to cultural, technological, and artistic pursuits. Land management was crucial in ancient Egypt because taxes were assessed based on the amount of land a person owned.

Farming in Egypt was dependent on the cycle of the Nile River. The Egyptians recognized three seasons: "Akhet" (flooding), "Peret" (planting), and "Shemu" (harvesting). The flooding season lasted from June to September, depositing on the river's banks a layer of mineral-rich silt ideal for growing crops. After the floodwaters had receded, the growing season lasted from October to February. Farmers plowed and planted seeds in the fields, which were irrigated with ditches and canals. Egypt received little rainfall, so farmers relied on the Nile to water their crops. From March to May, farmers used sickles to harvest their crops, which were then threshed with a flail to separate the straw from the grain. Winnowing removed the chaff from the grain, and the grain was then ground into flour, brewed to make beer, or stored for later use.

The ancient Egyptians cultivated emmer and barley, and several other cereal grains, all of which were used to make the two main food staples of bread and beer. Flax plants, uprooted before they started flowering, were grown for the fibers of their stems. These fibers were split along their length and spun into thread, which was used to weave sheets of linen and to make clothing. Papyrus
The Egyptians believed that a balanced relationship between people and animals was an essential element of the cosmic order; thus humans, animals and plants were believed to be members of a single whole. Animals, both domesticated and wild, were therefore a critical source of spirituality, companionship, and sustenance to the ancient Egyptians. Cattle were the most important livestock; the administration collected taxes on livestock in regular censuses, and the size of a herd reflected the prestige and importance of the estate or temple that owned them. In addition to cattle, the ancient Egyptians kept sheep, goats, and pigs. Poultry, such as ducks, geese, and pigeons, were captured in nets and bred on farms, where they were force-fed with dough to fatten them. The Nile provided a plentiful source of fish. Bees were also domesticated from at least the Old Kingdom, and provided both honey and wax.

The ancient Egyptians used donkeys and oxen as beasts of burden, and they were responsible for plowing the fields and trampling seed into the soil. The slaughter of a fattened ox was also a central part of an offering ritual. Horses were introduced by the Hyksos in the Second Intermediate Period. Camels, although known from the New Kingdom, were not used as beasts of burden until the Late Period. There is also evidence to suggest that elephants were briefly utilized in the Late Period but largely abandoned due to lack of grazing land. Dogs, cats, and monkeys were common family pets, while more exotic pets imported from the heart of Africa, such as Sub-Saharan African lions, were reserved for royalty. Herodotus observed that the Egyptians were the only people to keep their animals with them in their houses. During the Late Period, the worship of the gods in their animal form was extremely popular, such as the cat goddess Bastet and the ibis god Thoth, and these animals were bred in large numbers on farms for the purpose of ritual sacrifice.

Egypt is rich in building and decorative stone, copper and lead ores, gold, and semiprecious stones. These natural resources allowed the ancient Egyptians to build monuments, sculpt statues, make tools, and fashion jewelry. Embalmers used salts from the Wadi Natrun for mummification, which also provided the gypsum needed to make plaster. Ore-bearing rock formations were found in distant, inhospitable wadis in the eastern desert and the Sinai, requiring large, state-controlled expeditions to obtain natural resources found there. There were extensive gold mines in Nubia, and one of the first maps known is of a gold mine in this region. The Wadi Hammamat was a notable source of granite, greywacke, and gold. Flint was the first mineral collected and used to make tools, and flint handaxes are the earliest pieces of evidence of habitation in the Nile valley. Nodules of the mineral were carefully flaked to make blades and arrowheads of moderate hardness and durability even after copper was adopted for this purpose. Ancient Egyptians were among the first to use minerals such as sulfur as cosmetic substances.

The Egyptians worked deposits of the lead ore galena at Gebel Rosas to make net sinkers, plumb bobs, and small figurines. Copper was the most important metal for toolmaking in ancient Egypt and was smelted in furnaces from malachite ore mined in the Sinai. Workers collected gold by washing the nuggets out of sediment in alluvial deposits, or by the more labor-intensive process of grinding and washing gold-bearing quartzite. Iron deposits found in upper Egypt were utilized in the Late Period. High-quality building stones were abundant in Egypt; the ancient Egyptians quarried limestone all along the Nile valley, granite from Aswan, and basalt and sandstone from the wadis of the eastern desert. Deposits of decorative stones such as porphyry, greywacke, alabaster, and carnelian dotted the eastern desert and were collected even before the First Dynasty. In the Ptolemaic and Roman Periods, miners worked deposits of emeralds in Wadi Sikait and amethyst in Wadi el-Hudi
The ancient Egyptians engaged in trade with their foreign neighbors to obtain rare, exotic goods not found in Egypt. In the Predynastic Period, they established trade with Nubia to obtain gold and incense. They also established trade with Palestine, as evidenced by Palestinian-style oil jugs found in the burials of the First Dynasty pharaohs. An Egyptian colony stationed in southern Canaan dates to slightly before the First Dynasty. Narmer had Egyptian pottery produced in Canaan and exported back to Egypt.

By the Second Dynasty at latest, ancient Egyptian trade with Byblos yielded a critical source of quality timber not found in Egypt. By the Fifth Dynasty, trade with Punt provided gold, aromatic resins, ebony, ivory, and wild animals such as monkeys and baboons. Egypt relied on trade with Anatolia for essential quantities of tin as well as supplementary supplies of copper, both metals being necessary for the manufacture of bronze. The ancient Egyptians prized the blue stone lapis lazuli, which had to be imported from far-away Afghanistan. Egypt's Mediterranean trade partners also included Greece and Crete, which provided, among other goods, supplies of olive oil. In exchange for its luxury imports and raw materials, Egypt mainly exported grain, gold, linen, and papyrus, in addition to other finished goods including glass and stone objects.

The Egyptian language is a northern Afro-Asiatic language closely related to the Berber and Semitic languages. It has the second longest known history of any language (after Sumerian), having been written from c. 3200 BC to the Middle Ages and remaining as a spoken language for longer. The phases of ancient Egyptian are Old Egyptian, Middle Egyptian (Classical Egyptian), Late Egyptian, Demotic and Coptic. Egyptian writings do not show dialect differences before Coptic, but it was probably spoken in regional dialects around Memphis and later Thebes.

Ancient Egyptian was a synthetic language, but it became more analytic later on. Late Egyptian developed prefixal definite and indefinite articles, which replaced the older inflectional suffixes. There was a change from the older verb–subject–object word order to subject–verb–object. The Egyptian hieroglyphic, hieratic, and demotic scripts were eventually replaced by the more phonetic Coptic alphabet. Coptic is still used in the liturgy of the Egyptian Orthodox Church, and traces of it are found in modern Egyptian Arabic.

Ancient Egyptian has 25 consonants similar to those of other Afro-Asiatic languages. These include pharyngeal and emphatic consonants, voiced and voiceless stops, voiceless fricatives and voiced and voiceless affricates. It has three long and three short vowels, which expanded in Late Egyptian to about nine. The basic word in Egyptian, similar to Semitic and Berber, is a triliteral or biliteral root of consonants and semiconsonants. Suffixes are added to form words. The verb conjugation corresponds to the person. For example, the triconsonantal skeleton is the semantic core of the word 'hear'; its basic conjugation is ', 'he hears'. If the subject is a noun, suffixes are not added to the verb: ', 'the woman hears'.

Adjectives are derived from nouns through a process that Egyptologists call "nisbation" because of its similarity with Arabic. The word order is in verbal and adjectival sentences, and in nominal and adverbial sentences. The subject can be moved to the beginning of sentences if it is long and is followed by a resumptive pronoun. Verbs and nouns are negated by the particle "n", but "nn" is used for adverbial and adjectival sentences. Stress

Hieroglyphic writing dates from c. 3000 BC, and is composed of hundreds of symbols. A hieroglyph can represent a word, a sound, or a silent determinative; and the same symbol can serve different purposes in different contexts. Hieroglyphs were a formal script, used on stone monuments and in tombs, that could be as detailed as individual works of art. In day-to-day writing, scribes used a cursive form of writing, called hieratic, which was quicker and easier. While formal hieroglyphs may be read in rows or columns in either direction (though typically written from right to left), hieratic was always written from right to left, usually in horizontal rows. A new form of writing, Demotic, became the prevalent writing style, and it is this form of writing—along with formal hieroglyphs—that accompany the Greek text on the Rosetta Stone.

Around the first century AD, the Coptic alphabet started to be used alongside the Demotic script. Coptic is a modified Greek alphabet with the addition of some Demotic signs. Although formal hieroglyphs were used in a ceremonial role until the fourth century, towards the end only a small handful of priests could still read them. As the traditional religious establishments were disbanded, knowledge of hieroglyphic writing was mostly lost. Attempts to decipher them date to the Byzantine and Islamic periods in Egypt, but only in the 1820s, after the discovery of the Rosetta Stone and years of research by Thomas Young and Jean-François Champollion

Writing first appeared in association with kingship on labels and tags for items found in royal tombs. It was primarily an occupation of the scribes, who worked out of the "Per Ankh" institution or the House of Life. The latter comprised offices, libraries (called House of Books), laboratories and observatories. Some of the best-known pieces of ancient Egyptian literature, such as the Pyramid and Coffin Texts, were written in Classical Egyptian, which continued to be the language of writing until about 1300 BC. Late Egyptian was spoken from the New Kingdom onward and is represented in Ramesside administrative documents, love poetry and tales, as well as in Demotic and Coptic texts. During this period, the tradition of writing had evolved into the tomb autobiography, such as those of Harkhuf and Weni. The genre known as "Sebayt" ("instructions") was developed to communicate teachings and guidance from famous nobles; the Ipuwer papyrus, a poem of lamentations describing natural disasters and social upheaval, is a famous example.

The Story of Sinuhe, written in Middle Egyptian, might be the classic of Egyptian literature. Also written at this time was the Westcar Papyrus, a set of stories told to Khufu by his sons relating the marvels performed by priests. The Instruction of Amenemope is considered a masterpiece of Near Eastern literature. Towards the end of the New Kingdom, the vernacular language was more often employed to write popular pieces like the Story of Wenamun and the Instruction of Any. The former tells the story of a noble who is robbed on his way to buy cedar from Lebanon and of his struggle to return to Egypt. From about 700 BC, narrative stories and instructions, such as the popular Instructions of Onchsheshonqy, as well as personal and business documents were written in the demotic script and phase of Egyptian. Many stories written in demotic during the Greco-Roman period were set in previous historical eras, when Egypt was an independent nation ruled by great pharaohs such as Ramesses II

Most ancient Egyptians were farmers tied to the land. Their dwellings were restricted to immediate family members, and were constructed of mud-brick designed to remain cool in the heat of the day. Each home had a kitchen with an open roof, which contained a grindstone for milling grain and a small oven for baking the bread. Walls were painted white and could be covered with dyed linen wall hangings. Floors were covered with reed mats, while wooden stools, beds raised from the floor and individual tables comprised the furniture.

The ancient Egyptians placed a great value on hygiene and appearance. Most bathed in the Nile and used a pasty soap made from animal fat and chalk. Men shaved their entire bodies for cleanliness; perfumes and aromatic ointments covered bad odors and soothed skin. Clothing was made from simple linen sheets that were bleached white, and both men and women of the upper classes wore wigs, jewelry, and cosmetics. Children went without clothing until maturity, at about age 12, and at this age males were circumcised and had their heads shaved. Mothers were responsible for taking care of the children, while the father provided the family's income
Music and dance were popular entertainments for those who could afford them. Early instruments included flutes and harps, while instruments similar to trumpets, oboes, and pipes developed later and became popular. In the New Kingdom, the Egyptians played on bells, cymbals, tambourines, drums, and imported lutes and lyres from Asia. The sistrum was a rattle-like musical instrument that was especially important in religious ceremonies.

The ancient Egyptians enjoyed a variety of leisure activities, including games and music. Senet, a board game where pieces moved according to random chance, was particularly popular from the earliest times; another similar game was mehen, which had a circular gaming board. “Hounds and Jackals” also known as 58 holes is another example of board games played in ancient Egypt. The first complete set of this game was discovered from a Theban tomb of the Egyptian pharaoh Amenemhat IV that dates to the 13th Dynasty. Juggling and ball games were popular with children, and wrestling is also documented in a tomb at Beni Hasan. The wealthy members of ancient Egyptian society enjoyed hunting and boating as well.

The excavation of the workers village of Deir el-Medina
Egyptian cuisine remained remarkably stable over time; indeed, the cuisine of modern Egypt retains some striking similarities to the cuisine of the ancients. The staple diet consisted of bread and beer, supplemented with vegetables such as onions and garlic, and fruit such as dates and figs. Wine and meat were enjoyed by all on feast days while the upper classes indulged on a more regular basis. Fish, meat, and fowl could be salted or dried, and could be cooked in stews or roasted on a grill.

The architecture of ancient Egypt includes some of the most famous structures in the world: the Great Pyramids of Giza and the temples at Thebes. Building projects were organized and funded by the state for religious and commemorative purposes, but also to reinforce the wide-ranging power of the pharaoh. The ancient Egyptians were skilled builders; using only simple but effective tools and sighting instruments, architects could build large stone structures with great accuracy and precision that is still envied today.

The domestic dwellings of elite and ordinary Egyptians alike were constructed from perishable materials such as mud bricks and wood, and have not survived. Peasants lived in simple homes, while the palaces of the elite and the pharaoh were more elaborate structures. A few surviving New Kingdom palaces, such as those in Malkata and Amarna, show richly decorated walls and floors with scenes of people, birds, water pools, deities and geometric designs. Important structures such as temples and tombs that were intended to last forever were constructed of stone instead of mud bricks. The architectural elements used in the world's first large-scale stone building, Djoser's mortuary complex, include post and lintel supports in the papyrus and lotus motif.

The earliest preserved ancient Egyptian temples, such as those at Giza, consist of single, enclosed halls with roof slabs supported by columns. In the New Kingdom, architects added the pylon, the open courtyard, and the enclosed hypostyle hall to the front of the temple's sanctuary, a style that was standard until the Greco-Roman period. The earliest and most popular tomb architecture in the Old Kingdom was the mastaba, a flat-roofed rectangular structure of mudbrick or stone built over an underground burial chamber. The step pyramid of Djoser is a series of stone mastabas stacked on top of each other. Pyramids were built during the Old and Middle Kingdoms, but most later rulers abandoned them in favor of less conspicuous rock-cut tombs. The use of the pyramid form continued in private tomb chapels of the New Kingdom and in the royal pyramids of Nubia
The ancient Egyptians produced art to serve functional purposes. For over 3500 years, artists adhered to artistic forms and iconography that were developed during the Old Kingdom, following a strict set of principles that resisted foreign influence and internal change. These artistic standards—simple lines, shapes, and flat areas of color combined with the characteristic flat projection of figures with no indication of spatial depth—created a sense of order and balance within a composition. Images and text were intimately interwoven on tomb and temple walls, coffins, stelae, and even statues. The Narmer Palette, for example, displays figures that can also be read as hieroglyphs. Because of the rigid rules that governed its highly stylized and symbolic appearance, ancient Egyptian art served its political and religious purposes with precision and clarity.

Ancient Egyptian artisans used stone as a medium for carving statues and fine reliefs, but used wood as a cheap and easily carved substitute. Paints were obtained from minerals such as iron ores (red and yellow ochres), copper ores (blue and green), soot or charcoal (black), and limestone (white). Paints could be mixed with gum arabic as a binder and pressed into cakes, which could be moistened with water when needed.

Pharaohs used reliefs to record victories in battle, royal decrees, and religious scenes. Common citizens had access to pieces of funerary art, such as shabti statues and books of the dead, which they believed would protect them in the afterlife. During the Middle Kingdom, wooden or clay models depicting scenes from everyday life became popular additions to the tomb. In an attempt to duplicate the activities of the living in the afterlife, these models show laborers, houses, boats, and even military formations that are scale representations of the ideal ancient Egyptian afterlife.

Despite the homogeneity of ancient Egyptian art, the styles of particular times and places sometimes reflected changing cultural or political attitudes. After the invasion of the Hyksos in the Second Intermediate Period, Minoan-style frescoes were found in Avaris. The most striking example of a politically driven change in artistic forms comes from the Amarna period, where figures were radically altered to conform to Akhenaten's revolutionary religious ideas. This style, known as Amarna art

Beliefs in the divine and in the afterlife were ingrained in ancient Egyptian civilization from its inception; pharaonic rule was based on the divine right of kings. The Egyptian pantheon was populated by gods who had supernatural powers and were called on for help or protection. However, the gods were not always viewed as benevolent, and Egyptians believed they had to be appeased with offerings and prayers. The structure of this pantheon changed continually as new deities were promoted in the hierarchy, but priests made no effort to organize the diverse and sometimes conflicting myths
Gods were worshiped in cult temples administered by priests acting on the king's behalf. At the center of the temple was the cult statue in a shrine. Temples were not places of public worship or congregation, and only on select feast days and celebrations was a shrine carrying the statue of the god brought out for public worship. Normally, the god's domain was sealed off from the outside world and was only accessible to temple officials. Common citizens could worship private statues in their homes, and amulets offered protection against the forces of chaos. After the New Kingdom, the pharaoh's role as a spiritual intermediary was de-emphasized as religious customs shifted to direct worship of the gods. As a result, priests developed a system of oracles to communicate the will of the gods directly to the people.

The Egyptians believed that every human being was composed of physical and spiritual parts or "aspects". In addition to the body, each person had a "šwt" (shadow), a "ba" (personality or soul), a "ka" (life-force), and a "name". The heart, rather than the brain, was considered the seat of thoughts and emotions. After death, the spiritual aspects were released from the body and could move at will, but they required the physical remains (or a substitute, such as a statue) as a permanent home. The ultimate goal of the deceased was to rejoin his "ka" and "ba" and become one of the "blessed dead", living on as an "akh", or "effective one". For this to happen, the deceased had to be judged worthy in a trial, in which the heart was weighed against a "feather of truth

The ancient Egyptians maintained an elaborate set of burial customs that they believed were necessary to ensure immortality after death. These customs involved preserving the body by mummification, performing burial ceremonies, and interring with the body goods the deceased would use in the afterlife. Before the Old Kingdom, bodies buried in desert pits were naturally preserved by desiccation. The arid, desert conditions were a boon throughout the history of ancient Egypt for burials of the poor, who could not afford the elaborate burial preparations available to the elite. Wealthier Egyptians began to bury their dead in stone tombs and use artificial mummification, which involved removing the internal organs, wrapping the body in linen, and burying it in a rectangular stone sarcophagus or wooden coffin. Beginning in the Fourth Dynasty, some parts were preserved separately in canopic jars.

By the New Kingdom, the ancient Egyptians had perfected the art of mummification; the best technique took 70 days and involved removing the internal organs, removing the brain through the nose, and desiccating the body in a mixture of salts called natron. The body was then wrapped in linen with protective amulets inserted between layers and placed in a decorated anthropoid coffin. Mummies of the Late Period were also placed in painted cartonnage mummy cases. Actual preservation practices declined during the Ptolemaic and Roman eras, while greater emphasis was placed on the outer appearance of the mummy, which was decorated.

Wealthy Egyptians were buried with larger quantities of luxury items, but all burials, regardless of social status, included goods for the deceased. Funerary texts were often included in the grave, and, beginning in the New Kingdom, so were shabti
The ancient Egyptian military was responsible for defending Egypt against foreign invasion, and for maintaining Egypt's domination in the ancient Near East. The military protected mining expeditions to the Sinai during the Old Kingdom and fought civil wars during the First and Second Intermediate Periods. The military was responsible for maintaining fortifications along important trade routes, such as those found at the city of Buhen on the way to Nubia. Forts also were constructed to serve as military bases, such as the fortress at Sile, which was a base of operations for expeditions to the Levant. In the New Kingdom, a series of pharaohs used the standing Egyptian army to attack and conquer Kush and parts of the Levant.

Typical military equipment included bows and arrows, spears, and round-topped shields made by stretching animal skin over a wooden frame. In the New Kingdom, the military began using chariots that had earlier been introduced by the Hyksos invaders. Weapons and armor continued to improve after the adoption of bronze: shields were now made from solid wood with a bronze buckle, spears were tipped with a bronze point, and the Khopesh was adopted from Asiatic soldiers. The pharaoh was usually depicted in art and literature riding at the head of the army; it has been suggested that at least a few pharaohs, such as Seqenenre Tao II

In technology, medicine, and mathematics, ancient Egypt achieved a relatively high standard of productivity and sophistication. Traditional empiricism, as evidenced by the Edwin Smith and Ebers papyri (c. 1600 BC), is first credited to Egypt. The Egyptians created their own alphabet and decimal system

Even before the Old Kingdom, the ancient Egyptians had developed a glassy material known as faience, which they treated as a type of artificial semi-precious stone. Faience is a non-clay ceramic made of silica, small amounts of lime and soda, and a colorant, typically copper. The material was used to make beads, tiles, figurines, and small wares. Several methods can be used to create faience, but typically production involved application of the powdered materials in the form of a paste over a clay core, which was then fired. By a related technique, the ancient Egyptians produced a pigment known as Egyptian Blue, also called blue frit, which is produced by fusing (or sintering) silica, copper, lime, and an alkali such as natron. The product can be ground up and used as a pigment.

The ancient Egyptians could fabricate a wide variety of objects from glass with great skill, but it is not clear whether they developed the process independently. It is also unclear whether they made their own raw glass or merely imported pre-made ingots, which they melted and finished. However, they did have technical expertise in making objects, as well as adding trace elements to control the color of the finished glass. A range of colors could be produced, including yellow, red, green, blue, purple, and white, and the glass could be made either transparent or opaque.

The medical problems of the ancient Egyptians stemmed directly from their environment. Living and working close to the Nile brought hazards from malaria and debilitating schistosomiasis parasites, which caused liver and intestinal damage. Dangerous wildlife such as crocodiles and hippos were also a common threat. The lifelong labors of farming and building put stress on the spine and joints, and traumatic injuries from construction and warfare all took a significant toll on the body. The grit and sand from stone-ground flour abraded teeth, leaving them susceptible to abscesses (though caries were rare).

The diets of the wealthy were rich in sugars, which promoted periodontal disease. Despite the flattering physiques portrayed on tomb walls, the overweight mummies of many of the upper class show the effects of a life of overindulgence. Adult life expectancy was about 35 for men and 30 for women, but reaching adulthood was difficult as about one-third of the population died in infancy.

Ancient Egyptian physicians were renowned in the ancient Near East for their healing skills, and some, such as Imhotep, remained famous long after their deaths. Herodotus remarked that there was a high degree of specialization among Egyptian physicians, with some treating only the head or the stomach, while others were eye-doctors and dentists. Training of physicians took place at the "Per Ankh" or "House of Life" institution, most notably those headquartered in Per-Bastet during the New Kingdom and at Abydos and Saïs in the Late period. Medical papyri show empirical knowledge of anatomy, injuries, and practical treatments.

Wounds were treated by bandaging with raw meat, white linen, sutures, nets, pads, and swabs soaked with honey to prevent infection, while opium thyme and belladona were used to relieve pain. The earliest records of burn treatment describe burn dressings that use the milk from mothers of male babies. Prayers were made to the goddess Isis. Moldy bread, honey and copper salts were also used to prevent infection from dirt in burns. Garlic and onions were used regularly to promote good health and were thought to relieve asthma symptoms. Ancient Egyptian surgeons stitched wounds, set broken bones, and amputated diseased limbs, but they recognized that some injuries were so serious that they could only make the patient comfortable until death occurred.

Early Egyptians knew how to assemble planks of wood into a ship hull and had mastered advanced forms of shipbuilding as early as 3000 BC. The Archaeological Institute of America reports that the oldest planked ships known are the Abydos boats. A group of 14 discovered ships in Abydos were constructed of wooden planks "sewn" together. Discovered by Egyptologist David O'Connor of New York University, woven straps were found to have been used to lash the planks together, and reeds or grass stuffed between the planks helped to seal the seams. Because the ships are all buried together and near a mortuary belonging to Pharaoh Khasekhemwy, originally they were all thought to have belonged to him, but one of the 14 ships dates to 3000 BC, and the associated pottery jars buried with the vessels also suggest earlier dating. The ship dating to 3000 BC was long and is now thought to perhaps have belonged to an earlier pharaoh, perhaps one as early as Hor-Aha.

Early Egyptians also knew how to assemble planks of wood with treenails to fasten them together, using pitch for caulking the seams. The "Khufu ship", a vessel sealed into a pit in the Giza pyramid complex at the foot of the Great Pyramid of Giza in the Fourth Dynasty around 2500 BC, is a full-size surviving example that may have filled the symbolic function of a solar barque. Early Egyptians also knew how to fasten the planks of this ship together with mortise and tenon seagoing ships are known to have been heavily used by the Egyptians in their trade with the city states of the eastern Mediterranean, especially Byblos (on the coast of modern-day Lebanon), and in several expeditions down the Red Sea to the Land of Punt. In fact one of the earliest Egyptian words for a seagoing ship is a "Byblos Ship", which originally defined a class of Egyptian seagoing ships used on the Byblos run; however, by the end of the Old Kingdom, the term had come to include large seagoing ships, whatever their destination.

In 2011 archaeologists from Italy, the United States, and Egypt excavating a dried-up lagoon known as Mersa Gawasis have unearthed traces of an ancient harbor that once launched early voyages like Hatshepsut's Punt expedition onto the open ocean. Some of the site's most evocative evidence for the ancient Egyptians' seafaring prowess include large ship timbers and hundreds of feet of ropes, made from papyrus, coiled in huge bundles. And in 2013 a team of Franco-Egyptian archaeologists discovered what is believed to be the world's oldest port, dating back about 4500 years, from the time of King Cheops on the Red Sea coast near Wadi el-Jarf (about 110 miles south of Suez).

In 1977, an ancient north-south canal dating to the Middle Kingdom of Egypt was discovered extending from Lake Timsah to the Ballah Lakes. It was dated to the Middle Kingdom of Egypt

The earliest attested examples of mathematical calculations date to the predynastic Naqada period, and show a fully developed numeral system. The importance of mathematics to an educated Egyptian is suggested by a New Kingdom fictional letter in which the writer proposes a scholarly competition between himself and another scribe regarding everyday calculation tasks such as accounting of land, labor, and grain. Texts such as the Rhind Mathematical Papyrus and the Moscow Mathematical Papyrus show that the ancient Egyptians could perform the four basic mathematical operations—addition, subtraction, multiplication, and division—use fractions, compute the volumes of boxes and pyramids, and calculate the surface areas of rectangles, triangles, and circles. They understood basic concepts of algebra and geometry, and could solve simple sets of simultaneous equations.

Mathematical notation was decimal, and based on hieroglyphic signs for each power of ten up to one million. Each of these could be written as many times as necessary to add up to the desired number; so to write the number eighty or eight hundred, the symbol for ten or one hundred was written eight times respectively. Because their methods of calculation could not handle most fractions with a numerator greater than one, they had to write fractions as the sum of several fractions. For example, they resolved the fraction "two-fifths" into the sum of "one-third" + "one-fifteenth". Standard tables of values facilitated this. Some common fractions, however, were written with a special glyph—the equivalent of the modern two-thirds is shown on the right.

Ancient Egyptian mathematicians knew the Pythagorean theorem as an empirical formula. They were aware, for example, that a triangle had a right angle opposite the hypotenuse when its sides were in a 3–4–5 ratio. They were able to estimate the area of a circle by subtracting one-ninth from its diameter and squaring the result:

a reasonable approximation of the formula π"r".

The golden ratio seems to be reflected in many Egyptian constructions, including the pyramids, but its use may have been an unintended consequence of the ancient Egyptian practice of combining the use of knotted ropes with an intuitive sense of proportion and harmony.

Greek historian Herodotus claimed that ancient Egyptians looked like the people in Colchis (modern-day Georgia). This claim has been largely discredited as fictional by modern-day scholars.

A team led by Johannes Krause managed the first reliable sequencing of the genomes of 90 mummified individuals in 2017. Whilst not conclusive, because of the non-exhaustive time frame and restricted location that the mummies represent, their study nevertheless showed that these ancient Egyptians "closely resembled ancient and modern Near Eastern populations, especially those in the Levant, and had almost no DNA from sub-Saharan Africa. What's more, the genetics of the mummies remained remarkably consistent even as different powers—including Nubians, Greeks, and Romans—conquered the empire." Later, however, something did alter the genomes of Egyptians. Some 15% to 20% of modern Egyptians' DNA reflects sub-Saharan ancestry, but the ancient mummies had only 6–15% sub-Saharan DNA.

The culture and monuments of ancient Egypt have left a lasting legacy on the world. The cult of the goddess Isis, for example, became popular in the Roman Empire, as obelisks and other relics were transported back to Rome. The Romans also imported building materials from Egypt to erect Egyptian-style structures. Early historians such as Herodotus, Strabo, and Diodorus Siculus studied and wrote about the land, which Romans came to view as a place of mystery.

During the Middle Ages and the Renaissance, Egyptian pagan culture was in decline after the rise of Christianity and later Islam, but interest in Egyptian antiquity continued in the writings of medieval scholars such as Dhul-Nun al-Misri and al-Maqrizi. In the seventeenth and eighteenth centuries, European travelers and tourists brought back antiquities and wrote stories of their journeys, leading to a wave of Egyptomania across Europe. This renewed interest sent collectors to Egypt, who took, purchased, or were given many important antiquities.

Although the European colonial occupation of Egypt destroyed a significant portion of the country's historical legacy, some foreigners left more positive marks. Napoleon, for example, arranged the first studies in Egyptology when he brought some 150 scientists and artists to study and document Egypt's natural history, which was published in the "Description de l'Égypte".

In the 20th century, the Egyptian Government and archaeologists alike recognized the importance of cultural respect and integrity in excavations. The Supreme Council of Antiquities
Category:Former empires in AsiaAnalog Brothers

Analog Brothers were an experimental hip hop band featuring Tracy 'Ice Oscillator' Marrow (Body Count's Ice-T) on keyboards, drums and vocals, Keith 'Keith Korg' Thornton (Ultramagnetic MCs' Kool Keith) on bass, strings and vocals, Marc 'Mark Moog' Giveand (Raw Breed's Marc Live) on drums, violins and vocals, Christopher 'Silver Synth' Rodgers (Black Silver) on synthesizer, lazar bell and vocals, and Rex Colonel 'Rex Roland JX3P' Doby Jr. (Pimpin' Rex) on keyboards, vocals and production. Its album "Pimp to Eat" featured guest appearances by various members of Rhyme Syndicate, Odd Oberheim, Jacky Jasper (who appears as Jacky Jasper on the song "We Sleep Days" and H-Bomb on "War"), D.J. Cisco from S.M., Synth-A-Size Sisters and Teflon.

While the group only recorded one album together as the Analog Brothers, a few bootlegs of its live concert performances, including freestyles with original lyrics, have occasionally surfaced online. After "Pimp to Eat", the Analog Brothers continued performing together in various line ups. Kool Keith and Marc Live joined with Jacky Jasper to release two albums as KHM. Marc Live rapped with Ice T's group SMG. Marc also formed a group with Black Silver called Live Black, but while five of their tracks were released on a demo CD sold at concerts, Live Black's first album has yet to be released.

In 2008, Ice-T and Black Silver toured together as Black Ice, and released an album together called "Urban Legends".

In 2013 Black Silver and newest member to Analog Brothers, Kiew Kurzweil (Kiew Nikon of Kinetic) collaborated on the joint album called "Slang Banging (Return to Analog)" with production by Junkadelic Music. In addition to all this, the Analog Brothers continue to make frequent appearances on each other's solo albums.


Category:Ice-T
Category:American hip hop groupsMotor neuron disease

Motor neuron diseases (MNDs) are a group of neurodegenerative disorders that selectively affect motor neurons, the cells which control voluntary muscles of the body.

According to ICD-11, the following disorders are counted among motor neuron diseases: amyotrophic lateral sclerosis (ALS), progressive bulbar palsy (PBP), pseudobulbar palsy, progressive muscular atrophy (PMA), primary lateral sclerosis (PLS), and monomelic amyotrophy (MMA), as well as some rarer variants resembling ALS.

Motor neuron diseases affect both children and adults. While each motor neuron disease affects patients differently, they all cause movement-related symptoms, mainly muscle weakness. Most diseases seem to occur randomly without known causes, but some forms are inherited. Studies into these inherited forms have led to discoveries of various genes (e.g. "SOD1") that are thought be important in understanding how the disease occurs. 

Symptoms of motor neuron diseases can be first seen at birth or can come on slowly later in life. Most diseases worsen over time; while some diseases shortening one’s life expectancy (e.g. ALS), others do not.

Currently, there are no approved treatments for the majority of motor neuron disorders, and care is mostly symptomatic.

In the United States, the term "motor neuron disease" is often used to denote amyotrophic lateral sclerosis (Lou Gehrig's disease), the most common disorder in the group. In the United Kingdom, the term is spelled "motor neurone disease" and is frequently used for the entire group, but can also refer specifically to ALS.

While MND refers to a specific subset of similar diseases, there are numerous other diseases of motor neurons that are referred to collectively as "motor neuron disorders", for instance the diseases belonging to the spinal muscular atrophies group. However, they are not classified as "motor neuron diseases" by the 11th edition of the International Statistical Classification of Diseases and Related Health Problems
Motor neuron disease describes a collection of clinical disorders, characterized by progressive muscle weakness and the degeneration of the motor neuron on electrophysiological testing. As discussed above, the term "motor neuron disease" has varying meanings in different countries. Similarly, the literature inconsistently classifies which degenerative motor neuron disorders can be included under the umbrella term "motor neuron disease". The four main types of MND are marked (*) in the table below. 

All types of MND can be differentiated by two defining characteristics: 


Sporadic or acquired MNDs occur in patients with no family history of degenerative motor neuron disease. Inherited or genetic MNDs adhere to one of the following inheritance patterns: autosomal dominant, autosomal recessive, or X-linked
Signs and symptoms depend on the specific disease, but motor neuron diseases typically manifest as a group of movement-related symptoms. They come on slowly, and worsen over the course of more than three months. Various patterns of muscle weakness are seen, and muscle cramps and spasms may occur. One can have difficulty breathing with climbing stairs (exertion), difficulty breathing when lying down (orthopnea), or even respiratory failure if breathing muscles become involved. Bulbar symptoms, including difficulty speaking (dysarthria), difficulty swallowing (dysphagia), and excessive saliva production (sialorrhea), can also occur. Sensation, or the ability to feel, is typically not affected. Emotional disturbance (e.g. pseudobulbar affect) and cognitive and behavioral changes (e.g. problems in word fluency, decision-making, and memory) are also seen. There can be lower motor neuron findings (e.g. muscle wasting, muscle twitching), upper motor neuron findings (e.g. brisk reflexes, Babinski reflex, Hoffman's reflex, increased muscle tone), or both.

Motor neuron diseases are seen both in children and in adults. Those that affect children tend to be inherited or familial, and their symptoms are either present at birth or appear before learning to walk. Those that affect adults tend to appear after age 40. The clinical course depends on the specific disease, but most progress or worsen over the course of months. Some are fatal (e.g. ALS), while others are not (e.g. PLS).

Various patterns of muscle weakness occur in different motor neuron diseases. Weakness can be symmetric or asymmetric, and it can occur in body parts that are distal, proximal, or both. According to Statland et al., there are three main weakness patterns that are seen in motor neuron diseases, which are: 


Motor neuron diseases are on a spectrum in terms of upper and lower motor neuron involvement. Some have just lower or upper motor neuron findings, while others have a mix of both. Lower motor neuron (LMN) findings include muscle atrophy and fasciculations, and upper motor neuron (UMN) findings include hyperreflexia
Category:Systemic atrophies primarily affecting the central nervous system
Category:Rare diseasesAbjad

An abjad (pronounced or ) is a type of writing system where each symbol or glyph stands for a consonant, leaving the reader to supply the appropriate vowel. So-called impure abjads do represent vowels, either with optional diacritics, a limited number of distinct vowel glyphs, or both. The name "abjad" is based on the old Arabic alphabet's first four letters—a, b, j, d—to replace the common terms "consonantary" or "consonantal alphabet" to refer to the family of scripts called West Semitic.

The name "abjad" (' ) is derived from pronouncing the first letters of the "Arabic" alphabet in order. The ordering (') of Arabic letters used to match that of the older Hebrew, Phoenician and Semitic alphabets: "".

According to the formulations of Daniels, abjads differ from alphabets in that only consonants, not vowels, are represented among the basic graphemes. Abjads differ from abugidas, another category defined by Daniels, in that in abjads, the vowel sound is "implied" by phonology, and where vowel marks exist for the system, such as nikkud for Hebrew and ḥarakāt for Arabic, their use is optional and not the dominant (or literate) form. Abugidas mark the vowels (other than the "inherent" vowel) with a diacritic, a minor attachment to the letter, or a standalone glyph. Some abugidas use a special symbol to "suppress" the inherent vowel so that the consonant alone can be properly represented. In a syllabary

The first abjad to gain widespread usage was the Phoenician abjad. Unlike other contemporary scripts, such as cuneiform and Egyptian hieroglyphs, the Phoenician script consisted of only a few dozen symbols. This made the script easy to learn, and seafaring Phoenician merchants took the script throughout the then-known world.

The Phoenician abjad was a radical simplification of phonetic writing, since hieroglyphics required the writer to pick a hieroglyph starting with the same sound that the writer wanted to write in order to write phonetically, much as "man'yougana" (Chinese characters, or kanji, used solely for phonetic use) was used to represent Japanese phonetically before the invention of kana.

Phoenician gave rise to a number of new writing systems, including the Greek alphabet and Aramaic, a widely used abjad. The Greek alphabet evolved into the modern western alphabets, such as Latin and Cyrillic

Impure abjads have characters for some vowels, optional vowel diacritics, or both. The term pure abjad refers to scripts entirely lacking in vowel indicators. However, most modern abjads, such as Arabic, Hebrew, Aramaic, and Pahlavi, are "impure" abjadsthat is, they also contain symbols for some of the vowel phonemes, although the said non-diacritic vowel letters are also used to write certain consonants, particularly approximants that sound similar to long vowels. A "pure" abjad is exemplified (perhaps) by very early forms of ancient Phoenician, though at some point (at least by the 9th century BC) it and most of the contemporary Semitic abjads had begun to overload a few of the consonant symbols with a secondary function as vowel markers, called "matres lectionis". This practice was at first rare and limited in scope but became increasingly common and more developed in later times.

In the 9th century BC the Greeks adapted the Phoenician script for use in their own language. The phonetic structure of the Greek language created too many ambiguities when vowels went unrepresented, so the script was modified. They did not need letters for the guttural sounds represented by "aleph", "he", "heth" or "ayin", so these symbols were assigned vocalic values. The letters "waw" and "yod" were also adapted into vowel signs; along with "he", these were already used as "matres lectionis" in Phoenician. The major innovation of Greek was to dedicate these symbols exclusively and unambiguously to vowel sounds that could be combined arbitrarily with consonants (as opposed to syllabaries such as Linear B which usually have vowel symbols but cannot combine them with consonants to form arbitrary syllables).

Abugidas developed along a slightly different route. The basic consonantal symbol was considered to have an inherent "a" vowel sound. Hooks or short lines attached to various parts of the basic letter modify the vowel. In this way, the South Arabian alphabet evolved into the Ge'ez alphabet between the 5th century BC and the 5th century AD. Similarly, around the 3rd century BC, the Brāhmī script developed (from the Aramaic abjad, it has been hypothesized).

The other major family of abugidas, Canadian Aboriginal syllabics, was initially developed in the 1840s by missionary and linguist James Evans for the Cree and Ojibwe languages. Evans used features of Devanagari script and Pitman shorthand to create his initial abugida. Later in the 19th century, other missionaries adapted Evans' system to other Canadian aboriginal languages. Canadian syllabics differ from other abugidas in that the vowel is indicated by rotation of the consonantal symbol, with each vowel having a consistent orientation.

The abjad form of writing is well-adapted to the morphological structure of the Semitic languages it was developed to write. This is because words in Semitic languages are formed from a root consisting of (usually) three consonants, the vowels being used to indicate inflectional or derived forms. For instance, according to Classical Arabic and Modern Standard Arabic, from the Arabic root "Dh-B-Ḥ" (to slaughter) can be derived the forms ' (he slaughtered), ' (you (masculine singular) slaughtered), ' (he slaughters), and ' (slaughterhouse). In most cases, the absence of full glyphs for vowels makes the common root clearer, allowing readers to guess the meaning of unfamiliar words from familiar roots (especially in conjunction with context
Category:Arabic orthography